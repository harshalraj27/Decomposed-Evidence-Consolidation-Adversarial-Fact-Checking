Decomposer PEFT (Planned Extension)

This directory contains the data preparation and training pipeline for parameter-efficient fine-tuning (LoRA) of the claim decomposer module.

The goal of PEFT is to improve output stability, schema adherence, and determinism of structured claim decomposition, rather than raw decomposition quality.

Due to time and hardware constraints, full fine-tuning experiments were not done. The pipeline, dataset, and training configuration are provided to enable straightforward reproduction and extension.