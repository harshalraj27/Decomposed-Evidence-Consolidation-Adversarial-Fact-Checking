{
  "results": [
    {
      "claim": "Scaling laws indicate that increasing model size and data generally improves language model performance.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Scaling laws indicate that increasing model size improves language model performance.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.6005331421374969,
            "contradict": 2.989814397650803,
            "total": 3.5903475397883
          },
          "evidence": {
            "supporting": [
              {
                "id": 6300,
                "faiss_score": 0.8919124603271484,
                "faiss_rank": 18,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.019933873787522316,
                  "neutral": 0.28682276606559753,
                  "support": 0.6932433843612671
                },
                "stance_score": 0.6733095105737448,
                "evidence_contribution": 0.6005331421374969,
                "combined_rank_score": 0.8919124603271484
              }
            ],
            "contradicting": [
              {
                "id": 6414,
                "faiss_score": 0.8923674821853638,
                "faiss_rank": 17,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 153,
                "sentence": "Although larger models often support longer contexts, this approach scales poorly due to the quadratic cost of attention.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8851367235183716,
                  "neutral": 0.1074768453836441,
                  "support": 0.007386504206806421
                },
                "stance_score": -0.8777502193115652,
                "evidence_contribution": -0.7832757531947123,
                "combined_rank_score": 0.8923674821853638
              },
              {
                "id": 6153,
                "faiss_score": 0.8965537548065186,
                "faiss_rank": 11,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 29,
                "sentence": "Memory constraints become significant as models grow.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8544781804084778,
                  "neutral": 0.1416649967432022,
                  "support": 0.0038567606825381517
                },
                "stance_score": -0.8506214197259396,
                "evidence_contribution": -0.7626278277741427,
                "combined_rank_score": 0.8965537548065186
              },
              {
                "id": 6067,
                "faiss_score": 0.895867645740509,
                "faiss_rank": 12,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Large language models are also sensitive to the distribution of their training data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5488263964653015,
                  "neutral": 0.433756023645401,
                  "support": 0.01741757057607174
                },
                "stance_score": -0.5314088258892298,
                "evidence_contribution": -0.47607197377511234,
                "combined_rank_score": 0.895867645740509
              },
              {
                "id": 6121,
                "faiss_score": 0.8985731601715088,
                "faiss_rank": 9,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.45808807015419006,
                  "neutral": 0.5354201197624207,
                  "support": 0.006491828244179487
                },
                "stance_score": -0.4515962419100106,
                "evidence_contribution": -0.40579226221465536,
                "combined_rank_score": 0.8985731601715088
              },
              {
                "id": 1732,
                "faiss_score": 0.895524799823761,
                "faiss_rank": 13,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Before the emergence of transformer-based models in 2017, some language models were considered large relative to the computational and data constraints of their time.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.3592875897884369,
                  "neutral": 0.6360750198364258,
                  "support": 0.004637377802282572
                },
                "stance_score": -0.3546502119861543,
                "evidence_contribution": -0.3175980600963553,
                "combined_rank_score": 0.895524799823761
              },
              {
                "id": 6349,
                "faiss_score": 0.8930535316467285,
                "faiss_rank": 16,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 88,
                "sentence": "As models scale, training efficiency becomes a primary concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.28175315260887146,
                  "neutral": 0.7102158665657043,
                  "support": 0.00803101621568203
                },
                "stance_score": -0.27372213639318943,
                "evidence_contribution": -0.24444852059582534,
                "combined_rank_score": 0.8930535316467285
              }
            ],
            "neutral": [
              {
                "id": 6043,
                "faiss_score": 0.9340037107467651,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.011767260730266571,
                  "neutral": 0.8790037631988525,
                  "support": 0.10922899097204208
                },
                "stance_score": 0.09746173024177551,
                "evidence_contribution": 0.09102961770161855,
                "combined_rank_score": 0.9340037107467651
              },
              {
                "id": 6137,
                "faiss_score": 0.9238755106925964,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0034922210033982992,
                  "neutral": 0.992523729801178,
                  "support": 0.003984042908996344
                },
                "stance_score": 0.0004918219055980444,
                "evidence_contribution": 0.0004543822142041992,
                "combined_rank_score": 0.9238755106925964
              },
              {
                "id": 1796,
                "faiss_score": 0.9200311303138733,
                "faiss_rank": 3,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 64,
                "sentence": "The tendency towards larger models is visible in the list of large language models.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.012851376086473465,
                  "neutral": 0.9017986059188843,
                  "support": 0.08534999936819077
                },
                "stance_score": 0.0724986232817173,
                "evidence_contribution": 0.06670099032407806,
                "combined_rank_score": 0.9200311303138733
              }
            ]
          }
        },
        {
          "subclaim": "Scaling laws indicate that increasing data generally improves language model performance.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 0.6170988566037829,
            "total": 0.6170988566037829
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6157,
                "faiss_score": 0.882860541343689,
                "faiss_rank": 16,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 33,
                "sentence": "Inference efficiency is another scaling concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.43823960423469543,
                  "neutral": 0.5488245487213135,
                  "support": 0.012935844250023365
                },
                "stance_score": -0.42530375998467207,
                "evidence_contribution": -0.37548390777557394,
                "combined_rank_score": 0.882860541343689
              },
              {
                "id": 1789,
                "faiss_score": 0.8820173740386963,
                "faiss_rank": 19,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 57,
                "sentence": "Training of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.16672907769680023,
                  "neutral": 0.8279722929000854,
                  "support": 0.005298572592437267
                },
                "stance_score": -0.16143050510436296,
                "evidence_contribution": -0.14238451020189058,
                "combined_rank_score": 0.8820173740386963
              },
              {
                "id": 6121,
                "faiss_score": 0.8885934352874756,
                "faiss_rank": 13,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.11388173699378967,
                  "neutral": 0.8839079141616821,
                  "support": 0.0022103756200522184
                },
                "stance_score": -0.11167136137373745,
                "evidence_contribution": -0.09923043862631847,
                "combined_rank_score": 0.8885934352874756
              }
            ],
            "neutral": [
              {
                "id": 6043,
                "faiss_score": 0.9192824363708496,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.012720853090286255,
                  "neutral": 0.9637423157691956,
                  "support": 0.02353684790432453
                },
                "stance_score": 0.010815994814038277,
                "evidence_contribution": 0.009942954064423581,
                "combined_rank_score": 0.9192824363708496
              },
              {
                "id": 6127,
                "faiss_score": 0.9171009063720703,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004043751861900091,
                  "neutral": 0.9890744090080261,
                  "support": 0.006881888955831528
                },
                "stance_score": 0.0028381370939314365,
                "evidence_contribution": 0.002602858101252714,
                "combined_rank_score": 0.9171009063720703
              },
              {
                "id": 6137,
                "faiss_score": 0.9136135578155518,
                "faiss_rank": 3,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00184905668720603,
                  "neutral": 0.9949593544006348,
                  "support": 0.003191573079675436
                },
                "stance_score": 0.0013425163924694061,
                "evidence_contribution": 0.0012265411777496737,
                "combined_rank_score": 0.9136135578155518
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Scaling laws indicate that increasing model size improves language model performance.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6300,
                      "faiss_score": 0.8919124603271484,
                      "faiss_rank": 18,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.019933873787522316,
                        "neutral": 0.28682276606559753,
                        "support": 0.6932433843612671
                      },
                      "stance_score": 0.6733095105737448,
                      "evidence_contribution": 0.6005331421374969,
                      "combined_rank_score": 0.8919124603271484
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6121,
                      "faiss_score": 0.8985731601715088,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.45808807015419006,
                        "neutral": 0.5354201197624207,
                        "support": 0.006491828244179487
                      },
                      "stance_score": -0.4515962419100106,
                      "evidence_contribution": -0.40579226221465536,
                      "combined_rank_score": 0.8985731601715088
                    },
                    {
                      "id": 6153,
                      "faiss_score": 0.8965537548065186,
                      "faiss_rank": 11,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 29,
                      "sentence": "Memory constraints become significant as models grow.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.8544781804084778,
                        "neutral": 0.1416649967432022,
                        "support": 0.0038567606825381517
                      },
                      "stance_score": -0.8506214197259396,
                      "evidence_contribution": -0.7626278277741427,
                      "combined_rank_score": 0.8965537548065186
                    },
                    {
                      "id": 6067,
                      "faiss_score": 0.895867645740509,
                      "faiss_rank": 12,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "Large language models are also sensitive to the distribution of their training data.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.5488263964653015,
                        "neutral": 0.433756023645401,
                        "support": 0.01741757057607174
                      },
                      "stance_score": -0.5314088258892298,
                      "evidence_contribution": -0.47607197377511234,
                      "combined_rank_score": 0.895867645740509
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6043,
                      "faiss_score": 0.9340037107467651,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.011767260730266571,
                        "neutral": 0.8790037631988525,
                        "support": 0.10922899097204208
                      },
                      "stance_score": 0.09746173024177551,
                      "evidence_contribution": 0.09102961770161855,
                      "combined_rank_score": 0.9340037107467651
                    },
                    {
                      "id": 6137,
                      "faiss_score": 0.9238755106925964,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0034922210033982992,
                        "neutral": 0.992523729801178,
                        "support": 0.003984042908996344
                      },
                      "stance_score": 0.0004918219055980444,
                      "evidence_contribution": 0.0004543822142041992,
                      "combined_rank_score": 0.9238755106925964
                    },
                    {
                      "id": 1796,
                      "faiss_score": 0.9200311303138733,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 64,
                      "sentence": "The tendency towards larger models is visible in the list of large language models.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.012851376086473465,
                        "neutral": 0.9017986059188843,
                        "support": 0.08534999936819077
                      },
                      "stance_score": 0.0724986232817173,
                      "evidence_contribution": 0.06670099032407806,
                      "combined_rank_score": 0.9200311303138733
                    }
                  ]
                }
              },
              {
                "subclaim": "Scaling laws indicate that increasing data generally improves language model performance.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6121,
                      "faiss_score": 0.8885934352874756,
                      "faiss_rank": 13,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.11388173699378967,
                        "neutral": 0.8839079141616821,
                        "support": 0.0022103756200522184
                      },
                      "stance_score": -0.11167136137373745,
                      "evidence_contribution": -0.09923043862631847,
                      "combined_rank_score": 0.8885934352874756
                    },
                    {
                      "id": 6157,
                      "faiss_score": 0.882860541343689,
                      "faiss_rank": 16,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 33,
                      "sentence": "Inference efficiency is another scaling concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.43823960423469543,
                        "neutral": 0.5488245487213135,
                        "support": 0.012935844250023365
                      },
                      "stance_score": -0.42530375998467207,
                      "evidence_contribution": -0.37548390777557394,
                      "combined_rank_score": 0.882860541343689
                    },
                    {
                      "id": 1789,
                      "faiss_score": 0.8820173740386963,
                      "faiss_rank": 19,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 57,
                      "sentence": "Training of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.16672907769680023,
                        "neutral": 0.8279722929000854,
                        "support": 0.005298572592437267
                      },
                      "stance_score": -0.16143050510436296,
                      "evidence_contribution": -0.14238451020189058,
                      "combined_rank_score": 0.8820173740386963
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6043,
                      "faiss_score": 0.9192824363708496,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.012720853090286255,
                        "neutral": 0.9637423157691956,
                        "support": 0.02353684790432453
                      },
                      "stance_score": 0.010815994814038277,
                      "evidence_contribution": 0.009942954064423581,
                      "combined_rank_score": 0.9192824363708496
                    },
                    {
                      "id": 6127,
                      "faiss_score": 0.9171009063720703,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004043751861900091,
                        "neutral": 0.9890744090080261,
                        "support": 0.006881888955831528
                      },
                      "stance_score": 0.0028381370939314365,
                      "evidence_contribution": 0.002602858101252714,
                      "combined_rank_score": 0.9171009063720703
                    },
                    {
                      "id": 6137,
                      "faiss_score": 0.9136135578155518,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.00184905668720603,
                        "neutral": 0.9949593544006348,
                        "support": 0.003191573079675436
                      },
                      "stance_score": 0.0013425163924694061,
                      "evidence_contribution": 0.0012265411777496737,
                      "combined_rank_score": 0.9136135578155518
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Transformer architectures enabled significant improvements in natural language processing tasks.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Transformer architectures were used in natural language processing tasks.",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 2.990425269826994,
            "contradict": 3.4995724150356855,
            "total": 6.489997684862679
          },
          "evidence": {
            "supporting": [
              {
                "id": 6296,
                "faiss_score": 0.9599642753601074,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 35,
                "sentence": "The transformer architecture proved highly effective across a wide range of natural language processing tasks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0064346035942435265,
                  "neutral": 0.011724923737347126,
                  "support": 0.9818404316902161
                },
                "stance_score": 0.9754058280959725,
                "evidence_contribution": 0.9363547489501758,
                "combined_rank_score": 0.9599642753601074
              },
              {
                "id": 2184,
                "faiss_score": 0.9435071349143982,
                "faiss_rank": 2,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 115,
                "sentence": "Transformers have increasingly become the model of choice for natural language processing.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.001396269304677844,
                  "neutral": 0.01836763694882393,
                  "support": 0.9802360534667969
                },
                "stance_score": 0.978839784162119,
                "evidence_contribution": 0.9235423202950288,
                "combined_rank_score": 0.9435071349143982
              },
              {
                "id": 6298,
                "faiss_score": 0.9177358150482178,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "Models based on transformers achieved state-of-the-art performance in translation, summarization, language modeling, and many other tasks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005247808527201414,
                  "neutral": 0.10412941128015518,
                  "support": 0.8906227946281433
                },
                "stance_score": 0.8853749861009419,
                "evidence_contribution": 0.8125403344926524,
                "combined_rank_score": 0.9177358150482178
              },
              {
                "id": 3003,
                "faiss_score": 0.8870973587036133,
                "faiss_rank": 17,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 58,
                "sentence": "Tasks for pretraining and fine-tuning commonly include: language modeling next-sentence prediction question answering reading comprehension sentiment analysis paraphrasing The T5 transformer report documents a large number of natural language pretraining tasks.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.013680233620107174,
                  "neutral": 0.745046854019165,
                  "support": 0.24127286672592163
                },
                "stance_score": 0.22759263310581446,
                "evidence_contribution": 0.20189682368856854,
                "combined_rank_score": 0.8870973587036133
              },
              {
                "id": 3025,
                "faiss_score": 0.8943243622779846,
                "faiss_rank": 11,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 80,
                "sentence": "Transformer layers, which carry out repeated transformations on the vector representations, extracting more and more linguistic information.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.003647217759862542,
                  "neutral": 0.8628968596458435,
                  "support": 0.13345587253570557
                },
                "stance_score": 0.12980865477584302,
                "evidence_contribution": 0.11609104240056888,
                "combined_rank_score": 0.8943243622779846
              }
            ],
            "contradicting": [
              {
                "id": 2658,
                "faiss_score": 0.8916580677032471,
                "faiss_rank": 14,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 253,
                "sentence": "Neural networks have been used for implementing language models since the early 2000s.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.9757393598556519,
                  "neutral": 0.01614757440984249,
                  "support": 0.008112985640764236
                },
                "stance_score": -0.9676263742148876,
                "evidence_contribution": -0.8627918630911457,
                "combined_rank_score": 0.8916580677032471
              },
              {
                "id": 2665,
                "faiss_score": 0.8936270475387573,
                "faiss_rank": 12,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 260,
                "sentence": "Deep neural architectures provide the best results for constituency parsing, sentiment analysis, information retrieval, spoken language understanding, machine translation, contextual entity linking, writing style recognition, named-entity recognition (token classification), text classification, and others.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.9675283432006836,
                  "neutral": 0.030168380588293076,
                  "support": 0.002303250366821885
                },
                "stance_score": -0.9652250928338617,
                "evidence_contribution": -0.8625512499194468,
                "combined_rank_score": 0.8936270475387573
              },
              {
                "id": 1740,
                "faiss_score": 0.9042257070541382,
                "faiss_rank": 6,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 8,
                "sentence": "These early NMT systems used LSTM-based encoder-decoder architectures, as they preceded the invention of transformers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.7221269011497498,
                  "neutral": 0.18067628145217896,
                  "support": 0.09719686955213547
                },
                "stance_score": -0.6249300315976143,
                "evidence_contribution": -0.5650777996807177,
                "combined_rank_score": 0.9042257070541382
              },
              {
                "id": 6261,
                "faiss_score": 0.9068849682807922,
                "faiss_rank": 5,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Transformer-based neural network architectures emerged from a broader effort to overcome structural limitations present in earlier approaches to sequence modeling.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6116482615470886,
                  "neutral": 0.38283827900886536,
                  "support": 0.005513511132448912
                },
                "stance_score": -0.6061347504146397,
                "evidence_contribution": -0.5496944939036664,
                "combined_rank_score": 0.9068849682807922
              },
              {
                "id": 2987,
                "faiss_score": 0.8978081941604614,
                "faiss_rank": 8,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Transformer architecture is now used alongside many generative models that contribute to the ongoing AI boom.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.31608426570892334,
                  "neutral": 0.6735674142837524,
                  "support": 0.010348307900130749
                },
                "stance_score": -0.3057359578087926,
                "evidence_contribution": -0.2744922481702311,
                "combined_rank_score": 0.8978081941604614
              },
              {
                "id": 6333,
                "faiss_score": 0.8867658376693726,
                "faiss_rank": 18,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 72,
                "sentence": "The influence of transformer architectures is closely tied to their role in large-scale pretraining paradigms.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3140806257724762,
                  "neutral": 0.6732344031333923,
                  "support": 0.01268493290990591
                },
                "stance_score": -0.3013956928625703,
                "evidence_contribution": -0.26726740405121807,
                "combined_rank_score": 0.8867658376693726
              },
              {
                "id": 1807,
                "faiss_score": 0.9014351963996887,
                "faiss_rank": 7,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 75,
                "sentence": "LLMs are generally based on the transformer architecture, which leverages an attention mechanism that enables the model to process relationships between all elements in a sequence simultaneously, regardless of their distance from each other.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.1701473444700241,
                  "neutral": 0.7902719378471375,
                  "support": 0.03958071395754814
                },
                "stance_score": -0.13056663051247597,
                "evidence_contribution": -0.11769735621925936,
                "combined_rank_score": 0.9014351963996887
              }
            ],
            "neutral": [
              {
                "id": 6041,
                "faiss_score": 0.9166396856307983,
                "faiss_rank": 4,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "They are typically built using transformer architectures and trained using objectives that encourage prediction of the next token given a preceding context.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.008717341348528862,
                  "neutral": 0.9790101051330566,
                  "support": 0.012272553518414497
                },
                "stance_score": 0.0035552121698856354,
                "evidence_contribution": 0.0032588485657547572,
                "combined_rank_score": 0.9166396856307983
              },
              {
                "id": 2859,
                "faiss_score": 0.8975746631622314,
                "faiss_rank": 9,
                "doc_id": "wiki_Representation_learning",
                "file_type": ".txt",
                "position": 96,
                "sentence": "More recent transformer-based representation learning approaches attempt to solve this with word prediction tasks.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Feature_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.3169228732585907,
                  "neutral": 0.3083297908306122,
                  "support": 0.3747473359107971
                },
                "stance_score": 0.05782446265220642,
                "evidence_contribution": 0.05190177258759121,
                "combined_rank_score": 0.8975746631622314
              },
              {
                "id": 3083,
                "faiss_score": 0.8949947357177734,
                "faiss_rank": 10,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 138,
                "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.06788498163223267,
                  "neutral": 0.9225779175758362,
                  "support": 0.009537145495414734
                },
                "stance_score": -0.05834783613681793,
                "evidence_contribution": -0.052221006182975316,
                "combined_rank_score": 0.8949947357177734
              }
            ]
          }
        },
        {
          "subclaim": "These tasks saw significant improvements.",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 4.481031931768806,
            "contradict": 0.5095594670319483,
            "total": 4.990591398800754
          },
          "evidence": {
            "supporting": [
              {
                "id": 6044,
                "faiss_score": 0.8646043539047241,
                "faiss_rank": 14,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.000817636027932167,
                  "neutral": 0.1027408242225647,
                  "support": 0.8964415788650513
                },
                "stance_score": 0.8956239428371191,
                "evidence_contribution": 0.7743603604382889,
                "combined_rank_score": 0.8646043539047241
              },
              {
                "id": 5586,
                "faiss_score": 0.868844747543335,
                "faiss_rank": 11,
                "doc_id": "local_bio_gene_editing.txt",
                "file_type": ".txt",
                "position": 59,
                "sentence": "Improvements in precision, delivery, and control have expanded the range of possible applications.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\bio_gene_editing.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0007949198479764163,
                  "neutral": 0.13771769404411316,
                  "support": 0.8614874482154846
                },
                "stance_score": 0.8606925283675082,
                "evidence_contribution": 0.7478081825219023,
                "combined_rank_score": 0.868844747543335
              },
              {
                "id": 6300,
                "faiss_score": 0.8569948077201843,
                "faiss_rank": 20,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001147437491454184,
                  "neutral": 0.2226954698562622,
                  "support": 0.7761570811271667
                },
                "stance_score": 0.7750096436357126,
                "evidence_contribution": 0.6641792405288761,
                "combined_rank_score": 0.8569948077201843
              },
              {
                "id": 1922,
                "faiss_score": 0.8627696633338928,
                "faiss_rank": 16,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 190,
                "sentence": "They were originally used as a code completion tool, but advances have moved them towards automatic programming.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.0032875381875783205,
                  "neutral": 0.38289448618888855,
                  "support": 0.6138179898262024
                },
                "stance_score": 0.6105304516386241,
                "evidence_contribution": 0.5267471522153452,
                "combined_rank_score": 0.8627696633338928
              },
              {
                "id": 2539,
                "faiss_score": 0.8740763068199158,
                "faiss_rank": 4,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 134,
                "sentence": "They reported up to 70 times faster training.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.001099024317227304,
                  "neutral": 0.39966028928756714,
                  "support": 0.5992406606674194
                },
                "stance_score": 0.5981416363501921,
                "evidence_contribution": 0.522821432456197,
                "combined_rank_score": 0.8740763068199158
              },
              {
                "id": 6046,
                "faiss_score": 0.8739926815032959,
                "faiss_rank": 5,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 6,
                "sentence": "These include improved generalization, better handling of rare or ambiguous inputs, and the ability to adapt to new tasks with minimal additional data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0016440394101664424,
                  "neutral": 0.4812794029712677,
                  "support": 0.5170766115188599
                },
                "stance_score": 0.5154325721086934,
                "evidence_contribution": 0.4504842958314179,
                "combined_rank_score": 0.8739926815032959
              },
              {
                "id": 5589,
                "faiss_score": 0.8712761402130127,
                "faiss_rank": 6,
                "doc_id": "local_bio_gene_editing.txt",
                "file_type": ".txt",
                "position": 62,
                "sentence": "Small improvements in efficiency or specificity can have meaningful impacts when translated into clinical or agricultural settings.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\bio_gene_editing.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.028195634484291077,
                  "neutral": 0.5434474945068359,
                  "support": 0.4283568263053894
                },
                "stance_score": 0.4001611918210983,
                "evidence_contribution": 0.34865089867292554,
                "combined_rank_score": 0.8712761402130127
              },
              {
                "id": 6399,
                "faiss_score": 0.8873401880264282,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 138,
                "sentence": "Improvements in efficiency, training stability, and integration with other components are expected to yield practical gains.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0021322567481547594,
                  "neutral": 0.6527662873268127,
                  "support": 0.3451014459133148
                },
                "stance_score": 0.34296918916516006,
                "evidence_contribution": 0.3043303448010848,
                "combined_rank_score": 0.8873401880264282
              },
              {
                "id": 6672,
                "faiss_score": 0.8690682053565979,
                "faiss_rank": 10,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Faster execution reduces waiting time and allows more work to be completed.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009852963266894221,
                  "neutral": 0.8350387215614319,
                  "support": 0.16397598385810852
                },
                "stance_score": 0.1629906875314191,
                "evidence_contribution": 0.1416500243027684,
                "combined_rank_score": 0.8690682053565979
              }
            ],
            "contradicting": [
              {
                "id": 5969,
                "faiss_score": 0.8760039806365967,
                "faiss_rank": 3,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 64,
                "sentence": "Improvements in one area may expose constraints elsewhere.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3850768208503723,
                  "neutral": 0.5729495286941528,
                  "support": 0.04197365790605545
                },
                "stance_score": -0.34310316294431686,
                "evidence_contribution": -0.3005597365082284,
                "combined_rank_score": 0.8760039806365967
              },
              {
                "id": 6728,
                "faiss_score": 0.8701443076133728,
                "faiss_rank": 7,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 60,
                "sentence": "Assertions that a system improves both metrics simultaneously should be examined carefully, as such improvements usually depend on changing assumptions or workloads.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.2782565951347351,
                  "neutral": 0.683676540851593,
                  "support": 0.03806686028838158
                },
                "stance_score": -0.24018973484635353,
                "evidence_contribution": -0.2089997305237199,
                "combined_rank_score": 0.8701443076133728
              }
            ],
            "neutral": [
              {
                "id": 6311,
                "faiss_score": 0.8821069002151489,
                "faiss_rank": 2,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 50,
                "sentence": "Researchers have responded by exploring more efficient training regimes and architectural simplifications.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001056373119354248,
                  "neutral": 0.9978013634681702,
                  "support": 0.0011422268580645323
                },
                "stance_score": 8.585373871028423e-05,
                "evidence_contribution": 7.573217532561016e-05,
                "combined_rank_score": 0.8821069002151489
              },
              {
                "id": 1878,
                "faiss_score": 0.8694884777069092,
                "faiss_rank": 8,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 146,
                "sentence": "Later methods overcame this deficiency more systematically by breaking tasks into smaller steps for the LLM, either manually or automatically.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.0005965353338979185,
                  "neutral": 0.9968108534812927,
                  "support": 0.0025926055386662483
                },
                "stance_score": 0.00199607020476833,
                "evidence_contribution": 0.0017355600437401336,
                "combined_rank_score": 0.8694884777069092
              },
              {
                "id": 6174,
                "faiss_score": 0.8693499565124512,
                "faiss_rank": 9,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 50,
                "sentence": "Approaches include better architectures, improved training objectives, and more effective optimization methods.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0011292590061202645,
                  "neutral": 0.9922588467597961,
                  "support": 0.006611923687160015
                },
                "stance_score": 0.005482664681039751,
                "evidence_contribution": 0.004766354302034259,
                "combined_rank_score": 0.8693499565124512
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "These tasks saw significant improvements.",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6399,
                      "faiss_score": 0.8873401880264282,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 138,
                      "sentence": "Improvements in efficiency, training stability, and integration with other components are expected to yield practical gains.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0021322567481547594,
                        "neutral": 0.6527662873268127,
                        "support": 0.3451014459133148
                      },
                      "stance_score": 0.34296918916516006,
                      "evidence_contribution": 0.3043303448010848,
                      "combined_rank_score": 0.8873401880264282
                    },
                    {
                      "id": 2539,
                      "faiss_score": 0.8740763068199158,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 134,
                      "sentence": "They reported up to 70 times faster training.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.001099024317227304,
                        "neutral": 0.39966028928756714,
                        "support": 0.5992406606674194
                      },
                      "stance_score": 0.5981416363501921,
                      "evidence_contribution": 0.522821432456197,
                      "combined_rank_score": 0.8740763068199158
                    },
                    {
                      "id": 6046,
                      "faiss_score": 0.8739926815032959,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 6,
                      "sentence": "These include improved generalization, better handling of rare or ambiguous inputs, and the ability to adapt to new tasks with minimal additional data.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0016440394101664424,
                        "neutral": 0.4812794029712677,
                        "support": 0.5170766115188599
                      },
                      "stance_score": 0.5154325721086934,
                      "evidence_contribution": 0.4504842958314179,
                      "combined_rank_score": 0.8739926815032959
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5969,
                      "faiss_score": 0.8760039806365967,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 64,
                      "sentence": "Improvements in one area may expose constraints elsewhere.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.3850768208503723,
                        "neutral": 0.5729495286941528,
                        "support": 0.04197365790605545
                      },
                      "stance_score": -0.34310316294431686,
                      "evidence_contribution": -0.3005597365082284,
                      "combined_rank_score": 0.8760039806365967
                    },
                    {
                      "id": 6728,
                      "faiss_score": 0.8701443076133728,
                      "faiss_rank": 7,
                      "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                      "file_type": ".txt",
                      "position": 60,
                      "sentence": "Assertions that a system improves both metrics simultaneously should be examined carefully, as such improvements usually depend on changing assumptions or workloads.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.2782565951347351,
                        "neutral": 0.683676540851593,
                        "support": 0.03806686028838158
                      },
                      "stance_score": -0.24018973484635353,
                      "evidence_contribution": -0.2089997305237199,
                      "combined_rank_score": 0.8701443076133728
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6311,
                      "faiss_score": 0.8821069002151489,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 50,
                      "sentence": "Researchers have responded by exploring more efficient training regimes and architectural simplifications.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001056373119354248,
                        "neutral": 0.9978013634681702,
                        "support": 0.0011422268580645323
                      },
                      "stance_score": 8.585373871028423e-05,
                      "evidence_contribution": 7.573217532561016e-05,
                      "combined_rank_score": 0.8821069002151489
                    },
                    {
                      "id": 1878,
                      "faiss_score": 0.8694884777069092,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 146,
                      "sentence": "Later methods overcame this deficiency more systematically by breaking tasks into smaller steps for the LLM, either manually or automatically.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.0005965353338979185,
                        "neutral": 0.9968108534812927,
                        "support": 0.0025926055386662483
                      },
                      "stance_score": 0.00199607020476833,
                      "evidence_contribution": 0.0017355600437401336,
                      "combined_rank_score": 0.8694884777069092
                    },
                    {
                      "id": 6174,
                      "faiss_score": 0.8693499565124512,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 50,
                      "sentence": "Approaches include better architectures, improved training objectives, and more effective optimization methods.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0011292590061202645,
                        "neutral": 0.9922588467597961,
                        "support": 0.006611923687160015
                      },
                      "stance_score": 0.005482664681039751,
                      "evidence_contribution": 0.004766354302034259,
                      "combined_rank_score": 0.8693499565124512
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Transformer architectures were used in natural language processing tasks.",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6296,
                      "faiss_score": 0.9599642753601074,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 35,
                      "sentence": "The transformer architecture proved highly effective across a wide range of natural language processing tasks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0064346035942435265,
                        "neutral": 0.011724923737347126,
                        "support": 0.9818404316902161
                      },
                      "stance_score": 0.9754058280959725,
                      "evidence_contribution": 0.9363547489501758,
                      "combined_rank_score": 0.9599642753601074
                    },
                    {
                      "id": 2184,
                      "faiss_score": 0.9435071349143982,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 115,
                      "sentence": "Transformers have increasingly become the model of choice for natural language processing.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.001396269304677844,
                        "neutral": 0.01836763694882393,
                        "support": 0.9802360534667969
                      },
                      "stance_score": 0.978839784162119,
                      "evidence_contribution": 0.9235423202950288,
                      "combined_rank_score": 0.9435071349143982
                    },
                    {
                      "id": 6298,
                      "faiss_score": 0.9177358150482178,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 37,
                      "sentence": "Models based on transformers achieved state-of-the-art performance in translation, summarization, language modeling, and many other tasks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005247808527201414,
                        "neutral": 0.10412941128015518,
                        "support": 0.8906227946281433
                      },
                      "stance_score": 0.8853749861009419,
                      "evidence_contribution": 0.8125403344926524,
                      "combined_rank_score": 0.9177358150482178
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6261,
                      "faiss_score": 0.9068849682807922,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Transformer-based neural network architectures emerged from a broader effort to overcome structural limitations present in earlier approaches to sequence modeling.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.6116482615470886,
                        "neutral": 0.38283827900886536,
                        "support": 0.005513511132448912
                      },
                      "stance_score": -0.6061347504146397,
                      "evidence_contribution": -0.5496944939036664,
                      "combined_rank_score": 0.9068849682807922
                    },
                    {
                      "id": 1740,
                      "faiss_score": 0.9042257070541382,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "These early NMT systems used LSTM-based encoder-decoder architectures, as they preceded the invention of transformers.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.7221269011497498,
                        "neutral": 0.18067628145217896,
                        "support": 0.09719686955213547
                      },
                      "stance_score": -0.6249300315976143,
                      "evidence_contribution": -0.5650777996807177,
                      "combined_rank_score": 0.9042257070541382
                    },
                    {
                      "id": 1807,
                      "faiss_score": 0.9014351963996887,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "LLMs are generally based on the transformer architecture, which leverages an attention mechanism that enables the model to process relationships between all elements in a sequence simultaneously, regardless of their distance from each other.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.1701473444700241,
                        "neutral": 0.7902719378471375,
                        "support": 0.03958071395754814
                      },
                      "stance_score": -0.13056663051247597,
                      "evidence_contribution": -0.11769735621925936,
                      "combined_rank_score": 0.9014351963996887
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6041,
                      "faiss_score": 0.9166396856307983,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 1,
                      "sentence": "They are typically built using transformer architectures and trained using objectives that encourage prediction of the next token given a preceding context.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.008717341348528862,
                        "neutral": 0.9790101051330566,
                        "support": 0.012272553518414497
                      },
                      "stance_score": 0.0035552121698856354,
                      "evidence_contribution": 0.0032588485657547572,
                      "combined_rank_score": 0.9166396856307983
                    },
                    {
                      "id": 2859,
                      "faiss_score": 0.8975746631622314,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Representation_learning",
                      "file_type": ".txt",
                      "position": 96,
                      "sentence": "More recent transformer-based representation learning approaches attempt to solve this with word prediction tasks.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Feature_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.3169228732585907,
                        "neutral": 0.3083297908306122,
                        "support": 0.3747473359107971
                      },
                      "stance_score": 0.05782446265220642,
                      "evidence_contribution": 0.05190177258759121,
                      "combined_rank_score": 0.8975746631622314
                    },
                    {
                      "id": 3083,
                      "faiss_score": 0.8949947357177734,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 138,
                      "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "probs": {
                        "contradict": 0.06788498163223267,
                        "neutral": 0.9225779175758362,
                        "support": 0.009537145495414734
                      },
                      "stance_score": -0.05834783613681793,
                      "evidence_contribution": -0.052221006182975316,
                      "combined_rank_score": 0.8949947357177734
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Fault tolerance is a fundamental requirement for reliable distributed systems.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Fault tolerance is a fundamental requirement for reliable distributed systems.",
          "verdict": "SUPPORT",
          "controversial": true,
          "strengths": {
            "support": 1.8213664748306528,
            "contradict": 0.9612288004884137,
            "total": 2.782595275319067
          },
          "evidence": {
            "supporting": [
              {
                "id": 3787,
                "faiss_score": 0.8948857188224792,
                "faiss_rank": 19,
                "doc_id": "wiki_Byzantine_fault",
                "file_type": ".txt",
                "position": 77,
                "sentence": "Byzantine fault tolerance is a crucial concept in blockchain technology, ensuring that a network can continue to function even when some nodes (participants) fail or act maliciously.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Byzantine_fault",
                "primary_category": "all accuracy disputes",
                "probs": {
                  "contradict": 0.0018933520186692476,
                  "neutral": 0.19599293172359467,
                  "support": 0.8021137118339539
                },
                "stance_score": 0.8002203598152846,
                "evidence_contribution": 0.7161057719096839,
                "combined_rank_score": 0.8948857188224792
              },
              {
                "id": 430,
                "faiss_score": 0.9227766394615173,
                "faiss_rank": 2,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 6,
                "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.0015678618801757693,
                  "neutral": 0.3799082636833191,
                  "support": 0.618523895740509
                },
                "stance_score": 0.6169560338603333,
                "evidence_contribution": 0.5693126156211444,
                "combined_rank_score": 0.9227766394615173
              },
              {
                "id": 3508,
                "faiss_score": 0.9106696844100952,
                "faiss_rank": 13,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 79,
                "sentence": "The basic characteristics of fault tolerance require: No single point of failure \u2013 If a system experiences a failure, it must continue to operate without interruption during the repair process.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0023842875380069017,
                  "neutral": 0.8007035255432129,
                  "support": 0.19691221415996552
                },
                "stance_score": 0.1945279266219586,
                "evidence_contribution": 0.1771506855457692,
                "combined_rank_score": 0.9106696844100952
              },
              {
                "id": 6610,
                "faiss_score": 0.9200949668884277,
                "faiss_rank": 9,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Redundancy is a fundamental technique for achieving fault tolerance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004990473855286837,
                  "neutral": 0.8381791710853577,
                  "support": 0.1568303257226944
                },
                "stance_score": 0.15183985186740756,
                "evidence_contribution": 0.13970708347628613,
                "combined_rank_score": 0.9200949668884277
              },
              {
                "id": 6597,
                "faiss_score": 0.9170854091644287,
                "faiss_rank": 10,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Fault tolerance and reliability describe a system\u2019s ability to continue operating correctly in the presence of failures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002577927429229021,
                  "neutral": 0.8689212799072266,
                  "support": 0.1285007894039154
                },
                "stance_score": 0.12592286197468638,
                "evidence_contribution": 0.11548201939721114,
                "combined_rank_score": 0.9170854091644287
              },
              {
                "id": 5605,
                "faiss_score": 0.9225550889968872,
                "faiss_rank": 5,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Failures are another fundamental aspect of distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04997483640909195,
                  "neutral": 0.7877445220947266,
                  "support": 0.16228064894676208
                },
                "stance_score": 0.11230581253767014,
                "evidence_contribution": 0.103608298880558,
                "combined_rank_score": 0.9225550889968872
              }
            ],
            "contradicting": [
              {
                "id": 6601,
                "faiss_score": 0.9003157615661621,
                "faiss_rank": 16,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Fault tolerance focuses on how systems respond to failures, while reliability concerns the probability that a system performs its intended function over time.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.45627206563949585,
                  "neutral": 0.5289970636367798,
                  "support": 0.014730836264789104
                },
                "stance_score": -0.44154122937470675,
                "evidence_contribution": -0.39752652818734857,
                "combined_rank_score": 0.9003157615661621
              },
              {
                "id": 5662,
                "faiss_score": 0.895884096622467,
                "faiss_rank": 17,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 65,
                "sentence": "Distributed systems research emphasizes the importance of understanding failure modes.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.37855640053749084,
                  "neutral": 0.5872592926025391,
                  "support": 0.03418431058526039
                },
                "stance_score": -0.34437208995223045,
                "evidence_contribution": -0.30851747870884494,
                "combined_rank_score": 0.895884096622467
              },
              {
                "id": 3588,
                "faiss_score": 0.914236307144165,
                "faiss_rank": 11,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 159,
                "sentence": "There is a difference between fault tolerance and systems that rarely have problems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.29361289739608765,
                  "neutral": 0.6918976306915283,
                  "support": 0.014489445835351944
                },
                "stance_score": -0.2791234515607357,
                "evidence_contribution": -0.25518479359222024,
                "combined_rank_score": 0.914236307144165
              }
            ],
            "neutral": [
              {
                "id": 3457,
                "faiss_score": 0.9289537668228149,
                "faiss_rank": 1,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 28,
                "sentence": "Fault tolerance is notably successful in computer applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0026155493687838316,
                  "neutral": 0.9897157549858093,
                  "support": 0.007668755948543549
                },
                "stance_score": 0.005053206579759717,
                "evidence_contribution": 0.004694195286801622,
                "combined_rank_score": 0.9289537668228149
              },
              {
                "id": 568,
                "faiss_score": 0.9223860502243042,
                "faiss_rank": 6,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 144,
                "sentence": "There are also fundamental challenges that are unique to distributed computing, for example those related to fault-tolerance.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.0938965231180191,
                  "neutral": 0.8450294137001038,
                  "support": 0.061074014753103256
                },
                "stance_score": -0.03282250836491585,
                "evidence_contribution": -0.030275023849168914,
                "combined_rank_score": 0.9223860502243042
              },
              {
                "id": 3521,
                "faiss_score": 0.911074161529541,
                "faiss_rank": 12,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 92,
                "sentence": "Fault-tolerant systems are typically based on the concept of redundancy.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.026624124497175217,
                  "neutral": 0.926490306854248,
                  "support": 0.04688552767038345
                },
                "stance_score": 0.020261403173208237,
                "evidence_contribution": 0.018459640907442676,
                "combined_rank_score": 0.911074161529541
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Fault tolerance is a fundamental requirement for reliable distributed systems.",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 430,
                      "faiss_score": 0.9227766394615173,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 6,
                      "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.0015678618801757693,
                        "neutral": 0.3799082636833191,
                        "support": 0.618523895740509
                      },
                      "stance_score": 0.6169560338603333,
                      "evidence_contribution": 0.5693126156211444,
                      "combined_rank_score": 0.9227766394615173
                    },
                    {
                      "id": 5605,
                      "faiss_score": 0.9225550889968872,
                      "faiss_rank": 5,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Failures are another fundamental aspect of distributed systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.04997483640909195,
                        "neutral": 0.7877445220947266,
                        "support": 0.16228064894676208
                      },
                      "stance_score": 0.11230581253767014,
                      "evidence_contribution": 0.103608298880558,
                      "combined_rank_score": 0.9225550889968872
                    },
                    {
                      "id": 6610,
                      "faiss_score": 0.9200949668884277,
                      "faiss_rank": 9,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Redundancy is a fundamental technique for achieving fault tolerance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004990473855286837,
                        "neutral": 0.8381791710853577,
                        "support": 0.1568303257226944
                      },
                      "stance_score": 0.15183985186740756,
                      "evidence_contribution": 0.13970708347628613,
                      "combined_rank_score": 0.9200949668884277
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 3588,
                      "faiss_score": 0.914236307144165,
                      "faiss_rank": 11,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 159,
                      "sentence": "There is a difference between fault tolerance and systems that rarely have problems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.29361289739608765,
                        "neutral": 0.6918976306915283,
                        "support": 0.014489445835351944
                      },
                      "stance_score": -0.2791234515607357,
                      "evidence_contribution": -0.25518479359222024,
                      "combined_rank_score": 0.914236307144165
                    },
                    {
                      "id": 6601,
                      "faiss_score": 0.9003157615661621,
                      "faiss_rank": 16,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 4,
                      "sentence": "Fault tolerance focuses on how systems respond to failures, while reliability concerns the probability that a system performs its intended function over time.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.45627206563949585,
                        "neutral": 0.5289970636367798,
                        "support": 0.014730836264789104
                      },
                      "stance_score": -0.44154122937470675,
                      "evidence_contribution": -0.39752652818734857,
                      "combined_rank_score": 0.9003157615661621
                    },
                    {
                      "id": 5662,
                      "faiss_score": 0.895884096622467,
                      "faiss_rank": 17,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 65,
                      "sentence": "Distributed systems research emphasizes the importance of understanding failure modes.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.37855640053749084,
                        "neutral": 0.5872592926025391,
                        "support": 0.03418431058526039
                      },
                      "stance_score": -0.34437208995223045,
                      "evidence_contribution": -0.30851747870884494,
                      "combined_rank_score": 0.895884096622467
                    }
                  ],
                  "neutral": [
                    {
                      "id": 3457,
                      "faiss_score": 0.9289537668228149,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 28,
                      "sentence": "Fault tolerance is notably successful in computer applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.0026155493687838316,
                        "neutral": 0.9897157549858093,
                        "support": 0.007668755948543549
                      },
                      "stance_score": 0.005053206579759717,
                      "evidence_contribution": 0.004694195286801622,
                      "combined_rank_score": 0.9289537668228149
                    },
                    {
                      "id": 568,
                      "faiss_score": 0.9223860502243042,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 144,
                      "sentence": "There are also fundamental challenges that are unique to distributed computing, for example those related to fault-tolerance.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.0938965231180191,
                        "neutral": 0.8450294137001038,
                        "support": 0.061074014753103256
                      },
                      "stance_score": -0.03282250836491585,
                      "evidence_contribution": -0.030275023849168914,
                      "combined_rank_score": 0.9223860502243042
                    },
                    {
                      "id": 3521,
                      "faiss_score": 0.911074161529541,
                      "faiss_rank": 12,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 92,
                      "sentence": "Fault-tolerant systems are typically based on the concept of redundancy.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.026624124497175217,
                        "neutral": 0.926490306854248,
                        "support": 0.04688552767038345
                      },
                      "stance_score": 0.020261403173208237,
                      "evidence_contribution": 0.018459640907442676,
                      "combined_rank_score": 0.911074161529541
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Increasing computational resources can improve the training performance of deep learning models.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Increasing computational resources can improve the training performance of deep learning models.",
          "verdict": "SUPPORT",
          "controversial": true,
          "strengths": {
            "support": 3.2213760010844696,
            "contradict": 1.082767755407037,
            "total": 4.304143756491507
          },
          "evidence": {
            "supporting": [
              {
                "id": 2622,
                "faiss_score": 0.8935152292251587,
                "faiss_rank": 6,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 217,
                "sentence": "Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0011127914767712355,
                  "neutral": 0.14476646482944489,
                  "support": 0.8541207909584045
                },
                "stance_score": 0.8530079994816333,
                "evidence_contribution": 0.7621756381877256,
                "combined_rank_score": 0.8935152292251587
              },
              {
                "id": 5906,
                "faiss_score": 0.8968743085861206,
                "faiss_rank": 4,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Early successes in deep learning were often achieved by increasing model size and training data, but this approach quickly encounters practical limits.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.029276547953486443,
                  "neutral": 0.37700629234313965,
                  "support": 0.5937171578407288
                },
                "stance_score": 0.5644406098872423,
                "evidence_contribution": 0.5062322817305487,
                "combined_rank_score": 0.8968743085861206
              },
              {
                "id": 6137,
                "faiss_score": 0.8798841238021851,
                "faiss_rank": 18,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0015576517907902598,
                  "neutral": 0.5468114614486694,
                  "support": 0.4516308605670929
                },
                "stance_score": 0.45007320877630264,
                "evidence_contribution": 0.39601227095097497,
                "combined_rank_score": 0.8798841238021851
              },
              {
                "id": 2160,
                "faiss_score": 0.8832216262817383,
                "faiss_rank": 14,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 91,
                "sentence": "They also showed how max-pooling CNNs on GPU improved performance significantly.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.0014727589441463351,
                  "neutral": 0.643264889717102,
                  "support": 0.35526230931282043
                },
                "stance_score": 0.3537895503686741,
                "evidence_contribution": 0.3124745820381053,
                "combined_rank_score": 0.8832216262817383
              },
              {
                "id": 1901,
                "faiss_score": 0.8911174535751343,
                "faiss_rank": 9,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 169,
                "sentence": "OptiLLM demonstrates that strategic application of computational resources at inference time can substantially improve model performance across diverse tasks, achieving significant improvements on benchmarks such as the AIME 2024 mathematics competition and various coding challenges.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.004067023750394583,
                  "neutral": 0.642042338848114,
                  "support": 0.35389062762260437
                },
                "stance_score": 0.3498236038722098,
                "evidence_contribution": 0.31173391908308007,
                "combined_rank_score": 0.8911174535751343
              },
              {
                "id": 1416,
                "faiss_score": 0.8915122747421265,
                "faiss_rank": 8,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 66,
                "sentence": "Increase the amount of training data: If the model is underfitting due to a lack of data, increasing the amount of training data may help.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.008432808332145214,
                  "neutral": 0.6888686418533325,
                  "support": 0.3026985824108124
                },
                "stance_score": 0.29426577407866716,
                "evidence_contribution": 0.26234154962762524,
                "combined_rank_score": 0.8915122747421265
              },
              {
                "id": 1785,
                "faiss_score": 0.8816750049591064,
                "faiss_rank": 17,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Cleaned datasets can increase training efficiency and lead to improved downstream performance.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.005137357860803604,
                  "neutral": 0.752930760383606,
                  "support": 0.24193188548088074
                },
                "stance_score": 0.23679452762007713,
                "evidence_contribution": 0.20877581631372077,
                "combined_rank_score": 0.8816750049591064
              },
              {
                "id": 2393,
                "faiss_score": 0.9043774604797363,
                "faiss_rank": 2,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 324,
                "sentence": "Large and effective neural networks require considerable computing resources.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.007439768873155117,
                  "neutral": 0.7574302554130554,
                  "support": 0.23513001203536987
                },
                "stance_score": 0.22769024316221476,
                "evidence_contribution": 0.20591792388705743,
                "combined_rank_score": 0.9043774604797363
              },
              {
                "id": 2486,
                "faiss_score": 0.9054665565490723,
                "faiss_rank": 1,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 81,
                "sentence": "This can substantially facilitate downstream deep learning.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0010445635998621583,
                  "neutral": 0.8149314522743225,
                  "support": 0.18402396142482758
                },
                "stance_score": 0.18297939782496542,
                "evidence_contribution": 0.16568172526799424,
                "combined_rank_score": 0.9054665565490723
              },
              {
                "id": 5930,
                "faiss_score": 0.8846855759620667,
                "faiss_rank": 11,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 25,
                "sentence": "Techniques such as improved optimizers, adaptive learning rates, and better initialization schemes can reduce training time.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.016633983701467514,
                  "neutral": 0.8649666905403137,
                  "support": 0.11839928478002548
                },
                "stance_score": 0.10176530107855797,
                "evidence_contribution": 0.09003029399763718,
                "combined_rank_score": 0.8846855759620667
              }
            ],
            "contradicting": [
              {
                "id": 6246,
                "faiss_score": 0.8848081827163696,
                "faiss_rank": 10,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 54,
                "sentence": "By halting training when performance on a validation set stops improving, systems can avoid overfitting and reduce resource usage.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9594833850860596,
                  "neutral": 0.03648177161812782,
                  "support": 0.004034887999296188
                },
                "stance_score": -0.9554484970867634,
                "evidence_contribution": -0.8453886483864257,
                "combined_rank_score": 0.8848081827163696
              },
              {
                "id": 5905,
                "faiss_score": 0.8922489881515503,
                "faiss_rank": 7,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.28539374470710754,
                  "neutral": 0.6952583193778992,
                  "support": 0.019347932189702988
                },
                "stance_score": -0.26604581251740456,
                "evidence_contribution": -0.23737910702061127,
                "combined_rank_score": 0.8922489881515503
              }
            ],
            "neutral": [
              {
                "id": 6044,
                "faiss_score": 0.8992515802383423,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009964535711333156,
                  "neutral": 0.9319743514060974,
                  "support": 0.06702922284603119
                },
                "stance_score": 0.06603276927489787,
                "evidence_contribution": 0.05938007211796577,
                "combined_rank_score": 0.8992515802383423
              },
              {
                "id": 5907,
                "faiss_score": 0.8959633708000183,
                "faiss_rank": 5,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.07758736610412598,
                  "neutral": 0.8997015953063965,
                  "support": 0.022711053490638733
                },
                "stance_score": -0.054876312613487244,
                "evidence_contribution": -0.04916716602625559,
                "combined_rank_score": 0.8959633708000183
              },
              {
                "id": 6092,
                "faiss_score": 0.8839632868766785,
                "faiss_rank": 12,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.10281243920326233,
                  "neutral": 0.8933481574058533,
                  "support": 0.0038394108414649963
                },
                "stance_score": -0.09897302836179733,
                "evidence_contribution": -0.08748852346283309,
                "combined_rank_score": 0.8839632868766785
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Increasing computational resources can improve the training performance of deep learning models.",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 2486,
                      "faiss_score": 0.9054665565490723,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "This can substantially facilitate downstream deep learning.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.0010445635998621583,
                        "neutral": 0.8149314522743225,
                        "support": 0.18402396142482758
                      },
                      "stance_score": 0.18297939782496542,
                      "evidence_contribution": 0.16568172526799424,
                      "combined_rank_score": 0.9054665565490723
                    },
                    {
                      "id": 2393,
                      "faiss_score": 0.9043774604797363,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 324,
                      "sentence": "Large and effective neural networks require considerable computing resources.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.007439768873155117,
                        "neutral": 0.7574302554130554,
                        "support": 0.23513001203536987
                      },
                      "stance_score": 0.22769024316221476,
                      "evidence_contribution": 0.20591792388705743,
                      "combined_rank_score": 0.9043774604797363
                    },
                    {
                      "id": 5906,
                      "faiss_score": 0.8968743085861206,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 1,
                      "sentence": "Early successes in deep learning were often achieved by increasing model size and training data, but this approach quickly encounters practical limits.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.029276547953486443,
                        "neutral": 0.37700629234313965,
                        "support": 0.5937171578407288
                      },
                      "stance_score": 0.5644406098872423,
                      "evidence_contribution": 0.5062322817305487,
                      "combined_rank_score": 0.8968743085861206
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5905,
                      "faiss_score": 0.8922489881515503,
                      "faiss_rank": 7,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.28539374470710754,
                        "neutral": 0.6952583193778992,
                        "support": 0.019347932189702988
                      },
                      "stance_score": -0.26604581251740456,
                      "evidence_contribution": -0.23737910702061127,
                      "combined_rank_score": 0.8922489881515503
                    },
                    {
                      "id": 6246,
                      "faiss_score": 0.8848081827163696,
                      "faiss_rank": 10,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 54,
                      "sentence": "By halting training when performance on a validation set stops improving, systems can avoid overfitting and reduce resource usage.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9594833850860596,
                        "neutral": 0.03648177161812782,
                        "support": 0.004034887999296188
                      },
                      "stance_score": -0.9554484970867634,
                      "evidence_contribution": -0.8453886483864257,
                      "combined_rank_score": 0.8848081827163696
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6044,
                      "faiss_score": 0.8992515802383423,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 4,
                      "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0009964535711333156,
                        "neutral": 0.9319743514060974,
                        "support": 0.06702922284603119
                      },
                      "stance_score": 0.06603276927489787,
                      "evidence_contribution": 0.05938007211796577,
                      "combined_rank_score": 0.8992515802383423
                    },
                    {
                      "id": 5907,
                      "faiss_score": 0.8959633708000183,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 2,
                      "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.07758736610412598,
                        "neutral": 0.8997015953063965,
                        "support": 0.022711053490638733
                      },
                      "stance_score": -0.054876312613487244,
                      "evidence_contribution": -0.04916716602625559,
                      "combined_rank_score": 0.8959633708000183
                    },
                    {
                      "id": 6092,
                      "faiss_score": 0.8839632868766785,
                      "faiss_rank": 12,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 52,
                      "sentence": "The computational cost of training large language models is substantial.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.10281243920326233,
                        "neutral": 0.8933481574058533,
                        "support": 0.0038394108414649963
                      },
                      "stance_score": -0.09897302836179733,
                      "evidence_contribution": -0.08748852346283309,
                      "combined_rank_score": 0.8839632868766785
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Large language models can perform multiple language tasks without task-specific fine-tuning.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Large language models can perform multiple language tasks",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 3.2086697159974222,
            "contradict": 0.2792107250897615,
            "total": 3.4878804410871838
          },
          "evidence": {
            "supporting": [
              {
                "id": 6079,
                "faiss_score": 0.9092576503753662,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Large language models are often described as general-purpose systems because they can be adapted to many tasks with minimal fine-tuning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0010351998498663306,
                  "neutral": 0.16859209537506104,
                  "support": 0.8303727507591248
                },
                "stance_score": 0.8293375509092584,
                "evidence_contribution": 0.754081512907813,
                "combined_rank_score": 0.9092576503753662
              },
              {
                "id": 6042,
                "faiss_score": 0.8853220343589783,
                "faiss_rank": 11,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "This simple training signal, when combined with large datasets and high model capacity, produces systems that can generate coherent text, answer questions, summarize documents, and perform a wide variety of language-related tasks without explicit task-specific programming.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0015242607332766056,
                  "neutral": 0.19606323540210724,
                  "support": 0.8024125099182129
                },
                "stance_score": 0.8008882491849363,
                "evidence_contribution": 0.7090440140626081,
                "combined_rank_score": 0.8853220343589783
              },
              {
                "id": 2960,
                "faiss_score": 0.8849107623100281,
                "faiss_rank": 12,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 15,
                "sentence": "A 380M-parameter model for machine translation uses two long short-term memories (LSTM).",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.004476959351450205,
                  "neutral": 0.6493340134620667,
                  "support": 0.3461889922618866
                },
                "stance_score": 0.3417120329104364,
                "evidence_contribution": 0.30238465553328364,
                "combined_rank_score": 0.8849107623100281
              },
              {
                "id": 6040,
                "faiss_score": 0.9093468189239502,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0017207523342221975,
                  "neutral": 0.6858500242233276,
                  "support": 0.312429279088974
                },
                "stance_score": 0.3107085267547518,
                "evidence_contribution": 0.2825418104169806,
                "combined_rank_score": 0.9093468189239502
              },
              {
                "id": 6109,
                "faiss_score": 0.8795288801193237,
                "faiss_rank": 18,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 69,
                "sentence": "The rapid pace of development in large language models has reshaped expectations about what machine learning systems can do.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0014595793327316642,
                  "neutral": 0.7455239295959473,
                  "support": 0.2530164420604706
                },
                "stance_score": 0.2515568627277389,
                "evidence_contribution": 0.22125152576125867,
                "combined_rank_score": 0.8795288801193237
              },
              {
                "id": 6121,
                "faiss_score": 0.9074077606201172,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007413278333842754,
                  "neutral": 0.82762211561203,
                  "support": 0.16496461629867554
                },
                "stance_score": 0.15755133796483278,
                "evidence_contribution": 0.14296330676537217,
                "combined_rank_score": 0.9074077606201172
              },
              {
                "id": 6102,
                "faiss_score": 0.8894730806350708,
                "faiss_rank": 8,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 62,
                "sentence": "Evaluation of large language models presents its own challenges.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005187702365219593,
                  "neutral": 0.846477210521698,
                  "support": 0.1483350694179535
                },
                "stance_score": 0.1431473670527339,
                "evidence_contribution": 0.12732572955719446,
                "combined_rank_score": 0.8894730806350708
              },
              {
                "id": 6043,
                "faiss_score": 0.8912434577941895,
                "faiss_rank": 6,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002225017175078392,
                  "neutral": 0.8620526790618896,
                  "support": 0.13572227954864502
                },
                "stance_score": 0.13349726237356663,
                "evidence_contribution": 0.11897856172387566,
                "combined_rank_score": 0.8912434577941895
              },
              {
                "id": 2185,
                "faiss_score": 0.8812185525894165,
                "faiss_rank": 17,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 116,
                "sentence": "Many modern large language models such as ChatGPT, GPT-4, and BERT use this architecture.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.001421264372766018,
                  "neutral": 0.8628906011581421,
                  "support": 0.1356882005929947
                },
                "stance_score": 0.13426693622022867,
                "evidence_contribution": 0.11831851519660541,
                "combined_rank_score": 0.8812185525894165
              },
              {
                "id": 6092,
                "faiss_score": 0.8881949186325073,
                "faiss_rank": 9,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00429666880518198,
                  "neutral": 0.8582781553268433,
                  "support": 0.13742515444755554
                },
                "stance_score": 0.13312848564237356,
                "evidence_contribution": 0.1182440444727969,
                "combined_rank_score": 0.8881949186325073
              },
              {
                "id": 6115,
                "faiss_score": 0.8896223306655884,
                "faiss_rank": 7,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Large language models also influence how users interact with technology.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0022298081312328577,
                  "neutral": 0.8730888366699219,
                  "support": 0.12468136847019196
                },
                "stance_score": 0.1224515603389591,
                "evidence_contribution": 0.10893564250238272,
                "combined_rank_score": 0.8896223306655884
              },
              {
                "id": 6067,
                "faiss_score": 0.8841374516487122,
                "faiss_rank": 13,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Large language models are also sensitive to the distribution of their training data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0041082692332565784,
                  "neutral": 0.8730601668357849,
                  "support": 0.12283158302307129
                },
                "stance_score": 0.11872331378981471,
                "evidence_contribution": 0.10496772810541719,
                "combined_rank_score": 0.8841374516487122
              },
              {
                "id": 6047,
                "faiss_score": 0.883418083190918,
                "faiss_rank": 14,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Despite these capabilities, the behavior of large language models remains fundamentally probabilistic.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0030133984982967377,
                  "neutral": 0.8811923265457153,
                  "support": 0.11579427868127823
                },
                "stance_score": 0.11278088018298149,
                "evidence_contribution": 0.0996326689918341,
                "combined_rank_score": 0.883418083190918
              }
            ],
            "contradicting": [
              {
                "id": 2020,
                "faiss_score": 0.8814258575439453,
                "faiss_rank": 16,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 288,
                "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.22995056211948395,
                  "neutral": 0.7223102450370789,
                  "support": 0.047739166766405106
                },
                "stance_score": -0.18221139535307884,
                "evidence_contribution": -0.16060583540336637,
                "combined_rank_score": 0.8814258575439453
              },
              {
                "id": 6101,
                "faiss_score": 0.885404109954834,
                "faiss_rank": 10,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 61,
                "sentence": "This modular approach reflects a recognition that language models alone are insufficient for many real-world tasks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.21949805319309235,
                  "neutral": 0.6949595808982849,
                  "support": 0.08554239571094513
                },
                "stance_score": -0.13395565748214722,
                "evidence_contribution": -0.11860488968639515,
                "combined_rank_score": 0.885404109954834
              }
            ],
            "neutral": [
              {
                "id": 1796,
                "faiss_score": 0.8975953459739685,
                "faiss_rank": 4,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 64,
                "sentence": "The tendency towards larger models is visible in the list of large language models.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.0006239613867364824,
                  "neutral": 0.9933342933654785,
                  "support": 0.006041666492819786
                },
                "stance_score": 0.005417705106083304,
                "evidence_contribution": 0.004862906889079779,
                "combined_rank_score": 0.8975953459739685
              },
              {
                "id": 6099,
                "faiss_score": 0.8944740891456604,
                "faiss_rank": 5,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 59,
                "sentence": "Large language models are increasingly deployed as components within larger systems rather than standalone tools.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0012955378042533994,
                  "neutral": 0.9265615344047546,
                  "support": 0.07214298099279404
                },
                "stance_score": 0.07084744318854064,
                "evidence_contribution": 0.06337120221436882,
                "combined_rank_score": 0.8944740891456604
              },
              {
                "id": 2659,
                "faiss_score": 0.8818987607955933,
                "faiss_rank": 15,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 254,
                "sentence": "LSTM helped to improve machine translation and language modeling.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0035483064129948616,
                  "neutral": 0.9778492450714111,
                  "support": 0.018602406606078148
                },
                "stance_score": 0.015054100193083286,
                "evidence_contribution": 0.013276192305172851,
                "combined_rank_score": 0.8818987607955933
              }
            ]
          }
        },
        {
          "subclaim": "without task-specific fine-tuning",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 6.519066125943898,
            "contradict": 6.831000996066662,
            "total": 13.35006712201056
          },
          "evidence": {
            "supporting": [
              {
                "id": 1833,
                "faiss_score": 0.8788925409317017,
                "faiss_rank": 5,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 101,
                "sentence": "This technique, called few-shot prompting, allows LLMs to be adapted to any task without requiring fine-tuning.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.0010085511021316051,
                  "neutral": 0.02543622814118862,
                  "support": 0.9735552668571472
                },
                "stance_score": 0.9725467157550156,
                "evidence_contribution": 0.854764054184707,
                "combined_rank_score": 0.8788925409317017
              },
              {
                "id": 6432,
                "faiss_score": 0.8805605173110962,
                "faiss_rank": 4,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 171,
                "sentence": "By framing tasks as variations of a common input-output format, practitioners can leverage pretrained models without extensive task-specific training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0018275665352120996,
                  "neutral": 0.055858906358480453,
                  "support": 0.942313551902771
                },
                "stance_score": 0.9404859853675589,
                "evidence_contribution": 0.8281548257990937,
                "combined_rank_score": 0.8805605173110962
              },
              {
                "id": 2566,
                "faiss_score": 0.875229001045227,
                "faiss_rank": 7,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 161,
                "sentence": "Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0010565657867118716,
                  "neutral": 0.06393749266862869,
                  "support": 0.9350059628486633
                },
                "stance_score": 0.9339493970619515,
                "evidence_contribution": 0.8174195978173239,
                "combined_rank_score": 0.875229001045227
              },
              {
                "id": 6079,
                "faiss_score": 0.8675508499145508,
                "faiss_rank": 14,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Large language models are often described as general-purpose systems because they can be adapted to many tasks with minimal fine-tuning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0036333799362182617,
                  "neutral": 0.07261178642511368,
                  "support": 0.9237548112869263
                },
                "stance_score": 0.920121431350708,
                "evidence_contribution": 0.7982521297928997,
                "combined_rank_score": 0.8675508499145508
              },
              {
                "id": 287,
                "faiss_score": 0.8709167242050171,
                "faiss_rank": 11,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 178,
                "sentence": "Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0012470762012526393,
                  "neutral": 0.12183920294046402,
                  "support": 0.8769136667251587
                },
                "stance_score": 0.875666590523906,
                "evidence_contribution": 0.7626326785148563,
                "combined_rank_score": 0.8709167242050171
              },
              {
                "id": 2620,
                "faiss_score": 0.8634504079818726,
                "faiss_rank": 17,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 215,
                "sentence": "It doesn't require learning rates or randomized initial weights.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0013863015919923782,
                  "neutral": 0.1169942170381546,
                  "support": 0.8816194534301758
                },
                "stance_score": 0.8802331518381834,
                "evidence_contribution": 0.760037674073849,
                "combined_rank_score": 0.8634504079818726
              },
              {
                "id": 2897,
                "faiss_score": 0.8676455020904541,
                "faiss_rank": 13,
                "doc_id": "wiki_Self-supervised_learning",
                "file_type": ".txt",
                "position": 6,
                "sentence": "This approach enables continuous adaptation in dynamic environments without requiring manual annotation.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Self-supervised_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.002071550814434886,
                  "neutral": 0.1629922240972519,
                  "support": 0.8349362015724182
                },
                "stance_score": 0.8328646507579833,
                "evidence_contribution": 0.7226312680803011,
                "combined_rank_score": 0.8676455020904541
              },
              {
                "id": 6283,
                "faiss_score": 0.8607879281044006,
                "faiss_rank": 19,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 22,
                "sentence": "Unlike fixed-window approaches, self-attention does not impose a predefined notion of locality, allowing global dependencies to emerge organically during training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.006370016373693943,
                  "neutral": 0.15858252346515656,
                  "support": 0.8350474834442139
                },
                "stance_score": 0.8286774670705199,
                "evidence_contribution": 0.7133155599464356,
                "combined_rank_score": 0.8607879281044006
              },
              {
                "id": 6389,
                "faiss_score": 0.858421266078949,
                "faiss_rank": 20,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 128,
                "sentence": "Because they can adapt to many tasks with minimal supervision, traditional train-test splits may not adequately measure generalization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.049677774310112,
                  "neutral": 0.595598042011261,
                  "support": 0.3547241985797882
                },
                "stance_score": 0.3050464242696762,
                "evidence_contribution": 0.2618583377344317,
                "combined_rank_score": 0.858421266078949
              }
            ],
            "contradicting": [
              {
                "id": 6085,
                "faiss_score": 0.8813949823379517,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 45,
                "sentence": "Fine-tuning is commonly used to adapt large language models to specific domains or behaviors.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9929386973381042,
                  "neutral": 0.005900803487747908,
                  "support": 0.001160479267127812
                },
                "stance_score": -0.9917782180709764,
                "evidence_contribution": -0.8741483449998334,
                "combined_rank_score": 0.8813949823379517
              },
              {
                "id": 6175,
                "faiss_score": 0.8836016654968262,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 51,
                "sentence": "Parameter-efficient fine-tuning and modular architectures reflect attempts to decouple performance gains from raw scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9888522624969482,
                  "neutral": 0.009457197971642017,
                  "support": 0.0016905720112845302
                },
                "stance_score": -0.9871616904856637,
                "evidence_contribution": -0.8722577138277949,
                "combined_rank_score": 0.8836016654968262
              },
              {
                "id": 6335,
                "faiss_score": 0.8739376664161682,
                "faiss_rank": 8,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 74,
                "sentence": "These pretrained models are then adapted to downstream tasks through fine-tuning or lightweight adaptation mechanisms.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9972085356712341,
                  "neutral": 0.002253232290968299,
                  "support": 0.0005383074167184532
                },
                "stance_score": -0.9966702282545157,
                "evidence_contribution": -0.8710276534672211,
                "combined_rank_score": 0.8739376664161682
              },
              {
                "id": 6088,
                "faiss_score": 0.8841488361358643,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "Parameter-efficient fine-tuning methods aim to mitigate these risks by modifying only a subset of parameters.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9841687083244324,
                  "neutral": 0.014658700674772263,
                  "support": 0.001172599266283214
                },
                "stance_score": -0.9829961090581492,
                "evidence_contribution": -0.8691148657498456,
                "combined_rank_score": 0.8841488361358643
              },
              {
                "id": 1802,
                "faiss_score": 0.8630768656730652,
                "faiss_rank": 18,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 70,
                "sentence": "Instruction fine-tuning is a form of supervised learning used to teach LLMs to follow user instructions.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.9954550266265869,
                  "neutral": 0.0036955545656383038,
                  "support": 0.0008494564681313932
                },
                "stance_score": -0.9946055701584555,
                "evidence_contribution": -0.8584210580733317,
                "combined_rank_score": 0.8630768656730652
              },
              {
                "id": 1830,
                "faiss_score": 0.8653687238693237,
                "faiss_rank": 15,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 98,
                "sentence": "It is possible to fine-tune quantized models using low-rank adaptation.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.9130350351333618,
                  "neutral": 0.08356160670518875,
                  "support": 0.003403342328965664
                },
                "stance_score": -0.9096316928043962,
                "evidence_contribution": -0.787166817193233,
                "combined_rank_score": 0.8653687238693237
              },
              {
                "id": 6087,
                "faiss_score": 0.8714344501495361,
                "faiss_rank": 10,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "While fine-tuning can improve performance, it may also introduce overfitting or reduce generality if not carefully managed.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9041840434074402,
                  "neutral": 0.08107355237007141,
                  "support": 0.014742383733391762
                },
                "stance_score": -0.8894416596740484,
                "evidence_contribution": -0.7750901036381452,
                "combined_rank_score": 0.8714344501495361
              },
              {
                "id": 5793,
                "faiss_score": 0.8648276329040527,
                "faiss_rank": 16,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 41,
                "sentence": "Tasks with simple underlying structure require fewer samples, while complex or noisy tasks require more.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8009193539619446,
                  "neutral": 0.1551365852355957,
                  "support": 0.043944101780653
                },
                "stance_score": -0.7569752521812916,
                "evidence_contribution": -0.6546531155108948,
                "combined_rank_score": 0.8648276329040527
              },
              {
                "id": 4958,
                "faiss_score": 0.8734052777290344,
                "faiss_rank": 9,
                "doc_id": "wiki_Computational_complexity",
                "file_type": ".txt",
                "position": 88,
                "sentence": "This may also be used for tuning complex algorithms without testing all variants.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Computational_complexity",
                "primary_category": "all articles containing potentially dated statements",
                "probs": {
                  "contradict": 0.5674043893814087,
                  "neutral": 0.173320010304451,
                  "support": 0.2592755854129791
                },
                "stance_score": -0.30812880396842957,
                "evidence_contribution": -0.26912132360636143,
                "combined_rank_score": 0.8734052777290344
              }
            ],
            "neutral": [
              {
                "id": 5910,
                "faiss_score": 0.8757848739624023,
                "faiss_rank": 6,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 5,
                "sentence": "These techniques do not change the underlying task but alter how the model represents and computes its function.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3810672163963318,
                  "neutral": 0.2503509223461151,
                  "support": 0.3685818016529083
                },
                "stance_score": -0.012485414743423462,
                "evidence_contribution": -0.010934537377437437,
                "combined_rank_score": 0.8757848739624023
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Large language models can perform multiple language tasks",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6040,
                      "faiss_score": 0.9093468189239502,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0017207523342221975,
                        "neutral": 0.6858500242233276,
                        "support": 0.312429279088974
                      },
                      "stance_score": 0.3107085267547518,
                      "evidence_contribution": 0.2825418104169806,
                      "combined_rank_score": 0.9093468189239502
                    },
                    {
                      "id": 6079,
                      "faiss_score": 0.9092576503753662,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "Large language models are often described as general-purpose systems because they can be adapted to many tasks with minimal fine-tuning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0010351998498663306,
                        "neutral": 0.16859209537506104,
                        "support": 0.8303727507591248
                      },
                      "stance_score": 0.8293375509092584,
                      "evidence_contribution": 0.754081512907813,
                      "combined_rank_score": 0.9092576503753662
                    },
                    {
                      "id": 6121,
                      "faiss_score": 0.9074077606201172,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.007413278333842754,
                        "neutral": 0.82762211561203,
                        "support": 0.16496461629867554
                      },
                      "stance_score": 0.15755133796483278,
                      "evidence_contribution": 0.14296330676537217,
                      "combined_rank_score": 0.9074077606201172
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6101,
                      "faiss_score": 0.885404109954834,
                      "faiss_rank": 10,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 61,
                      "sentence": "This modular approach reflects a recognition that language models alone are insufficient for many real-world tasks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.21949805319309235,
                        "neutral": 0.6949595808982849,
                        "support": 0.08554239571094513
                      },
                      "stance_score": -0.13395565748214722,
                      "evidence_contribution": -0.11860488968639515,
                      "combined_rank_score": 0.885404109954834
                    },
                    {
                      "id": 2020,
                      "faiss_score": 0.8814258575439453,
                      "faiss_rank": 16,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 288,
                      "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.22995056211948395,
                        "neutral": 0.7223102450370789,
                        "support": 0.047739166766405106
                      },
                      "stance_score": -0.18221139535307884,
                      "evidence_contribution": -0.16060583540336637,
                      "combined_rank_score": 0.8814258575439453
                    }
                  ],
                  "neutral": [
                    {
                      "id": 1796,
                      "faiss_score": 0.8975953459739685,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 64,
                      "sentence": "The tendency towards larger models is visible in the list of large language models.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.0006239613867364824,
                        "neutral": 0.9933342933654785,
                        "support": 0.006041666492819786
                      },
                      "stance_score": 0.005417705106083304,
                      "evidence_contribution": 0.004862906889079779,
                      "combined_rank_score": 0.8975953459739685
                    },
                    {
                      "id": 6099,
                      "faiss_score": 0.8944740891456604,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 59,
                      "sentence": "Large language models are increasingly deployed as components within larger systems rather than standalone tools.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0012955378042533994,
                        "neutral": 0.9265615344047546,
                        "support": 0.07214298099279404
                      },
                      "stance_score": 0.07084744318854064,
                      "evidence_contribution": 0.06337120221436882,
                      "combined_rank_score": 0.8944740891456604
                    },
                    {
                      "id": 2659,
                      "faiss_score": 0.8818987607955933,
                      "faiss_rank": 15,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 254,
                      "sentence": "LSTM helped to improve machine translation and language modeling.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.0035483064129948616,
                        "neutral": 0.9778492450714111,
                        "support": 0.018602406606078148
                      },
                      "stance_score": 0.015054100193083286,
                      "evidence_contribution": 0.013276192305172851,
                      "combined_rank_score": 0.8818987607955933
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "without task-specific fine-tuning",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6432,
                      "faiss_score": 0.8805605173110962,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 171,
                      "sentence": "By framing tasks as variations of a common input-output format, practitioners can leverage pretrained models without extensive task-specific training.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0018275665352120996,
                        "neutral": 0.055858906358480453,
                        "support": 0.942313551902771
                      },
                      "stance_score": 0.9404859853675589,
                      "evidence_contribution": 0.8281548257990937,
                      "combined_rank_score": 0.8805605173110962
                    },
                    {
                      "id": 1833,
                      "faiss_score": 0.8788925409317017,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 101,
                      "sentence": "This technique, called few-shot prompting, allows LLMs to be adapted to any task without requiring fine-tuning.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.0010085511021316051,
                        "neutral": 0.02543622814118862,
                        "support": 0.9735552668571472
                      },
                      "stance_score": 0.9725467157550156,
                      "evidence_contribution": 0.854764054184707,
                      "combined_rank_score": 0.8788925409317017
                    },
                    {
                      "id": 2566,
                      "faiss_score": 0.875229001045227,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 161,
                      "sentence": "Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.0010565657867118716,
                        "neutral": 0.06393749266862869,
                        "support": 0.9350059628486633
                      },
                      "stance_score": 0.9339493970619515,
                      "evidence_contribution": 0.8174195978173239,
                      "combined_rank_score": 0.875229001045227
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6088,
                      "faiss_score": 0.8841488361358643,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 48,
                      "sentence": "Parameter-efficient fine-tuning methods aim to mitigate these risks by modifying only a subset of parameters.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9841687083244324,
                        "neutral": 0.014658700674772263,
                        "support": 0.001172599266283214
                      },
                      "stance_score": -0.9829961090581492,
                      "evidence_contribution": -0.8691148657498456,
                      "combined_rank_score": 0.8841488361358643
                    },
                    {
                      "id": 6175,
                      "faiss_score": 0.8836016654968262,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 51,
                      "sentence": "Parameter-efficient fine-tuning and modular architectures reflect attempts to decouple performance gains from raw scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9888522624969482,
                        "neutral": 0.009457197971642017,
                        "support": 0.0016905720112845302
                      },
                      "stance_score": -0.9871616904856637,
                      "evidence_contribution": -0.8722577138277949,
                      "combined_rank_score": 0.8836016654968262
                    },
                    {
                      "id": 6085,
                      "faiss_score": 0.8813949823379517,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 45,
                      "sentence": "Fine-tuning is commonly used to adapt large language models to specific domains or behaviors.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9929386973381042,
                        "neutral": 0.005900803487747908,
                        "support": 0.001160479267127812
                      },
                      "stance_score": -0.9917782180709764,
                      "evidence_contribution": -0.8741483449998334,
                      "combined_rank_score": 0.8813949823379517
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5910,
                      "faiss_score": 0.8757848739624023,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 5,
                      "sentence": "These techniques do not change the underlying task but alter how the model represents and computes its function.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.3810672163963318,
                        "neutral": 0.2503509223461151,
                        "support": 0.3685818016529083
                      },
                      "stance_score": -0.012485414743423462,
                      "evidence_contribution": -0.010934537377437437,
                      "combined_rank_score": 0.8757848739624023
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Distributed consensus protocols help systems remain consistent despite node failures.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Distributed consensus protocols help systems remain consistent",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.6086698798392132,
            "contradict": 2.1980086716524805,
            "total": 2.806678551491694
          },
          "evidence": {
            "supporting": [
              {
                "id": 5619,
                "faiss_score": 0.9086953401565552,
                "faiss_rank": 2,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 22,
                "sentence": "Many higher-level abstractions, such as consistent replication and leader election, rely on solving consensus.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0018748909933492541,
                  "neutral": 0.7076581716537476,
                  "support": 0.29046696424484253
                },
                "stance_score": 0.2885920732514933,
                "evidence_contribution": 0.26224227216975116,
                "combined_rank_score": 0.9086953401565552
              },
              {
                "id": 3661,
                "faiss_score": 0.9006098508834839,
                "faiss_rank": 9,
                "doc_id": "wiki_Consensus_algorithm",
                "file_type": ".txt",
                "position": 70,
                "sentence": "An interactive consistency algorithm can solve the consensus problem by having each process choose the majority value in its consensus vector as its consensus value.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.0034708958119153976,
                  "neutral": 0.730571448802948,
                  "support": 0.2659575939178467
                },
                "stance_score": 0.2624866981059313,
                "evidence_contribution": 0.23639810604008082,
                "combined_rank_score": 0.9006098508834839
              },
              {
                "id": 3611,
                "faiss_score": 0.8874310255050659,
                "faiss_rank": 19,
                "doc_id": "wiki_Consensus_algorithm",
                "file_type": ".txt",
                "position": 20,
                "sentence": "A protocol that can correctly guarantee consensus amongst n processes of which at most t fail is said to be t-resilient.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.001991230295971036,
                  "neutral": 0.872031033039093,
                  "support": 0.1259777694940567
                },
                "stance_score": 0.12398653919808567,
                "evidence_contribution": 0.11002950162938122,
                "combined_rank_score": 0.8874310255050659
              }
            ],
            "contradicting": [
              {
                "id": 3230,
                "faiss_score": 0.8962163925170898,
                "faiss_rank": 10,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 145,
                "sentence": "Examples of related problems include consensus problems, Byzantine fault tolerance, and self-stabilisation.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.932668924331665,
                  "neutral": 0.06433884799480438,
                  "support": 0.002992313588038087
                },
                "stance_score": -0.929676610743627,
                "evidence_contribution": -0.8331914182881681,
                "combined_rank_score": 0.8962163925170898
              },
              {
                "id": 5618,
                "faiss_score": 0.9274933934211731,
                "faiss_rank": 1,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Consensus is a fundamental problem in distributed systems that captures the difficulty of agreement in the presence of failures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8703222274780273,
                  "neutral": 0.12668642401695251,
                  "support": 0.002991301706060767
                },
                "stance_score": -0.8673309257719666,
                "evidence_contribution": -0.8044437035633689,
                "combined_rank_score": 0.9274933934211731
              },
              {
                "id": 3616,
                "faiss_score": 0.8934632539749146,
                "faiss_rank": 14,
                "doc_id": "wiki_Consensus_algorithm",
                "file_type": ".txt",
                "position": 25,
                "sentence": "Varying models of computation may define a \"consensus problem\".",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.4453965425491333,
                  "neutral": 0.5506017208099365,
                  "support": 0.004001695662736893
                },
                "stance_score": -0.4413948468863964,
                "evidence_contribution": -0.3943700761868789,
                "combined_rank_score": 0.8934632539749146
              },
              {
                "id": 3637,
                "faiss_score": 0.9029970765113831,
                "faiss_rank": 5,
                "doc_id": "wiki_Consensus_algorithm",
                "file_type": ".txt",
                "position": 46,
                "sentence": "The consensus problem may be considered in the case of asynchronous or synchronous systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.18643596768379211,
                  "neutral": 0.8109642267227173,
                  "support": 0.0025998535566031933
                },
                "stance_score": -0.18383611412718892,
                "evidence_contribution": -0.16600347361406456,
                "combined_rank_score": 0.9029970765113831
              }
            ],
            "neutral": [
              {
                "id": 5610,
                "faiss_score": 0.9084477424621582,
                "faiss_rank": 3,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Consistency is a central concept in distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.000766043784096837,
                  "neutral": 0.9977141618728638,
                  "support": 0.0015198341570794582
                },
                "stance_score": 0.0007537903729826212,
                "evidence_contribution": 0.0006847791626257704,
                "combined_rank_score": 0.9084477424621582
              },
              {
                "id": 3598,
                "faiss_score": 0.9066146612167358,
                "faiss_rank": 4,
                "doc_id": "wiki_Consensus_algorithm",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Protocols that solve consensus problems are designed to deal with a limited number of faulty processes.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.006723729893565178,
                  "neutral": 0.9666137099266052,
                  "support": 0.026662535965442657
                },
                "stance_score": 0.01993880607187748,
                "evidence_contribution": 0.018076813911921397,
                "combined_rank_score": 0.9066146612167358
              },
              {
                "id": 3592,
                "faiss_score": 0.9013365507125854,
                "faiss_rank": 6,
                "doc_id": "wiki_Consensus_algorithm",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Some of the processes (agents) may fail or be unreliable in other ways, so consensus protocols must be fault-tolerant or resilient.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.0038521725218743086,
                  "neutral": 0.950269341468811,
                  "support": 0.045878443866968155
                },
                "stance_score": 0.042026271345093846,
                "evidence_contribution": 0.037879814453498056,
                "combined_rank_score": 0.9013365507125854
              }
            ]
          }
        },
        {
          "subclaim": "Systems remain consistent despite node failures",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 3.3131390660922477,
            "contradict": 3.304779494676682,
            "total": 6.6179185607689295
          },
          "evidence": {
            "supporting": [
              {
                "id": 3474,
                "faiss_score": 0.9279701709747314,
                "faiss_rank": 1,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 45,
                "sentence": "Resilient networks continue to transmit data despite the failure of some links or nodes.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.001138089457526803,
                  "neutral": 0.016104355454444885,
                  "support": 0.9827576279640198
                },
                "stance_score": 0.981619538506493,
                "evidence_contribution": 0.9109136509800073,
                "combined_rank_score": 0.9279701709747314
              },
              {
                "id": 5615,
                "faiss_score": 0.9032431840896606,
                "faiss_rank": 3,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "By maintaining multiple copies of data across different nodes, a system can continue to operate even if some replicas fail.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009699473739601672,
                  "neutral": 0.08712581545114517,
                  "support": 0.9119042158126831
                },
                "stance_score": 0.9109342684387229,
                "evidence_contribution": 0.8227951691209777,
                "combined_rank_score": 0.9032431840896606
              },
              {
                "id": 6611,
                "faiss_score": 0.8802043199539185,
                "faiss_rank": 8,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "By replicating components or data, a system can continue operating when individual elements fail.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002681432291865349,
                  "neutral": 0.33525410294532776,
                  "support": 0.6620644330978394
                },
                "stance_score": 0.659383000805974,
                "evidence_contribution": 0.5803917658135964,
                "combined_rank_score": 0.8802043199539185
              },
              {
                "id": 3463,
                "faiss_score": 0.9054452180862427,
                "faiss_rank": 2,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 34,
                "sentence": "A highly fault-tolerant system might continue at the same level of performance even though one or more components have failed.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.00400190707296133,
                  "neutral": 0.46762439608573914,
                  "support": 0.5283737182617188
                },
                "stance_score": 0.5243718111887574,
                "evidence_contribution": 0.47478994894008253,
                "combined_rank_score": 0.9054452180862427
              },
              {
                "id": 529,
                "faiss_score": 0.8926143646240234,
                "faiss_rank": 4,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 105,
                "sentence": "The system must work correctly regardless of the structure of the network.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.015622247941792011,
                  "neutral": 0.6268813014030457,
                  "support": 0.357496440410614
                },
                "stance_score": 0.341874192468822,
                "evidence_contribution": 0.30516181509190865,
                "combined_rank_score": 0.8926143646240234
              },
              {
                "id": 430,
                "faiss_score": 0.8767738342285156,
                "faiss_rank": 17,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 6,
                "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.034422557801008224,
                  "neutral": 0.791019082069397,
                  "support": 0.17455832660198212
                },
                "stance_score": 0.1401357688009739,
                "evidence_contribution": 0.12286737532419068,
                "combined_rank_score": 0.8767738342285156
              },
              {
                "id": 3668,
                "faiss_score": 0.8798153400421143,
                "faiss_rank": 10,
                "doc_id": "wiki_Consensus_algorithm",
                "file_type": ".txt",
                "position": 77,
                "sentence": "These algorithms are typically synchronous, dependent on an elected leader to make progress, and tolerate only crashes and not Byzantine failures.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.29799264669418335,
                  "neutral": 0.2946515679359436,
                  "support": 0.40735575556755066
                },
                "stance_score": 0.10936310887336731,
                "evidence_contribution": 0.09621934082148442,
                "combined_rank_score": 0.8798153400421143
              }
            ],
            "contradicting": [
              {
                "id": 6623,
                "faiss_score": 0.8907701373100281,
                "faiss_rank": 7,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 26,
                "sentence": "Some systems restart failed components, others reroute requests, and still others degrade functionality gracefully.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9080203771591187,
                  "neutral": 0.07945631444454193,
                  "support": 0.012523368000984192
                },
                "stance_score": -0.8954970091581345,
                "evidence_contribution": -0.7976819938085109,
                "combined_rank_score": 0.8907701373100281
              },
              {
                "id": 6605,
                "faiss_score": 0.8778896331787109,
                "faiss_rank": 15,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Failures in computing systems take many forms.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8227906823158264,
                  "neutral": 0.1751573234796524,
                  "support": 0.0020519725512713194
                },
                "stance_score": -0.8207387097645551,
                "evidence_contribution": -0.7205180048507738,
                "combined_rank_score": 0.8778896331787109
              },
              {
                "id": 6603,
                "faiss_score": 0.8794848322868347,
                "faiss_rank": 11,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 6,
                "sentence": "A system may tolerate certain failures gracefully yet still exhibit low overall reliability if failures occur frequently.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7329874634742737,
                  "neutral": 0.24647438526153564,
                  "support": 0.020538147538900375
                },
                "stance_score": -0.7124493159353733,
                "evidence_contribution": -0.6265883671382919,
                "combined_rank_score": 0.8794848322868347
              },
              {
                "id": 6659,
                "faiss_score": 0.878364622592926,
                "faiss_rank": 14,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 62,
                "sentence": "In large-scale systems, failures are often correlated rather than independent.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.4171348512172699,
                  "neutral": 0.5790106058120728,
                  "support": 0.0038546037394553423
                },
                "stance_score": -0.41328024747781456,
                "evidence_contribution": -0.36301074860096166,
                "combined_rank_score": 0.878364622592926
              },
              {
                "id": 5662,
                "faiss_score": 0.8791956305503845,
                "faiss_rank": 12,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 65,
                "sentence": "Distributed systems research emphasizes the importance of understanding failure modes.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3670976459980011,
                  "neutral": 0.6293862462043762,
                  "support": 0.0035161017440259457
                },
                "stance_score": -0.36358154425397515,
                "evidence_contribution": -0.31965930505685625,
                "combined_rank_score": 0.8791956305503845
              },
              {
                "id": 3588,
                "faiss_score": 0.8751884698867798,
                "faiss_rank": 20,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 159,
                "sentence": "There is a difference between fault tolerance and systems that rarely have problems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.28837132453918457,
                  "neutral": 0.6803242564201355,
                  "support": 0.03130445256829262
                },
                "stance_score": -0.25706687197089195,
                "evidence_contribution": -0.22498196233878565,
                "combined_rank_score": 0.8751884698867798
              },
              {
                "id": 5636,
                "faiss_score": 0.8800848722457886,
                "faiss_rank": 9,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Managing this state across multiple nodes while preserving correctness requires careful design.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.1958034336566925,
                  "neutral": 0.7837867736816406,
                  "support": 0.0204098392277956
                },
                "stance_score": -0.1753935944288969,
                "evidence_contribution": -0.1543612491456854,
                "combined_rank_score": 0.8800848722457886
              },
              {
                "id": 5605,
                "faiss_score": 0.8787782192230225,
                "faiss_rank": 13,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Failures are another fundamental aspect of distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.11729293316602707,
                  "neutral": 0.876907467842102,
                  "support": 0.005799655802547932
                },
                "stance_score": -0.11149327736347914,
                "evidence_contribution": -0.09797786373681672,
                "combined_rank_score": 0.8787782192230225
              }
            ],
            "neutral": [
              {
                "id": 3457,
                "faiss_score": 0.8775272965431213,
                "faiss_rank": 16,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 28,
                "sentence": "Fault tolerance is notably successful in computer applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.004335539415478706,
                  "neutral": 0.8984509110450745,
                  "support": 0.09721354395151138
                },
                "stance_score": 0.09287800453603268,
                "evidence_contribution": 0.08150298422882452,
                "combined_rank_score": 0.8775272965431213
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Distributed consensus protocols help systems remain consistent",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5619,
                      "faiss_score": 0.9086953401565552,
                      "faiss_rank": 2,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 22,
                      "sentence": "Many higher-level abstractions, such as consistent replication and leader election, rely on solving consensus.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0018748909933492541,
                        "neutral": 0.7076581716537476,
                        "support": 0.29046696424484253
                      },
                      "stance_score": 0.2885920732514933,
                      "evidence_contribution": 0.26224227216975116,
                      "combined_rank_score": 0.9086953401565552
                    },
                    {
                      "id": 3661,
                      "faiss_score": 0.9006098508834839,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Consensus_algorithm",
                      "file_type": ".txt",
                      "position": 70,
                      "sentence": "An interactive consistency algorithm can solve the consensus problem by having each process choose the majority value in its consensus vector as its consensus value.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.0034708958119153976,
                        "neutral": 0.730571448802948,
                        "support": 0.2659575939178467
                      },
                      "stance_score": 0.2624866981059313,
                      "evidence_contribution": 0.23639810604008082,
                      "combined_rank_score": 0.9006098508834839
                    },
                    {
                      "id": 3611,
                      "faiss_score": 0.8874310255050659,
                      "faiss_rank": 19,
                      "doc_id": "wiki_Consensus_algorithm",
                      "file_type": ".txt",
                      "position": 20,
                      "sentence": "A protocol that can correctly guarantee consensus amongst n processes of which at most t fail is said to be t-resilient.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.001991230295971036,
                        "neutral": 0.872031033039093,
                        "support": 0.1259777694940567
                      },
                      "stance_score": 0.12398653919808567,
                      "evidence_contribution": 0.11002950162938122,
                      "combined_rank_score": 0.8874310255050659
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5618,
                      "faiss_score": 0.9274933934211731,
                      "faiss_rank": 1,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "Consensus is a fundamental problem in distributed systems that captures the difficulty of agreement in the presence of failures.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.8703222274780273,
                        "neutral": 0.12668642401695251,
                        "support": 0.002991301706060767
                      },
                      "stance_score": -0.8673309257719666,
                      "evidence_contribution": -0.8044437035633689,
                      "combined_rank_score": 0.9274933934211731
                    },
                    {
                      "id": 3637,
                      "faiss_score": 0.9029970765113831,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Consensus_algorithm",
                      "file_type": ".txt",
                      "position": 46,
                      "sentence": "The consensus problem may be considered in the case of asynchronous or synchronous systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.18643596768379211,
                        "neutral": 0.8109642267227173,
                        "support": 0.0025998535566031933
                      },
                      "stance_score": -0.18383611412718892,
                      "evidence_contribution": -0.16600347361406456,
                      "combined_rank_score": 0.9029970765113831
                    },
                    {
                      "id": 3230,
                      "faiss_score": 0.8962163925170898,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 145,
                      "sentence": "Examples of related problems include consensus problems, Byzantine fault tolerance, and self-stabilisation.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.932668924331665,
                        "neutral": 0.06433884799480438,
                        "support": 0.002992313588038087
                      },
                      "stance_score": -0.929676610743627,
                      "evidence_contribution": -0.8331914182881681,
                      "combined_rank_score": 0.8962163925170898
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5610,
                      "faiss_score": 0.9084477424621582,
                      "faiss_rank": 3,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Consistency is a central concept in distributed systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.000766043784096837,
                        "neutral": 0.9977141618728638,
                        "support": 0.0015198341570794582
                      },
                      "stance_score": 0.0007537903729826212,
                      "evidence_contribution": 0.0006847791626257704,
                      "combined_rank_score": 0.9084477424621582
                    },
                    {
                      "id": 3598,
                      "faiss_score": 0.9066146612167358,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Consensus_algorithm",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Protocols that solve consensus problems are designed to deal with a limited number of faulty processes.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.006723729893565178,
                        "neutral": 0.9666137099266052,
                        "support": 0.026662535965442657
                      },
                      "stance_score": 0.01993880607187748,
                      "evidence_contribution": 0.018076813911921397,
                      "combined_rank_score": 0.9066146612167358
                    },
                    {
                      "id": 3592,
                      "faiss_score": 0.9013365507125854,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Consensus_algorithm",
                      "file_type": ".txt",
                      "position": 1,
                      "sentence": "Some of the processes (agents) may fail or be unreliable in other ways, so consensus protocols must be fault-tolerant or resilient.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.0038521725218743086,
                        "neutral": 0.950269341468811,
                        "support": 0.045878443866968155
                      },
                      "stance_score": 0.042026271345093846,
                      "evidence_contribution": 0.037879814453498056,
                      "combined_rank_score": 0.9013365507125854
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Systems remain consistent despite node failures",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 3474,
                      "faiss_score": 0.9279701709747314,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 45,
                      "sentence": "Resilient networks continue to transmit data despite the failure of some links or nodes.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.001138089457526803,
                        "neutral": 0.016104355454444885,
                        "support": 0.9827576279640198
                      },
                      "stance_score": 0.981619538506493,
                      "evidence_contribution": 0.9109136509800073,
                      "combined_rank_score": 0.9279701709747314
                    },
                    {
                      "id": 3463,
                      "faiss_score": 0.9054452180862427,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 34,
                      "sentence": "A highly fault-tolerant system might continue at the same level of performance even though one or more components have failed.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.00400190707296133,
                        "neutral": 0.46762439608573914,
                        "support": 0.5283737182617188
                      },
                      "stance_score": 0.5243718111887574,
                      "evidence_contribution": 0.47478994894008253,
                      "combined_rank_score": 0.9054452180862427
                    },
                    {
                      "id": 5615,
                      "faiss_score": 0.9032431840896606,
                      "faiss_rank": 3,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "By maintaining multiple copies of data across different nodes, a system can continue to operate even if some replicas fail.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0009699473739601672,
                        "neutral": 0.08712581545114517,
                        "support": 0.9119042158126831
                      },
                      "stance_score": 0.9109342684387229,
                      "evidence_contribution": 0.8227951691209777,
                      "combined_rank_score": 0.9032431840896606
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6623,
                      "faiss_score": 0.8907701373100281,
                      "faiss_rank": 7,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 26,
                      "sentence": "Some systems restart failed components, others reroute requests, and still others degrade functionality gracefully.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9080203771591187,
                        "neutral": 0.07945631444454193,
                        "support": 0.012523368000984192
                      },
                      "stance_score": -0.8954970091581345,
                      "evidence_contribution": -0.7976819938085109,
                      "combined_rank_score": 0.8907701373100281
                    },
                    {
                      "id": 5636,
                      "faiss_score": 0.8800848722457886,
                      "faiss_rank": 9,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "Managing this state across multiple nodes while preserving correctness requires careful design.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.1958034336566925,
                        "neutral": 0.7837867736816406,
                        "support": 0.0204098392277956
                      },
                      "stance_score": -0.1753935944288969,
                      "evidence_contribution": -0.1543612491456854,
                      "combined_rank_score": 0.8800848722457886
                    },
                    {
                      "id": 6603,
                      "faiss_score": 0.8794848322868347,
                      "faiss_rank": 11,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 6,
                      "sentence": "A system may tolerate certain failures gracefully yet still exhibit low overall reliability if failures occur frequently.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.7329874634742737,
                        "neutral": 0.24647438526153564,
                        "support": 0.020538147538900375
                      },
                      "stance_score": -0.7124493159353733,
                      "evidence_contribution": -0.6265883671382919,
                      "combined_rank_score": 0.8794848322868347
                    }
                  ],
                  "neutral": [
                    {
                      "id": 3457,
                      "faiss_score": 0.8775272965431213,
                      "faiss_rank": 16,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 28,
                      "sentence": "Fault tolerance is notably successful in computer applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.004335539415478706,
                        "neutral": 0.8984509110450745,
                        "support": 0.09721354395151138
                      },
                      "stance_score": 0.09287800453603268,
                      "evidence_contribution": 0.08150298422882452,
                      "combined_rank_score": 0.8775272965431213
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Increasing model size always guarantees better generalization performance.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Increasing model size always guarantees better generalization performance.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 7.236197821035883,
            "total": 7.236197821035883
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 1453,
                "faiss_score": 0.9143708348274231,
                "faiss_rank": 4,
                "doc_id": "wiki_Regularization_(mathematics)",
                "file_type": ".txt",
                "position": 25,
                "sentence": "By regularizing for time, model complexity can be controlled, improving generalization.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Regularization_(mathematics)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.9792255163192749,
                  "neutral": 0.019215479493141174,
                  "support": 0.0015590087277814746
                },
                "stance_score": -0.9776665075914934,
                "evidence_contribution": -0.893949740729245,
                "combined_rank_score": 0.9143708348274231
              },
              {
                "id": 5941,
                "faiss_score": 0.901360034942627,
                "faiss_rank": 9,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 36,
                "sentence": "Smaller or compressed models may generalize better due to implicit regularization, but excessive compression can harm performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9887085556983948,
                  "neutral": 0.010507587343454361,
                  "support": 0.0007837332668714225
                },
                "stance_score": -0.9879248224315234,
                "evidence_contribution": -0.8904759524675664,
                "combined_rank_score": 0.901360034942627
              },
              {
                "id": 5905,
                "faiss_score": 0.8995159864425659,
                "faiss_rank": 13,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9100438952445984,
                  "neutral": 0.0877692922949791,
                  "support": 0.002186903264373541
                },
                "stance_score": -0.9078569919802248,
                "evidence_contribution": -0.8166318776898727,
                "combined_rank_score": 0.8995159864425659
              },
              {
                "id": 6133,
                "faiss_score": 0.8974666595458984,
                "faiss_rank": 15,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.904425859451294,
                  "neutral": 0.09184230118989944,
                  "support": 0.003731856355443597
                },
                "stance_score": -0.9006940030958503,
                "evidence_contribution": -0.8083428382314559,
                "combined_rank_score": 0.8974666595458984
              },
              {
                "id": 6134,
                "faiss_score": 0.8920220136642456,
                "faiss_rank": 19,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 10,
                "sentence": "Large models are also more sensitive to optimization choices and require careful tuning to train effectively.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9068106412887573,
                  "neutral": 0.09030203521251678,
                  "support": 0.0028873810078948736
                },
                "stance_score": -0.9039232602808625,
                "evidence_contribution": -0.806319446833685,
                "combined_rank_score": 0.8920220136642456
              },
              {
                "id": 5906,
                "faiss_score": 0.895328938961029,
                "faiss_rank": 18,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Early successes in deep learning were often achieved by increasing model size and training data, but this approach quickly encounters practical limits.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8033847808837891,
                  "neutral": 0.19272951781749725,
                  "support": 0.0038856947794556618
                },
                "stance_score": -0.7994990861043334,
                "evidence_contribution": -0.7158146684621052,
                "combined_rank_score": 0.895328938961029
              },
              {
                "id": 5922,
                "faiss_score": 0.8979805111885071,
                "faiss_rank": 14,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 17,
                "sentence": "Distilled models often achieve better performance than models trained directly on the same data, given similar size constraints.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7945719957351685,
                  "neutral": 0.20232698321342468,
                  "support": 0.0031010955572128296
                },
                "stance_score": -0.7914709001779556,
                "evidence_contribution": -0.7107254435326285,
                "combined_rank_score": 0.8979805111885071
              },
              {
                "id": 5940,
                "faiss_score": 0.8920051455497742,
                "faiss_rank": 20,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 35,
                "sentence": "The relationship between efficiency and generalization is complex.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5858945846557617,
                  "neutral": 0.4124264419078827,
                  "support": 0.0016789331566542387
                },
                "stance_score": -0.5842156514991075,
                "evidence_contribution": -0.5211233672479175,
                "combined_rank_score": 0.8920051455497742
              },
              {
                "id": 1443,
                "faiss_score": 0.8999907970428467,
                "faiss_rank": 11,
                "doc_id": "wiki_Regularization_(mathematics)",
                "file_type": ".txt",
                "position": 15,
                "sentence": "Regularization can be motivated as a technique to improve the generalizability of a learned model.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Regularization_(mathematics)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.5267986059188843,
                  "neutral": 0.4700230360031128,
                  "support": 0.0031784214079380035
                },
                "stance_score": -0.5236201845109463,
                "evidence_contribution": -0.471253347205729,
                "combined_rank_score": 0.8999907970428467
              },
              {
                "id": 5728,
                "faiss_score": 0.9036639332771301,
                "faiss_rank": 6,
                "doc_id": "local_math_computation_limits.txt",
                "file_type": ".txt",
                "position": 51,
                "sentence": "Bounds on generalization depend on factors such as model capacity and data distribution.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.27987390756607056,
                  "neutral": 0.71832275390625,
                  "support": 0.0018033733358606696
                },
                "stance_score": -0.2780705342302099,
                "evidence_contribution": -0.2512823126909443,
                "combined_rank_score": 0.9036639332771301
              },
              {
                "id": 6221,
                "faiss_score": 0.900503396987915,
                "faiss_rank": 10,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 29,
                "sentence": "Surprisingly, such models can still generalize well.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.26446568965911865,
                  "neutral": 0.7334563732147217,
                  "support": 0.002077879384160042
                },
                "stance_score": -0.2623878102749586,
                "evidence_contribution": -0.2362811144808208,
                "combined_rank_score": 0.900503396987915
              },
              {
                "id": 6211,
                "faiss_score": 0.9146316051483154,
                "faiss_rank": 3,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 19,
                "sentence": "Batch size influences both optimization efficiency and generalization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.12615004181861877,
                  "neutral": 0.8723376989364624,
                  "support": 0.0015121976612135768
                },
                "stance_score": -0.1246378441574052,
                "evidence_contribution": -0.1139977114639131,
                "combined_rank_score": 0.9146316051483154
              }
            ],
            "neutral": [
              {
                "id": 6137,
                "faiss_score": 0.9333542585372925,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.08033034205436707,
                  "neutral": 0.8913941979408264,
                  "support": 0.028275374323129654
                },
                "stance_score": -0.05205496773123741,
                "evidence_contribution": -0.04858572580997178,
                "combined_rank_score": 0.9333542585372925
              },
              {
                "id": 6132,
                "faiss_score": 0.9239883422851562,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Larger models have greater representational capacity, allowing them to fit more complex functions.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.018399924039840698,
                  "neutral": 0.949671745300293,
                  "support": 0.03192831203341484
                },
                "stance_score": 0.013528387993574142,
                "evidence_contribution": 0.012500072795972983,
                "combined_rank_score": 0.9239883422851562
              },
              {
                "id": 6131,
                "faiss_score": 0.9053013920783997,
                "faiss_rank": 5,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.010888082906603813,
                  "neutral": 0.9879173636436462,
                  "support": 0.0011945862788707018
                },
                "stance_score": -0.009693496627733111,
                "evidence_contribution": -0.008775535991194058,
                "combined_rank_score": 0.9053013920783997
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Increasing model size always guarantees better generalization performance.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6211,
                      "faiss_score": 0.9146316051483154,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 19,
                      "sentence": "Batch size influences both optimization efficiency and generalization.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.12615004181861877,
                        "neutral": 0.8723376989364624,
                        "support": 0.0015121976612135768
                      },
                      "stance_score": -0.1246378441574052,
                      "evidence_contribution": -0.1139977114639131,
                      "combined_rank_score": 0.9146316051483154
                    },
                    {
                      "id": 1453,
                      "faiss_score": 0.9143708348274231,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Regularization_(mathematics)",
                      "file_type": ".txt",
                      "position": 25,
                      "sentence": "By regularizing for time, model complexity can be controlled, improving generalization.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Regularization_(mathematics)",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.9792255163192749,
                        "neutral": 0.019215479493141174,
                        "support": 0.0015590087277814746
                      },
                      "stance_score": -0.9776665075914934,
                      "evidence_contribution": -0.893949740729245,
                      "combined_rank_score": 0.9143708348274231
                    },
                    {
                      "id": 5728,
                      "faiss_score": 0.9036639332771301,
                      "faiss_rank": 6,
                      "doc_id": "local_math_computation_limits.txt",
                      "file_type": ".txt",
                      "position": 51,
                      "sentence": "Bounds on generalization depend on factors such as model capacity and data distribution.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.27987390756607056,
                        "neutral": 0.71832275390625,
                        "support": 0.0018033733358606696
                      },
                      "stance_score": -0.2780705342302099,
                      "evidence_contribution": -0.2512823126909443,
                      "combined_rank_score": 0.9036639332771301
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6137,
                      "faiss_score": 0.9333542585372925,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.08033034205436707,
                        "neutral": 0.8913941979408264,
                        "support": 0.028275374323129654
                      },
                      "stance_score": -0.05205496773123741,
                      "evidence_contribution": -0.04858572580997178,
                      "combined_rank_score": 0.9333542585372925
                    },
                    {
                      "id": 6132,
                      "faiss_score": 0.9239883422851562,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Larger models have greater representational capacity, allowing them to fit more complex functions.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.018399924039840698,
                        "neutral": 0.949671745300293,
                        "support": 0.03192831203341484
                      },
                      "stance_score": 0.013528387993574142,
                      "evidence_contribution": 0.012500072795972983,
                      "combined_rank_score": 0.9239883422851562
                    },
                    {
                      "id": 6131,
                      "faiss_score": 0.9053013920783997,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.010888082906603813,
                        "neutral": 0.9879173636436462,
                        "support": 0.0011945862788707018
                      },
                      "stance_score": -0.009693496627733111,
                      "evidence_contribution": -0.008775535991194058,
                      "combined_rank_score": 0.9053013920783997
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Distributed systems do not need fault tolerance mechanisms.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Distributed systems do not need fault tolerance mechanisms.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.4805527413154298,
            "contradict": 8.511564482714613,
            "total": 8.992117224030043
          },
          "evidence": {
            "supporting": [
              {
                "id": 3487,
                "faiss_score": 0.8769917488098145,
                "faiss_rank": 17,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 58,
                "sentence": "Some components, like the drive shaft in a car, are not likely to fail, so no fault tolerance is needed.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.023633461445569992,
                  "neutral": 0.4047772288322449,
                  "support": 0.5715892910957336
                },
                "stance_score": 0.5479558296501637,
                "evidence_contribution": 0.4805527413154298,
                "combined_rank_score": 0.8769917488098145
              }
            ],
            "contradicting": [
              {
                "id": 3809,
                "faiss_score": 0.9038978815078735,
                "faiss_rank": 4,
                "doc_id": "wiki_CAP_theorem",
                "file_type": ".txt",
                "position": 0,
                "sentence": "No distributed system is safe from network failures, thus network partitioning generally has to be tolerated.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/CAP_theorem",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.9990100860595703,
                  "neutral": 0.0007420883048325777,
                  "support": 0.0002478054666426033
                },
                "stance_score": -0.9987622805929277,
                "evidence_contribution": -0.9027791095579197,
                "combined_rank_score": 0.9038978815078735
              },
              {
                "id": 5605,
                "faiss_score": 0.8947681188583374,
                "faiss_rank": 5,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Failures are another fundamental aspect of distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9942522644996643,
                  "neutral": 0.005194053985178471,
                  "support": 0.0005536171956919134
                },
                "stance_score": -0.9936986473039724,
                "evidence_contribution": -0.8891298693602498,
                "combined_rank_score": 0.8947681188583374
              },
              {
                "id": 430,
                "faiss_score": 0.8796877861022949,
                "faiss_rank": 13,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 6,
                "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.9988288283348083,
                  "neutral": 0.0008527741301804781,
                  "support": 0.0003183769586030394
                },
                "stance_score": -0.9985104513762053,
                "evidence_contribution": -0.8783774483711373,
                "combined_rank_score": 0.8796877861022949
              },
              {
                "id": 5662,
                "faiss_score": 0.8758388757705688,
                "faiss_rank": 19,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 65,
                "sentence": "Distributed systems research emphasizes the importance of understanding failure modes.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9825316071510315,
                  "neutral": 0.016489431262016296,
                  "support": 0.0009789773030206561
                },
                "stance_score": -0.9815526298480108,
                "evidence_contribution": -0.8596819518357272,
                "combined_rank_score": 0.8758388757705688
              },
              {
                "id": 3457,
                "faiss_score": 0.8790138959884644,
                "faiss_rank": 16,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 28,
                "sentence": "Fault tolerance is notably successful in computer applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.8814926743507385,
                  "neutral": 0.11563555151224136,
                  "support": 0.002871742006391287
                },
                "stance_score": -0.8786209323443472,
                "evidence_contribution": -0.7723200088370217,
                "combined_rank_score": 0.8790138959884644
              },
              {
                "id": 6619,
                "faiss_score": 0.884694516658783,
                "faiss_rank": 12,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 22,
                "sentence": "In distributed systems, it is often impossible to distinguish between a failed component and a slow or unreachable one.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8715810775756836,
                  "neutral": 0.12195269018411636,
                  "support": 0.006466217804700136
                },
                "stance_score": -0.8651148597709835,
                "evidence_contribution": -0.765362372719421,
                "combined_rank_score": 0.884694516658783
              },
              {
                "id": 3508,
                "faiss_score": 0.8738317489624023,
                "faiss_rank": 20,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 79,
                "sentence": "The basic characteristics of fault tolerance require: No single point of failure \u2013 If a system experiences a failure, it must continue to operate without interruption during the repair process.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.8368813395500183,
                  "neutral": 0.15880845487117767,
                  "support": 0.004310184624046087
                },
                "stance_score": -0.8325711549259722,
                "evidence_contribution": -0.7275271084446095,
                "combined_rank_score": 0.8738317489624023
              },
              {
                "id": 498,
                "faiss_score": 0.8943179845809937,
                "faiss_rank": 6,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 74,
                "sentence": "It can provide more reliability than a non-distributed system, as there is no single point of failure.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.7238815426826477,
                  "neutral": 0.25395071506500244,
                  "support": 0.022167732939124107
                },
                "stance_score": -0.7017138097435236,
                "evidence_contribution": -0.6275552800824789,
                "combined_rank_score": 0.8943179845809937
              },
              {
                "id": 6648,
                "faiss_score": 0.8767505288124084,
                "faiss_rank": 18,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 51,
                "sentence": "A highly reliable component does not guarantee a reliable system if integration is flawed.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.708969235420227,
                  "neutral": 0.2794010639190674,
                  "support": 0.011629695072770119
                },
                "stance_score": -0.6973395403474569,
                "evidence_contribution": -0.6113928107614347,
                "combined_rank_score": 0.8767505288124084
              },
              {
                "id": 3662,
                "faiss_score": 0.8928186893463135,
                "faiss_rank": 10,
                "doc_id": "wiki_Consensus_algorithm",
                "file_type": ".txt",
                "position": 71,
                "sentence": "In a fully asynchronous system there is no consensus solution that can tolerate one or more crash failures even when only requiring the non triviality property.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.620490550994873,
                  "neutral": 0.3692409098148346,
                  "support": 0.010268524289131165
                },
                "stance_score": -0.6102220267057419,
                "evidence_contribution": -0.5448176300936716,
                "combined_rank_score": 0.8928186893463135
              },
              {
                "id": 6665,
                "faiss_score": 0.9101653099060059,
                "faiss_rank": 1,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 68,
                "sentence": "Ultimately, fault tolerance and reliability are not properties that can be added as afterthoughts.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5150806307792664,
                  "neutral": 0.46868276596069336,
                  "support": 0.01623660698533058
                },
                "stance_score": -0.4988440237939358,
                "evidence_contribution": -0.4540305255111665,
                "combined_rank_score": 0.9101653099060059
              },
              {
                "id": 3482,
                "faiss_score": 0.9055246114730835,
                "faiss_rank": 3,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Providing fault-tolerant design for every component is normally not an option.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.4294501543045044,
                  "neutral": 0.508485734462738,
                  "support": 0.06206406280398369
                },
                "stance_score": -0.3673860915005207,
                "evidence_contribution": -0.3326771477666237,
                "combined_rank_score": 0.9055246114730835
              },
              {
                "id": 3588,
                "faiss_score": 0.9097967147827148,
                "faiss_rank": 2,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 159,
                "sentence": "There is a difference between fault tolerance and systems that rarely have problems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.19584187865257263,
                  "neutral": 0.7686963081359863,
                  "support": 0.03546185418963432
                },
                "stance_score": -0.1603800244629383,
                "evidence_contribution": -0.1459132193731527,
                "combined_rank_score": 0.9097967147827148
              }
            ],
            "neutral": [
              {
                "id": 3456,
                "faiss_score": 0.893700361251831,
                "faiss_rank": 9,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 27,
                "sentence": "It is helpful if the time between failures is as long as possible, but this is not specifically required in a fault-tolerant system.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.051901448518037796,
                  "neutral": 0.8763694167137146,
                  "support": 0.07172917574644089
                },
                "stance_score": 0.01982772722840309,
                "evidence_contribution": 0.01772004698682661,
                "combined_rank_score": 0.893700361251831
              },
              {
                "id": 5601,
                "faiss_score": 0.8898274898529053,
                "faiss_rank": 11,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "One defining characteristic of distributed systems is the absence of a global clock.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04679067060351372,
                  "neutral": 0.9044023752212524,
                  "support": 0.04880689084529877
                },
                "stance_score": 0.0020162202417850494,
                "evidence_contribution": 0.0017940881967382083,
                "combined_rank_score": 0.8898274898529053
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Distributed systems do not need fault tolerance mechanisms.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 3487,
                      "faiss_score": 0.8769917488098145,
                      "faiss_rank": 17,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 58,
                      "sentence": "Some components, like the drive shaft in a car, are not likely to fail, so no fault tolerance is needed.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.023633461445569992,
                        "neutral": 0.4047772288322449,
                        "support": 0.5715892910957336
                      },
                      "stance_score": 0.5479558296501637,
                      "evidence_contribution": 0.4805527413154298,
                      "combined_rank_score": 0.8769917488098145
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6665,
                      "faiss_score": 0.9101653099060059,
                      "faiss_rank": 1,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 68,
                      "sentence": "Ultimately, fault tolerance and reliability are not properties that can be added as afterthoughts.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.5150806307792664,
                        "neutral": 0.46868276596069336,
                        "support": 0.01623660698533058
                      },
                      "stance_score": -0.4988440237939358,
                      "evidence_contribution": -0.4540305255111665,
                      "combined_rank_score": 0.9101653099060059
                    },
                    {
                      "id": 3588,
                      "faiss_score": 0.9097967147827148,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 159,
                      "sentence": "There is a difference between fault tolerance and systems that rarely have problems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.19584187865257263,
                        "neutral": 0.7686963081359863,
                        "support": 0.03546185418963432
                      },
                      "stance_score": -0.1603800244629383,
                      "evidence_contribution": -0.1459132193731527,
                      "combined_rank_score": 0.9097967147827148
                    },
                    {
                      "id": 3482,
                      "faiss_score": 0.9055246114730835,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "Providing fault-tolerant design for every component is normally not an option.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.4294501543045044,
                        "neutral": 0.508485734462738,
                        "support": 0.06206406280398369
                      },
                      "stance_score": -0.3673860915005207,
                      "evidence_contribution": -0.3326771477666237,
                      "combined_rank_score": 0.9055246114730835
                    }
                  ],
                  "neutral": [
                    {
                      "id": 3456,
                      "faiss_score": 0.893700361251831,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "It is helpful if the time between failures is as long as possible, but this is not specifically required in a fault-tolerant system.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.051901448518037796,
                        "neutral": 0.8763694167137146,
                        "support": 0.07172917574644089
                      },
                      "stance_score": 0.01982772722840309,
                      "evidence_contribution": 0.01772004698682661,
                      "combined_rank_score": 0.893700361251831
                    },
                    {
                      "id": 5601,
                      "faiss_score": 0.8898274898529053,
                      "faiss_rank": 11,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 4,
                      "sentence": "One defining characteristic of distributed systems is the absence of a global clock.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.04679067060351372,
                        "neutral": 0.9044023752212524,
                        "support": 0.04880689084529877
                      },
                      "stance_score": 0.0020162202417850494,
                      "evidence_contribution": 0.0017940881967382083,
                      "combined_rank_score": 0.8898274898529053
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Quantum computers can function reliably without error correction.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Quantum computers can function reliably without error correction.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 9.52250000698392,
            "total": 9.52250000698392
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6553,
                "faiss_score": 0.9091418981552124,
                "faiss_rank": 1,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9906208515167236,
                  "neutral": 0.008175135590136051,
                  "support": 0.001204083557240665
                },
                "stance_score": -0.989416767959483,
                "evidence_contribution": -0.8995202384892796,
                "combined_rank_score": 0.9091418981552124
              },
              {
                "id": 671,
                "faiss_score": 0.9006523489952087,
                "faiss_rank": 2,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Scientists at Harvard University successfully created \"quantum circuits\" that correct errors more efficiently than alternative methods, which may potentially remove a major obstacle to practical quantum computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.998163640499115,
                  "neutral": 0.0014617514098063111,
                  "support": 0.00037455931305885315
                },
                "stance_score": -0.9977890811860561,
                "evidence_contribution": -0.8986610797719925,
                "combined_rank_score": 0.9006523489952087
              },
              {
                "id": 6549,
                "faiss_score": 0.895329475402832,
                "faiss_rank": 9,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "A central difficulty in quantum computing is noise.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9979390501976013,
                  "neutral": 0.0016882190247997642,
                  "support": 0.0003727333096321672
                },
                "stance_score": -0.9975663168879692,
                "evidence_contribution": -0.8931505271788407,
                "combined_rank_score": 0.895329475402832
              },
              {
                "id": 6561,
                "faiss_score": 0.8931423425674438,
                "faiss_rank": 16,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Small errors accumulate quickly in quantum circuits, limiting the depth of computations that can be performed reliably.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9992790818214417,
                  "neutral": 0.000551443372387439,
                  "support": 0.00016951408179011196
                },
                "stance_score": -0.9991095677396515,
                "evidence_contribution": -0.8923470598125386,
                "combined_rank_score": 0.8931423425674438
              },
              {
                "id": 4824,
                "faiss_score": 0.8938266038894653,
                "faiss_rank": 15,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 71,
                "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.976203203201294,
                  "neutral": 0.022158455103635788,
                  "support": 0.0016382795292884111
                },
                "stance_score": -0.9745649236720055,
                "evidence_contribution": -0.8710920559955447,
                "combined_rank_score": 0.8938266038894653
              },
              {
                "id": 6547,
                "faiss_score": 0.8988208174705505,
                "faiss_rank": 5,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "However, such algorithms rely on idealized assumptions about qubit coherence and error-free operations.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9536645412445068,
                  "neutral": 0.03877651318907738,
                  "support": 0.0075589134357869625
                },
                "stance_score": -0.9461056278087199,
                "evidence_contribution": -0.850379433800522,
                "combined_rank_score": 0.8988208174705505
              },
              {
                "id": 4862,
                "faiss_score": 0.9004368782043457,
                "faiss_rank": 4,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 109,
                "sentence": "Quantum error correction can be applied to quantum metrology.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.9318203926086426,
                  "neutral": 0.066192626953125,
                  "support": 0.0019869431853294373
                },
                "stance_score": -0.9298334494233131,
                "evidence_contribution": -0.8372563284487065,
                "combined_rank_score": 0.9004368782043457
              },
              {
                "id": 6554,
                "faiss_score": 0.8949320316314697,
                "faiss_rank": 10,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9315681457519531,
                  "neutral": 0.06641007959842682,
                  "support": 0.002021821215748787
                },
                "stance_score": -0.9295463245362043,
                "evidence_contribution": -0.8318807807127508,
                "combined_rank_score": 0.8949320316314697
              },
              {
                "id": 678,
                "faiss_score": 0.8949060440063477,
                "faiss_rank": 11,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 82,
                "sentence": "In principle, quantum encryption would be impossible to decode even with a quantum computer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.8523216843605042,
                  "neutral": 0.1419842392206192,
                  "support": 0.005694021470844746
                },
                "stance_score": -0.8466276628896594,
                "evidence_contribution": -0.7576522125429248,
                "combined_rank_score": 0.8949060440063477
              },
              {
                "id": 793,
                "faiss_score": 0.8939269781112671,
                "faiss_rank": 13,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.7898147106170654,
                  "neutral": 0.20260053873062134,
                  "support": 0.007584744598716497
                },
                "stance_score": -0.7822299660183489,
                "evidence_contribution": -0.6992564697108619,
                "combined_rank_score": 0.8939269781112671
              },
              {
                "id": 803,
                "faiss_score": 0.8927560448646545,
                "faiss_rank": 19,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 207,
                "sentence": "A practical quantum computer must use a physical system as a programmable quantum register.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.7235676050186157,
                  "neutral": 0.2637607157230377,
                  "support": 0.012671682983636856
                },
                "stance_score": -0.7108959220349789,
                "evidence_contribution": -0.6346566316663595,
                "combined_rank_score": 0.8927560448646545
              },
              {
                "id": 820,
                "faiss_score": 0.8958958387374878,
                "faiss_rank": 7,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 224,
                "sentence": "In other words, quantum computers provide no additional power over classical computers in terms of computability.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.5178208947181702,
                  "neutral": 0.4740683436393738,
                  "support": 0.008110759779810905
                },
                "stance_score": -0.5097101349383593,
                "evidence_contribution": -0.45664718885359945,
                "combined_rank_score": 0.8958958387374878
              }
            ],
            "neutral": [
              {
                "id": 4930,
                "faiss_score": 0.8965480923652649,
                "faiss_rank": 6,
                "doc_id": "wiki_Computational_complexity",
                "file_type": ".txt",
                "position": 60,
                "sentence": "A quantum computer is a computer whose model of computation is based on quantum mechanics.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Computational_complexity",
                "primary_category": "all articles containing potentially dated statements",
                "probs": {
                  "contradict": 0.010156561620533466,
                  "neutral": 0.9860877394676208,
                  "support": 0.0037557336036115885
                },
                "stance_score": -0.006400828016921878,
                "evidence_contribution": -0.005738650148129451,
                "combined_rank_score": 0.8965480923652649
              },
              {
                "id": 823,
                "faiss_score": 0.8930922746658325,
                "faiss_rank": 17,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 227,
                "sentence": "For instance, it is known that quantum computers can efficiently factor integers, while this is not believed to be the case for classical computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.16369999945163727,
                  "neutral": 0.7589327096939087,
                  "support": 0.07736729085445404
                },
                "stance_score": -0.08633270859718323,
                "evidence_contribution": -0.07710307509912084,
                "combined_rank_score": 0.8930922746658325
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Quantum computers can function reliably without error correction.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6553,
                      "faiss_score": 0.9091418981552124,
                      "faiss_rank": 1,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9906208515167236,
                        "neutral": 0.008175135590136051,
                        "support": 0.001204083557240665
                      },
                      "stance_score": -0.989416767959483,
                      "evidence_contribution": -0.8995202384892796,
                      "combined_rank_score": 0.9091418981552124
                    },
                    {
                      "id": 671,
                      "faiss_score": 0.9006523489952087,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "Scientists at Harvard University successfully created \"quantum circuits\" that correct errors more efficiently than alternative methods, which may potentially remove a major obstacle to practical quantum computers.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.998163640499115,
                        "neutral": 0.0014617514098063111,
                        "support": 0.00037455931305885315
                      },
                      "stance_score": -0.9977890811860561,
                      "evidence_contribution": -0.8986610797719925,
                      "combined_rank_score": 0.9006523489952087
                    },
                    {
                      "id": 4862,
                      "faiss_score": 0.9004368782043457,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 109,
                      "sentence": "Quantum error correction can be applied to quantum metrology.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.9318203926086426,
                        "neutral": 0.066192626953125,
                        "support": 0.0019869431853294373
                      },
                      "stance_score": -0.9298334494233131,
                      "evidence_contribution": -0.8372563284487065,
                      "combined_rank_score": 0.9004368782043457
                    }
                  ],
                  "neutral": [
                    {
                      "id": 4930,
                      "faiss_score": 0.8965480923652649,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Computational_complexity",
                      "file_type": ".txt",
                      "position": 60,
                      "sentence": "A quantum computer is a computer whose model of computation is based on quantum mechanics.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Computational_complexity",
                      "primary_category": "all articles containing potentially dated statements",
                      "probs": {
                        "contradict": 0.010156561620533466,
                        "neutral": 0.9860877394676208,
                        "support": 0.0037557336036115885
                      },
                      "stance_score": -0.006400828016921878,
                      "evidence_contribution": -0.005738650148129451,
                      "combined_rank_score": 0.8965480923652649
                    },
                    {
                      "id": 823,
                      "faiss_score": 0.8930922746658325,
                      "faiss_rank": 17,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 227,
                      "sentence": "For instance, it is known that quantum computers can efficiently factor integers, while this is not believed to be the case for classical computers.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.16369999945163727,
                        "neutral": 0.7589327096939087,
                        "support": 0.07736729085445404
                      },
                      "stance_score": -0.08633270859718323,
                      "evidence_contribution": -0.07710307509912084,
                      "combined_rank_score": 0.8930922746658325
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Scaling neural networks has no impact on performance improvements.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Scaling neural networks has no impact on performance improvements.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.1742834868029015,
            "contradict": 12.852074850074176,
            "total": 13.026358336877077
          },
          "evidence": {
            "supporting": [
              {
                "id": 2421,
                "faiss_score": 0.8671966791152954,
                "faiss_rank": 7,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 16,
                "sentence": "Beyond that, more layers do not add to the function approximator ability of the network.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.05025213584303856,
                  "neutral": 0.6985222697257996,
                  "support": 0.2512255609035492
                },
                "stance_score": 0.20097342506051064,
                "evidence_contribution": 0.1742834868029015,
                "combined_rank_score": 0.8671966791152954
              }
            ],
            "contradicting": [
              {
                "id": 6125,
                "faiss_score": 0.8836263418197632,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Over the past decade, scaling has emerged as one of the most reliable drivers of progress in machine learning systems, particularly in deep learning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9991558790206909,
                  "neutral": 0.0007174470811150968,
                  "support": 0.0001267673069378361
                },
                "stance_score": -0.9990291117137531,
                "evidence_contribution": -0.8827684393550712,
                "combined_rank_score": 0.8836263418197632
              },
              {
                "id": 2985,
                "faiss_score": 0.8640903234481812,
                "faiss_rank": 11,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 40,
                "sentence": "Its parallelizability was an important factor to its widespread use in large neural networks.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.9947782754898071,
                  "neutral": 0.0048780133947730064,
                  "support": 0.0003436481347307563
                },
                "stance_score": -0.9944346273550764,
                "evidence_contribution": -0.8592813387993194,
                "combined_rank_score": 0.8640903234481812
              },
              {
                "id": 6135,
                "faiss_score": 0.867847204208374,
                "faiss_rank": 6,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 11,
                "sentence": "Data scaling plays an equally important role.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9858559370040894,
                  "neutral": 0.013569191098213196,
                  "support": 0.0005748308030888438
                },
                "stance_score": -0.9852811062010005,
                "evidence_contribution": -0.8550734533758724,
                "combined_rank_score": 0.867847204208374
              },
              {
                "id": 6124,
                "faiss_score": 0.8662250638008118,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9827069044113159,
                  "neutral": 0.016630327329039574,
                  "support": 0.0006628449191339314
                },
                "stance_score": -0.982044059492182,
                "evidence_contribution": -0.8506711780888235,
                "combined_rank_score": 0.8662250638008118
              },
              {
                "id": 6352,
                "faiss_score": 0.8593572378158569,
                "faiss_rank": 14,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 91,
                "sentence": "Communication overhead, memory constraints, and numerical stability all play important roles in large-scale training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9893548488616943,
                  "neutral": 0.010181973688304424,
                  "support": 0.0004631532356142998
                },
                "stance_score": -0.98889169562608,
                "evidence_contribution": -0.8498112360522673,
                "combined_rank_score": 0.8593572378158569
              },
              {
                "id": 6165,
                "faiss_score": 0.8637666702270508,
                "faiss_rank": 12,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 41,
                "sentence": "From a systems perspective, scaling reshapes the entire machine learning pipeline.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9798367619514465,
                  "neutral": 0.019408749416470528,
                  "support": 0.0007544597610831261
                },
                "stance_score": -0.9790823021903634,
                "evidence_contribution": -0.8456986600412053,
                "combined_rank_score": 0.8637666702270508
              },
              {
                "id": 2393,
                "faiss_score": 0.8614013195037842,
                "faiss_rank": 13,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 324,
                "sentence": "Large and effective neural networks require considerable computing resources.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.9643079042434692,
                  "neutral": 0.03442241623997688,
                  "support": 0.0012696814956143498
                },
                "stance_score": -0.9630382227478549,
                "evidence_contribution": -0.8295623958075814,
                "combined_rank_score": 0.8614013195037842
              },
              {
                "id": 6142,
                "faiss_score": 0.8561908602714539,
                "faiss_rank": 20,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8800991773605347,
                  "neutral": 0.11783106625080109,
                  "support": 0.0020697445143014193
                },
                "stance_score": -0.8780294328462332,
                "evidence_contribution": -0.7517607754522732,
                "combined_rank_score": 0.8561908602714539
              },
              {
                "id": 6137,
                "faiss_score": 0.8579269051551819,
                "faiss_rank": 17,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8592372536659241,
                  "neutral": 0.1386318802833557,
                  "support": 0.0021308623254299164
                },
                "stance_score": -0.8571063913404942,
                "evidence_contribution": -0.7353346337114763,
                "combined_rank_score": 0.8579269051551819
              },
              {
                "id": 1541,
                "faiss_score": 0.868371844291687,
                "faiss_rank": 5,
                "doc_id": "wiki_Loss_function",
                "file_type": ".txt",
                "position": 41,
                "sentence": "The choice of a loss function is not arbitrary.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Loss_function",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.84165358543396,
                  "neutral": 0.1532692164182663,
                  "support": 0.005077296867966652
                },
                "stance_score": -0.8365762885659933,
                "evidence_contribution": -0.7264592945927462,
                "combined_rank_score": 0.868371844291687
              },
              {
                "id": 6161,
                "faiss_score": 0.8589440584182739,
                "faiss_rank": 15,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "Scaling affects robustness and generalization in nontrivial ways.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8270083069801331,
                  "neutral": 0.17144151031970978,
                  "support": 0.001550139975734055
                },
                "stance_score": -0.825458167004399,
                "evidence_contribution": -0.7090223880212678,
                "combined_rank_score": 0.8589440584182739
              },
              {
                "id": 6126,
                "faiss_score": 0.8569101095199585,
                "faiss_rank": 19,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "Rather than relying on narrowly optimized architectures or handcrafted features, many modern systems achieve strong performance by training large models on vast amounts of data using substantial compute.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8216933012008667,
                  "neutral": 0.17589551210403442,
                  "support": 0.002411083085462451
                },
                "stance_score": -0.8192822181154042,
                "evidence_contribution": -0.7020512152530256,
                "combined_rank_score": 0.8569101095199585
              },
              {
                "id": 2711,
                "faiss_score": 0.8573455214500427,
                "faiss_rank": 18,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 306,
                "sentence": "Using physics informed neural networks does not require the often expensive mesh generation that conventional CFD methods rely on.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.8062475323677063,
                  "neutral": 0.1896733045578003,
                  "support": 0.004079161211848259
                },
                "stance_score": -0.802168371155858,
                "evidence_contribution": -0.6877354604593505,
                "combined_rank_score": 0.8573455214500427
              },
              {
                "id": 6131,
                "faiss_score": 0.8818397521972656,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7417044043540955,
                  "neutral": 0.25547850131988525,
                  "support": 0.002817087108269334
                },
                "stance_score": -0.7388873172458261,
                "evidence_contribution": -0.6515802087417617,
                "combined_rank_score": 0.8818397521972656
              },
              {
                "id": 2094,
                "faiss_score": 0.8585313558578491,
                "faiss_rank": 16,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 25,
                "sentence": "The first perceptrons did not have adaptive hidden units.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.7615829706192017,
                  "neutral": 0.23416003584861755,
                  "support": 0.004257057327777147
                },
                "stance_score": -0.7573259132914245,
                "evidence_contribution": -0.6501880431643705,
                "combined_rank_score": 0.8585313558578491
              },
              {
                "id": 6128,
                "faiss_score": 0.8699010610580444,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "These trends have been observed across different domains and architectures, suggesting that scaling captures general properties of learning systems rather than task-specific quirks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7391960620880127,
                  "neutral": 0.25634506344795227,
                  "support": 0.004458927549421787
                },
                "stance_score": -0.7347371345385909,
                "evidence_contribution": -0.6391486129338674,
                "combined_rank_score": 0.8699010610580444
              },
              {
                "id": 6044,
                "faiss_score": 0.8642265796661377,
                "faiss_rank": 10,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.727155864238739,
                  "neutral": 0.2699514925479889,
                  "support": 0.0028926548548042774
                },
                "stance_score": -0.7242632093839347,
                "evidence_contribution": -0.6259275162238976,
                "combined_rank_score": 0.8642265796661377
              }
            ],
            "neutral": [
              {
                "id": 2620,
                "faiss_score": 0.8775732517242432,
                "faiss_rank": 3,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 215,
                "sentence": "It doesn't require learning rates or randomized initial weights.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.06666158139705658,
                  "neutral": 0.8607234954833984,
                  "support": 0.0726148784160614
                },
                "stance_score": 0.005953297019004822,
                "evidence_contribution": 0.005224454223448305,
                "combined_rank_score": 0.8775732517242432
              },
              {
                "id": 5910,
                "faiss_score": 0.8651031255722046,
                "faiss_rank": 9,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 5,
                "sentence": "These techniques do not change the underlying task but alter how the model represents and computes its function.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.07155194133520126,
                  "neutral": 0.9201792478561401,
                  "support": 0.008268792182207108
                },
                "stance_score": -0.06328314915299416,
                "evidence_contribution": -0.054746450128307256,
                "combined_rank_score": 0.8651031255722046
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Scaling neural networks has no impact on performance improvements.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 2421,
                      "faiss_score": 0.8671966791152954,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 16,
                      "sentence": "Beyond that, more layers do not add to the function approximator ability of the network.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.05025213584303856,
                        "neutral": 0.6985222697257996,
                        "support": 0.2512255609035492
                      },
                      "stance_score": 0.20097342506051064,
                      "evidence_contribution": 0.1742834868029015,
                      "combined_rank_score": 0.8671966791152954
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6125,
                      "faiss_score": 0.8836263418197632,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 1,
                      "sentence": "Over the past decade, scaling has emerged as one of the most reliable drivers of progress in machine learning systems, particularly in deep learning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9991558790206909,
                        "neutral": 0.0007174470811150968,
                        "support": 0.0001267673069378361
                      },
                      "stance_score": -0.9990291117137531,
                      "evidence_contribution": -0.8827684393550712,
                      "combined_rank_score": 0.8836263418197632
                    },
                    {
                      "id": 6131,
                      "faiss_score": 0.8818397521972656,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.7417044043540955,
                        "neutral": 0.25547850131988525,
                        "support": 0.002817087108269334
                      },
                      "stance_score": -0.7388873172458261,
                      "evidence_contribution": -0.6515802087417617,
                      "combined_rank_score": 0.8818397521972656
                    },
                    {
                      "id": 6128,
                      "faiss_score": 0.8699010610580444,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 4,
                      "sentence": "These trends have been observed across different domains and architectures, suggesting that scaling captures general properties of learning systems rather than task-specific quirks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.7391960620880127,
                        "neutral": 0.25634506344795227,
                        "support": 0.004458927549421787
                      },
                      "stance_score": -0.7347371345385909,
                      "evidence_contribution": -0.6391486129338674,
                      "combined_rank_score": 0.8699010610580444
                    }
                  ],
                  "neutral": [
                    {
                      "id": 2620,
                      "faiss_score": 0.8775732517242432,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 215,
                      "sentence": "It doesn't require learning rates or randomized initial weights.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.06666158139705658,
                        "neutral": 0.8607234954833984,
                        "support": 0.0726148784160614
                      },
                      "stance_score": 0.005953297019004822,
                      "evidence_contribution": 0.005224454223448305,
                      "combined_rank_score": 0.8775732517242432
                    },
                    {
                      "id": 5910,
                      "faiss_score": 0.8651031255722046,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 5,
                      "sentence": "These techniques do not change the underlying task but alter how the model represents and computes its function.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.07155194133520126,
                        "neutral": 0.9201792478561401,
                        "support": 0.008268792182207108
                      },
                      "stance_score": -0.06328314915299416,
                      "evidence_contribution": -0.054746450128307256,
                      "combined_rank_score": 0.8651031255722046
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Larger datasets always reduce overfitting in machine learning models.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Larger datasets reduce overfitting in machine learning models.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 1.792453588613567,
            "total": 1.792453588613567
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6136,
                "faiss_score": 0.912011444568634,
                "faiss_rank": 5,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8988689184188843,
                  "neutral": 0.0965760350227356,
                  "support": 0.004554989747703075
                },
                "stance_score": -0.8943139286711812,
                "evidence_contribution": -0.8156245379852542,
                "combined_rank_score": 0.912011444568634
              },
              {
                "id": 1359,
                "faiss_score": 0.8930516242980957,
                "faiss_rank": 17,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 9,
                "sentence": "With so many candidate models, overfitting is a real danger.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.5918819904327393,
                  "neutral": 0.40306854248046875,
                  "support": 0.005049500148743391
                },
                "stance_score": -0.5868324902839959,
                "evidence_contribution": -0.524071708639019,
                "combined_rank_score": 0.8930516242980957
              },
              {
                "id": 6134,
                "faiss_score": 0.8903393745422363,
                "faiss_rank": 20,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 10,
                "sentence": "Large models are also more sensitive to optimization choices and require careful tuning to train effectively.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5185151100158691,
                  "neutral": 0.4714919924736023,
                  "support": 0.009992904961109161
                },
                "stance_score": -0.50852220505476,
                "evidence_contribution": -0.45275734198929385,
                "combined_rank_score": 0.8903393745422363
              }
            ],
            "neutral": [
              {
                "id": 6137,
                "faiss_score": 0.9167360067367554,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009765849681571126,
                  "neutral": 0.9913299083709717,
                  "support": 0.007693538907915354
                },
                "stance_score": 0.006716953939758241,
                "evidence_contribution": 0.0061576735321686865,
                "combined_rank_score": 0.9167360067367554
              },
              {
                "id": 1311,
                "faiss_score": 0.9151633977890015,
                "faiss_rank": 2,
                "doc_id": "wiki_Statistical_learning_theory",
                "file_type": ".txt",
                "position": 21,
                "sentence": "In machine learning problems, a major problem that arises is that of overfitting.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.029516814276576042,
                  "neutral": 0.9693301320075989,
                  "support": 0.0011531136697158217
                },
                "stance_score": -0.02836370060686022,
                "evidence_contribution": -0.025957420621244162,
                "combined_rank_score": 0.9151633977890015
              },
              {
                "id": 1218,
                "faiss_score": 0.9120239019393921,
                "faiss_rank": 3,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 243,
                "sentence": "Overfitting is something to watch out for when training a machine learning model.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.01058642566204071,
                  "neutral": 0.9885988235473633,
                  "support": 0.0008147225598804653
                },
                "stance_score": -0.009771703102160245,
                "evidence_contribution": -0.008912026791825449,
                "combined_rank_score": 0.9120239019393921
              }
            ]
          }
        },
        {
          "subclaim": "Machine learning models can suffer from overfitting.",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 5.888961360786536,
            "contradict": 0.0,
            "total": 5.888961360786536
          },
          "evidence": {
            "supporting": [
              {
                "id": 1218,
                "faiss_score": 0.9458591341972351,
                "faiss_rank": 1,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 243,
                "sentence": "Overfitting is something to watch out for when training a machine learning model.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0004957018536515534,
                  "neutral": 0.013847441412508488,
                  "support": 0.9856568574905396
                },
                "stance_score": 0.985161155636888,
                "evidence_contribution": 0.9318236777154545,
                "combined_rank_score": 0.9458591341972351
              },
              {
                "id": 1311,
                "faiss_score": 0.9410011172294617,
                "faiss_rank": 3,
                "doc_id": "wiki_Statistical_learning_theory",
                "file_type": ".txt",
                "position": 21,
                "sentence": "In machine learning problems, a major problem that arises is that of overfitting.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0006119771278463304,
                  "neutral": 0.030699515715241432,
                  "support": 0.9686884880065918
                },
                "stance_score": 0.9680765108787455,
                "evidence_contribution": 0.9109610783004986,
                "combined_rank_score": 0.9410011172294617
              },
              {
                "id": 2607,
                "faiss_score": 0.9083086252212524,
                "faiss_rank": 16,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 202,
                "sentence": "DNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0009529117960482836,
                  "neutral": 0.06537891179323196,
                  "support": 0.9336680769920349
                },
                "stance_score": 0.9327151651959866,
                "evidence_contribution": 0.84719322942218,
                "combined_rank_score": 0.9083086252212524
              },
              {
                "id": 1361,
                "faiss_score": 0.9267687797546387,
                "faiss_rank": 5,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 11,
                "sentence": "In regression analysis, overfitting occurs frequently.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0014857416972517967,
                  "neutral": 0.11948006600141525,
                  "support": 0.8790342211723328
                },
                "stance_score": 0.877548479475081,
                "evidence_contribution": 0.8132845334986594,
                "combined_rank_score": 0.9267687797546387
              },
              {
                "id": 6220,
                "faiss_score": 0.9114083647727966,
                "faiss_rank": 14,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 28,
                "sentence": "Modern models often have far more parameters than necessary to fit training data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001182478736154735,
                  "neutral": 0.5505284070968628,
                  "support": 0.448289155960083
                },
                "stance_score": 0.4471066772239283,
                "evidence_contribution": 0.40749676556765907,
                "combined_rank_score": 0.9114083647727966
              },
              {
                "id": 1326,
                "faiss_score": 0.9078381061553955,
                "faiss_rank": 17,
                "doc_id": "wiki_Bias\u2013variance_tradeoff",
                "file_type": ".txt",
                "position": 3,
                "sentence": "High-variance learning methods may be able to represent their training set well but are at risk of overfitting to noisy or unrepresentative training data.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0015318793011829257,
                  "neutral": 0.566816508769989,
                  "support": 0.43165162205696106
                },
                "stance_score": 0.43011974275577813,
                "evidence_contribution": 0.3904790926834515,
                "combined_rank_score": 0.9078381061553955
              },
              {
                "id": 1377,
                "faiss_score": 0.9115912914276123,
                "faiss_rank": 13,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Overfitting is especially likely in cases where learning was performed too long or where training examples are rare, causing the learner to adjust to very specific random features of the training data that have no causal relation to the target function.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0014486738946288824,
                  "neutral": 0.6907151937484741,
                  "support": 0.3078361749649048
                },
                "stance_score": 0.3063875010702759,
                "evidence_contribution": 0.27930017777793176,
                "combined_rank_score": 0.9115912914276123
              },
              {
                "id": 5988,
                "faiss_score": 0.9075533747673035,
                "faiss_rank": 18,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Overfitting occurs when a model learns patterns specific to the training data that do not generalize.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0010803007753565907,
                  "neutral": 0.7501620054244995,
                  "support": 0.24875766038894653
                },
                "stance_score": 0.24767735961358994,
                "evidence_contribution": 0.22478042357076858,
                "combined_rank_score": 0.9075533747673035
              },
              {
                "id": 6309,
                "faiss_score": 0.9066196084022522,
                "faiss_rank": 19,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "High-capacity models are prone to overfitting when data is scarce, and strong generalization typically requires pretraining on massive corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0012985646026208997,
                  "neutral": 0.762039303779602,
                  "support": 0.2366621494293213
                },
                "stance_score": 0.2353635848267004,
                "evidence_contribution": 0.21338524110773338,
                "combined_rank_score": 0.9066196084022522
              },
              {
                "id": 6136,
                "faiss_score": 0.9201747179031372,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0011870772577822208,
                  "neutral": 0.7740406394004822,
                  "support": 0.22477230429649353
                },
                "stance_score": 0.2235852270387113,
                "evidence_contribution": 0.20573747321765506,
                "combined_rank_score": 0.9201747179031372
              },
              {
                "id": 1359,
                "faiss_score": 0.9295470118522644,
                "faiss_rank": 4,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 9,
                "sentence": "With so many candidate models, overfitting is a real danger.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0013157170033082366,
                  "neutral": 0.8337580561637878,
                  "support": 0.164926216006279
                },
                "stance_score": 0.16361049900297076,
                "evidence_contribution": 0.15208365045586936,
                "combined_rank_score": 0.9295470118522644
              },
              {
                "id": 1356,
                "faiss_score": 0.9041652679443359,
                "faiss_rank": 20,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 6,
                "sentence": "Overfitting is more likely to be a serious concern when there is little theory available to guide the analysis, in part because then there tend to be a large number of models to select from.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0012551085092127323,
                  "neutral": 0.8333354592323303,
                  "support": 0.16540944576263428
                },
                "stance_score": 0.16415433725342155,
                "evidence_contribution": 0.14842265032696478,
                "combined_rank_score": 0.9041652679443359
              },
              {
                "id": 1386,
                "faiss_score": 0.9205211400985718,
                "faiss_rank": 7,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 36,
                "sentence": "The most obvious consequence of overfitting is poor performance on the validation dataset.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0017709588864818215,
                  "neutral": 0.8408529758453369,
                  "support": 0.15737611055374146
                },
                "stance_score": 0.15560515166725963,
                "evidence_contribution": 0.143237831617957,
                "combined_rank_score": 0.9205211400985718
              },
              {
                "id": 169,
                "faiss_score": 0.913119912147522,
                "faiss_rank": 10,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 60,
                "sentence": "But if the hypothesis is too complex, then the model is subject to overfitting and generalisation will be poorer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.001047988422214985,
                  "neutral": 0.8687575459480286,
                  "support": 0.1301945149898529
                },
                "stance_score": 0.12914652656763792,
                "evidence_contribution": 0.11792626499359915,
                "combined_rank_score": 0.913119912147522
              },
              {
                "id": 1314,
                "faiss_score": 0.9098666310310364,
                "faiss_rank": 15,
                "doc_id": "wiki_Statistical_learning_theory",
                "file_type": ".txt",
                "position": 24,
                "sentence": "Overfitting is symptomatic of unstable solutions; a small perturbation in the training set data would cause a large variation in the learned function.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0020382176153361797,
                  "neutral": 0.8828858137130737,
                  "support": 0.1150759607553482
                },
                "stance_score": 0.11303774314001203,
                "evidence_contribution": 0.10284927053015439,
                "combined_rank_score": 0.9098666310310364
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 5990,
                "faiss_score": 0.9263968467712402,
                "faiss_rank": 6,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 16,
                "sentence": "Overfitting can arise from excessive model capacity, insufficient data, or overly aggressive optimization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001319977454841137,
                  "neutral": 0.9183411002159119,
                  "support": 0.08033887296915054
                },
                "stance_score": 0.0790188955143094,
                "evidence_contribution": 0.07320285563980233,
                "combined_rank_score": 0.9263968467712402
              },
              {
                "id": 2606,
                "faiss_score": 0.919596254825592,
                "faiss_rank": 9,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 201,
                "sentence": "Two common issues are overfitting and computation time.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0011310025583952665,
                  "neutral": 0.9234166741371155,
                  "support": 0.07545234262943268
                },
                "stance_score": 0.07432134007103741,
                "evidence_contribution": 0.0683456259829452,
                "combined_rank_score": 0.919596254825592
              },
              {
                "id": 5805,
                "faiss_score": 0.9124560952186584,
                "faiss_rank": 12,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 53,
                "sentence": "If it is too high, the model may overfit.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0010165415005758405,
                  "neutral": 0.9106842875480652,
                  "support": 0.08829912543296814
                },
                "stance_score": 0.0872825839323923,
                "evidence_contribution": 0.0796415257155455,
                "combined_rank_score": 0.9124560952186584
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Machine learning models can suffer from overfitting.",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 1218,
                      "faiss_score": 0.9458591341972351,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 243,
                      "sentence": "Overfitting is something to watch out for when training a machine learning model.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.0004957018536515534,
                        "neutral": 0.013847441412508488,
                        "support": 0.9856568574905396
                      },
                      "stance_score": 0.985161155636888,
                      "evidence_contribution": 0.9318236777154545,
                      "combined_rank_score": 0.9458591341972351
                    },
                    {
                      "id": 1311,
                      "faiss_score": 0.9410011172294617,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Statistical_learning_theory",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "In machine learning problems, a major problem that arises is that of overfitting.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.0006119771278463304,
                        "neutral": 0.030699515715241432,
                        "support": 0.9686884880065918
                      },
                      "stance_score": 0.9680765108787455,
                      "evidence_contribution": 0.9109610783004986,
                      "combined_rank_score": 0.9410011172294617
                    },
                    {
                      "id": 1359,
                      "faiss_score": 0.9295470118522644,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Overfitting",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "With so many candidate models, overfitting is a real danger.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.0013157170033082366,
                        "neutral": 0.8337580561637878,
                        "support": 0.164926216006279
                      },
                      "stance_score": 0.16361049900297076,
                      "evidence_contribution": 0.15208365045586936,
                      "combined_rank_score": 0.9295470118522644
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 5990,
                      "faiss_score": 0.9263968467712402,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_evaluation_and_generalization.txt",
                      "file_type": ".txt",
                      "position": 16,
                      "sentence": "Overfitting can arise from excessive model capacity, insufficient data, or overly aggressive optimization.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001319977454841137,
                        "neutral": 0.9183411002159119,
                        "support": 0.08033887296915054
                      },
                      "stance_score": 0.0790188955143094,
                      "evidence_contribution": 0.07320285563980233,
                      "combined_rank_score": 0.9263968467712402
                    },
                    {
                      "id": 2606,
                      "faiss_score": 0.919596254825592,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 201,
                      "sentence": "Two common issues are overfitting and computation time.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.0011310025583952665,
                        "neutral": 0.9234166741371155,
                        "support": 0.07545234262943268
                      },
                      "stance_score": 0.07432134007103741,
                      "evidence_contribution": 0.0683456259829452,
                      "combined_rank_score": 0.919596254825592
                    },
                    {
                      "id": 5805,
                      "faiss_score": 0.9124560952186584,
                      "faiss_rank": 12,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "If it is too high, the model may overfit.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0010165415005758405,
                        "neutral": 0.9106842875480652,
                        "support": 0.08829912543296814
                      },
                      "stance_score": 0.0872825839323923,
                      "evidence_contribution": 0.0796415257155455,
                      "combined_rank_score": 0.9124560952186584
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Larger datasets reduce overfitting in machine learning models.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6136,
                      "faiss_score": 0.912011444568634,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 12,
                      "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.8988689184188843,
                        "neutral": 0.0965760350227356,
                        "support": 0.004554989747703075
                      },
                      "stance_score": -0.8943139286711812,
                      "evidence_contribution": -0.8156245379852542,
                      "combined_rank_score": 0.912011444568634
                    },
                    {
                      "id": 1359,
                      "faiss_score": 0.8930516242980957,
                      "faiss_rank": 17,
                      "doc_id": "wiki_Overfitting",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "With so many candidate models, overfitting is a real danger.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.5918819904327393,
                        "neutral": 0.40306854248046875,
                        "support": 0.005049500148743391
                      },
                      "stance_score": -0.5868324902839959,
                      "evidence_contribution": -0.524071708639019,
                      "combined_rank_score": 0.8930516242980957
                    },
                    {
                      "id": 6134,
                      "faiss_score": 0.8903393745422363,
                      "faiss_rank": 20,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 10,
                      "sentence": "Large models are also more sensitive to optimization choices and require careful tuning to train effectively.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.5185151100158691,
                        "neutral": 0.4714919924736023,
                        "support": 0.009992904961109161
                      },
                      "stance_score": -0.50852220505476,
                      "evidence_contribution": -0.45275734198929385,
                      "combined_rank_score": 0.8903393745422363
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6137,
                      "faiss_score": 0.9167360067367554,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0009765849681571126,
                        "neutral": 0.9913299083709717,
                        "support": 0.007693538907915354
                      },
                      "stance_score": 0.006716953939758241,
                      "evidence_contribution": 0.0061576735321686865,
                      "combined_rank_score": 0.9167360067367554
                    },
                    {
                      "id": 1311,
                      "faiss_score": 0.9151633977890015,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Statistical_learning_theory",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "In machine learning problems, a major problem that arises is that of overfitting.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.029516814276576042,
                        "neutral": 0.9693301320075989,
                        "support": 0.0011531136697158217
                      },
                      "stance_score": -0.02836370060686022,
                      "evidence_contribution": -0.025957420621244162,
                      "combined_rank_score": 0.9151633977890015
                    },
                    {
                      "id": 1218,
                      "faiss_score": 0.9120239019393921,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 243,
                      "sentence": "Overfitting is something to watch out for when training a machine learning model.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.01058642566204071,
                        "neutral": 0.9885988235473633,
                        "support": 0.0008147225598804653
                      },
                      "stance_score": -0.009771703102160245,
                      "evidence_contribution": -0.008912026791825449,
                      "combined_rank_score": 0.9120239019393921
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Transformer models eliminate the need for optimization techniques.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Transformer models exist",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 10.965940800382477,
            "contradict": 0.0,
            "total": 10.965940800382477
          },
          "evidence": {
            "supporting": [
              {
                "id": 6304,
                "faiss_score": 0.9101985692977905,
                "faiss_rank": 2,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 43,
                "sentence": "To address these issues, numerous variants of the transformer architecture have been proposed.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004565074574202299,
                  "neutral": 0.17873318493366241,
                  "support": 0.8167017102241516
                },
                "stance_score": 0.8121366356499493,
                "evidence_contribution": 0.7392056038429049,
                "combined_rank_score": 0.9101985692977905
              },
              {
                "id": 6298,
                "faiss_score": 0.8935939073562622,
                "faiss_rank": 9,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "Models based on transformers achieved state-of-the-art performance in translation, summarization, language modeling, and many other tasks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0069143869914114475,
                  "neutral": 0.1628517508506775,
                  "support": 0.8302338123321533
                },
                "stance_score": 0.8233194253407419,
                "evidence_contribution": 0.735713222292546,
                "combined_rank_score": 0.8935939073562622
              },
              {
                "id": 1759,
                "faiss_score": 0.9132465124130249,
                "faiss_rank": 1,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 27,
                "sentence": "As of 2024, the largest and most capable models are all based on the transformer architecture.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.011396590620279312,
                  "neutral": 0.17400501668453217,
                  "support": 0.8145983815193176
                },
                "stance_score": 0.8032017908990383,
                "evidence_contribution": 0.7335212343024424,
                "combined_rank_score": 0.9132465124130249
              },
              {
                "id": 6392,
                "faiss_score": 0.8948999643325806,
                "faiss_rank": 8,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 131,
                "sentence": "As transformer-based models become more capable, concerns about misuse and unintended consequences grow.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.018157165497541428,
                  "neutral": 0.15676067769527435,
                  "support": 0.8250821828842163
                },
                "stance_score": 0.8069250173866749,
                "evidence_contribution": 0.7221171692784023,
                "combined_rank_score": 0.8948999643325806
              },
              {
                "id": 6300,
                "faiss_score": 0.8872029781341553,
                "faiss_rank": 15,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04400254786014557,
                  "neutral": 0.12755577266216278,
                  "support": 0.8284416794776917
                },
                "stance_score": 0.7844391316175461,
                "evidence_contribution": 0.6959567337360575,
                "combined_rank_score": 0.8872029781341553
              },
              {
                "id": 6367,
                "faiss_score": 0.8867349624633789,
                "faiss_rank": 17,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 106,
                "sentence": "Interpretability remains a challenging aspect of transformer-based models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.021283458918333054,
                  "neutral": 0.21903814375400543,
                  "support": 0.7596783638000488
                },
                "stance_score": 0.7383949048817158,
                "evidence_contribution": 0.6547605782634385,
                "combined_rank_score": 0.8867349624633789
              },
              {
                "id": 2987,
                "faiss_score": 0.8926093578338623,
                "faiss_rank": 12,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Transformer architecture is now used alongside many generative models that contribute to the ongoing AI boom.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.022291269153356552,
                  "neutral": 0.24094286561012268,
                  "support": 0.7367658615112305
                },
                "stance_score": 0.7144745923578739,
                "evidence_contribution": 0.6377467070731724,
                "combined_rank_score": 0.8926093578338623
              },
              {
                "id": 3066,
                "faiss_score": 0.8990744352340698,
                "faiss_rank": 5,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 121,
                "sentence": "These feed-forward layers contain most of the parameters in a transformer model.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.006744684651494026,
                  "neutral": 0.3021673262119293,
                  "support": 0.6910879611968994
                },
                "stance_score": 0.6843432765454054,
                "evidence_contribution": 0.6152755448662932,
                "combined_rank_score": 0.8990744352340698
              },
              {
                "id": 6400,
                "faiss_score": 0.8874496221542358,
                "faiss_rank": 14,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 139,
                "sentence": "Whether transformers will eventually be supplanted by fundamentally different architectures remains an open question, but their influence on the field is undeniable.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04509371891617775,
                  "neutral": 0.2564258575439453,
                  "support": 0.698480486869812
                },
                "stance_score": 0.6533867679536343,
                "evidence_contribution": 0.5798478403410301,
                "combined_rank_score": 0.8874496221542358
              },
              {
                "id": 6363,
                "faiss_score": 0.8928086161613464,
                "faiss_rank": 11,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 102,
                "sentence": "These hybrid models attempt to balance efficiency and flexibility, though they often sacrifice the simplicity of the original transformer design.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.060536615550518036,
                  "neutral": 0.2372356504201889,
                  "support": 0.7022277116775513
                },
                "stance_score": 0.6416910961270332,
                "evidence_contribution": 0.5729073395362341,
                "combined_rank_score": 0.8928086161613464
              },
              {
                "id": 6465,
                "faiss_score": 0.8868331909179688,
                "faiss_rank": 16,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 204,
                "sentence": "Looking ahead, transformers are likely to remain influential, even as new architectures emerge.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.033728837966918945,
                  "neutral": 0.3078342080116272,
                  "support": 0.6584368944168091
                },
                "stance_score": 0.6247080564498901,
                "evidence_contribution": 0.5540118390936186,
                "combined_rank_score": 0.8868331909179688
              },
              {
                "id": 6462,
                "faiss_score": 0.9030354022979736,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 201,
                "sentence": "The continued evolution of transformers is shaped by practical demands as much as theoretical insights.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.040574561804533005,
                  "neutral": 0.3076690435409546,
                  "support": 0.6517564058303833
                },
                "stance_score": 0.6111818440258503,
                "evidence_contribution": 0.5519188423971011,
                "combined_rank_score": 0.9030354022979736
              },
              {
                "id": 3010,
                "faiss_score": 0.902931809425354,
                "faiss_rank": 4,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 65,
                "sentence": "These classes are independent of a specific modeling architecture such as transformer, but they are often discussed in the context of transformer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.031252454966306686,
                  "neutral": 0.3576362133026123,
                  "support": 0.6111113429069519
                },
                "stance_score": 0.5798588879406452,
                "evidence_contribution": 0.5235730348996204,
                "combined_rank_score": 0.902931809425354
              },
              {
                "id": 6315,
                "faiss_score": 0.8958632946014404,
                "faiss_rank": 7,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 54,
                "sentence": "In practice, transformers are often used as components within larger systems rather than standalone models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.02291276305913925,
                  "neutral": 0.37171968817710876,
                  "support": 0.6053675413131714
                },
                "stance_score": 0.5824547782540321,
                "evidence_contribution": 0.5217998566030086,
                "combined_rank_score": 0.8958632946014404
              },
              {
                "id": 6398,
                "faiss_score": 0.8935900926589966,
                "faiss_rank": 10,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 137,
                "sentence": "The future of transformer research is likely to involve incremental refinement rather than radical departure.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.039210498332977295,
                  "neutral": 0.3383573889732361,
                  "support": 0.6224320530891418
                },
                "stance_score": 0.5832215547561646,
                "evidence_contribution": 0.5211610031552851,
                "combined_rank_score": 0.8935900926589966
              },
              {
                "id": 6388,
                "faiss_score": 0.884501576423645,
                "faiss_rank": 20,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 127,
                "sentence": "Transformers also raise questions about evaluation methodology.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.044395916163921356,
                  "neutral": 0.33084335923194885,
                  "support": 0.6247608065605164
                },
                "stance_score": 0.580364890396595,
                "evidence_contribution": 0.5133336604567242,
                "combined_rank_score": 0.884501576423645
              },
              {
                "id": 6467,
                "faiss_score": 0.8982804417610168,
                "faiss_rank": 6,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 206,
                "sentence": "Future systems may incorporate these ideas in different forms, building on lessons learned from transformer research.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0426999069750309,
                  "neutral": 0.47481054067611694,
                  "support": 0.48248955607414246
                },
                "stance_score": 0.43978964909911156,
                "evidence_contribution": 0.3950544402746725,
                "combined_rank_score": 0.8982804417610168
              },
              {
                "id": 6378,
                "faiss_score": 0.8857048749923706,
                "faiss_rank": 18,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 117,
                "sentence": "The success of transformers has also influenced educational and research priorities.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.13242551684379578,
                  "neutral": 0.3794748783111572,
                  "support": 0.48809969425201416
                },
                "stance_score": 0.3556741774082184,
                "evidence_contribution": 0.3150223528393603,
                "combined_rank_score": 0.8857048749923706
              },
              {
                "id": 6320,
                "faiss_score": 0.8881544470787048,
                "faiss_rank": 13,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 59,
                "sentence": "Understanding how and why transformers produce specific outputs remains an active area of research, particularly in high-stakes applications.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.03948766738176346,
                  "neutral": 0.6247231364250183,
                  "support": 0.33578917384147644
                },
                "stance_score": 0.296301506459713,
                "evidence_contribution": 0.2631615006383137,
                "combined_rank_score": 0.8881544470787048
              },
              {
                "id": 6314,
                "faiss_score": 0.8850823640823364,
                "faiss_rank": 19,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 53,
                "sentence": "At the same time, the limitations of transformers have motivated ongoing research into alternative approaches that may offer improved efficiency or inductive biases.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.15399281680583954,
                  "neutral": 0.5566006898880005,
                  "support": 0.28940653800964355
                },
                "stance_score": 0.13541372120380402,
                "evidence_contribution": 0.11985229649224927,
                "combined_rank_score": 0.8850823640823364
              }
            ],
            "contradicting": [],
            "neutral": []
          }
        },
        {
          "subclaim": "Optimization techniques are needed",
          "verdict": "SUPPORT",
          "controversial": true,
          "strengths": {
            "support": 0.7750860239319834,
            "contradict": 0.3141652972039711,
            "total": 1.0892513211359545
          },
          "evidence": {
            "supporting": [
              {
                "id": 5951,
                "faiss_score": 0.8863611221313477,
                "faiss_rank": 16,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 46,
                "sentence": "Effective optimization requires understanding how model behavior interacts with system architecture.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00443139998242259,
                  "neutral": 0.7683227062225342,
                  "support": 0.22724591195583344
                },
                "stance_score": 0.22281451197341084,
                "evidence_contribution": 0.19749412085990103,
                "combined_rank_score": 0.8863611221313477
              },
              {
                "id": 1636,
                "faiss_score": 0.8969464898109436,
                "faiss_rank": 4,
                "doc_id": "wiki_Optimization_(mathematics)",
                "file_type": ".txt",
                "position": 85,
                "sentence": "Many optimization algorithms need to start from a feasible point.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                "primary_category": "all articles with style issues",
                "probs": {
                  "contradict": 0.005357774440199137,
                  "neutral": 0.7723470330238342,
                  "support": 0.2222951352596283
                },
                "stance_score": 0.21693736081942916,
                "evidence_contribution": 0.1945812042958371,
                "combined_rank_score": 0.8969464898109436
              },
              {
                "id": 5899,
                "faiss_score": 0.8871976137161255,
                "faiss_rank": 14,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 68,
                "sentence": "From a systems perspective, optimization must be efficient not only in iteration count but also in wall-clock time.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0027748181018978357,
                  "neutral": 0.8443925976753235,
                  "support": 0.15283261239528656
                },
                "stance_score": 0.15005779429338872,
                "evidence_contribution": 0.1331309170165997,
                "combined_rank_score": 0.8871976137161255
              },
              {
                "id": 5891,
                "faiss_score": 0.8919302225112915,
                "faiss_rank": 7,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 60,
                "sentence": "Analyzing these effects requires extending classical optimization theory.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0053406101651489735,
                  "neutral": 0.8452781438827515,
                  "support": 0.14938127994537354
                },
                "stance_score": 0.14404066978022456,
                "evidence_contribution": 0.12847422664775116,
                "combined_rank_score": 0.8919302225112915
              },
              {
                "id": 1487,
                "faiss_score": 0.8900490999221802,
                "faiss_rank": 11,
                "doc_id": "wiki_Gradient_descent",
                "file_type": ".txt",
                "position": 22,
                "sentence": "To say more, we need more information about the objective function that we are optimising.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Gradient_descent",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.005644820164889097,
                  "neutral": 0.852307140827179,
                  "support": 0.14204803109169006
                },
                "stance_score": 0.13640321092680097,
                "evidence_contribution": 0.12140555511189449,
                "combined_rank_score": 0.8900490999221802
              }
            ],
            "contradicting": [
              {
                "id": 1632,
                "faiss_score": 0.8906309604644775,
                "faiss_rank": 9,
                "doc_id": "wiki_Optimization_(mathematics)",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Classical optimization techniques due to their iterative approach do not perform satisfactorily when they are used to obtain multiple solutions, since it is not guaranteed that different solutions will be obtained even with different starting points in multiple runs of the algorithm.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                "primary_category": "all articles with style issues",
                "probs": {
                  "contradict": 0.2238139808177948,
                  "neutral": 0.7673050165176392,
                  "support": 0.008881048299372196
                },
                "stance_score": -0.2149329325184226,
                "evidence_contribution": -0.19142592412432946,
                "combined_rank_score": 0.8906309604644775
              },
              {
                "id": 6229,
                "faiss_score": 0.8993328809738159,
                "faiss_rank": 3,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "These techniques alter the optimization path as well as the final solution.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.1437188684940338,
                  "neutral": 0.8490404486656189,
                  "support": 0.007240623701363802
                },
                "stance_score": -0.13647824479267,
                "evidence_contribution": -0.12273937307964161,
                "combined_rank_score": 0.8993328809738159
              }
            ],
            "neutral": [
              {
                "id": 5901,
                "faiss_score": 0.9013645052909851,
                "faiss_rank": 1,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 70,
                "sentence": "Optimizing these factors often requires algorithmic compromises.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005268564913421869,
                  "neutral": 0.9169650673866272,
                  "support": 0.07776641845703125
                },
                "stance_score": 0.07249785354360938,
                "evidence_contribution": 0.06534699189399376,
                "combined_rank_score": 0.9013645052909851
              },
              {
                "id": 6345,
                "faiss_score": 0.8997242450714111,
                "faiss_rank": 2,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 84,
                "sentence": "Transformers also exhibit a strong dependence on optimization techniques.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0024206028319895267,
                  "neutral": 0.9552444219589233,
                  "support": 0.042334962636232376
                },
                "stance_score": 0.03991435980424285,
                "evidence_contribution": 0.035911917242381075,
                "combined_rank_score": 0.8997242450714111
              },
              {
                "id": 5892,
                "faiss_score": 0.8930001258850098,
                "faiss_rank": 5,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 61,
                "sentence": "Optimization also interacts with data properties.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0020997938700020313,
                  "neutral": 0.9941021800041199,
                  "support": 0.003798038698732853
                },
                "stance_score": 0.0016982448287308216,
                "evidence_contribution": 0.0015165328458401905,
                "combined_rank_score": 0.8930001258850098
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Transformer models exist",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 1759,
                      "faiss_score": 0.9132465124130249,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "As of 2024, the largest and most capable models are all based on the transformer architecture.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.011396590620279312,
                        "neutral": 0.17400501668453217,
                        "support": 0.8145983815193176
                      },
                      "stance_score": 0.8032017908990383,
                      "evidence_contribution": 0.7335212343024424,
                      "combined_rank_score": 0.9132465124130249
                    },
                    {
                      "id": 6304,
                      "faiss_score": 0.9101985692977905,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 43,
                      "sentence": "To address these issues, numerous variants of the transformer architecture have been proposed.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004565074574202299,
                        "neutral": 0.17873318493366241,
                        "support": 0.8167017102241516
                      },
                      "stance_score": 0.8121366356499493,
                      "evidence_contribution": 0.7392056038429049,
                      "combined_rank_score": 0.9101985692977905
                    },
                    {
                      "id": 6462,
                      "faiss_score": 0.9030354022979736,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 201,
                      "sentence": "The continued evolution of transformers is shaped by practical demands as much as theoretical insights.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.040574561804533005,
                        "neutral": 0.3076690435409546,
                        "support": 0.6517564058303833
                      },
                      "stance_score": 0.6111818440258503,
                      "evidence_contribution": 0.5519188423971011,
                      "combined_rank_score": 0.9030354022979736
                    }
                  ],
                  "contradicting": [],
                  "neutral": []
                }
              },
              {
                "subclaim": "Optimization techniques are needed",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 1636,
                      "faiss_score": 0.8969464898109436,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Optimization_(mathematics)",
                      "file_type": ".txt",
                      "position": 85,
                      "sentence": "Many optimization algorithms need to start from a feasible point.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                      "primary_category": "all articles with style issues",
                      "probs": {
                        "contradict": 0.005357774440199137,
                        "neutral": 0.7723470330238342,
                        "support": 0.2222951352596283
                      },
                      "stance_score": 0.21693736081942916,
                      "evidence_contribution": 0.1945812042958371,
                      "combined_rank_score": 0.8969464898109436
                    },
                    {
                      "id": 5891,
                      "faiss_score": 0.8919302225112915,
                      "faiss_rank": 7,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 60,
                      "sentence": "Analyzing these effects requires extending classical optimization theory.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0053406101651489735,
                        "neutral": 0.8452781438827515,
                        "support": 0.14938127994537354
                      },
                      "stance_score": 0.14404066978022456,
                      "evidence_contribution": 0.12847422664775116,
                      "combined_rank_score": 0.8919302225112915
                    },
                    {
                      "id": 1487,
                      "faiss_score": 0.8900490999221802,
                      "faiss_rank": 11,
                      "doc_id": "wiki_Gradient_descent",
                      "file_type": ".txt",
                      "position": 22,
                      "sentence": "To say more, we need more information about the objective function that we are optimising.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Gradient_descent",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.005644820164889097,
                        "neutral": 0.852307140827179,
                        "support": 0.14204803109169006
                      },
                      "stance_score": 0.13640321092680097,
                      "evidence_contribution": 0.12140555511189449,
                      "combined_rank_score": 0.8900490999221802
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6229,
                      "faiss_score": 0.8993328809738159,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 37,
                      "sentence": "These techniques alter the optimization path as well as the final solution.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.1437188684940338,
                        "neutral": 0.8490404486656189,
                        "support": 0.007240623701363802
                      },
                      "stance_score": -0.13647824479267,
                      "evidence_contribution": -0.12273937307964161,
                      "combined_rank_score": 0.8993328809738159
                    },
                    {
                      "id": 1632,
                      "faiss_score": 0.8906309604644775,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Optimization_(mathematics)",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Classical optimization techniques due to their iterative approach do not perform satisfactorily when they are used to obtain multiple solutions, since it is not guaranteed that different solutions will be obtained even with different starting points in multiple runs of the algorithm.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                      "primary_category": "all articles with style issues",
                      "probs": {
                        "contradict": 0.2238139808177948,
                        "neutral": 0.7673050165176392,
                        "support": 0.008881048299372196
                      },
                      "stance_score": -0.2149329325184226,
                      "evidence_contribution": -0.19142592412432946,
                      "combined_rank_score": 0.8906309604644775
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5901,
                      "faiss_score": 0.9013645052909851,
                      "faiss_rank": 1,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 70,
                      "sentence": "Optimizing these factors often requires algorithmic compromises.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005268564913421869,
                        "neutral": 0.9169650673866272,
                        "support": 0.07776641845703125
                      },
                      "stance_score": 0.07249785354360938,
                      "evidence_contribution": 0.06534699189399376,
                      "combined_rank_score": 0.9013645052909851
                    },
                    {
                      "id": 6345,
                      "faiss_score": 0.8997242450714111,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 84,
                      "sentence": "Transformers also exhibit a strong dependence on optimization techniques.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0024206028319895267,
                        "neutral": 0.9552444219589233,
                        "support": 0.042334962636232376
                      },
                      "stance_score": 0.03991435980424285,
                      "evidence_contribution": 0.035911917242381075,
                      "combined_rank_score": 0.8997242450714111
                    },
                    {
                      "id": 5892,
                      "faiss_score": 0.8930001258850098,
                      "faiss_rank": 5,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 61,
                      "sentence": "Optimization also interacts with data properties.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0020997938700020313,
                        "neutral": 0.9941021800041199,
                        "support": 0.003798038698732853
                      },
                      "stance_score": 0.0016982448287308216,
                      "evidence_contribution": 0.0015165328458401905,
                      "combined_rank_score": 0.8930001258850098
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Scaling model size improves performance but introduces efficiency and stability challenges.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Scaling model size improves performance",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 3.9750071159876663,
            "contradict": 4.025112899050111,
            "total": 8.000120015037776
          },
          "evidence": {
            "supporting": [
              {
                "id": 6300,
                "faiss_score": 0.8937974572181702,
                "faiss_rank": 13,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0006018584244884551,
                  "neutral": 0.04180032014846802,
                  "support": 0.9575978517532349
                },
                "stance_score": 0.9569959933287464,
                "evidence_contribution": 0.8553605854052104,
                "combined_rank_score": 0.8937974572181702
              },
              {
                "id": 6137,
                "faiss_score": 0.9351097345352173,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00106658018194139,
                  "neutral": 0.08652021735906601,
                  "support": 0.9124131798744202
                },
                "stance_score": 0.9113465996924788,
                "evidence_contribution": 0.8522090769080067,
                "combined_rank_score": 0.9351097345352173
              },
              {
                "id": 6127,
                "faiss_score": 0.9101240634918213,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.000981850316748023,
                  "neutral": 0.09745568037033081,
                  "support": 0.901562511920929
                },
                "stance_score": 0.9005806616041809,
                "evidence_contribution": 0.8196401312413499,
                "combined_rank_score": 0.9101240634918213
              },
              {
                "id": 6124,
                "faiss_score": 0.9064903259277344,
                "faiss_rank": 6,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0015502498717978597,
                  "neutral": 0.32961592078208923,
                  "support": 0.66883385181427
                },
                "stance_score": 0.6672836019424722,
                "evidence_contribution": 0.6048861298110642,
                "combined_rank_score": 0.9064903259277344
              },
              {
                "id": 6133,
                "faiss_score": 0.9184768795967102,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.1632184386253357,
                  "neutral": 0.1580629199743271,
                  "support": 0.678718626499176
                },
                "stance_score": 0.5155001878738403,
                "evidence_contribution": 0.47347500398988274,
                "combined_rank_score": 0.9184768795967102
              },
              {
                "id": 6132,
                "faiss_score": 0.9063695073127747,
                "faiss_rank": 7,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Larger models have greater representational capacity, allowing them to fit more complex functions.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0020745203364640474,
                  "neutral": 0.588250994682312,
                  "support": 0.4096744954586029
                },
                "stance_score": 0.40759997512213886,
                "evidence_contribution": 0.3694361886321522,
                "combined_rank_score": 0.9063695073127747
              }
            ],
            "contradicting": [
              {
                "id": 6153,
                "faiss_score": 0.8882825374603271,
                "faiss_rank": 15,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 29,
                "sentence": "Memory constraints become significant as models grow.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9535151720046997,
                  "neutral": 0.043259624391794205,
                  "support": 0.00322523876093328
                },
                "stance_score": -0.9502899332437664,
                "evidence_contribution": -0.8441259532247778,
                "combined_rank_score": 0.8882825374603271
              },
              {
                "id": 6173,
                "faiss_score": 0.8844408988952637,
                "faiss_rank": 18,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 49,
                "sentence": "Efficiency-oriented research aims to counterbalance brute-force scaling by achieving comparable performance with fewer resources.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.938567042350769,
                  "neutral": 0.05764458328485489,
                  "support": 0.0037883685436099768
                },
                "stance_score": -0.9347786738071591,
                "evidence_contribution": -0.8267564905301262,
                "combined_rank_score": 0.8844408988952637
              },
              {
                "id": 5968,
                "faiss_score": 0.9052228331565857,
                "faiss_rank": 8,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 63,
                "sentence": "As models continue to scale, new bottlenecks emerge.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8900476098060608,
                  "neutral": 0.10481911152601242,
                  "support": 0.0051333229057490826
                },
                "stance_score": -0.8849142869003117,
                "evidence_contribution": -0.8010446178886399,
                "combined_rank_score": 0.9052228331565857
              },
              {
                "id": 6157,
                "faiss_score": 0.8893459439277649,
                "faiss_rank": 14,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 33,
                "sentence": "Inference efficiency is another scaling concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8525574803352356,
                  "neutral": 0.14441968500614166,
                  "support": 0.0030228709802031517
                },
                "stance_score": -0.8495346093550324,
                "evidence_contribution": -0.7555301590561563,
                "combined_rank_score": 0.8893459439277649
              },
              {
                "id": 6149,
                "faiss_score": 0.8847784996032715,
                "faiss_rank": 17,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 25,
                "sentence": "Scaling also introduces engineering challenges.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6516427993774414,
                  "neutral": 0.3442355990409851,
                  "support": 0.004121542442589998
                },
                "stance_score": -0.6475212569348514,
                "evidence_contribution": -0.5729128861720423,
                "combined_rank_score": 0.8847784996032715
              },
              {
                "id": 6349,
                "faiss_score": 0.8993617296218872,
                "faiss_rank": 10,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 88,
                "sentence": "As models scale, training efficiency becomes a primary concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.26972973346710205,
                  "neutral": 0.7104320526123047,
                  "support": 0.019838299602270126
                },
                "stance_score": -0.24989143386483192,
                "evidence_contribution": -0.22474279217836868,
                "combined_rank_score": 0.8993617296218872
              }
            ],
            "neutral": [
              {
                "id": 6142,
                "faiss_score": 0.9155328869819641,
                "faiss_rank": 3,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.003673245431855321,
                  "neutral": 0.966631293296814,
                  "support": 0.029695525765419006
                },
                "stance_score": 0.026022280333563685,
                "evidence_contribution": 0.02382425343964155,
                "combined_rank_score": 0.9155328869819641
              },
              {
                "id": 6131,
                "faiss_score": 0.9074476361274719,
                "faiss_rank": 5,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0011911247856914997,
                  "neutral": 0.995375394821167,
                  "support": 0.0034334997180849314
                },
                "stance_score": 0.0022423749323934317,
                "evidence_contribution": 0.0020348378317119192,
                "combined_rank_score": 0.9074476361274719
              },
              {
                "id": 6135,
                "faiss_score": 0.904282808303833,
                "faiss_rank": 9,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 11,
                "sentence": "Data scaling plays an equally important role.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009410643251612782,
                  "neutral": 0.9886835217475891,
                  "support": 0.010375399142503738
                },
                "stance_score": 0.00943433481734246,
                "evidence_contribution": 0.00853130678310507,
                "combined_rank_score": 0.904282808303833
              }
            ]
          }
        },
        {
          "subclaim": "Scaling model size introduces efficiency challenges",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 5.444449710887134,
            "contradict": 0.12417701182928981,
            "total": 5.568626722716424
          },
          "evidence": {
            "supporting": [
              {
                "id": 5905,
                "faiss_score": 0.9015026092529297,
                "faiss_rank": 5,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009848137851804495,
                  "neutral": 0.09008853882551193,
                  "support": 0.9089266657829285
                },
                "stance_score": 0.907941851997748,
                "evidence_contribution": 0.8185119486259071,
                "combined_rank_score": 0.9015026092529297
              },
              {
                "id": 5907,
                "faiss_score": 0.890177845954895,
                "faiss_rank": 20,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0012398363323882222,
                  "neutral": 0.0943501889705658,
                  "support": 0.9044098854064941
                },
                "stance_score": 0.9031700490741059,
                "evidence_contribution": 0.8039819688157644,
                "combined_rank_score": 0.890177845954895
              },
              {
                "id": 6349,
                "faiss_score": 0.9152157306671143,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 88,
                "sentence": "As models scale, training efficiency becomes a primary concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0020032706670463085,
                  "neutral": 0.1527910679578781,
                  "support": 0.8452056646347046
                },
                "stance_score": 0.8432023939676583,
                "evidence_contribution": 0.7717120950953703,
                "combined_rank_score": 0.9152157306671143
              },
              {
                "id": 5968,
                "faiss_score": 0.9191259145736694,
                "faiss_rank": 2,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 63,
                "sentence": "As models continue to scale, new bottlenecks emerge.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0010979146463796496,
                  "neutral": 0.21369385719299316,
                  "support": 0.7852082848548889
                },
                "stance_score": 0.7841103702085093,
                "evidence_contribution": 0.7206961611445946,
                "combined_rank_score": 0.9191259145736694
              },
              {
                "id": 6414,
                "faiss_score": 0.8914526700973511,
                "faiss_rank": 14,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 153,
                "sentence": "Although larger models often support longer contexts, this approach scales poorly due to the quadratic cost of attention.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0015683926176279783,
                  "neutral": 0.3869890570640564,
                  "support": 0.6114425659179688
                },
                "stance_score": 0.6098741733003408,
                "evidence_contribution": 0.5436739602120034,
                "combined_rank_score": 0.8914526700973511
              },
              {
                "id": 6154,
                "faiss_score": 0.8912881016731262,
                "faiss_rank": 15,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 30,
                "sentence": "Activations, gradients, and optimizer states consume large amounts of memory, limiting feasible model sizes.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0035515723284333944,
                  "neutral": 0.4775678217411041,
                  "support": 0.5188806056976318
                },
                "stance_score": 0.5153290333691984,
                "evidence_contribution": 0.45930663588868,
                "combined_rank_score": 0.8912881016731262
              },
              {
                "id": 5929,
                "faiss_score": 0.897426187992096,
                "faiss_rank": 8,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 24,
                "sentence": "Large models require many iterations to converge, consuming significant compute.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001607345649972558,
                  "neutral": 0.6167876720428467,
                  "support": 0.38160499930381775
                },
                "stance_score": 0.3799976536538452,
                "evidence_contribution": 0.34101984576451105,
                "combined_rank_score": 0.897426187992096
              },
              {
                "id": 6149,
                "faiss_score": 0.9049237966537476,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 25,
                "sentence": "Scaling also introduces engineering challenges.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.003267299383878708,
                  "neutral": 0.6837592720985413,
                  "support": 0.31297338008880615
                },
                "stance_score": 0.30970608070492744,
                "evidence_contribution": 0.2802604023982549,
                "combined_rank_score": 0.9049237966537476
              },
              {
                "id": 6158,
                "faiss_score": 0.8926526308059692,
                "faiss_rank": 12,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 34,
                "sentence": "While large models may perform well during evaluation, deploying them in real-time systems can be costly or impractical.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0017582079162821174,
                  "neutral": 0.8006249666213989,
                  "support": 0.19761686027050018
                },
                "stance_score": 0.19585865235421807,
                "evidence_contribution": 0.17483374129010448,
                "combined_rank_score": 0.8926526308059692
              },
              {
                "id": 5949,
                "faiss_score": 0.8981167078018188,
                "faiss_rank": 7,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 44,
                "sentence": "A model that is efficient in isolation may be inefficient when integrated into a larger pipeline.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0014452391769737005,
                  "neutral": 0.8145927786827087,
                  "support": 0.18396194279193878
                },
                "stance_score": 0.18251670361496508,
                "evidence_contribution": 0.16392130096951277,
                "combined_rank_score": 0.8981167078018188
              },
              {
                "id": 6157,
                "faiss_score": 0.9232777953147888,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 33,
                "sentence": "Inference efficiency is another scaling concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0029566814191639423,
                  "neutral": 0.8427377939224243,
                  "support": 0.15430548787117004
                },
                "stance_score": 0.1513488064520061,
                "evidence_contribution": 0.13973699234453288,
                "combined_rank_score": 0.9232777953147888
              },
              {
                "id": 6211,
                "faiss_score": 0.8909123539924622,
                "faiss_rank": 16,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 19,
                "sentence": "Batch size influences both optimization efficiency and generalization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005222289822995663,
                  "neutral": 0.8444947600364685,
                  "support": 0.15028297901153564
                },
                "stance_score": 0.14506068918853998,
                "evidence_contribution": 0.12923636007673106,
                "combined_rank_score": 0.8909123539924622
              },
              {
                "id": 6173,
                "faiss_score": 0.8956167697906494,
                "faiss_rank": 10,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 49,
                "sentence": "Efficiency-oriented research aims to counterbalance brute-force scaling by achieving comparable performance with fewer resources.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0026571243070065975,
                  "neutral": 0.8857571482658386,
                  "support": 0.11158574372529984
                },
                "stance_score": 0.10892861941829324,
                "evidence_contribution": 0.0975582982611668,
                "combined_rank_score": 0.8956167697906494
              }
            ],
            "contradicting": [
              {
                "id": 5914,
                "faiss_score": 0.8902338147163391,
                "faiss_rank": 19,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "By identifying and removing such parameters, models can be made smaller and faster.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.15298616886138916,
                  "neutral": 0.8335157036781311,
                  "support": 0.01349808182567358
                },
                "stance_score": -0.13948808703571558,
                "evidence_contribution": -0.12417701182928981,
                "combined_rank_score": 0.8902338147163391
              }
            ],
            "neutral": [
              {
                "id": 6137,
                "faiss_score": 0.9006619453430176,
                "faiss_rank": 6,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04962897300720215,
                  "neutral": 0.9424659013748169,
                  "support": 0.007905115373432636
                },
                "stance_score": -0.04172385763376951,
                "evidence_contribution": -0.03757909078364596,
                "combined_rank_score": 0.9006619453430176
              },
              {
                "id": 6142,
                "faiss_score": 0.8960381746292114,
                "faiss_rank": 9,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.013231821358203888,
                  "neutral": 0.9757226705551147,
                  "support": 0.011045468039810658
                },
                "stance_score": -0.0021863533183932304,
                "evidence_contribution": -0.0019590560365075893,
                "combined_rank_score": 0.8960381746292114
              },
              {
                "id": 6131,
                "faiss_score": 0.8946009874343872,
                "faiss_rank": 11,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0008040505927056074,
                  "neutral": 0.9974097609519958,
                  "support": 0.0017861495725810528
                },
                "stance_score": 0.0009820989798754454,
                "evidence_contribution": 0.0008785867171548778,
                "combined_rank_score": 0.8946009874343872
              }
            ]
          }
        },
        {
          "subclaim": "Scaling model size introduces stability challenges",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 2.6583148047665204,
            "contradict": 0.0,
            "total": 2.6583148047665204
          },
          "evidence": {
            "supporting": [
              {
                "id": 5968,
                "faiss_score": 0.8963637351989746,
                "faiss_rank": 2,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 63,
                "sentence": "As models continue to scale, new bottlenecks emerge.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0010524292010813951,
                  "neutral": 0.18886996805667877,
                  "support": 0.8100776076316833
                },
                "stance_score": 0.809025178430602,
                "evidence_contribution": 0.7251808308080713,
                "combined_rank_score": 0.8963637351989746
              },
              {
                "id": 6153,
                "faiss_score": 0.8813247680664062,
                "faiss_rank": 9,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 29,
                "sentence": "Memory constraints become significant as models grow.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001798501587472856,
                  "neutral": 0.21860766410827637,
                  "support": 0.7795938849449158
                },
                "stance_score": 0.7777953833574429,
                "evidence_contribution": 0.6854903358406199,
                "combined_rank_score": 0.8813247680664062
              },
              {
                "id": 6133,
                "faiss_score": 0.9155011177062988,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004420503508299589,
                  "neutral": 0.3866603672504425,
                  "support": 0.608919084072113
                },
                "stance_score": 0.6044985805638134,
                "evidence_contribution": 0.5534191261580423,
                "combined_rank_score": 0.9155011177062988
              },
              {
                "id": 6134,
                "faiss_score": 0.877892792224884,
                "faiss_rank": 15,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 10,
                "sentence": "Large models are also more sensitive to optimization choices and require careful tuning to train effectively.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00174881296698004,
                  "neutral": 0.7042301893234253,
                  "support": 0.2940210700035095
                },
                "stance_score": 0.2922722570365295,
                "evidence_contribution": 0.2565837078196679,
                "combined_rank_score": 0.877892792224884
              },
              {
                "id": 6349,
                "faiss_score": 0.8802475929260254,
                "faiss_rank": 12,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 88,
                "sentence": "As models scale, training efficiency becomes a primary concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0099205132573843,
                  "neutral": 0.7918288707733154,
                  "support": 0.1982506662607193
                },
                "stance_score": 0.188330153003335,
                "evidence_contribution": 0.1657771638565757,
                "combined_rank_score": 0.8802475929260254
              },
              {
                "id": 6162,
                "faiss_score": 0.8794705271720886,
                "faiss_rank": 13,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 38,
                "sentence": "Larger models often generalize better on average, but they may also exhibit sharper failure modes under distribution shift.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002526637399569154,
                  "neutral": 0.8095825910568237,
                  "support": 0.18789075314998627
                },
                "stance_score": 0.1853641157504171,
                "evidence_contribution": 0.16302227659780738,
                "combined_rank_score": 0.8794705271720886
              },
              {
                "id": 6149,
                "faiss_score": 0.8830956220626831,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 25,
                "sentence": "Scaling also introduces engineering challenges.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.010862507857382298,
                  "neutral": 0.8550251126289368,
                  "support": 0.13411231338977814
                },
                "stance_score": 0.12324980553239584,
                "evidence_contribution": 0.10884136368573583,
                "combined_rank_score": 0.8830956220626831
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 6131,
                "faiss_score": 0.8920418620109558,
                "faiss_rank": 3,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0010439755860716105,
                  "neutral": 0.9971585273742676,
                  "support": 0.001797515549696982
                },
                "stance_score": 0.0007535399636253715,
                "evidence_contribution": 0.0006721891922520443,
                "combined_rank_score": 0.8920418620109558
              },
              {
                "id": 6161,
                "faiss_score": 0.8898634910583496,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "Scaling affects robustness and generalization in nontrivial ways.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001566248363815248,
                  "neutral": 0.9417255520820618,
                  "support": 0.05670818313956261
                },
                "stance_score": 0.05514193477574736,
                "evidence_contribution": 0.04906879458325836,
                "combined_rank_score": 0.8898634910583496
              },
              {
                "id": 6127,
                "faiss_score": 0.8886144161224365,
                "faiss_rank": 5,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.08219602704048157,
                  "neutral": 0.9124544262886047,
                  "support": 0.005349518731236458
                },
                "stance_score": -0.07684650830924511,
                "evidence_contribution": -0.06828691511226781,
                "combined_rank_score": 0.8886144161224365
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Scaling model size introduces efficiency challenges",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6157,
                      "faiss_score": 0.9232777953147888,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 33,
                      "sentence": "Inference efficiency is another scaling concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0029566814191639423,
                        "neutral": 0.8427377939224243,
                        "support": 0.15430548787117004
                      },
                      "stance_score": 0.1513488064520061,
                      "evidence_contribution": 0.13973699234453288,
                      "combined_rank_score": 0.9232777953147888
                    },
                    {
                      "id": 5968,
                      "faiss_score": 0.9191259145736694,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "As models continue to scale, new bottlenecks emerge.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0010979146463796496,
                        "neutral": 0.21369385719299316,
                        "support": 0.7852082848548889
                      },
                      "stance_score": 0.7841103702085093,
                      "evidence_contribution": 0.7206961611445946,
                      "combined_rank_score": 0.9191259145736694
                    },
                    {
                      "id": 6349,
                      "faiss_score": 0.9152157306671143,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 88,
                      "sentence": "As models scale, training efficiency becomes a primary concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0020032706670463085,
                        "neutral": 0.1527910679578781,
                        "support": 0.8452056646347046
                      },
                      "stance_score": 0.8432023939676583,
                      "evidence_contribution": 0.7717120950953703,
                      "combined_rank_score": 0.9152157306671143
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5914,
                      "faiss_score": 0.8902338147163391,
                      "faiss_rank": 19,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "By identifying and removing such parameters, models can be made smaller and faster.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.15298616886138916,
                        "neutral": 0.8335157036781311,
                        "support": 0.01349808182567358
                      },
                      "stance_score": -0.13948808703571558,
                      "evidence_contribution": -0.12417701182928981,
                      "combined_rank_score": 0.8902338147163391
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6137,
                      "faiss_score": 0.9006619453430176,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.04962897300720215,
                        "neutral": 0.9424659013748169,
                        "support": 0.007905115373432636
                      },
                      "stance_score": -0.04172385763376951,
                      "evidence_contribution": -0.03757909078364596,
                      "combined_rank_score": 0.9006619453430176
                    },
                    {
                      "id": 6142,
                      "faiss_score": 0.8960381746292114,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.013231821358203888,
                        "neutral": 0.9757226705551147,
                        "support": 0.011045468039810658
                      },
                      "stance_score": -0.0021863533183932304,
                      "evidence_contribution": -0.0019590560365075893,
                      "combined_rank_score": 0.8960381746292114
                    },
                    {
                      "id": 6131,
                      "faiss_score": 0.8946009874343872,
                      "faiss_rank": 11,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0008040505927056074,
                        "neutral": 0.9974097609519958,
                        "support": 0.0017861495725810528
                      },
                      "stance_score": 0.0009820989798754454,
                      "evidence_contribution": 0.0008785867171548778,
                      "combined_rank_score": 0.8946009874343872
                    }
                  ]
                }
              },
              {
                "subclaim": "Scaling model size introduces stability challenges",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6133,
                      "faiss_score": 0.9155011177062988,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004420503508299589,
                        "neutral": 0.3866603672504425,
                        "support": 0.608919084072113
                      },
                      "stance_score": 0.6044985805638134,
                      "evidence_contribution": 0.5534191261580423,
                      "combined_rank_score": 0.9155011177062988
                    },
                    {
                      "id": 5968,
                      "faiss_score": 0.8963637351989746,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "As models continue to scale, new bottlenecks emerge.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0010524292010813951,
                        "neutral": 0.18886996805667877,
                        "support": 0.8100776076316833
                      },
                      "stance_score": 0.809025178430602,
                      "evidence_contribution": 0.7251808308080713,
                      "combined_rank_score": 0.8963637351989746
                    },
                    {
                      "id": 6149,
                      "faiss_score": 0.8830956220626831,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 25,
                      "sentence": "Scaling also introduces engineering challenges.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.010862507857382298,
                        "neutral": 0.8550251126289368,
                        "support": 0.13411231338977814
                      },
                      "stance_score": 0.12324980553239584,
                      "evidence_contribution": 0.10884136368573583,
                      "combined_rank_score": 0.8830956220626831
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 6131,
                      "faiss_score": 0.8920418620109558,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0010439755860716105,
                        "neutral": 0.9971585273742676,
                        "support": 0.001797515549696982
                      },
                      "stance_score": 0.0007535399636253715,
                      "evidence_contribution": 0.0006721891922520443,
                      "combined_rank_score": 0.8920418620109558
                    },
                    {
                      "id": 6161,
                      "faiss_score": 0.8898634910583496,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 37,
                      "sentence": "Scaling affects robustness and generalization in nontrivial ways.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001566248363815248,
                        "neutral": 0.9417255520820618,
                        "support": 0.05670818313956261
                      },
                      "stance_score": 0.05514193477574736,
                      "evidence_contribution": 0.04906879458325836,
                      "combined_rank_score": 0.8898634910583496
                    },
                    {
                      "id": 6127,
                      "faiss_score": 0.8886144161224365,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.08219602704048157,
                        "neutral": 0.9124544262886047,
                        "support": 0.005349518731236458
                      },
                      "stance_score": -0.07684650830924511,
                      "evidence_contribution": -0.06828691511226781,
                      "combined_rank_score": 0.8886144161224365
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Scaling model size improves performance",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6137,
                      "faiss_score": 0.9351097345352173,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.00106658018194139,
                        "neutral": 0.08652021735906601,
                        "support": 0.9124131798744202
                      },
                      "stance_score": 0.9113465996924788,
                      "evidence_contribution": 0.8522090769080067,
                      "combined_rank_score": 0.9351097345352173
                    },
                    {
                      "id": 6133,
                      "faiss_score": 0.9184768795967102,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.1632184386253357,
                        "neutral": 0.1580629199743271,
                        "support": 0.678718626499176
                      },
                      "stance_score": 0.5155001878738403,
                      "evidence_contribution": 0.47347500398988274,
                      "combined_rank_score": 0.9184768795967102
                    },
                    {
                      "id": 6127,
                      "faiss_score": 0.9101240634918213,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.000981850316748023,
                        "neutral": 0.09745568037033081,
                        "support": 0.901562511920929
                      },
                      "stance_score": 0.9005806616041809,
                      "evidence_contribution": 0.8196401312413499,
                      "combined_rank_score": 0.9101240634918213
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5968,
                      "faiss_score": 0.9052228331565857,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "As models continue to scale, new bottlenecks emerge.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.8900476098060608,
                        "neutral": 0.10481911152601242,
                        "support": 0.0051333229057490826
                      },
                      "stance_score": -0.8849142869003117,
                      "evidence_contribution": -0.8010446178886399,
                      "combined_rank_score": 0.9052228331565857
                    },
                    {
                      "id": 6349,
                      "faiss_score": 0.8993617296218872,
                      "faiss_rank": 10,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 88,
                      "sentence": "As models scale, training efficiency becomes a primary concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.26972973346710205,
                        "neutral": 0.7104320526123047,
                        "support": 0.019838299602270126
                      },
                      "stance_score": -0.24989143386483192,
                      "evidence_contribution": -0.22474279217836868,
                      "combined_rank_score": 0.8993617296218872
                    },
                    {
                      "id": 6157,
                      "faiss_score": 0.8893459439277649,
                      "faiss_rank": 14,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 33,
                      "sentence": "Inference efficiency is another scaling concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.8525574803352356,
                        "neutral": 0.14441968500614166,
                        "support": 0.0030228709802031517
                      },
                      "stance_score": -0.8495346093550324,
                      "evidence_contribution": -0.7555301590561563,
                      "combined_rank_score": 0.8893459439277649
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6142,
                      "faiss_score": 0.9155328869819641,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.003673245431855321,
                        "neutral": 0.966631293296814,
                        "support": 0.029695525765419006
                      },
                      "stance_score": 0.026022280333563685,
                      "evidence_contribution": 0.02382425343964155,
                      "combined_rank_score": 0.9155328869819641
                    },
                    {
                      "id": 6131,
                      "faiss_score": 0.9074476361274719,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0011911247856914997,
                        "neutral": 0.995375394821167,
                        "support": 0.0034334997180849314
                      },
                      "stance_score": 0.0022423749323934317,
                      "evidence_contribution": 0.0020348378317119192,
                      "combined_rank_score": 0.9074476361274719
                    },
                    {
                      "id": 6135,
                      "faiss_score": 0.904282808303833,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 11,
                      "sentence": "Data scaling plays an equally important role.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0009410643251612782,
                        "neutral": 0.9886835217475891,
                        "support": 0.010375399142503738
                      },
                      "stance_score": 0.00943433481734246,
                      "evidence_contribution": 0.00853130678310507,
                      "combined_rank_score": 0.904282808303833
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Distributed systems improve scalability but increase system complexity.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Distributed systems improve scalability",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 1.27381838622602,
            "contradict": 0.7142825961756749,
            "total": 1.9881009824016949
          },
          "evidence": {
            "supporting": [
              {
                "id": 499,
                "faiss_score": 0.9017831683158875,
                "faiss_rank": 10,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.0015425255987793207,
                  "neutral": 0.4211810231208801,
                  "support": 0.5772764086723328
                },
                "stance_score": 0.5757338830735534,
                "evidence_contribution": 0.5191871251848778,
                "combined_rank_score": 0.9017831683158875
              },
              {
                "id": 502,
                "faiss_score": 0.895154595375061,
                "faiss_rank": 13,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 78,
                "sentence": "Subsequently, Reactive systems are more flexible, loosely-coupled and scalable.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.009046770632266998,
                  "neutral": 0.5073032379150391,
                  "support": 0.48364999890327454
                },
                "stance_score": 0.47460322827100754,
                "evidence_contribution": 0.4248432607666315,
                "combined_rank_score": 0.895154595375061
              },
              {
                "id": 6684,
                "faiss_score": 0.9061692357063293,
                "faiss_rank": 3,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 16,
                "sentence": "By distributing work across multiple processors or machines, systems can handle more requests concurrently.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0014126799069344997,
                  "neutral": 0.6332381963729858,
                  "support": 0.3653491139411926
                },
                "stance_score": 0.3639364340342581,
                "evidence_contribution": 0.3297880002745106,
                "combined_rank_score": 0.9061692357063293
              }
            ],
            "contradicting": [
              {
                "id": 5658,
                "faiss_score": 0.9028811454772949,
                "faiss_rank": 9,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 61,
                "sentence": "Eventually consistent systems illustrate how relaxing guarantees can improve scalability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8435043692588806,
                  "neutral": 0.10410597920417786,
                  "support": 0.052389614284038544
                },
                "stance_score": -0.7911147549748421,
                "evidence_contribution": -0.7142825961756749,
                "combined_rank_score": 0.9028811454772949
              }
            ],
            "neutral": [
              {
                "id": 759,
                "faiss_score": 0.9175848364830017,
                "faiss_rank": 1,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 163,
                "sentence": "Meeting this scalability condition is possible for a wide range of systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0008614318794570863,
                  "neutral": 0.9977839589118958,
                  "support": 0.0013546152040362358
                },
                "stance_score": 0.0004931833245791495,
                "evidence_contribution": 0.00045253754024010204,
                "combined_rank_score": 0.9175848364830017
              },
              {
                "id": 445,
                "faiss_score": 0.9056973457336426,
                "faiss_rank": 4,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Distributed systems are groups of networked computers which share a common goal for their work.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.000767619232647121,
                  "neutral": 0.9977124929428101,
                  "support": 0.001519894110970199
                },
                "stance_score": 0.0007522748783230782,
                "evidence_contribution": 0.0006813333605593108,
                "combined_rank_score": 0.9056973457336426
              },
              {
                "id": 5646,
                "faiss_score": 0.9050657749176025,
                "faiss_rank": 7,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 49,
                "sentence": "The evolution of distributed systems has been driven by practical needs.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0006361278356052935,
                  "neutral": 0.9965994954109192,
                  "support": 0.002764445496723056
                },
                "stance_score": 0.0021283176611177623,
                "evidence_contribution": 0.001926267473230367,
                "combined_rank_score": 0.9050657749176025
              }
            ]
          }
        },
        {
          "subclaim": "Distributed systems increase system complexity",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 1.2898558216369702,
            "contradict": 0.917054421216765,
            "total": 2.206910242853735
          },
          "evidence": {
            "supporting": [
              {
                "id": 6234,
                "faiss_score": 0.8951437473297119,
                "faiss_rank": 15,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Distributed training introduces additional complexity into training dynamics.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0011164408642798662,
                  "neutral": 0.06910634785890579,
                  "support": 0.929777204990387
                },
                "stance_score": 0.9286607641261071,
                "evidence_contribution": 0.8312848763979173,
                "combined_rank_score": 0.8951437473297119
              },
              {
                "id": 5716,
                "faiss_score": 0.903039813041687,
                "faiss_rank": 6,
                "doc_id": "local_math_computation_limits.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Communication complexity highlights situations where computation is distributed across multiple parties or components.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.015548361465334892,
                  "neutral": 0.5749548673629761,
                  "support": 0.4094967544078827
                },
                "stance_score": 0.3939483929425478,
                "evidence_contribution": 0.3557510831109114,
                "combined_rank_score": 0.903039813041687
              },
              {
                "id": 5674,
                "faiss_score": 0.9308851957321167,
                "faiss_rank": 1,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 77,
                "sentence": "Distributed systems exemplify the broader theme that complexity emerges from interaction.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.13098503649234772,
                  "neutral": 0.6275760531425476,
                  "support": 0.24143889546394348
                },
                "stance_score": 0.11045385897159576,
                "evidence_contribution": 0.10281986212814154,
                "combined_rank_score": 0.9308851957321167
              }
            ],
            "contradicting": [
              {
                "id": 499,
                "faiss_score": 0.9024401903152466,
                "faiss_rank": 8,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.8282386660575867,
                  "neutral": 0.16808989644050598,
                  "support": 0.0036715413443744183
                },
                "stance_score": -0.8245671247132123,
                "evidence_contribution": -0.7441225129538869,
                "combined_rank_score": 0.9024401903152466
              },
              {
                "id": 495,
                "faiss_score": 0.8924154043197632,
                "faiss_rank": 16,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 71,
                "sentence": "Reasons for using distributed systems and distributed computing may include: The very nature of an application may require the use of a communication network that connects several computers: for example, data produced in one physical location and required in another location.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.19817553460597992,
                  "neutral": 0.7974284887313843,
                  "support": 0.004395925439894199
                },
                "stance_score": -0.19377960916608572,
                "evidence_contribution": -0.17293190826287808,
                "combined_rank_score": 0.8924154043197632
              }
            ],
            "neutral": [
              {
                "id": 5650,
                "faiss_score": 0.9090577363967896,
                "faiss_rank": 2,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Distributed systems also intersect with security concerns.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0072384984232485294,
                  "neutral": 0.9825186729431152,
                  "support": 0.010242801159620285
                },
                "stance_score": 0.0030043027363717556,
                "evidence_contribution": 0.002731084644976789,
                "combined_rank_score": 0.9090577363967896
              },
              {
                "id": 445,
                "faiss_score": 0.9034885168075562,
                "faiss_rank": 3,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Distributed systems are groups of networked computers which share a common goal for their work.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.03827379271388054,
                  "neutral": 0.9580088257789612,
                  "support": 0.003717323299497366
                },
                "stance_score": -0.03455646941438317,
                "evidence_contribution": -0.03122137329730673,
                "combined_rank_score": 0.9034885168075562
              },
              {
                "id": 5597,
                "faiss_score": 0.9027834534645081,
                "faiss_rank": 7,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Distributed systems are collections of independent computing components that coordinate their actions through communication in order to achieve a common goal.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04560400918126106,
                  "neutral": 0.9508848190307617,
                  "support": 0.0035111713223159313
                },
                "stance_score": -0.04209283785894513,
                "evidence_contribution": -0.038000717528420075,
                "combined_rank_score": 0.9027834534645081
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Distributed systems improve scalability",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6684,
                      "faiss_score": 0.9061692357063293,
                      "faiss_rank": 3,
                      "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                      "file_type": ".txt",
                      "position": 16,
                      "sentence": "By distributing work across multiple processors or machines, systems can handle more requests concurrently.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0014126799069344997,
                        "neutral": 0.6332381963729858,
                        "support": 0.3653491139411926
                      },
                      "stance_score": 0.3639364340342581,
                      "evidence_contribution": 0.3297880002745106,
                      "combined_rank_score": 0.9061692357063293
                    },
                    {
                      "id": 499,
                      "faiss_score": 0.9017831683158875,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.0015425255987793207,
                        "neutral": 0.4211810231208801,
                        "support": 0.5772764086723328
                      },
                      "stance_score": 0.5757338830735534,
                      "evidence_contribution": 0.5191871251848778,
                      "combined_rank_score": 0.9017831683158875
                    },
                    {
                      "id": 502,
                      "faiss_score": 0.895154595375061,
                      "faiss_rank": 13,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 78,
                      "sentence": "Subsequently, Reactive systems are more flexible, loosely-coupled and scalable.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.009046770632266998,
                        "neutral": 0.5073032379150391,
                        "support": 0.48364999890327454
                      },
                      "stance_score": 0.47460322827100754,
                      "evidence_contribution": 0.4248432607666315,
                      "combined_rank_score": 0.895154595375061
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5658,
                      "faiss_score": 0.9028811454772949,
                      "faiss_rank": 9,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 61,
                      "sentence": "Eventually consistent systems illustrate how relaxing guarantees can improve scalability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.8435043692588806,
                        "neutral": 0.10410597920417786,
                        "support": 0.052389614284038544
                      },
                      "stance_score": -0.7911147549748421,
                      "evidence_contribution": -0.7142825961756749,
                      "combined_rank_score": 0.9028811454772949
                    }
                  ],
                  "neutral": [
                    {
                      "id": 759,
                      "faiss_score": 0.9175848364830017,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 163,
                      "sentence": "Meeting this scalability condition is possible for a wide range of systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.0008614318794570863,
                        "neutral": 0.9977839589118958,
                        "support": 0.0013546152040362358
                      },
                      "stance_score": 0.0004931833245791495,
                      "evidence_contribution": 0.00045253754024010204,
                      "combined_rank_score": 0.9175848364830017
                    },
                    {
                      "id": 445,
                      "faiss_score": 0.9056973457336426,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "Distributed systems are groups of networked computers which share a common goal for their work.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.000767619232647121,
                        "neutral": 0.9977124929428101,
                        "support": 0.001519894110970199
                      },
                      "stance_score": 0.0007522748783230782,
                      "evidence_contribution": 0.0006813333605593108,
                      "combined_rank_score": 0.9056973457336426
                    },
                    {
                      "id": 5646,
                      "faiss_score": 0.9050657749176025,
                      "faiss_rank": 7,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 49,
                      "sentence": "The evolution of distributed systems has been driven by practical needs.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0006361278356052935,
                        "neutral": 0.9965994954109192,
                        "support": 0.002764445496723056
                      },
                      "stance_score": 0.0021283176611177623,
                      "evidence_contribution": 0.001926267473230367,
                      "combined_rank_score": 0.9050657749176025
                    }
                  ]
                }
              },
              {
                "subclaim": "Distributed systems increase system complexity",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5674,
                      "faiss_score": 0.9308851957321167,
                      "faiss_rank": 1,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 77,
                      "sentence": "Distributed systems exemplify the broader theme that complexity emerges from interaction.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.13098503649234772,
                        "neutral": 0.6275760531425476,
                        "support": 0.24143889546394348
                      },
                      "stance_score": 0.11045385897159576,
                      "evidence_contribution": 0.10281986212814154,
                      "combined_rank_score": 0.9308851957321167
                    },
                    {
                      "id": 5716,
                      "faiss_score": 0.903039813041687,
                      "faiss_rank": 6,
                      "doc_id": "local_math_computation_limits.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "Communication complexity highlights situations where computation is distributed across multiple parties or components.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.015548361465334892,
                        "neutral": 0.5749548673629761,
                        "support": 0.4094967544078827
                      },
                      "stance_score": 0.3939483929425478,
                      "evidence_contribution": 0.3557510831109114,
                      "combined_rank_score": 0.903039813041687
                    },
                    {
                      "id": 6234,
                      "faiss_score": 0.8951437473297119,
                      "faiss_rank": 15,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Distributed training introduces additional complexity into training dynamics.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0011164408642798662,
                        "neutral": 0.06910634785890579,
                        "support": 0.929777204990387
                      },
                      "stance_score": 0.9286607641261071,
                      "evidence_contribution": 0.8312848763979173,
                      "combined_rank_score": 0.8951437473297119
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 499,
                      "faiss_score": 0.9024401903152466,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.8282386660575867,
                        "neutral": 0.16808989644050598,
                        "support": 0.0036715413443744183
                      },
                      "stance_score": -0.8245671247132123,
                      "evidence_contribution": -0.7441225129538869,
                      "combined_rank_score": 0.9024401903152466
                    },
                    {
                      "id": 495,
                      "faiss_score": 0.8924154043197632,
                      "faiss_rank": 16,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 71,
                      "sentence": "Reasons for using distributed systems and distributed computing may include: The very nature of an application may require the use of a communication network that connects several computers: for example, data produced in one physical location and required in another location.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.19817553460597992,
                        "neutral": 0.7974284887313843,
                        "support": 0.004395925439894199
                      },
                      "stance_score": -0.19377960916608572,
                      "evidence_contribution": -0.17293190826287808,
                      "combined_rank_score": 0.8924154043197632
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5650,
                      "faiss_score": 0.9090577363967896,
                      "faiss_rank": 2,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "Distributed systems also intersect with security concerns.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0072384984232485294,
                        "neutral": 0.9825186729431152,
                        "support": 0.010242801159620285
                      },
                      "stance_score": 0.0030043027363717556,
                      "evidence_contribution": 0.002731084644976789,
                      "combined_rank_score": 0.9090577363967896
                    },
                    {
                      "id": 445,
                      "faiss_score": 0.9034885168075562,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "Distributed systems are groups of networked computers which share a common goal for their work.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.03827379271388054,
                        "neutral": 0.9580088257789612,
                        "support": 0.003717323299497366
                      },
                      "stance_score": -0.03455646941438317,
                      "evidence_contribution": -0.03122137329730673,
                      "combined_rank_score": 0.9034885168075562
                    },
                    {
                      "id": 5597,
                      "faiss_score": 0.9027834534645081,
                      "faiss_rank": 7,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Distributed systems are collections of independent computing components that coordinate their actions through communication in order to achieve a common goal.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.04560400918126106,
                        "neutral": 0.9508848190307617,
                        "support": 0.0035111713223159313
                      },
                      "stance_score": -0.04209283785894513,
                      "evidence_contribution": -0.038000717528420075,
                      "combined_rank_score": 0.9027834534645081
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Large language models are powerful but can produce incorrect or misleading outputs.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Large language models are powerful",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 0.9176420898718681,
            "contradict": 0.9369176415234411,
            "total": 1.8545597313953093
          },
          "evidence": {
            "supporting": [
              {
                "id": 6121,
                "faiss_score": 0.9278501868247986,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007072408217936754,
                  "neutral": 0.2285161018371582,
                  "support": 0.764411449432373
                },
                "stance_score": 0.7573390412144363,
                "evidence_contribution": 0.7026971708805285,
                "combined_rank_score": 0.9278501868247986
              },
              {
                "id": 6043,
                "faiss_score": 0.9241077899932861,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005367050878703594,
                  "neutral": 0.8640390634536743,
                  "support": 0.130593940615654
                },
                "stance_score": 0.1252268897369504,
                "evidence_contribution": 0.11572314432254616,
                "combined_rank_score": 0.9241077899932861
              },
              {
                "id": 6109,
                "faiss_score": 0.8944122791290283,
                "faiss_rank": 13,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 69,
                "sentence": "The rapid pace of development in large language models has reshaped expectations about what machine learning systems can do.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0023451675660908222,
                  "neutral": 0.8843744993209839,
                  "support": 0.11328033357858658
                },
                "stance_score": 0.11093516601249576,
                "evidence_contribution": 0.09922177466879345,
                "combined_rank_score": 0.8944122791290283
              }
            ],
            "contradicting": [
              {
                "id": 6072,
                "faiss_score": 0.8847416639328003,
                "faiss_rank": 17,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 32,
                "sentence": "Another limitation of large language models is their lack of persistent memory beyond the context window.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.914618194103241,
                  "neutral": 0.07705717533826828,
                  "support": 0.008324596099555492
                },
                "stance_score": -0.9062935980036855,
                "evidence_contribution": -0.8018357059094251,
                "combined_rank_score": 0.8847416639328003
              },
              {
                "id": 2020,
                "faiss_score": 0.9012563228607178,
                "faiss_rank": 10,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 288,
                "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.2466990351676941,
                  "neutral": 0.6564837694168091,
                  "support": 0.09681721776723862
                },
                "stance_score": -0.14988181740045547,
                "evidence_contribution": -0.13508193561401605,
                "combined_rank_score": 0.9012563228607178
              }
            ],
            "neutral": [
              {
                "id": 6040,
                "faiss_score": 0.925839900970459,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0008157117408700287,
                  "neutral": 0.9963352680206299,
                  "support": 0.002849036827683449
                },
                "stance_score": 0.00203332508681342,
                "evidence_contribution": 0.0018825334970160867,
                "combined_rank_score": 0.925839900970459
              },
              {
                "id": 1796,
                "faiss_score": 0.9162331819534302,
                "faiss_rank": 4,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 64,
                "sentence": "The tendency towards larger models is visible in the list of large language models.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.0007646913290955126,
                  "neutral": 0.9953639507293701,
                  "support": 0.003871325869113207
                },
                "stance_score": 0.0031066345400176942,
                "evidence_contribution": 0.002846401649766843,
                "combined_rank_score": 0.9162331819534302
              },
              {
                "id": 6102,
                "faiss_score": 0.9150678515434265,
                "faiss_rank": 5,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 62,
                "sentence": "Evaluation of large language models presents its own challenges.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.02573368325829506,
                  "neutral": 0.9543356895446777,
                  "support": 0.019930649548768997
                },
                "stance_score": -0.005803033709526062,
                "evidence_contribution": -0.005310169589010094,
                "combined_rank_score": 0.9150678515434265
              }
            ]
          }
        },
        {
          "subclaim": "can produce incorrect or misleading outputs",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 6.417425539020938,
            "contradict": 0.0,
            "total": 6.417425539020938
          },
          "evidence": {
            "supporting": [
              {
                "id": 1219,
                "faiss_score": 0.8399705290794373,
                "faiss_rank": 16,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 244,
                "sentence": "Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0005253414856269956,
                  "neutral": 0.025972124189138412,
                  "support": 0.973502516746521
                },
                "stance_score": 0.972977175260894,
                "evidence_contribution": 0.8172721526861095,
                "combined_rank_score": 0.8399705290794373
              },
              {
                "id": 6606,
                "faiss_score": 0.863052248954773,
                "faiss_rank": 1,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "Components may crash completely, producing no output, or they may continue running while producing incorrect results.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009414730593562126,
                  "neutral": 0.20099835097789764,
                  "support": 0.7980602383613586
                },
                "stance_score": 0.7971187653020024,
                "evidence_contribution": 0.687955143077945,
                "combined_rank_score": 0.863052248954773
              },
              {
                "id": 6006,
                "faiss_score": 0.838417649269104,
                "faiss_rank": 20,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 32,
                "sentence": "High evaluation scores on flawed data may provide false confidence.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001357669709250331,
                  "neutral": 0.21175873279571533,
                  "support": 0.786883533000946
                },
                "stance_score": 0.7855258632916957,
                "evidence_contribution": 0.658598747741107,
                "combined_rank_score": 0.838417649269104
              },
              {
                "id": 1342,
                "faiss_score": 0.8386974334716797,
                "faiss_rank": 19,
                "doc_id": "wiki_Bias\u2013variance_tradeoff",
                "file_type": ".txt",
                "position": 19,
                "sentence": "This means that test data would also not agree as closely with the training data, but in this case the reason is inaccuracy or high bias.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0012351502664387226,
                  "neutral": 0.2274545133113861,
                  "support": 0.7713103890419006
                },
                "stance_score": 0.7700752387754619,
                "evidence_contribution": 0.6458601263410708,
                "combined_rank_score": 0.8386974334716797
              },
              {
                "id": 892,
                "faiss_score": 0.8531967401504517,
                "faiss_rank": 5,
                "doc_id": "wiki_Error_correction",
                "file_type": ".txt",
                "position": 65,
                "sentence": "of errors in the output.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Error_detection_and_correction",
                "primary_category": "all articles needing additional references",
                "probs": {
                  "contradict": 0.0012530958047136664,
                  "neutral": 0.3292033076286316,
                  "support": 0.6695435643196106
                },
                "stance_score": 0.6682904685148969,
                "evidence_contribution": 0.5701832492105281,
                "combined_rank_score": 0.8531967401504517
              },
              {
                "id": 1335,
                "faiss_score": 0.8503156900405884,
                "faiss_rank": 7,
                "doc_id": "wiki_Bias\u2013variance_tradeoff",
                "file_type": ".txt",
                "position": 12,
                "sentence": "In other words, test data may not agree as closely with training data, which would indicate imprecision and therefore inflated variance.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.001529883244074881,
                  "neutral": 0.4423833191394806,
                  "support": 0.5560867786407471
                },
                "stance_score": 0.5545568953966722,
                "evidence_contribution": 0.4715484291759877,
                "combined_rank_score": 0.8503156900405884
              },
              {
                "id": 6360,
                "faiss_score": 0.8480008840560913,
                "faiss_rank": 9,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 99,
                "sentence": "However, approximations can introduce errors or biases that affect model behavior in subtle ways.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0016916384920477867,
                  "neutral": 0.5194053053855896,
                  "support": 0.4789030849933624
                },
                "stance_score": 0.47721144650131464,
                "evidence_contribution": 0.40467572851480094,
                "combined_rank_score": 0.8480008840560913
              },
              {
                "id": 2227,
                "faiss_score": 0.8592409491539001,
                "faiss_rank": 2,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 158,
                "sentence": "The outputs are actually numbers, so when the error is low, the difference between the output (almost certainly a cat) and the correct answer (cat) is small.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.007495637983083725,
                  "neutral": 0.5303006172180176,
                  "support": 0.4622037410736084
                },
                "stance_score": 0.4547081030905247,
                "evidence_contribution": 0.3907038220874719,
                "combined_rank_score": 0.8592409491539001
              },
              {
                "id": 3532,
                "faiss_score": 0.8423595428466797,
                "faiss_rank": 15,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 103,
                "sentence": "The voting circuit can then only detect a mismatch and recovery relies on other methods.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.009126483462750912,
                  "neutral": 0.5999426245689392,
                  "support": 0.3909308612346649
                },
                "stance_score": 0.381804377771914,
                "evidence_contribution": 0.3216165611168105,
                "combined_rank_score": 0.8423595428466797
              },
              {
                "id": 4087,
                "faiss_score": 0.8452894687652588,
                "faiss_rank": 10,
                "doc_id": "wiki_Information_theory",
                "file_type": ".txt",
                "position": 81,
                "sentence": "However, channels often fail to produce exact reconstruction of a signal; noise, periods of silence, and other forms of signal corruption often degrade quality.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Information_theory",
                "primary_category": "all articles needing additional references",
                "probs": {
                  "contradict": 0.0018954407423734665,
                  "neutral": 0.6166093945503235,
                  "support": 0.3814951479434967
                },
                "stance_score": 0.37959970720112324,
                "evidence_contribution": 0.32087163484348524,
                "combined_rank_score": 0.8452894687652588
              },
              {
                "id": 6083,
                "faiss_score": 0.8439639210700989,
                "faiss_rank": 12,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 43,
                "sentence": "Small changes in phrasing can lead to significant differences in output, which allows users to guide behavior but also introduces unpredictability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0018205326050519943,
                  "neutral": 0.6606401801109314,
                  "support": 0.33753934502601624
                },
                "stance_score": 0.33571881242096424,
                "evidence_contribution": 0.283334565307794,
                "combined_rank_score": 0.8439639210700989
              },
              {
                "id": 3535,
                "faiss_score": 0.8539549112319946,
                "faiss_rank": 4,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 106,
                "sentence": "In this case, the voting circuit can output the correct result, and discard the erroneous version.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.11982972174882889,
                  "neutral": 0.4495139420032501,
                  "support": 0.4306562840938568
                },
                "stance_score": 0.3108265623450279,
                "evidence_contribution": 0.26543186945589436,
                "combined_rank_score": 0.8539549112319946
              },
              {
                "id": 6428,
                "faiss_score": 0.843582034111023,
                "faiss_rank": 13,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 167,
                "sentence": "Small changes in phrasing, ordering, or context can lead to significant differences in output.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0022780755534768105,
                  "neutral": 0.7048073410987854,
                  "support": 0.29291456937789917
                },
                "stance_score": 0.29063649382442236,
                "evidence_contribution": 0.24517572464730197,
                "combined_rank_score": 0.843582034111023
              },
              {
                "id": 5722,
                "faiss_score": 0.8450711369514465,
                "faiss_rank": 11,
                "doc_id": "local_math_computation_limits.txt",
                "file_type": ".txt",
                "position": 45,
                "sentence": "Algorithms that are theoretically efficient may perform poorly if they amplify numerical errors.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0019951513968408108,
                  "neutral": 0.7426140308380127,
                  "support": 0.25539082288742065
                },
                "stance_score": 0.25339567149057984,
                "evidence_contribution": 0.21413736820511955,
                "combined_rank_score": 0.8450711369514465
              },
              {
                "id": 2969,
                "faiss_score": 0.8526178598403931,
                "faiss_rank": 6,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 24,
                "sentence": "If the input is long, then the output vector would not be able to contain all relevant information, degrading the output.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.002237267093732953,
                  "neutral": 0.8547115921974182,
                  "support": 0.1430511325597763
                },
                "stance_score": 0.14081386546604335,
                "evidence_contribution": 0.12006041660951092,
                "combined_rank_score": 0.8526178598403931
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 1986,
                "faiss_score": 0.8568795919418335,
                "faiss_rank": 3,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 254,
                "sentence": "Results are often sensitive to the prompting method.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.001743515720590949,
                  "neutral": 0.9241812229156494,
                  "support": 0.07407531142234802
                },
                "stance_score": 0.07233179570175707,
                "evidence_contribution": 0.06197963958534167,
                "combined_rank_score": 0.8568795919418335
              },
              {
                "id": 1310,
                "faiss_score": 0.8482428789138794,
                "faiss_rank": 8,
                "doc_id": "wiki_Statistical_learning_theory",
                "file_type": ".txt",
                "position": 20,
                "sentence": "It takes the value 0 if the predicted output is the same as the actual output, and it takes the value 1 if the predicted output is different from the actual output.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.004643861670047045,
                  "neutral": 0.9214097261428833,
                  "support": 0.07394646108150482
                },
                "stance_score": 0.06930259941145778,
                "evidence_contribution": 0.05878543644099027,
                "combined_rank_score": 0.8482428789138794
              },
              {
                "id": 5865,
                "faiss_score": 0.8430364727973938,
                "faiss_rank": 14,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 34,
                "sentence": "This sensitivity complicates reproducibility and analysis.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001287212478928268,
                  "neutral": 0.9425387382507324,
                  "support": 0.05617403984069824
                },
                "stance_score": 0.054886827361769974,
                "evidence_contribution": 0.04627159734210604,
                "combined_rank_score": 0.8430364727973938
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "can produce incorrect or misleading outputs",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6606,
                      "faiss_score": 0.863052248954773,
                      "faiss_rank": 1,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "Components may crash completely, producing no output, or they may continue running while producing incorrect results.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0009414730593562126,
                        "neutral": 0.20099835097789764,
                        "support": 0.7980602383613586
                      },
                      "stance_score": 0.7971187653020024,
                      "evidence_contribution": 0.687955143077945,
                      "combined_rank_score": 0.863052248954773
                    },
                    {
                      "id": 2227,
                      "faiss_score": 0.8592409491539001,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 158,
                      "sentence": "The outputs are actually numbers, so when the error is low, the difference between the output (almost certainly a cat) and the correct answer (cat) is small.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.007495637983083725,
                        "neutral": 0.5303006172180176,
                        "support": 0.4622037410736084
                      },
                      "stance_score": 0.4547081030905247,
                      "evidence_contribution": 0.3907038220874719,
                      "combined_rank_score": 0.8592409491539001
                    },
                    {
                      "id": 3535,
                      "faiss_score": 0.8539549112319946,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 106,
                      "sentence": "In this case, the voting circuit can output the correct result, and discard the erroneous version.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.11982972174882889,
                        "neutral": 0.4495139420032501,
                        "support": 0.4306562840938568
                      },
                      "stance_score": 0.3108265623450279,
                      "evidence_contribution": 0.26543186945589436,
                      "combined_rank_score": 0.8539549112319946
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 1986,
                      "faiss_score": 0.8568795919418335,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 254,
                      "sentence": "Results are often sensitive to the prompting method.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.001743515720590949,
                        "neutral": 0.9241812229156494,
                        "support": 0.07407531142234802
                      },
                      "stance_score": 0.07233179570175707,
                      "evidence_contribution": 0.06197963958534167,
                      "combined_rank_score": 0.8568795919418335
                    },
                    {
                      "id": 1310,
                      "faiss_score": 0.8482428789138794,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Statistical_learning_theory",
                      "file_type": ".txt",
                      "position": 20,
                      "sentence": "It takes the value 0 if the predicted output is the same as the actual output, and it takes the value 1 if the predicted output is different from the actual output.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.004643861670047045,
                        "neutral": 0.9214097261428833,
                        "support": 0.07394646108150482
                      },
                      "stance_score": 0.06930259941145778,
                      "evidence_contribution": 0.05878543644099027,
                      "combined_rank_score": 0.8482428789138794
                    },
                    {
                      "id": 5865,
                      "faiss_score": 0.8430364727973938,
                      "faiss_rank": 14,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 34,
                      "sentence": "This sensitivity complicates reproducibility and analysis.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001287212478928268,
                        "neutral": 0.9425387382507324,
                        "support": 0.05617403984069824
                      },
                      "stance_score": 0.054886827361769974,
                      "evidence_contribution": 0.04627159734210604,
                      "combined_rank_score": 0.8430364727973938
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Large language models are powerful",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6121,
                      "faiss_score": 0.9278501868247986,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.007072408217936754,
                        "neutral": 0.2285161018371582,
                        "support": 0.764411449432373
                      },
                      "stance_score": 0.7573390412144363,
                      "evidence_contribution": 0.7026971708805285,
                      "combined_rank_score": 0.9278501868247986
                    },
                    {
                      "id": 6043,
                      "faiss_score": 0.9241077899932861,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005367050878703594,
                        "neutral": 0.8640390634536743,
                        "support": 0.130593940615654
                      },
                      "stance_score": 0.1252268897369504,
                      "evidence_contribution": 0.11572314432254616,
                      "combined_rank_score": 0.9241077899932861
                    },
                    {
                      "id": 6109,
                      "faiss_score": 0.8944122791290283,
                      "faiss_rank": 13,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 69,
                      "sentence": "The rapid pace of development in large language models has reshaped expectations about what machine learning systems can do.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0023451675660908222,
                        "neutral": 0.8843744993209839,
                        "support": 0.11328033357858658
                      },
                      "stance_score": 0.11093516601249576,
                      "evidence_contribution": 0.09922177466879345,
                      "combined_rank_score": 0.8944122791290283
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 2020,
                      "faiss_score": 0.9012563228607178,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 288,
                      "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.2466990351676941,
                        "neutral": 0.6564837694168091,
                        "support": 0.09681721776723862
                      },
                      "stance_score": -0.14988181740045547,
                      "evidence_contribution": -0.13508193561401605,
                      "combined_rank_score": 0.9012563228607178
                    },
                    {
                      "id": 6072,
                      "faiss_score": 0.8847416639328003,
                      "faiss_rank": 17,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 32,
                      "sentence": "Another limitation of large language models is their lack of persistent memory beyond the context window.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.914618194103241,
                        "neutral": 0.07705717533826828,
                        "support": 0.008324596099555492
                      },
                      "stance_score": -0.9062935980036855,
                      "evidence_contribution": -0.8018357059094251,
                      "combined_rank_score": 0.8847416639328003
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6040,
                      "faiss_score": 0.925839900970459,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0008157117408700287,
                        "neutral": 0.9963352680206299,
                        "support": 0.002849036827683449
                      },
                      "stance_score": 0.00203332508681342,
                      "evidence_contribution": 0.0018825334970160867,
                      "combined_rank_score": 0.925839900970459
                    },
                    {
                      "id": 1796,
                      "faiss_score": 0.9162331819534302,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 64,
                      "sentence": "The tendency towards larger models is visible in the list of large language models.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.0007646913290955126,
                        "neutral": 0.9953639507293701,
                        "support": 0.003871325869113207
                      },
                      "stance_score": 0.0031066345400176942,
                      "evidence_contribution": 0.002846401649766843,
                      "combined_rank_score": 0.9162331819534302
                    },
                    {
                      "id": 6102,
                      "faiss_score": 0.9150678515434265,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 62,
                      "sentence": "Evaluation of large language models presents its own challenges.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.02573368325829506,
                        "neutral": 0.9543356895446777,
                        "support": 0.019930649548768997
                      },
                      "stance_score": -0.005803033709526062,
                      "evidence_contribution": -0.005310169589010094,
                      "combined_rank_score": 0.9150678515434265
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Quantum error correction enables scaling but adds significant overhead.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Quantum error correction enables scaling",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 1.6039180045508503,
            "contradict": 2.51697936368912,
            "total": 4.12089736823997
          },
          "evidence": {
            "supporting": [
              {
                "id": 6553,
                "faiss_score": 0.9426121711730957,
                "faiss_rank": 3,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.009470941498875618,
                  "neutral": 0.13609865307807922,
                  "support": 0.8544303774833679
                },
                "stance_score": 0.8449594359844923,
                "evidence_contribution": 0.7964690485065367,
                "combined_rank_score": 0.9426121711730957
              },
              {
                "id": 4795,
                "faiss_score": 0.9083656072616577,
                "faiss_rank": 9,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.020467771217226982,
                  "neutral": 0.22572223842144012,
                  "support": 0.7538099884986877
                },
                "stance_score": 0.7333422172814608,
                "evidence_contribution": 0.6661428485314846,
                "combined_rank_score": 0.9083656072616577
              },
              {
                "id": 4719,
                "faiss_score": 0.9455520510673523,
                "faiss_rank": 1,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.1649482250213623,
                  "neutral": 0.5206605792045593,
                  "support": 0.31439119577407837
                },
                "stance_score": 0.14944297075271606,
                "evidence_contribution": 0.14130610751282902,
                "combined_rank_score": 0.9455520510673523
              }
            ],
            "contradicting": [
              {
                "id": 6519,
                "faiss_score": 0.9007676839828491,
                "faiss_rank": 13,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "However, practical quantum systems face substantial obstacles, including noise, error correction, and scalability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9674301147460938,
                  "neutral": 0.030045244842767715,
                  "support": 0.002524576848372817
                },
                "stance_score": -0.9649055378977209,
                "evidence_contribution": -0.8691557266343554,
                "combined_rank_score": 0.9007676839828491
              },
              {
                "id": 760,
                "faiss_score": 0.8989653587341309,
                "faiss_rank": 15,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 164,
                "sentence": "However, the use of error correction brings with it the cost of a greatly increased number of required qubits.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.7653741836547852,
                  "neutral": 0.22782734036445618,
                  "support": 0.006798561662435532
                },
                "stance_score": -0.7585756219923496,
                "evidence_contribution": -0.681933206151319,
                "combined_rank_score": 0.8989653587341309
              },
              {
                "id": 764,
                "faiss_score": 0.9256996512413025,
                "faiss_rank": 4,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 168,
                "sentence": "However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.7112657427787781,
                  "neutral": 0.26489055156707764,
                  "support": 0.02384369447827339
                },
                "stance_score": -0.6874220483005047,
                "evidence_contribution": -0.636346350367359,
                "combined_rank_score": 0.9256996512413025
              },
              {
                "id": 744,
                "faiss_score": 0.893892765045166,
                "faiss_rank": 18,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 148,
                "sentence": "Scaling these systems to support a growing number of qubits is an additional challenge.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.3714944124221802,
                  "neutral": 0.6256728768348694,
                  "support": 0.002832651836797595
                },
                "stance_score": -0.3686617605853826,
                "evidence_contribution": -0.32954408053608664,
                "combined_rank_score": 0.893892765045166
              }
            ],
            "neutral": [
              {
                "id": 4862,
                "faiss_score": 0.9224804043769836,
                "faiss_rank": 6,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 109,
                "sentence": "Quantum error correction can be applied to quantum metrology.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.0023149496410042048,
                  "neutral": 0.9899492263793945,
                  "support": 0.007735862862318754
                },
                "stance_score": 0.0054209132213145494,
                "evidence_contribution": 0.005000686220490783,
                "combined_rank_score": 0.9224804043769836
              },
              {
                "id": 4786,
                "faiss_score": 0.9128077030181885,
                "faiss_rank": 7,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 33,
                "sentence": "It states that errors can be corrected by recursively concatenating quantum codes\u2014such as CSS codes\u2014across logarithmically many levels, provided the error rate of individual quantum gates remains below a certain threshold.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.0012575651053339243,
                  "neutral": 0.9948614239692688,
                  "support": 0.003881047712638974
                },
                "stance_score": 0.00262348260730505,
                "evidence_contribution": 0.0023947351326822908,
                "combined_rank_score": 0.9128077030181885
              },
              {
                "id": 4866,
                "faiss_score": 0.908725380897522,
                "faiss_rank": 8,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 113,
                "sentence": "In this scheme, the errors can be detected, and corrected following the general rules of quantum error correction.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.0012080748565495014,
                  "neutral": 0.9974058270454407,
                  "support": 0.0013860358158126473
                },
                "stance_score": 0.00017796095926314592,
                "evidence_contribution": 0.00016171764049129067,
                "combined_rank_score": 0.908725380897522
              }
            ]
          }
        },
        {
          "subclaim": "Quantum error correction adds significant overhead",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 3.1046247250785473,
            "contradict": 0.7044130873171879,
            "total": 3.809037812395735
          },
          "evidence": {
            "supporting": [
              {
                "id": 6553,
                "faiss_score": 0.9569774270057678,
                "faiss_rank": 3,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009398495312780142,
                  "neutral": 0.05072243511676788,
                  "support": 0.9483376741409302
                },
                "stance_score": 0.9473978246096522,
                "evidence_contribution": 0.9066383325458066,
                "combined_rank_score": 0.9569774270057678
              },
              {
                "id": 4719,
                "faiss_score": 0.9596387147903442,
                "faiss_rank": 1,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.001737573416903615,
                  "neutral": 0.12948888540267944,
                  "support": 0.8687735199928284
                },
                "stance_score": 0.8670359465759248,
                "evidence_contribution": 0.83204126144915,
                "combined_rank_score": 0.9596387147903442
              },
              {
                "id": 764,
                "faiss_score": 0.9263245463371277,
                "faiss_rank": 6,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 168,
                "sentence": "However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.001764934859238565,
                  "neutral": 0.11494402587413788,
                  "support": 0.8832909464836121
                },
                "stance_score": 0.8815260116243735,
                "evidence_contribution": 0.8165791828023253,
                "combined_rank_score": 0.9263245463371277
              },
              {
                "id": 760,
                "faiss_score": 0.9360631704330444,
                "faiss_rank": 4,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 164,
                "sentence": "However, the use of error correction brings with it the cost of a greatly increased number of required qubits.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.005362153984606266,
                  "neutral": 0.6224373579025269,
                  "support": 0.37220048904418945
                },
                "stance_score": 0.3668383350595832,
                "evidence_contribution": 0.3433838549522529,
                "combined_rank_score": 0.9360631704330444
              },
              {
                "id": 6519,
                "faiss_score": 0.8970855474472046,
                "faiss_rank": 10,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "However, practical quantum systems face substantial obstacles, including noise, error correction, and scalability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0018105971394106746,
                  "neutral": 0.7667663097381592,
                  "support": 0.23142313957214355
                },
                "stance_score": 0.22961254243273288,
                "evidence_contribution": 0.20598209332901268,
                "combined_rank_score": 0.8970855474472046
              }
            ],
            "contradicting": [
              {
                "id": 757,
                "faiss_score": 0.8856757879257202,
                "faiss_rank": 15,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 161,
                "sentence": "This allows the total calculation time to be longer than the decoherence time if the error correction scheme can correct errors faster than decoherence introduces them.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.4519113004207611,
                  "neutral": 0.543056845664978,
                  "support": 0.005031846463680267
                },
                "stance_score": -0.44687945395708084,
                "evidence_contribution": -0.3957903124912532,
                "combined_rank_score": 0.8856757879257202
              },
              {
                "id": 4824,
                "faiss_score": 0.8923410177230835,
                "faiss_rank": 14,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 71,
                "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.20826101303100586,
                  "neutral": 0.7879799008369446,
                  "support": 0.003759042825549841
                },
                "stance_score": -0.20450197020545602,
                "evidence_contribution": -0.18248549621951232,
                "combined_rank_score": 0.8923410177230835
              },
              {
                "id": 4795,
                "faiss_score": 0.89435875415802,
                "faiss_rank": 11,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.14968205988407135,
                  "neutral": 0.841672420501709,
                  "support": 0.008645503781735897
                },
                "stance_score": -0.14103655610233545,
                "evidence_contribution": -0.12613727860642243,
                "combined_rank_score": 0.89435875415802
              }
            ],
            "neutral": [
              {
                "id": 6554,
                "faiss_score": 0.915757417678833,
                "faiss_rank": 8,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0015190973645076156,
                  "neutral": 0.9730349183082581,
                  "support": 0.025445954874157906
                },
                "stance_score": 0.02392685750965029,
                "evidence_contribution": 0.021911197246206743,
                "combined_rank_score": 0.915757417678833
              },
              {
                "id": 6555,
                "faiss_score": 0.9089707136154175,
                "faiss_rank": 9,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 15,
                "sentence": "This overhead means that a useful, fault-tolerant quantum computer would need orders of magnitude more qubits than are currently available.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.008294355124235153,
                  "neutral": 0.9852702617645264,
                  "support": 0.006435340270400047
                },
                "stance_score": -0.001859014853835106,
                "evidence_contribution": -0.0016897900583121572,
                "combined_rank_score": 0.9089707136154175
              },
              {
                "id": 4862,
                "faiss_score": 0.894229531288147,
                "faiss_rank": 12,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 109,
                "sentence": "Quantum error correction can be applied to quantum metrology.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.00450995983555913,
                  "neutral": 0.9947214126586914,
                  "support": 0.0007686226163059473
                },
                "stance_score": -0.0037413372192531824,
                "evidence_contribution": -0.0033456142279636725,
                "combined_rank_score": 0.894229531288147
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Quantum error correction adds significant overhead",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 4719,
                      "faiss_score": 0.9596387147903442,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.001737573416903615,
                        "neutral": 0.12948888540267944,
                        "support": 0.8687735199928284
                      },
                      "stance_score": 0.8670359465759248,
                      "evidence_contribution": 0.83204126144915,
                      "combined_rank_score": 0.9596387147903442
                    },
                    {
                      "id": 6553,
                      "faiss_score": 0.9569774270057678,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0009398495312780142,
                        "neutral": 0.05072243511676788,
                        "support": 0.9483376741409302
                      },
                      "stance_score": 0.9473978246096522,
                      "evidence_contribution": 0.9066383325458066,
                      "combined_rank_score": 0.9569774270057678
                    },
                    {
                      "id": 760,
                      "faiss_score": 0.9360631704330444,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 164,
                      "sentence": "However, the use of error correction brings with it the cost of a greatly increased number of required qubits.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.005362153984606266,
                        "neutral": 0.6224373579025269,
                        "support": 0.37220048904418945
                      },
                      "stance_score": 0.3668383350595832,
                      "evidence_contribution": 0.3433838549522529,
                      "combined_rank_score": 0.9360631704330444
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 4795,
                      "faiss_score": 0.89435875415802,
                      "faiss_rank": 11,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.14968205988407135,
                        "neutral": 0.841672420501709,
                        "support": 0.008645503781735897
                      },
                      "stance_score": -0.14103655610233545,
                      "evidence_contribution": -0.12613727860642243,
                      "combined_rank_score": 0.89435875415802
                    },
                    {
                      "id": 4824,
                      "faiss_score": 0.8923410177230835,
                      "faiss_rank": 14,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 71,
                      "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.20826101303100586,
                        "neutral": 0.7879799008369446,
                        "support": 0.003759042825549841
                      },
                      "stance_score": -0.20450197020545602,
                      "evidence_contribution": -0.18248549621951232,
                      "combined_rank_score": 0.8923410177230835
                    },
                    {
                      "id": 757,
                      "faiss_score": 0.8856757879257202,
                      "faiss_rank": 15,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 161,
                      "sentence": "This allows the total calculation time to be longer than the decoherence time if the error correction scheme can correct errors faster than decoherence introduces them.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.4519113004207611,
                        "neutral": 0.543056845664978,
                        "support": 0.005031846463680267
                      },
                      "stance_score": -0.44687945395708084,
                      "evidence_contribution": -0.3957903124912532,
                      "combined_rank_score": 0.8856757879257202
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6554,
                      "faiss_score": 0.915757417678833,
                      "faiss_rank": 8,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0015190973645076156,
                        "neutral": 0.9730349183082581,
                        "support": 0.025445954874157906
                      },
                      "stance_score": 0.02392685750965029,
                      "evidence_contribution": 0.021911197246206743,
                      "combined_rank_score": 0.915757417678833
                    },
                    {
                      "id": 6555,
                      "faiss_score": 0.9089707136154175,
                      "faiss_rank": 9,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 15,
                      "sentence": "This overhead means that a useful, fault-tolerant quantum computer would need orders of magnitude more qubits than are currently available.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.008294355124235153,
                        "neutral": 0.9852702617645264,
                        "support": 0.006435340270400047
                      },
                      "stance_score": -0.001859014853835106,
                      "evidence_contribution": -0.0016897900583121572,
                      "combined_rank_score": 0.9089707136154175
                    },
                    {
                      "id": 4862,
                      "faiss_score": 0.894229531288147,
                      "faiss_rank": 12,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 109,
                      "sentence": "Quantum error correction can be applied to quantum metrology.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.00450995983555913,
                        "neutral": 0.9947214126586914,
                        "support": 0.0007686226163059473
                      },
                      "stance_score": -0.0037413372192531824,
                      "evidence_contribution": -0.0033456142279636725,
                      "combined_rank_score": 0.894229531288147
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Quantum error correction enables scaling",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 4719,
                      "faiss_score": 0.9455520510673523,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.1649482250213623,
                        "neutral": 0.5206605792045593,
                        "support": 0.31439119577407837
                      },
                      "stance_score": 0.14944297075271606,
                      "evidence_contribution": 0.14130610751282902,
                      "combined_rank_score": 0.9455520510673523
                    },
                    {
                      "id": 6553,
                      "faiss_score": 0.9426121711730957,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.009470941498875618,
                        "neutral": 0.13609865307807922,
                        "support": 0.8544303774833679
                      },
                      "stance_score": 0.8449594359844923,
                      "evidence_contribution": 0.7964690485065367,
                      "combined_rank_score": 0.9426121711730957
                    },
                    {
                      "id": 4795,
                      "faiss_score": 0.9083656072616577,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.020467771217226982,
                        "neutral": 0.22572223842144012,
                        "support": 0.7538099884986877
                      },
                      "stance_score": 0.7333422172814608,
                      "evidence_contribution": 0.6661428485314846,
                      "combined_rank_score": 0.9083656072616577
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 764,
                      "faiss_score": 0.9256996512413025,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 168,
                      "sentence": "However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.7112657427787781,
                        "neutral": 0.26489055156707764,
                        "support": 0.02384369447827339
                      },
                      "stance_score": -0.6874220483005047,
                      "evidence_contribution": -0.636346350367359,
                      "combined_rank_score": 0.9256996512413025
                    },
                    {
                      "id": 6519,
                      "faiss_score": 0.9007676839828491,
                      "faiss_rank": 13,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 48,
                      "sentence": "However, practical quantum systems face substantial obstacles, including noise, error correction, and scalability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9674301147460938,
                        "neutral": 0.030045244842767715,
                        "support": 0.002524576848372817
                      },
                      "stance_score": -0.9649055378977209,
                      "evidence_contribution": -0.8691557266343554,
                      "combined_rank_score": 0.9007676839828491
                    },
                    {
                      "id": 760,
                      "faiss_score": 0.8989653587341309,
                      "faiss_rank": 15,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 164,
                      "sentence": "However, the use of error correction brings with it the cost of a greatly increased number of required qubits.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.7653741836547852,
                        "neutral": 0.22782734036445618,
                        "support": 0.006798561662435532
                      },
                      "stance_score": -0.7585756219923496,
                      "evidence_contribution": -0.681933206151319,
                      "combined_rank_score": 0.8989653587341309
                    }
                  ],
                  "neutral": [
                    {
                      "id": 4862,
                      "faiss_score": 0.9224804043769836,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 109,
                      "sentence": "Quantum error correction can be applied to quantum metrology.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.0023149496410042048,
                        "neutral": 0.9899492263793945,
                        "support": 0.007735862862318754
                      },
                      "stance_score": 0.0054209132213145494,
                      "evidence_contribution": 0.005000686220490783,
                      "combined_rank_score": 0.9224804043769836
                    },
                    {
                      "id": 4786,
                      "faiss_score": 0.9128077030181885,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 33,
                      "sentence": "It states that errors can be corrected by recursively concatenating quantum codes\u2014such as CSS codes\u2014across logarithmically many levels, provided the error rate of individual quantum gates remains below a certain threshold.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.0012575651053339243,
                        "neutral": 0.9948614239692688,
                        "support": 0.003881047712638974
                      },
                      "stance_score": 0.00262348260730505,
                      "evidence_contribution": 0.0023947351326822908,
                      "combined_rank_score": 0.9128077030181885
                    },
                    {
                      "id": 4866,
                      "faiss_score": 0.908725380897522,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 113,
                      "sentence": "In this scheme, the errors can be detected, and corrected following the general rules of quantum error correction.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.0012080748565495014,
                        "neutral": 0.9974058270454407,
                        "support": 0.0013860358158126473
                      },
                      "stance_score": 0.00017796095926314592,
                      "evidence_contribution": 0.00016171764049129067,
                      "combined_rank_score": 0.908725380897522
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Future architectures will eliminate the need for large datasets in machine learning.",
      "expected_verdict": "INCONCLUSIVE",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Future architectures will eliminate the need for large datasets in machine learning.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 0.7544019555528143,
            "total": 0.7544019555528143
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 5952,
                "faiss_score": 0.8825785517692566,
                "faiss_rank": 3,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Energy efficiency has become increasingly important as machine learning workloads scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.2467861920595169,
                  "neutral": 0.7516210675239563,
                  "support": 0.0015927674248814583
                },
                "stance_score": -0.24519342463463545,
                "evidence_contribution": -0.21640245761738092,
                "combined_rank_score": 0.8825785517692566
              },
              {
                "id": 6125,
                "faiss_score": 0.8606041669845581,
                "faiss_rank": 18,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Over the past decade, scaling has emerged as one of the most reliable drivers of progress in machine learning systems, particularly in deep learning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.22337916493415833,
                  "neutral": 0.7750259637832642,
                  "support": 0.0015949285589158535
                },
                "stance_score": -0.22178423637524247,
                "evidence_contribution": -0.19086843799602188,
                "combined_rank_score": 0.8606041669845581
              },
              {
                "id": 6165,
                "faiss_score": 0.8752605319023132,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 41,
                "sentence": "From a systems perspective, scaling reshapes the entire machine learning pipeline.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.1764662116765976,
                  "neutral": 0.8213576674461365,
                  "support": 0.002176115522161126
                },
                "stance_score": -0.17429009615443647,
                "evidence_contribution": -0.15254924226543737,
                "combined_rank_score": 0.8752605319023132
              },
              {
                "id": 5905,
                "faiss_score": 0.9030225276947021,
                "faiss_rank": 1,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.11705312877893448,
                  "neutral": 0.8816056251525879,
                  "support": 0.0013412677217274904
                },
                "stance_score": -0.11571186105720699,
                "evidence_contribution": -0.10449041725613722,
                "combined_rank_score": 0.9030225276947021
              },
              {
                "id": 6124,
                "faiss_score": 0.8617883920669556,
                "faiss_rank": 16,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.10562246292829514,
                  "neutral": 0.893295168876648,
                  "support": 0.0010824142955243587
                },
                "stance_score": -0.10454004863277078,
                "evidence_contribution": -0.09009140041783686,
                "combined_rank_score": 0.8617883920669556
              }
            ],
            "neutral": [
              {
                "id": 5965,
                "faiss_score": 0.9007288813591003,
                "faiss_rank": 2,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 60,
                "sentence": "By reducing resource requirements, efficiency techniques can democratize access to machine learning technology.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0034897448495030403,
                  "neutral": 0.995370090007782,
                  "support": 0.0011401893571019173
                },
                "stance_score": -0.002349555492401123,
                "evidence_contribution": -0.0021163124903615937,
                "combined_rank_score": 0.9007288813591003
              },
              {
                "id": 6126,
                "faiss_score": 0.872998833656311,
                "faiss_rank": 5,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "Rather than relying on narrowly optimized architectures or handcrafted features, many modern systems achieve strong performance by training large models on vast amounts of data using substantial compute.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0634174570441246,
                  "neutral": 0.935447633266449,
                  "support": 0.0011348612606525421
                },
                "stance_score": -0.06228259578347206,
                "evidence_contribution": -0.054372633476058585,
                "combined_rank_score": 0.872998833656311
              },
              {
                "id": 6246,
                "faiss_score": 0.8729766607284546,
                "faiss_rank": 6,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 54,
                "sentence": "By halting training when performance on a validation set stops improving, systems can avoid overfitting and reduce resource usage.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.008792835287749767,
                  "neutral": 0.9905010461807251,
                  "support": 0.0007061547366902232
                },
                "stance_score": -0.008086680551059544,
                "evidence_contribution": -0.0070594833838417,
                "combined_rank_score": 0.8729766607284546
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Future architectures will eliminate the need for large datasets in machine learning.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 5905,
                      "faiss_score": 0.9030225276947021,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.11705312877893448,
                        "neutral": 0.8816056251525879,
                        "support": 0.0013412677217274904
                      },
                      "stance_score": -0.11571186105720699,
                      "evidence_contribution": -0.10449041725613722,
                      "combined_rank_score": 0.9030225276947021
                    },
                    {
                      "id": 5952,
                      "faiss_score": 0.8825785517692566,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 47,
                      "sentence": "Energy efficiency has become increasingly important as machine learning workloads scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.2467861920595169,
                        "neutral": 0.7516210675239563,
                        "support": 0.0015927674248814583
                      },
                      "stance_score": -0.24519342463463545,
                      "evidence_contribution": -0.21640245761738092,
                      "combined_rank_score": 0.8825785517692566
                    },
                    {
                      "id": 6165,
                      "faiss_score": 0.8752605319023132,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 41,
                      "sentence": "From a systems perspective, scaling reshapes the entire machine learning pipeline.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.1764662116765976,
                        "neutral": 0.8213576674461365,
                        "support": 0.002176115522161126
                      },
                      "stance_score": -0.17429009615443647,
                      "evidence_contribution": -0.15254924226543737,
                      "combined_rank_score": 0.8752605319023132
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5965,
                      "faiss_score": 0.9007288813591003,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 60,
                      "sentence": "By reducing resource requirements, efficiency techniques can democratize access to machine learning technology.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0034897448495030403,
                        "neutral": 0.995370090007782,
                        "support": 0.0011401893571019173
                      },
                      "stance_score": -0.002349555492401123,
                      "evidence_contribution": -0.0021163124903615937,
                      "combined_rank_score": 0.9007288813591003
                    },
                    {
                      "id": 6126,
                      "faiss_score": 0.872998833656311,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 2,
                      "sentence": "Rather than relying on narrowly optimized architectures or handcrafted features, many modern systems achieve strong performance by training large models on vast amounts of data using substantial compute.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0634174570441246,
                        "neutral": 0.935447633266449,
                        "support": 0.0011348612606525421
                      },
                      "stance_score": -0.06228259578347206,
                      "evidence_contribution": -0.054372633476058585,
                      "combined_rank_score": 0.872998833656311
                    },
                    {
                      "id": 6246,
                      "faiss_score": 0.8729766607284546,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 54,
                      "sentence": "By halting training when performance on a validation set stops improving, systems can avoid overfitting and reduce resource usage.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.008792835287749767,
                        "neutral": 0.9905010461807251,
                        "support": 0.0007061547366902232
                      },
                      "stance_score": -0.008086680551059544,
                      "evidence_contribution": -0.0070594833838417,
                      "combined_rank_score": 0.8729766607284546
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "A single algorithm can optimally solve all machine learning problems.",
      "expected_verdict": "INCONCLUSIVE",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "A single algorithm can optimally solve all machine learning problems.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.32533318359961605,
            "contradict": 7.537053563742442,
            "total": 7.862386747342058
          },
          "evidence": {
            "supporting": [
              {
                "id": 267,
                "faiss_score": 0.8847181797027588,
                "faiss_rank": 9,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 158,
                "sentence": "This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.04583118110895157,
                  "neutral": 0.5406124591827393,
                  "support": 0.41355639696121216
                },
                "stance_score": 0.3677252158522606,
                "evidence_contribution": 0.32533318359961605,
                "combined_rank_score": 0.8847181797027588
              }
            ],
            "contradicting": [
              {
                "id": 2303,
                "faiss_score": 0.8766059875488281,
                "faiss_rank": 17,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 234,
                "sentence": "Learning algorithm: Numerous trade-offs exist between learning algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.9910756349563599,
                  "neutral": 0.008461421355605125,
                  "support": 0.00046292017214000225
                },
                "stance_score": -0.9906127147842199,
                "evidence_contribution": -0.8683770371218467,
                "combined_rank_score": 0.8766059875488281
              },
              {
                "id": 5971,
                "faiss_score": 0.8860356211662292,
                "faiss_rank": 7,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 66,
                "sentence": "Ultimately, efficiency in machine learning is not merely about reducing cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9790518283843994,
                  "neutral": 0.020076565444469452,
                  "support": 0.0008715971489436924
                },
                "stance_score": -0.9781802312354557,
                "evidence_contribution": -0.8667025287952328,
                "combined_rank_score": 0.8860356211662292
              },
              {
                "id": 5905,
                "faiss_score": 0.8929596543312073,
                "faiss_rank": 2,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9651382565498352,
                  "neutral": 0.03367020934820175,
                  "support": 0.001191639807075262
                },
                "stance_score": -0.9639466167427599,
                "evidence_contribution": -0.8607654376803516,
                "combined_rank_score": 0.8929596543312073
              },
              {
                "id": 6332,
                "faiss_score": 0.8764703273773193,
                "faiss_rank": 18,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 71,
                "sentence": "Understanding both its strengths and limitations is essential for building robust and reliable machine learning systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9810643196105957,
                  "neutral": 0.017950979992747307,
                  "support": 0.0009847128530964255
                },
                "stance_score": -0.9800796067574993,
                "evidence_contribution": -0.8590106937905798,
                "combined_rank_score": 0.8764703273773193
              },
              {
                "id": 1558,
                "faiss_score": 0.8794730305671692,
                "faiss_rank": 14,
                "doc_id": "wiki_Optimization_(mathematics)",
                "file_type": ".txt",
                "position": 7,
                "sentence": "In machine learning, it is always necessary to continuously evaluate the quality of a data model by using a cost function where a minimum implies a set of possibly optimal parameters with an optimal (lowest) error.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                "primary_category": "all articles with style issues",
                "probs": {
                  "contradict": 0.8922678232192993,
                  "neutral": 0.10589844733476639,
                  "support": 0.0018336758948862553
                },
                "stance_score": -0.8904341473244131,
                "evidence_contribution": -0.7831128180678948,
                "combined_rank_score": 0.8794730305671692
              },
              {
                "id": 1311,
                "faiss_score": 0.8889755606651306,
                "faiss_rank": 3,
                "doc_id": "wiki_Statistical_learning_theory",
                "file_type": ".txt",
                "position": 21,
                "sentence": "In machine learning problems, a major problem that arises is that of overfitting.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.8508790135383606,
                  "neutral": 0.14767500758171082,
                  "support": 0.0014459060039371252
                },
                "stance_score": -0.8494331075344235,
                "evidence_contribution": -0.7551252730179383,
                "combined_rank_score": 0.8889755606651306
              },
              {
                "id": 5840,
                "faiss_score": 0.8876022100448608,
                "faiss_rank": 4,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "Gradient-based methods are the most widely used optimization techniques in machine learning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8216201663017273,
                  "neutral": 0.17583926022052765,
                  "support": 0.0025405713822692633
                },
                "stance_score": -0.819079594919458,
                "evidence_contribution": -0.7270168586531603,
                "combined_rank_score": 0.8876022100448608
              },
              {
                "id": 5834,
                "faiss_score": 0.8729329109191895,
                "faiss_rank": 20,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The behavior of learning systems is therefore tightly coupled to the properties of optimization algorithms and the landscapes they operate on.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6857085227966309,
                  "neutral": 0.3120211958885193,
                  "support": 0.002270284341648221
                },
                "stance_score": -0.6834382384549826,
                "evidence_contribution": -0.5965957309279911,
                "combined_rank_score": 0.8729329109191895
              },
              {
                "id": 2304,
                "faiss_score": 0.8852899074554443,
                "faiss_rank": 8,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 235,
                "sentence": "Almost any algorithm will work well with the correct hyperparameters for training on a particular data set.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.5949611067771912,
                  "neutral": 0.39376574754714966,
                  "support": 0.011273126117885113
                },
                "stance_score": -0.583687980659306,
                "evidence_contribution": -0.5167330783807322,
                "combined_rank_score": 0.8852899074554443
              },
              {
                "id": 1316,
                "faiss_score": 0.8732139468193054,
                "faiss_rank": 19,
                "doc_id": "wiki_Statistical_learning_theory",
                "file_type": ".txt",
                "position": 26,
                "sentence": "Regularization can solve the overfitting problem and give the problem stability.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.26942452788352966,
                  "neutral": 0.7251327633857727,
                  "support": 0.005442693363875151
                },
                "stance_score": -0.2639818345196545,
                "evidence_contribution": -0.23051261960950828,
                "combined_rank_score": 0.8732139468193054
              },
              {
                "id": 5965,
                "faiss_score": 0.8805195093154907,
                "faiss_rank": 11,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 60,
                "sentence": "By reducing resource requirements, efficiency techniques can democratize access to machine learning technology.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.25360676646232605,
                  "neutral": 0.7442765235900879,
                  "support": 0.002116743940860033
                },
                "stance_score": -0.251490022521466,
                "evidence_contribution": -0.22144187122834297,
                "combined_rank_score": 0.8805195093154907
              },
              {
                "id": 147,
                "faiss_score": 0.8778112530708313,
                "faiss_rank": 15,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 38,
                "sentence": "Machine learning also has intimate ties to optimisation: Many learning problems are formulated as minimisation of some loss function on a training set of examples.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.1633848398923874,
                  "neutral": 0.8352454304695129,
                  "support": 0.0013697107788175344
                },
                "stance_score": -0.16201512911356986,
                "evidence_contribution": -0.14221870350361526,
                "combined_rank_score": 0.8778112530708313
              },
              {
                "id": 338,
                "faiss_score": 0.8796346187591553,
                "faiss_rank": 12,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 229,
                "sentence": "In machine learning, genetic algorithms were used in the 1980s and 1990s.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.12754929065704346,
                  "neutral": 0.8693177700042725,
                  "support": 0.0031329584307968616
                },
                "stance_score": -0.1244163322262466,
                "evidence_contribution": -0.10944091296524683,
                "combined_rank_score": 0.8796346187591553
              }
            ],
            "neutral": [
              {
                "id": 5831,
                "faiss_score": 0.8993061780929565,
                "faiss_rank": 1,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Optimization lies at the core of modern machine learning and computational systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.07188953459262848,
                  "neutral": 0.9265451431274414,
                  "support": 0.001565277692861855
                },
                "stance_score": -0.07032425689976662,
                "evidence_contribution": -0.06324303869975635,
                "combined_rank_score": 0.8993061780929565
              },
              {
                "id": 331,
                "faiss_score": 0.8863186836242676,
                "faiss_rank": 5,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 222,
                "sentence": "Efficient algorithms exist that perform inference and learning.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.029771577566862106,
                  "neutral": 0.967642605304718,
                  "support": 0.0025857884902507067
                },
                "stance_score": -0.0271857890766114,
                "evidence_contribution": -0.02409527278766921,
                "combined_rank_score": 0.8863186836242676
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "A single algorithm can optimally solve all machine learning problems.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 267,
                      "faiss_score": 0.8847181797027588,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 158,
                      "sentence": "This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.04583118110895157,
                        "neutral": 0.5406124591827393,
                        "support": 0.41355639696121216
                      },
                      "stance_score": 0.3677252158522606,
                      "evidence_contribution": 0.32533318359961605,
                      "combined_rank_score": 0.8847181797027588
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5905,
                      "faiss_score": 0.8929596543312073,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9651382565498352,
                        "neutral": 0.03367020934820175,
                        "support": 0.001191639807075262
                      },
                      "stance_score": -0.9639466167427599,
                      "evidence_contribution": -0.8607654376803516,
                      "combined_rank_score": 0.8929596543312073
                    },
                    {
                      "id": 1311,
                      "faiss_score": 0.8889755606651306,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Statistical_learning_theory",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "In machine learning problems, a major problem that arises is that of overfitting.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.8508790135383606,
                        "neutral": 0.14767500758171082,
                        "support": 0.0014459060039371252
                      },
                      "stance_score": -0.8494331075344235,
                      "evidence_contribution": -0.7551252730179383,
                      "combined_rank_score": 0.8889755606651306
                    },
                    {
                      "id": 5840,
                      "faiss_score": 0.8876022100448608,
                      "faiss_rank": 4,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "Gradient-based methods are the most widely used optimization techniques in machine learning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.8216201663017273,
                        "neutral": 0.17583926022052765,
                        "support": 0.0025405713822692633
                      },
                      "stance_score": -0.819079594919458,
                      "evidence_contribution": -0.7270168586531603,
                      "combined_rank_score": 0.8876022100448608
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5831,
                      "faiss_score": 0.8993061780929565,
                      "faiss_rank": 1,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Optimization lies at the core of modern machine learning and computational systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.07188953459262848,
                        "neutral": 0.9265451431274414,
                        "support": 0.001565277692861855
                      },
                      "stance_score": -0.07032425689976662,
                      "evidence_contribution": -0.06324303869975635,
                      "combined_rank_score": 0.8993061780929565
                    },
                    {
                      "id": 331,
                      "faiss_score": 0.8863186836242676,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 222,
                      "sentence": "Efficient algorithms exist that perform inference and learning.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.029771577566862106,
                        "neutral": 0.967642605304718,
                        "support": 0.0025857884902507067
                      },
                      "stance_score": -0.0271857890766114,
                      "evidence_contribution": -0.02409527278766921,
                      "combined_rank_score": 0.8863186836242676
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Quantum computers will replace classical computers for most workloads.",
      "expected_verdict": "INCONCLUSIVE",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Quantum computers will replace classical computers for most workloads.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 4.538150743660596,
            "total": 4.538150743660596
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 736,
                "faiss_score": 0.9381494522094727,
                "faiss_rank": 1,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 140,
                "sentence": "As of 2023, classical computers outperform quantum computers for all real-world applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.9913483262062073,
                  "neutral": 0.006687983404844999,
                  "support": 0.0019637111108750105
                },
                "stance_score": -0.9893846150953323,
                "evidence_contribution": -0.9281906346761659,
                "combined_rank_score": 0.9381494522094727
              },
              {
                "id": 6594,
                "faiss_score": 0.9081912636756897,
                "faiss_rank": 11,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 54,
                "sentence": "Ultimately, quantum computing represents a long-term research effort rather than a near-term replacement for classical computation.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.990568220615387,
                  "neutral": 0.007592997048050165,
                  "support": 0.001838862313888967
                },
                "stance_score": -0.988729358301498,
                "evidence_contribution": -0.8979553653490913,
                "combined_rank_score": 0.9081912636756897
              },
              {
                "id": 6574,
                "faiss_score": 0.9328113794326782,
                "faiss_rank": 3,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 34,
                "sentence": "Rather than replacing classical systems, quantum computers are expected to act as accelerators for specific subroutines.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9586077928543091,
                  "neutral": 0.03871520608663559,
                  "support": 0.002676980337128043
                },
                "stance_score": -0.955930812517181,
                "evidence_contribution": -0.8917031398663525,
                "combined_rank_score": 0.9328113794326782
              },
              {
                "id": 4663,
                "faiss_score": 0.9036572575569153,
                "faiss_rank": 17,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 141,
                "sentence": "While current quantum computers may speed up solutions to particular mathematical problems, they give no computational advantage for practical tasks.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.9388755559921265,
                  "neutral": 0.05857974663376808,
                  "support": 0.00254472135566175
                },
                "stance_score": -0.9363308346364647,
                "evidence_contribution": -0.8461221541935653,
                "combined_rank_score": 0.9036572575569153
              },
              {
                "id": 820,
                "faiss_score": 0.9049538373947144,
                "faiss_rank": 15,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 224,
                "sentence": "In other words, quantum computers provide no additional power over classical computers in terms of computability.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.5743324160575867,
                  "neutral": 0.4228309094905853,
                  "support": 0.002836654195562005
                },
                "stance_score": -0.5714957618620247,
                "evidence_contribution": -0.517177282751855,
                "combined_rank_score": 0.9049538373947144
              },
              {
                "id": 822,
                "faiss_score": 0.902823269367218,
                "faiss_rank": 19,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 226,
                "sentence": "While quantum computers cannot solve any problems that classical computers cannot already solve, it is suspected that they can solve certain problems faster than classical computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.35174041986465454,
                  "neutral": 0.6457991003990173,
                  "support": 0.002460495801642537
                },
                "stance_score": -0.349279924063012,
                "evidence_contribution": -0.31533804296690215,
                "combined_rank_score": 0.902823269367218
              },
              {
                "id": 6573,
                "faiss_score": 0.9102804064750671,
                "faiss_rank": 8,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 33,
                "sentence": "The integration of quantum and classical computing is widely viewed as essential.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.15705923736095428,
                  "neutral": 0.8415084481239319,
                  "support": 0.0014323306968435645
                },
                "stance_score": -0.15562690666411072,
                "evidence_contribution": -0.14166412385666405,
                "combined_rank_score": 0.9102804064750671
              }
            ],
            "neutral": [
              {
                "id": 701,
                "faiss_score": 0.9195835590362549,
                "faiss_rank": 4,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 105,
                "sentence": "In June 2023, IBM computer scientists reported that a quantum computer produced better results for a physics problem than a conventional supercomputer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.004546861629933119,
                  "neutral": 0.9946832060813904,
                  "support": 0.0007699198322370648
                },
                "stance_score": -0.003776941797696054,
                "evidence_contribution": -0.003473213580598128,
                "combined_rank_score": 0.9195835590362549
              },
              {
                "id": 4603,
                "faiss_score": 0.9152406454086304,
                "faiss_rank": 6,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Quantum cryptography replaces conventional algorithms with computations based on quantum computing.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0016549596330150962,
                  "neutral": 0.9966773986816406,
                  "support": 0.0016676676459610462
                },
                "stance_score": 1.2708012945950031e-05,
                "evidence_contribution": 1.1630889970512537e-05,
                "combined_rank_score": 0.9152406454086304
              },
              {
                "id": 4932,
                "faiss_score": 0.9101486206054688,
                "faiss_rank": 9,
                "doc_id": "wiki_Computational_complexity",
                "file_type": ".txt",
                "position": 62,
                "sentence": "However, some problems may theoretically be solved with a much lower time complexity using a quantum computer rather than a classical computer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Computational_complexity",
                "primary_category": "all articles containing potentially dated statements",
                "probs": {
                  "contradict": 0.09721063077449799,
                  "neutral": 0.9004706144332886,
                  "support": 0.0023187061306089163
                },
                "stance_score": -0.09489192464388907,
                "evidence_contribution": -0.08636575432123372,
                "combined_rank_score": 0.9101486206054688
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Quantum computers will replace classical computers for most workloads.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 736,
                      "faiss_score": 0.9381494522094727,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 140,
                      "sentence": "As of 2023, classical computers outperform quantum computers for all real-world applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.9913483262062073,
                        "neutral": 0.006687983404844999,
                        "support": 0.0019637111108750105
                      },
                      "stance_score": -0.9893846150953323,
                      "evidence_contribution": -0.9281906346761659,
                      "combined_rank_score": 0.9381494522094727
                    },
                    {
                      "id": 6574,
                      "faiss_score": 0.9328113794326782,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 34,
                      "sentence": "Rather than replacing classical systems, quantum computers are expected to act as accelerators for specific subroutines.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9586077928543091,
                        "neutral": 0.03871520608663559,
                        "support": 0.002676980337128043
                      },
                      "stance_score": -0.955930812517181,
                      "evidence_contribution": -0.8917031398663525,
                      "combined_rank_score": 0.9328113794326782
                    },
                    {
                      "id": 6573,
                      "faiss_score": 0.9102804064750671,
                      "faiss_rank": 8,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 33,
                      "sentence": "The integration of quantum and classical computing is widely viewed as essential.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.15705923736095428,
                        "neutral": 0.8415084481239319,
                        "support": 0.0014323306968435645
                      },
                      "stance_score": -0.15562690666411072,
                      "evidence_contribution": -0.14166412385666405,
                      "combined_rank_score": 0.9102804064750671
                    }
                  ],
                  "neutral": [
                    {
                      "id": 701,
                      "faiss_score": 0.9195835590362549,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 105,
                      "sentence": "In June 2023, IBM computer scientists reported that a quantum computer produced better results for a physics problem than a conventional supercomputer.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.004546861629933119,
                        "neutral": 0.9946832060813904,
                        "support": 0.0007699198322370648
                      },
                      "stance_score": -0.003776941797696054,
                      "evidence_contribution": -0.003473213580598128,
                      "combined_rank_score": 0.9195835590362549
                    },
                    {
                      "id": 4603,
                      "faiss_score": 0.9152406454086304,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Quantum cryptography replaces conventional algorithms with computations based on quantum computing.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.0016549596330150962,
                        "neutral": 0.9966773986816406,
                        "support": 0.0016676676459610462
                      },
                      "stance_score": 1.2708012945950031e-05,
                      "evidence_contribution": 1.1630889970512537e-05,
                      "combined_rank_score": 0.9152406454086304
                    },
                    {
                      "id": 4932,
                      "faiss_score": 0.9101486206054688,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Computational_complexity",
                      "file_type": ".txt",
                      "position": 62,
                      "sentence": "However, some problems may theoretically be solved with a much lower time complexity using a quantum computer rather than a classical computer.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Computational_complexity",
                      "primary_category": "all articles containing potentially dated statements",
                      "probs": {
                        "contradict": 0.09721063077449799,
                        "neutral": 0.9004706144332886,
                        "support": 0.0023187061306089163
                      },
                      "stance_score": -0.09489192464388907,
                      "evidence_contribution": -0.08636575432123372,
                      "combined_rank_score": 0.9101486206054688
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Increasing data quality is more important than model size for all tasks.",
      "expected_verdict": "INCONCLUSIVE",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Increasing data quality is more important than model size for all tasks.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 2.3520252510418187,
            "total": 2.3520252510418187
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6137,
                "faiss_score": 0.9282467365264893,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7659299969673157,
                  "neutral": 0.23193812370300293,
                  "support": 0.0021318739745765924
                },
                "stance_score": -0.7637981229927391,
                "evidence_contribution": -0.7089931150330682,
                "combined_rank_score": 0.9282467365264893
              },
              {
                "id": 6349,
                "faiss_score": 0.8851536512374878,
                "faiss_rank": 20,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 88,
                "sentence": "As models scale, training efficiency becomes a primary concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5371345281600952,
                  "neutral": 0.4516849219799042,
                  "support": 0.011180499568581581
                },
                "stance_score": -0.5259540285915136,
                "evidence_contribution": -0.46555012879084434,
                "combined_rank_score": 0.8851536512374878
              },
              {
                "id": 6135,
                "faiss_score": 0.912760317325592,
                "faiss_rank": 3,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 11,
                "sentence": "Data scaling plays an equally important role.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5072497725486755,
                  "neutral": 0.4902275800704956,
                  "support": 0.0025226445868611336
                },
                "stance_score": -0.5047271279618144,
                "evidence_contribution": -0.4606948934812604,
                "combined_rank_score": 0.912760317325592
              },
              {
                "id": 6132,
                "faiss_score": 0.8877804279327393,
                "faiss_rank": 14,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Larger models have greater representational capacity, allowing them to fit more complex functions.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.31466788053512573,
                  "neutral": 0.6821066737174988,
                  "support": 0.0032254562247544527
                },
                "stance_score": -0.3114424243103713,
                "evidence_contribution": -0.27649248873067117,
                "combined_rank_score": 0.8877804279327393
              },
              {
                "id": 349,
                "faiss_score": 0.9008208513259888,
                "faiss_rank": 4,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 240,
                "sentence": "Typically, machine learning models require a high quantity of reliable data to perform accurate predictions.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.21835577487945557,
                  "neutral": 0.7786141037940979,
                  "support": 0.0030300808139145374
                },
                "stance_score": -0.21532569406554103,
                "evidence_contribution": -0.19396987504048008,
                "combined_rank_score": 0.9008208513259888
              },
              {
                "id": 6436,
                "faiss_score": 0.8860062956809998,
                "faiss_rank": 19,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 175,
                "sentence": "Memory usage, latency, and throughput must be balanced against accuracy and robustness.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.18055666983127594,
                  "neutral": 0.8162810802459717,
                  "support": 0.003162240842357278
                },
                "stance_score": -0.17739442898891866,
                "evidence_contribution": -0.15717258090291797,
                "combined_rank_score": 0.8860062956809998
              },
              {
                "id": 5914,
                "faiss_score": 0.8886445760726929,
                "faiss_rank": 11,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "By identifying and removing such parameters, models can be made smaller and faster.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.10239699482917786,
                  "neutral": 0.8955297470092773,
                  "support": 0.002073230454698205
                },
                "stance_score": -0.10032376437447965,
                "evidence_contribution": -0.0891521690625762,
                "combined_rank_score": 0.8886445760726929
              }
            ],
            "neutral": [
              {
                "id": 5767,
                "faiss_score": 0.9157058596611023,
                "faiss_rank": 2,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 15,
                "sentence": "This observation emphasizes the importance of data quality and task definition.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0025519374758005142,
                  "neutral": 0.9963298439979553,
                  "support": 0.00111820874735713
                },
                "stance_score": -0.0014337287284433842,
                "evidence_contribution": -0.0013128737978000682,
                "combined_rank_score": 0.9157058596611023
              },
              {
                "id": 6134,
                "faiss_score": 0.8952429890632629,
                "faiss_rank": 6,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 10,
                "sentence": "Large models are also more sensitive to optimization choices and require careful tuning to train effectively.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04769546538591385,
                  "neutral": 0.9500605463981628,
                  "support": 0.0022439900785684586
                },
                "stance_score": -0.04545147530734539,
                "evidence_contribution": -0.040690114611482975,
                "combined_rank_score": 0.8952429890632629
              },
              {
                "id": 6147,
                "faiss_score": 0.8930780291557312,
                "faiss_rank": 7,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 23,
                "sentence": "For example, increasing model size without increasing data may yield limited benefits, while increasing data without sufficient model capacity may fail to exploit the additional information.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.028468823060393333,
                  "neutral": 0.9641625881195068,
                  "support": 0.007368524093180895
                },
                "stance_score": -0.02110029896721244,
                "evidence_contribution": -0.018844213416234795,
                "combined_rank_score": 0.8930780291557312
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Increasing data quality is more important than model size for all tasks.",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6137,
                      "faiss_score": 0.9282467365264893,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.7659299969673157,
                        "neutral": 0.23193812370300293,
                        "support": 0.0021318739745765924
                      },
                      "stance_score": -0.7637981229927391,
                      "evidence_contribution": -0.7089931150330682,
                      "combined_rank_score": 0.9282467365264893
                    },
                    {
                      "id": 6135,
                      "faiss_score": 0.912760317325592,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 11,
                      "sentence": "Data scaling plays an equally important role.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.5072497725486755,
                        "neutral": 0.4902275800704956,
                        "support": 0.0025226445868611336
                      },
                      "stance_score": -0.5047271279618144,
                      "evidence_contribution": -0.4606948934812604,
                      "combined_rank_score": 0.912760317325592
                    },
                    {
                      "id": 349,
                      "faiss_score": 0.9008208513259888,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 240,
                      "sentence": "Typically, machine learning models require a high quantity of reliable data to perform accurate predictions.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.21835577487945557,
                        "neutral": 0.7786141037940979,
                        "support": 0.0030300808139145374
                      },
                      "stance_score": -0.21532569406554103,
                      "evidence_contribution": -0.19396987504048008,
                      "combined_rank_score": 0.9008208513259888
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5767,
                      "faiss_score": 0.9157058596611023,
                      "faiss_rank": 2,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 15,
                      "sentence": "This observation emphasizes the importance of data quality and task definition.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0025519374758005142,
                        "neutral": 0.9963298439979553,
                        "support": 0.00111820874735713
                      },
                      "stance_score": -0.0014337287284433842,
                      "evidence_contribution": -0.0013128737978000682,
                      "combined_rank_score": 0.9157058596611023
                    },
                    {
                      "id": 6134,
                      "faiss_score": 0.8952429890632629,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 10,
                      "sentence": "Large models are also more sensitive to optimization choices and require careful tuning to train effectively.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.04769546538591385,
                        "neutral": 0.9500605463981628,
                        "support": 0.0022439900785684586
                      },
                      "stance_score": -0.04545147530734539,
                      "evidence_contribution": -0.040690114611482975,
                      "combined_rank_score": 0.8952429890632629
                    },
                    {
                      "id": 6147,
                      "faiss_score": 0.8930780291557312,
                      "faiss_rank": 7,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 23,
                      "sentence": "For example, increasing model size without increasing data may yield limited benefits, while increasing data without sufficient model capacity may fail to exploit the additional information.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.028468823060393333,
                        "neutral": 0.9641625881195068,
                        "support": 0.007368524093180895
                      },
                      "stance_score": -0.02110029896721244,
                      "evidence_contribution": -0.018844213416234795,
                      "combined_rank_score": 0.8930780291557312
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Scaling large language models improves performance, enables emergent abilities, and supports zero-shot learning, but increases training cost, energy consumption, optimization instability, and diminishing returns.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Scaling large language models improves performance",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 1.5336560036649034,
            "total": 1.5336560036649034
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 2020,
                "faiss_score": 0.9002507925033569,
                "faiss_rank": 7,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 288,
                "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.7573868036270142,
                  "neutral": 0.23684409260749817,
                  "support": 0.005769144278019667
                },
                "stance_score": -0.7516176593489945,
                "evidence_contribution": -0.6766443934884505,
                "combined_rank_score": 0.9002507925033569
              },
              {
                "id": 6414,
                "faiss_score": 0.8823122978210449,
                "faiss_rank": 15,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 153,
                "sentence": "Although larger models often support longer contexts, this approach scales poorly due to the quadratic cost of attention.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.4957807660102844,
                  "neutral": 0.5006844401359558,
                  "support": 0.0035347621887922287
                },
                "stance_score": -0.4922460038214922,
                "evidence_contribution": -0.43431470272496764,
                "combined_rank_score": 0.8823122978210449
              },
              {
                "id": 6092,
                "faiss_score": 0.9074421525001526,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.34977227449417114,
                  "neutral": 0.6438031792640686,
                  "support": 0.0064245653338730335
                },
                "stance_score": -0.3433477091602981,
                "evidence_contribution": -0.3115681842564173,
                "combined_rank_score": 0.9074421525001526
              },
              {
                "id": 6102,
                "faiss_score": 0.8919915556907654,
                "faiss_rank": 9,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 62,
                "sentence": "Evaluation of large language models presents its own challenges.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.12720470130443573,
                  "neutral": 0.8701755404472351,
                  "support": 0.0026197514962404966
                },
                "stance_score": -0.12458494980819523,
                "evidence_contribution": -0.11112872319506799,
                "combined_rank_score": 0.8919915556907654
              }
            ],
            "neutral": [
              {
                "id": 6043,
                "faiss_score": 0.9281105995178223,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0006025525508448482,
                  "neutral": 0.9942904710769653,
                  "support": 0.005106922704726458
                },
                "stance_score": 0.0045043701538816094,
                "evidence_contribution": 0.004180553683969246,
                "combined_rank_score": 0.9281105995178223
              },
              {
                "id": 6121,
                "faiss_score": 0.9091229438781738,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.01936933770775795,
                  "neutral": 0.9794360399246216,
                  "support": 0.0011946404119953513
                },
                "stance_score": -0.0181746972957626,
                "evidence_contribution": -0.01652303430961838,
                "combined_rank_score": 0.9091229438781738
              },
              {
                "id": 6067,
                "faiss_score": 0.9033756256103516,
                "faiss_rank": 4,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Large language models are also sensitive to the distribution of their training data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.010189454071223736,
                  "neutral": 0.9881002902984619,
                  "support": 0.0017101936973631382
                },
                "stance_score": -0.008479260373860598,
                "evidence_contribution": -0.007659957144949381,
                "combined_rank_score": 0.9033756256103516
              }
            ]
          }
        },
        {
          "subclaim": "Scaling large language models enables emergent abilities",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.12601461293447808,
            "contradict": 1.5409051281133226,
            "total": 1.6669197410478007
          },
          "evidence": {
            "supporting": [
              {
                "id": 6109,
                "faiss_score": 0.8844212293624878,
                "faiss_rank": 9,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 69,
                "sentence": "The rapid pace of development in large language models has reshaped expectations about what machine learning systems can do.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001335775014013052,
                  "neutral": 0.8548458814620972,
                  "support": 0.14381834864616394
                },
                "stance_score": 0.1424825736321509,
                "evidence_contribution": 0.12601461293447808,
                "combined_rank_score": 0.8844212293624878
              }
            ],
            "contradicting": [
              {
                "id": 2020,
                "faiss_score": 0.8869941234588623,
                "faiss_rank": 7,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 288,
                "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.6738033890724182,
                  "neutral": 0.3211841583251953,
                  "support": 0.005012524779886007
                },
                "stance_score": -0.6687908642925322,
                "evidence_contribution": -0.5932135664504495,
                "combined_rank_score": 0.8869941234588623
              },
              {
                "id": 6153,
                "faiss_score": 0.8741754293441772,
                "faiss_rank": 15,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 29,
                "sentence": "Memory constraints become significant as models grow.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6067615151405334,
                  "neutral": 0.3883894979953766,
                  "support": 0.004848997574299574
                },
                "stance_score": -0.6019125175662339,
                "evidence_contribution": -0.5261771334710972,
                "combined_rank_score": 0.8741754293441772
              },
              {
                "id": 5932,
                "faiss_score": 0.8700584173202515,
                "faiss_rank": 20,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Memory efficiency during training is a limiting factor for large models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.48960521817207336,
                  "neutral": 0.5052563548088074,
                  "support": 0.0051384055987000465
                },
                "stance_score": -0.4844668125733733,
                "evidence_contribution": -0.4215144281917761,
                "combined_rank_score": 0.8700584173202515
              }
            ],
            "neutral": [
              {
                "id": 6043,
                "faiss_score": 0.9116201400756836,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0006786141893826425,
                  "neutral": 0.9966127276420593,
                  "support": 0.002708665793761611
                },
                "stance_score": 0.0020300516043789685,
                "evidence_contribution": 0.0018506359279448215,
                "combined_rank_score": 0.9116201400756836
              },
              {
                "id": 6040,
                "faiss_score": 0.9047881960868835,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0008272023987956345,
                  "neutral": 0.9973071813583374,
                  "support": 0.0018656117608770728
                },
                "stance_score": 0.0010384093620814383,
                "evidence_contribution": 0.000939540533517396,
                "combined_rank_score": 0.9047881960868835
              },
              {
                "id": 6121,
                "faiss_score": 0.8979462385177612,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.029849844053387642,
                  "neutral": 0.9665637612342834,
                  "support": 0.003586337435990572
                },
                "stance_score": -0.02626350661739707,
                "evidence_contribution": -0.02358321697737803,
                "combined_rank_score": 0.8979462385177612
              }
            ]
          }
        },
        {
          "subclaim": "Scaling large language models supports zero-shot learning",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 6.089503724643841,
            "total": 6.089503724643841
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6072,
                "faiss_score": 0.8564934134483337,
                "faiss_rank": 9,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 32,
                "sentence": "Another limitation of large language models is their lack of persistent memory beyond the context window.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8833795785903931,
                  "neutral": 0.1140100508928299,
                  "support": 0.0026103612035512924
                },
                "stance_score": -0.8807692173868418,
                "evidence_contribution": -0.7543730334598736,
                "combined_rank_score": 0.8564934134483337
              },
              {
                "id": 5932,
                "faiss_score": 0.8466452360153198,
                "faiss_rank": 19,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Memory efficiency during training is a limiting factor for large models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8860950469970703,
                  "neutral": 0.11094070225954056,
                  "support": 0.002964213490486145
                },
                "stance_score": -0.8831308335065842,
                "evidence_contribution": -0.7476985129665881,
                "combined_rank_score": 0.8466452360153198
              },
              {
                "id": 6414,
                "faiss_score": 0.851560115814209,
                "faiss_rank": 13,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 153,
                "sentence": "Although larger models often support longer contexts, this approach scales poorly due to the quadratic cost of attention.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8501889705657959,
                  "neutral": 0.14699102938175201,
                  "support": 0.002819999121129513
                },
                "stance_score": -0.8473689714446664,
                "evidence_contribution": -0.7215856194607873,
                "combined_rank_score": 0.851560115814209
              },
              {
                "id": 2020,
                "faiss_score": 0.8652899861335754,
                "faiss_rank": 5,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 288,
                "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.8215959668159485,
                  "neutral": 0.17487108707427979,
                  "support": 0.003532965900376439
                },
                "stance_score": -0.818063000915572,
                "evidence_contribution": -0.7078617227186265,
                "combined_rank_score": 0.8652899861335754
              },
              {
                "id": 6102,
                "faiss_score": 0.855239748954773,
                "faiss_rank": 10,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 62,
                "sentence": "Evaluation of large language models presents its own challenges.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7986255884170532,
                  "neutral": 0.19749756157398224,
                  "support": 0.003876908216625452
                },
                "stance_score": -0.7947486802004278,
                "evidence_contribution": -0.6797006617367509,
                "combined_rank_score": 0.855239748954773
              },
              {
                "id": 6309,
                "faiss_score": 0.8539784550666809,
                "faiss_rank": 12,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "High-capacity models are prone to overfitting when data is scarce, and strong generalization typically requires pretraining on massive corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7871667146682739,
                  "neutral": 0.20872174203395844,
                  "support": 0.004111547488719225
                },
                "stance_score": -0.7830551671795547,
                "evidence_contribution": -0.6687122418999777,
                "combined_rank_score": 0.8539784550666809
              },
              {
                "id": 6092,
                "faiss_score": 0.8831982612609863,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7527527809143066,
                  "neutral": 0.2425219714641571,
                  "support": 0.004725265316665173
                },
                "stance_score": -0.7480275155976415,
                "evidence_contribution": -0.6606566011512123,
                "combined_rank_score": 0.8831982612609863
              },
              {
                "id": 6121,
                "faiss_score": 0.8645410537719727,
                "faiss_rank": 6,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5763959884643555,
                  "neutral": 0.4200174808502197,
                  "support": 0.003586551873013377
                },
                "stance_score": -0.5728094365913421,
                "evidence_contribution": -0.49521727392120884,
                "combined_rank_score": 0.8645410537719727
              },
              {
                "id": 6047,
                "faiss_score": 0.8596764802932739,
                "faiss_rank": 8,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Despite these capabilities, the behavior of large language models remains fundamentally probabilistic.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5432117581367493,
                  "neutral": 0.45265936851501465,
                  "support": 0.004128914326429367
                },
                "stance_score": -0.5390828438103199,
                "evidence_contribution": -0.46343684175334454,
                "combined_rank_score": 0.8596764802932739
              },
              {
                "id": 6067,
                "faiss_score": 0.8749508857727051,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Large language models are also sensitive to the distribution of their training data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.22105905413627625,
                  "neutral": 0.7753354907035828,
                  "support": 0.0036054591182619333
                },
                "stance_score": -0.2174535950180143,
                "evidence_contribution": -0.1902612155754707,
                "combined_rank_score": 0.8749508857727051
              }
            ],
            "neutral": [
              {
                "id": 6043,
                "faiss_score": 0.8965744376182556,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0036855970975011587,
                  "neutral": 0.9953210949897766,
                  "support": 0.0009933628607541323
                },
                "stance_score": -0.0026922342367470264,
                "evidence_contribution": -0.002413788396748079,
                "combined_rank_score": 0.8965744376182556
              },
              {
                "id": 6040,
                "faiss_score": 0.8675651550292969,
                "faiss_rank": 4,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.03993375971913338,
                  "neutral": 0.9570171236991882,
                  "support": 0.003049140563234687
                },
                "stance_score": -0.03688461915589869,
                "evidence_contribution": -0.03199981033618382,
                "combined_rank_score": 0.8675651550292969
              },
              {
                "id": 1796,
                "faiss_score": 0.8599752187728882,
                "faiss_rank": 7,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 64,
                "sentence": "The tendency towards larger models is visible in the list of large language models.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.003957678563892841,
                  "neutral": 0.9950253367424011,
                  "support": 0.0010169995948672295
                },
                "stance_score": -0.002940678969025612,
                "evidence_contribution": -0.002528911039728632,
                "combined_rank_score": 0.8599752187728882
              }
            ]
          }
        },
        {
          "subclaim": "Scaling large language models increases training cost",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 0.4929024356047792,
            "contradict": 0.0,
            "total": 0.4929024356047792
          },
          "evidence": {
            "supporting": [
              {
                "id": 6092,
                "faiss_score": 0.9561026096343994,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0017482315888628364,
                  "neutral": 0.5767940878868103,
                  "support": 0.4214576482772827
                },
                "stance_score": 0.4197094166884199,
                "evidence_contribution": 0.40128526858392977,
                "combined_rank_score": 0.9561026096343994
              },
              {
                "id": 6354,
                "faiss_score": 0.8835115432739258,
                "faiss_rank": 10,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 93,
                "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.003150227013975382,
                  "neutral": 0.890002965927124,
                  "support": 0.10684685409069061
                },
                "stance_score": 0.10369662707671523,
                "evidence_contribution": 0.09161716702084943,
                "combined_rank_score": 0.8835115432739258
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 6043,
                "faiss_score": 0.904009222984314,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0030199771281331778,
                  "neutral": 0.995822548866272,
                  "support": 0.0011574995005503297
                },
                "stance_score": -0.001862477627582848,
                "evidence_contribution": -0.001683696952936839,
                "combined_rank_score": 0.904009222984314
              },
              {
                "id": 6067,
                "faiss_score": 0.8991430997848511,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Large language models are also sensitive to the distribution of their training data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001271996065042913,
                  "neutral": 0.9961495399475098,
                  "support": 0.002578491810709238
                },
                "stance_score": 0.001306495745666325,
                "evidence_contribution": 0.00117472663461414,
                "combined_rank_score": 0.8991430997848511
              },
              {
                "id": 6414,
                "faiss_score": 0.8984808325767517,
                "faiss_rank": 4,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 153,
                "sentence": "Although larger models often support longer contexts, this approach scales poorly due to the quadratic cost of attention.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0027736963238567114,
                  "neutral": 0.9656725525856018,
                  "support": 0.031553715467453
                },
                "stance_score": 0.02878001914359629,
                "evidence_contribution": 0.02585829556171325,
                "combined_rank_score": 0.8984808325767517
              }
            ]
          }
        },
        {
          "subclaim": "Scaling large language models increases energy consumption",
          "verdict": "INCONCLUSIVE",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 0.16502106975161723,
            "total": 0.16502106975161723
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 5952,
                "faiss_score": 0.9094395637512207,
                "faiss_rank": 2,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Energy efficiency has become increasingly important as machine learning workloads scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.21414585411548615,
                  "neutral": 0.7531618475914001,
                  "support": 0.03269226849079132
                },
                "stance_score": -0.18145358562469482,
                "evidence_contribution": -0.16502106975161723,
                "combined_rank_score": 0.9094395637512207
              }
            ],
            "neutral": [
              {
                "id": 6092,
                "faiss_score": 0.9095553159713745,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002043407876044512,
                  "neutral": 0.9531852602958679,
                  "support": 0.04477132856845856
                },
                "stance_score": 0.042727920692414045,
                "evidence_contribution": 0.03886340740618849,
                "combined_rank_score": 0.9095553159713745
              },
              {
                "id": 5907,
                "faiss_score": 0.8961602449417114,
                "faiss_rank": 3,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.003515135031193495,
                  "neutral": 0.9713563323020935,
                  "support": 0.025128565728664398
                },
                "stance_score": 0.021613430697470903,
                "evidence_contribution": 0.01936909734787623,
                "combined_rank_score": 0.8961602449417114
              },
              {
                "id": 6043,
                "faiss_score": 0.8894945979118347,
                "faiss_rank": 4,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002962291007861495,
                  "neutral": 0.9959206581115723,
                  "support": 0.0011170216603204608
                },
                "stance_score": -0.0018452693475410342,
                "evidence_contribution": -0.0016413571163300458,
                "combined_rank_score": 0.8894945979118347
              }
            ]
          }
        },
        {
          "subclaim": "Scaling large language models causes optimization instability",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.08988059760441569,
            "contradict": 0.589641439639073,
            "total": 0.6795220372434887
          },
          "evidence": {
            "supporting": [
              {
                "id": 6060,
                "faiss_score": 0.8820145130157471,
                "faiss_rank": 11,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 20,
                "sentence": "Hallucination is one of the most widely discussed failure modes of large language models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002278294414281845,
                  "neutral": 0.8935396075248718,
                  "support": 0.10418205708265305
                },
                "stance_score": 0.1019037626683712,
                "evidence_contribution": 0.08988059760441569,
                "combined_rank_score": 0.8820145130157471
              }
            ],
            "contradicting": [
              {
                "id": 6352,
                "faiss_score": 0.8873025178909302,
                "faiss_rank": 9,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 91,
                "sentence": "Communication overhead, memory constraints, and numerical stability all play important roles in large-scale training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.4487369656562805,
                  "neutral": 0.5440756678581238,
                  "support": 0.0071873352862894535
                },
                "stance_score": -0.44154963036999106,
                "evidence_contribution": -0.3917880988011026,
                "combined_rank_score": 0.8873025178909302
              },
              {
                "id": 6241,
                "faiss_score": 0.8801034688949585,
                "faiss_rank": 15,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 49,
                "sentence": "Careful scaling and normalization are required to prevent numerical issues from dominating training dynamics.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.22982844710350037,
                  "neutral": 0.7651500105857849,
                  "support": 0.005021537654101849
                },
                "stance_score": -0.22480690944939852,
                "evidence_contribution": -0.19785334083797046,
                "combined_rank_score": 0.8801034688949585
              }
            ],
            "neutral": [
              {
                "id": 6043,
                "faiss_score": 0.9122200608253479,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.009328887797892094,
                  "neutral": 0.988326370716095,
                  "support": 0.0023446741979569197
                },
                "stance_score": -0.006984213599935174,
                "evidence_contribution": -0.0063711397549500864,
                "combined_rank_score": 0.9122200608253479
              },
              {
                "id": 6121,
                "faiss_score": 0.9029004573822021,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0007098660571500659,
                  "neutral": 0.9972711205482483,
                  "support": 0.0020190386567264795
                },
                "stance_score": 0.0013091725995764136,
                "evidence_contribution": 0.0011820525389497905,
                "combined_rank_score": 0.9029004573822021
              },
              {
                "id": 2020,
                "faiss_score": 0.9003187417984009,
                "faiss_rank": 3,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 288,
                "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.0010097158374264836,
                  "neutral": 0.9976261258125305,
                  "support": 0.001364142750389874
                },
                "stance_score": 0.00035442691296339035,
                "evidence_contribution": 0.00031909719233869094,
                "combined_rank_score": 0.9003187417984009
              }
            ]
          }
        },
        {
          "subclaim": "Scaling large language models exhibits diminishing returns",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 0.9830119203821057,
            "contradict": 0.7333751692386625,
            "total": 1.7163870896207682
          },
          "evidence": {
            "supporting": [
              {
                "id": 2020,
                "faiss_score": 0.9000077843666077,
                "faiss_rank": 6,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 288,
                "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.00867969449609518,
                  "neutral": 0.5747266411781311,
                  "support": 0.41659367084503174
                },
                "stance_score": 0.40791397634893656,
                "evidence_contribution": 0.3671257540659792,
                "combined_rank_score": 0.9000077843666077
              },
              {
                "id": 6092,
                "faiss_score": 0.9190564751625061,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007081387564539909,
                  "neutral": 0.6965577006340027,
                  "support": 0.29636096954345703
                },
                "stance_score": 0.2892795819789171,
                "evidence_contribution": 0.2658642729500268,
                "combined_rank_score": 0.9190564751625061
              },
              {
                "id": 2037,
                "faiss_score": 0.8823869824409485,
                "faiss_rank": 16,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 305,
                "sentence": "This phenomenon undermines the reliability of large language models in multiple-choice settings.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.006240415386855602,
                  "neutral": 0.7071327567100525,
                  "support": 0.28662681579589844
                },
                "stance_score": 0.28038640040904284,
                "evidence_contribution": 0.24740930977441483,
                "combined_rank_score": 0.8823869824409485
              },
              {
                "id": 6072,
                "faiss_score": 0.8800252676010132,
                "faiss_rank": 17,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 32,
                "sentence": "Another limitation of large language models is their lack of persistent memory beyond the context window.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.003200442995876074,
                  "neutral": 0.876997172832489,
                  "support": 0.11980230361223221
                },
                "stance_score": 0.11660186061635613,
                "evidence_contribution": 0.10261258359168485,
                "combined_rank_score": 0.8800252676010132
              }
            ],
            "contradicting": [
              {
                "id": 6109,
                "faiss_score": 0.8939100503921509,
                "faiss_rank": 9,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 69,
                "sentence": "The rapid pace of development in large language models has reshaped expectations about what machine learning systems can do.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7240055203437805,
                  "neutral": 0.2712302803993225,
                  "support": 0.004764168988913298
                },
                "stance_score": -0.7192413513548672,
                "evidence_contribution": -0.642937072633748,
                "combined_rank_score": 0.8939100503921509
              },
              {
                "id": 1796,
                "faiss_score": 0.8970776200294495,
                "faiss_rank": 7,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 64,
                "sentence": "The tendency towards larger models is visible in the list of large language models.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.11149914562702179,
                  "neutral": 0.8778157830238342,
                  "support": 0.010685019195079803
                },
                "stance_score": -0.10081412643194199,
                "evidence_contribution": -0.09043809660491453,
                "combined_rank_score": 0.8970776200294495
              }
            ],
            "neutral": [
              {
                "id": 6043,
                "faiss_score": 0.924456000328064,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.08674194663763046,
                  "neutral": 0.9057531952857971,
                  "support": 0.007504891604185104
                },
                "stance_score": -0.07923705503344536,
                "evidence_contribution": -0.07325117097399358,
                "combined_rank_score": 0.924456000328064
              },
              {
                "id": 6121,
                "faiss_score": 0.9107099771499634,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00297346618026495,
                  "neutral": 0.9608861207962036,
                  "support": 0.036140382289886475
                },
                "stance_score": 0.033166916109621525,
                "evidence_contribution": 0.03020544141232817,
                "combined_rank_score": 0.9107099771499634
              },
              {
                "id": 6067,
                "faiss_score": 0.9055986404418945,
                "faiss_rank": 4,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Large language models are also sensitive to the distribution of their training data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005949373822659254,
                  "neutral": 0.9811984300613403,
                  "support": 0.012852229177951813
                },
                "stance_score": 0.006902855355292559,
                "evidence_contribution": 0.006251216424919992,
                "combined_rank_score": 0.9055986404418945
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Scaling large language models increases training cost",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6092,
                      "faiss_score": 0.9561026096343994,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 52,
                      "sentence": "The computational cost of training large language models is substantial.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0017482315888628364,
                        "neutral": 0.5767940878868103,
                        "support": 0.4214576482772827
                      },
                      "stance_score": 0.4197094166884199,
                      "evidence_contribution": 0.40128526858392977,
                      "combined_rank_score": 0.9561026096343994
                    },
                    {
                      "id": 6354,
                      "faiss_score": 0.8835115432739258,
                      "faiss_rank": 10,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 93,
                      "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.003150227013975382,
                        "neutral": 0.890002965927124,
                        "support": 0.10684685409069061
                      },
                      "stance_score": 0.10369662707671523,
                      "evidence_contribution": 0.09161716702084943,
                      "combined_rank_score": 0.8835115432739258
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 6043,
                      "faiss_score": 0.904009222984314,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0030199771281331778,
                        "neutral": 0.995822548866272,
                        "support": 0.0011574995005503297
                      },
                      "stance_score": -0.001862477627582848,
                      "evidence_contribution": -0.001683696952936839,
                      "combined_rank_score": 0.904009222984314
                    },
                    {
                      "id": 6067,
                      "faiss_score": 0.8991430997848511,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "Large language models are also sensitive to the distribution of their training data.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001271996065042913,
                        "neutral": 0.9961495399475098,
                        "support": 0.002578491810709238
                      },
                      "stance_score": 0.001306495745666325,
                      "evidence_contribution": 0.00117472663461414,
                      "combined_rank_score": 0.8991430997848511
                    },
                    {
                      "id": 6414,
                      "faiss_score": 0.8984808325767517,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 153,
                      "sentence": "Although larger models often support longer contexts, this approach scales poorly due to the quadratic cost of attention.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0027736963238567114,
                        "neutral": 0.9656725525856018,
                        "support": 0.031553715467453
                      },
                      "stance_score": 0.02878001914359629,
                      "evidence_contribution": 0.02585829556171325,
                      "combined_rank_score": 0.8984808325767517
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Scaling large language models improves performance",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6092,
                      "faiss_score": 0.9074421525001526,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 52,
                      "sentence": "The computational cost of training large language models is substantial.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.34977227449417114,
                        "neutral": 0.6438031792640686,
                        "support": 0.0064245653338730335
                      },
                      "stance_score": -0.3433477091602981,
                      "evidence_contribution": -0.3115681842564173,
                      "combined_rank_score": 0.9074421525001526
                    },
                    {
                      "id": 2020,
                      "faiss_score": 0.9002507925033569,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 288,
                      "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.7573868036270142,
                        "neutral": 0.23684409260749817,
                        "support": 0.005769144278019667
                      },
                      "stance_score": -0.7516176593489945,
                      "evidence_contribution": -0.6766443934884505,
                      "combined_rank_score": 0.9002507925033569
                    },
                    {
                      "id": 6102,
                      "faiss_score": 0.8919915556907654,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 62,
                      "sentence": "Evaluation of large language models presents its own challenges.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.12720470130443573,
                        "neutral": 0.8701755404472351,
                        "support": 0.0026197514962404966
                      },
                      "stance_score": -0.12458494980819523,
                      "evidence_contribution": -0.11112872319506799,
                      "combined_rank_score": 0.8919915556907654
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6043,
                      "faiss_score": 0.9281105995178223,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0006025525508448482,
                        "neutral": 0.9942904710769653,
                        "support": 0.005106922704726458
                      },
                      "stance_score": 0.0045043701538816094,
                      "evidence_contribution": 0.004180553683969246,
                      "combined_rank_score": 0.9281105995178223
                    },
                    {
                      "id": 6121,
                      "faiss_score": 0.9091229438781738,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.01936933770775795,
                        "neutral": 0.9794360399246216,
                        "support": 0.0011946404119953513
                      },
                      "stance_score": -0.0181746972957626,
                      "evidence_contribution": -0.01652303430961838,
                      "combined_rank_score": 0.9091229438781738
                    },
                    {
                      "id": 6067,
                      "faiss_score": 0.9033756256103516,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "Large language models are also sensitive to the distribution of their training data.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.010189454071223736,
                        "neutral": 0.9881002902984619,
                        "support": 0.0017101936973631382
                      },
                      "stance_score": -0.008479260373860598,
                      "evidence_contribution": -0.007659957144949381,
                      "combined_rank_score": 0.9033756256103516
                    }
                  ]
                }
              },
              {
                "subclaim": "Scaling large language models enables emergent abilities",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6109,
                      "faiss_score": 0.8844212293624878,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 69,
                      "sentence": "The rapid pace of development in large language models has reshaped expectations about what machine learning systems can do.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001335775014013052,
                        "neutral": 0.8548458814620972,
                        "support": 0.14381834864616394
                      },
                      "stance_score": 0.1424825736321509,
                      "evidence_contribution": 0.12601461293447808,
                      "combined_rank_score": 0.8844212293624878
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 2020,
                      "faiss_score": 0.8869941234588623,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 288,
                      "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.6738033890724182,
                        "neutral": 0.3211841583251953,
                        "support": 0.005012524779886007
                      },
                      "stance_score": -0.6687908642925322,
                      "evidence_contribution": -0.5932135664504495,
                      "combined_rank_score": 0.8869941234588623
                    },
                    {
                      "id": 6153,
                      "faiss_score": 0.8741754293441772,
                      "faiss_rank": 15,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 29,
                      "sentence": "Memory constraints become significant as models grow.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.6067615151405334,
                        "neutral": 0.3883894979953766,
                        "support": 0.004848997574299574
                      },
                      "stance_score": -0.6019125175662339,
                      "evidence_contribution": -0.5261771334710972,
                      "combined_rank_score": 0.8741754293441772
                    },
                    {
                      "id": 5932,
                      "faiss_score": 0.8700584173202515,
                      "faiss_rank": 20,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "Memory efficiency during training is a limiting factor for large models.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.48960521817207336,
                        "neutral": 0.5052563548088074,
                        "support": 0.0051384055987000465
                      },
                      "stance_score": -0.4844668125733733,
                      "evidence_contribution": -0.4215144281917761,
                      "combined_rank_score": 0.8700584173202515
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6043,
                      "faiss_score": 0.9116201400756836,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0006786141893826425,
                        "neutral": 0.9966127276420593,
                        "support": 0.002708665793761611
                      },
                      "stance_score": 0.0020300516043789685,
                      "evidence_contribution": 0.0018506359279448215,
                      "combined_rank_score": 0.9116201400756836
                    },
                    {
                      "id": 6040,
                      "faiss_score": 0.9047881960868835,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0008272023987956345,
                        "neutral": 0.9973071813583374,
                        "support": 0.0018656117608770728
                      },
                      "stance_score": 0.0010384093620814383,
                      "evidence_contribution": 0.000939540533517396,
                      "combined_rank_score": 0.9047881960868835
                    },
                    {
                      "id": 6121,
                      "faiss_score": 0.8979462385177612,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.029849844053387642,
                        "neutral": 0.9665637612342834,
                        "support": 0.003586337435990572
                      },
                      "stance_score": -0.02626350661739707,
                      "evidence_contribution": -0.02358321697737803,
                      "combined_rank_score": 0.8979462385177612
                    }
                  ]
                }
              },
              {
                "subclaim": "Scaling large language models supports zero-shot learning",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6092,
                      "faiss_score": 0.8831982612609863,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 52,
                      "sentence": "The computational cost of training large language models is substantial.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.7527527809143066,
                        "neutral": 0.2425219714641571,
                        "support": 0.004725265316665173
                      },
                      "stance_score": -0.7480275155976415,
                      "evidence_contribution": -0.6606566011512123,
                      "combined_rank_score": 0.8831982612609863
                    },
                    {
                      "id": 6067,
                      "faiss_score": 0.8749508857727051,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "Large language models are also sensitive to the distribution of their training data.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.22105905413627625,
                        "neutral": 0.7753354907035828,
                        "support": 0.0036054591182619333
                      },
                      "stance_score": -0.2174535950180143,
                      "evidence_contribution": -0.1902612155754707,
                      "combined_rank_score": 0.8749508857727051
                    },
                    {
                      "id": 2020,
                      "faiss_score": 0.8652899861335754,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 288,
                      "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.8215959668159485,
                        "neutral": 0.17487108707427979,
                        "support": 0.003532965900376439
                      },
                      "stance_score": -0.818063000915572,
                      "evidence_contribution": -0.7078617227186265,
                      "combined_rank_score": 0.8652899861335754
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6043,
                      "faiss_score": 0.8965744376182556,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0036855970975011587,
                        "neutral": 0.9953210949897766,
                        "support": 0.0009933628607541323
                      },
                      "stance_score": -0.0026922342367470264,
                      "evidence_contribution": -0.002413788396748079,
                      "combined_rank_score": 0.8965744376182556
                    },
                    {
                      "id": 6040,
                      "faiss_score": 0.8675651550292969,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.03993375971913338,
                        "neutral": 0.9570171236991882,
                        "support": 0.003049140563234687
                      },
                      "stance_score": -0.03688461915589869,
                      "evidence_contribution": -0.03199981033618382,
                      "combined_rank_score": 0.8675651550292969
                    },
                    {
                      "id": 1796,
                      "faiss_score": 0.8599752187728882,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 64,
                      "sentence": "The tendency towards larger models is visible in the list of large language models.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.003957678563892841,
                        "neutral": 0.9950253367424011,
                        "support": 0.0010169995948672295
                      },
                      "stance_score": -0.002940678969025612,
                      "evidence_contribution": -0.002528911039728632,
                      "combined_rank_score": 0.8599752187728882
                    }
                  ]
                }
              },
              {
                "subclaim": "Scaling large language models causes optimization instability",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6060,
                      "faiss_score": 0.8820145130157471,
                      "faiss_rank": 11,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 20,
                      "sentence": "Hallucination is one of the most widely discussed failure modes of large language models.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.002278294414281845,
                        "neutral": 0.8935396075248718,
                        "support": 0.10418205708265305
                      },
                      "stance_score": 0.1019037626683712,
                      "evidence_contribution": 0.08988059760441569,
                      "combined_rank_score": 0.8820145130157471
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6352,
                      "faiss_score": 0.8873025178909302,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 91,
                      "sentence": "Communication overhead, memory constraints, and numerical stability all play important roles in large-scale training.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.4487369656562805,
                        "neutral": 0.5440756678581238,
                        "support": 0.0071873352862894535
                      },
                      "stance_score": -0.44154963036999106,
                      "evidence_contribution": -0.3917880988011026,
                      "combined_rank_score": 0.8873025178909302
                    },
                    {
                      "id": 6241,
                      "faiss_score": 0.8801034688949585,
                      "faiss_rank": 15,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 49,
                      "sentence": "Careful scaling and normalization are required to prevent numerical issues from dominating training dynamics.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.22982844710350037,
                        "neutral": 0.7651500105857849,
                        "support": 0.005021537654101849
                      },
                      "stance_score": -0.22480690944939852,
                      "evidence_contribution": -0.19785334083797046,
                      "combined_rank_score": 0.8801034688949585
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6043,
                      "faiss_score": 0.9122200608253479,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.009328887797892094,
                        "neutral": 0.988326370716095,
                        "support": 0.0023446741979569197
                      },
                      "stance_score": -0.006984213599935174,
                      "evidence_contribution": -0.0063711397549500864,
                      "combined_rank_score": 0.9122200608253479
                    },
                    {
                      "id": 6121,
                      "faiss_score": 0.9029004573822021,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0007098660571500659,
                        "neutral": 0.9972711205482483,
                        "support": 0.0020190386567264795
                      },
                      "stance_score": 0.0013091725995764136,
                      "evidence_contribution": 0.0011820525389497905,
                      "combined_rank_score": 0.9029004573822021
                    },
                    {
                      "id": 2020,
                      "faiss_score": 0.9003187417984009,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 288,
                      "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.0010097158374264836,
                        "neutral": 0.9976261258125305,
                        "support": 0.001364142750389874
                      },
                      "stance_score": 0.00035442691296339035,
                      "evidence_contribution": 0.00031909719233869094,
                      "combined_rank_score": 0.9003187417984009
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Scaling large language models exhibits diminishing returns",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6092,
                      "faiss_score": 0.9190564751625061,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 52,
                      "sentence": "The computational cost of training large language models is substantial.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.007081387564539909,
                        "neutral": 0.6965577006340027,
                        "support": 0.29636096954345703
                      },
                      "stance_score": 0.2892795819789171,
                      "evidence_contribution": 0.2658642729500268,
                      "combined_rank_score": 0.9190564751625061
                    },
                    {
                      "id": 2020,
                      "faiss_score": 0.9000077843666077,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 288,
                      "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.00867969449609518,
                        "neutral": 0.5747266411781311,
                        "support": 0.41659367084503174
                      },
                      "stance_score": 0.40791397634893656,
                      "evidence_contribution": 0.3671257540659792,
                      "combined_rank_score": 0.9000077843666077
                    },
                    {
                      "id": 2037,
                      "faiss_score": 0.8823869824409485,
                      "faiss_rank": 16,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 305,
                      "sentence": "This phenomenon undermines the reliability of large language models in multiple-choice settings.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.006240415386855602,
                        "neutral": 0.7071327567100525,
                        "support": 0.28662681579589844
                      },
                      "stance_score": 0.28038640040904284,
                      "evidence_contribution": 0.24740930977441483,
                      "combined_rank_score": 0.8823869824409485
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 1796,
                      "faiss_score": 0.8970776200294495,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 64,
                      "sentence": "The tendency towards larger models is visible in the list of large language models.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.11149914562702179,
                        "neutral": 0.8778157830238342,
                        "support": 0.010685019195079803
                      },
                      "stance_score": -0.10081412643194199,
                      "evidence_contribution": -0.09043809660491453,
                      "combined_rank_score": 0.8970776200294495
                    },
                    {
                      "id": 6109,
                      "faiss_score": 0.8939100503921509,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 69,
                      "sentence": "The rapid pace of development in large language models has reshaped expectations about what machine learning systems can do.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.7240055203437805,
                        "neutral": 0.2712302803993225,
                        "support": 0.004764168988913298
                      },
                      "stance_score": -0.7192413513548672,
                      "evidence_contribution": -0.642937072633748,
                      "combined_rank_score": 0.8939100503921509
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6043,
                      "faiss_score": 0.924456000328064,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.08674194663763046,
                        "neutral": 0.9057531952857971,
                        "support": 0.007504891604185104
                      },
                      "stance_score": -0.07923705503344536,
                      "evidence_contribution": -0.07325117097399358,
                      "combined_rank_score": 0.924456000328064
                    },
                    {
                      "id": 6121,
                      "faiss_score": 0.9107099771499634,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.00297346618026495,
                        "neutral": 0.9608861207962036,
                        "support": 0.036140382289886475
                      },
                      "stance_score": 0.033166916109621525,
                      "evidence_contribution": 0.03020544141232817,
                      "combined_rank_score": 0.9107099771499634
                    },
                    {
                      "id": 6067,
                      "faiss_score": 0.9055986404418945,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "Large language models are also sensitive to the distribution of their training data.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005949373822659254,
                        "neutral": 0.9811984300613403,
                        "support": 0.012852229177951813
                      },
                      "stance_score": 0.006902855355292559,
                      "evidence_contribution": 0.006251216424919992,
                      "combined_rank_score": 0.9055986404418945
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "EVIDENCE_LIMITATIONS",
            "items": [
              {
                "subclaim": "Scaling large language models increases energy consumption",
                "verdict": "INCONCLUSIVE",
                "strength_summary": {
                  "support": "none",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 5952,
                      "faiss_score": 0.9094395637512207,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 47,
                      "sentence": "Energy efficiency has become increasingly important as machine learning workloads scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.21414585411548615,
                        "neutral": 0.7531618475914001,
                        "support": 0.03269226849079132
                      },
                      "stance_score": -0.18145358562469482,
                      "evidence_contribution": -0.16502106975161723,
                      "combined_rank_score": 0.9094395637512207
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6092,
                      "faiss_score": 0.9095553159713745,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 52,
                      "sentence": "The computational cost of training large language models is substantial.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.002043407876044512,
                        "neutral": 0.9531852602958679,
                        "support": 0.04477132856845856
                      },
                      "stance_score": 0.042727920692414045,
                      "evidence_contribution": 0.03886340740618849,
                      "combined_rank_score": 0.9095553159713745
                    },
                    {
                      "id": 5907,
                      "faiss_score": 0.8961602449417114,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 2,
                      "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.003515135031193495,
                        "neutral": 0.9713563323020935,
                        "support": 0.025128565728664398
                      },
                      "stance_score": 0.021613430697470903,
                      "evidence_contribution": 0.01936909734787623,
                      "combined_rank_score": 0.8961602449417114
                    },
                    {
                      "id": 6043,
                      "faiss_score": 0.8894945979118347,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.002962291007861495,
                        "neutral": 0.9959206581115723,
                        "support": 0.0011170216603204608
                      },
                      "stance_score": -0.0018452693475410342,
                      "evidence_contribution": -0.0016413571163300458,
                      "combined_rank_score": 0.8894945979118347
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Transformer architectures improve parallelization, capture long-range dependencies, and scale efficiently, but require large compute budgets, are sensitive to hyperparameters, and struggle with very long contexts.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Transformer architectures improve parallelization",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 0.6603479544992529,
            "contradict": 0.9265684754898563,
            "total": 1.5869164299891092
          },
          "evidence": {
            "supporting": [
              {
                "id": 6275,
                "faiss_score": 0.9147120714187622,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Instead of processing tokens sequentially, transformers process entire sequences in parallel, enabling efficient training on modern hardware.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0016989217838272452,
                  "neutral": 0.43683573603630066,
                  "support": 0.561465322971344
                },
                "stance_score": 0.5597664011875167,
                "evidence_contribution": 0.5120250843408594,
                "combined_rank_score": 0.9147120714187622
              },
              {
                "id": 6284,
                "faiss_score": 0.8840556144714355,
                "faiss_rank": 18,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 23,
                "sentence": "Transformers typically employ multiple attention heads in parallel.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001994922524318099,
                  "neutral": 0.8282346129417419,
                  "support": 0.16977041959762573
                },
                "stance_score": 0.16777549707330763,
                "evidence_contribution": 0.14832287015839352,
                "combined_rank_score": 0.8840556144714355
              }
            ],
            "contradicting": [
              {
                "id": 6354,
                "faiss_score": 0.8843683004379272,
                "faiss_rank": 17,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 93,
                "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8079596757888794,
                  "neutral": 0.1881577968597412,
                  "support": 0.003882531775161624
                },
                "stance_score": -0.8040771440137178,
                "evidence_contribution": -0.7111003372723941,
                "combined_rank_score": 0.8843683004379272
              },
              {
                "id": 6426,
                "faiss_score": 0.8849560618400574,
                "faiss_rank": 16,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 165,
                "sentence": "This interdependence complicates efforts to simplify or interpret transformer architectures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.25036686658859253,
                  "neutral": 0.7427451610565186,
                  "support": 0.006887955591082573
                },
                "stance_score": -0.24347891099750996,
                "evidence_contribution": -0.21546813821746225,
                "combined_rank_score": 0.8849560618400574
              }
            ],
            "neutral": [
              {
                "id": 3083,
                "faiss_score": 0.9109269380569458,
                "faiss_rank": 2,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 138,
                "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.0007497426704503596,
                  "neutral": 0.9901717305183411,
                  "support": 0.00907858181744814
                },
                "stance_score": 0.00832883914699778,
                "evidence_contribution": 0.007586963941743512,
                "combined_rank_score": 0.9109269380569458
              },
              {
                "id": 6304,
                "faiss_score": 0.909870982170105,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 43,
                "sentence": "To address these issues, numerous variants of the transformer architecture have been proposed.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0011379255447536707,
                  "neutral": 0.9968006610870361,
                  "support": 0.0020614054519683123
                },
                "stance_score": 0.0009234799072146416,
                "evidence_contribution": 0.0008402475701917433,
                "combined_rank_score": 0.909870982170105
              },
              {
                "id": 6351,
                "faiss_score": 0.9036628603935242,
                "faiss_rank": 4,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 90,
                "sentence": "The architecture of transformers lends itself well to these approaches, but achieving efficient scaling still requires careful engineering.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0044351923279464245,
                  "neutral": 0.943244993686676,
                  "support": 0.05231977626681328
                },
                "stance_score": 0.047884583938866854,
                "evidence_contribution": 0.04327152009095023,
                "combined_rank_score": 0.9036628603935242
              }
            ]
          }
        },
        {
          "subclaim": "Transformer architectures capture long-range dependencies",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 0.8223583935232294,
            "contradict": 1.2776435979783423,
            "total": 2.1000019915015717
          },
          "evidence": {
            "supporting": [
              {
                "id": 6334,
                "faiss_score": 0.886968731880188,
                "faiss_rank": 18,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 73,
                "sentence": "Rather than training models from scratch for each individual task, practitioners increasingly rely on pretrained transformer backbones that capture broad linguistic or sequential knowledge.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.008221310563385487,
                  "neutral": 0.6556732058525085,
                  "support": 0.3361055552959442
                },
                "stance_score": 0.3278842447325587,
                "evidence_contribution": 0.2908230727539308,
                "combined_rank_score": 0.886968731880188
              },
              {
                "id": 1807,
                "faiss_score": 0.9011234641075134,
                "faiss_rank": 2,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 75,
                "sentence": "LLMs are generally based on the transformer architecture, which leverages an attention mechanism that enables the model to process relationships between all elements in a sequence simultaneously, regardless of their distance from each other.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.0071091135032474995,
                  "neutral": 0.7715122699737549,
                  "support": 0.22137866914272308
                },
                "stance_score": 0.21426955563947558,
                "evidence_contribution": 0.19308332423062183,
                "combined_rank_score": 0.9011234641075134
              },
              {
                "id": 6345,
                "faiss_score": 0.8888646364212036,
                "faiss_rank": 13,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 84,
                "sentence": "Transformers also exhibit a strong dependence on optimization techniques.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.014505324885249138,
                  "neutral": 0.755142867565155,
                  "support": 0.23035182058811188
                },
                "stance_score": 0.21584649570286274,
                "evidence_contribution": 0.19185831692571598,
                "combined_rank_score": 0.8888646364212036
              },
              {
                "id": 6333,
                "faiss_score": 0.8927822113037109,
                "faiss_rank": 6,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 72,
                "sentence": "The influence of transformer architectures is closely tied to their role in large-scale pretraining paradigms.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00578355323523283,
                  "neutral": 0.8242341876029968,
                  "support": 0.16998225450515747
                },
                "stance_score": 0.16419870126992464,
                "evidence_contribution": 0.14659367961296077,
                "combined_rank_score": 0.8927822113037109
              }
            ],
            "contradicting": [
              {
                "id": 6408,
                "faiss_score": 0.8920823335647583,
                "faiss_rank": 7,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 147,
                "sentence": "One consequence of this data dependence is that transformers can perform well on surface-level tasks while struggling with deeper reasoning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.795606791973114,
                  "neutral": 0.15556006133556366,
                  "support": 0.048833150416612625
                },
                "stance_score": -0.7467736415565014,
                "evidence_contribution": -0.6661835728043761,
                "combined_rank_score": 0.8920823335647583
              },
              {
                "id": 6426,
                "faiss_score": 0.9104562997817993,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 165,
                "sentence": "This interdependence complicates efforts to simplify or interpret transformer architectures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6054443120956421,
                  "neutral": 0.32951802015304565,
                  "support": 0.06503769010305405
                },
                "stance_score": -0.540406621992588,
                "evidence_contribution": -0.49201661343695324,
                "combined_rank_score": 0.9104562997817993
              },
              {
                "id": 6308,
                "faiss_score": 0.8934979438781738,
                "faiss_rank": 5,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Another challenge associated with transformers is their reliance on large datasets for effective training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.2442263662815094,
                  "neutral": 0.6452279090881348,
                  "support": 0.11054568737745285
                },
                "stance_score": -0.13368067890405655,
                "evidence_contribution": -0.1194434117370129,
                "combined_rank_score": 0.8934979438781738
              }
            ],
            "neutral": [
              {
                "id": 6351,
                "faiss_score": 0.9003123044967651,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 90,
                "sentence": "The architecture of transformers lends itself well to these approaches, but achieving efficient scaling still requires careful engineering.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.010348428040742874,
                  "neutral": 0.956598699092865,
                  "support": 0.03305292874574661
                },
                "stance_score": 0.02270450070500374,
                "evidence_contribution": 0.020441141352170344,
                "combined_rank_score": 0.9003123044967651
              },
              {
                "id": 3083,
                "faiss_score": 0.8960912823677063,
                "faiss_rank": 4,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 138,
                "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.017301296815276146,
                  "neutral": 0.9663417935371399,
                  "support": 0.016356920823454857
                },
                "stance_score": -0.0009443759918212891,
                "evidence_contribution": -0.0008462470935484134,
                "combined_rank_score": 0.8960912823677063
              },
              {
                "id": 6296,
                "faiss_score": 0.8920329809188843,
                "faiss_rank": 8,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 35,
                "sentence": "The transformer architecture proved highly effective across a wide range of natural language processing tasks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0042916773818433285,
                  "neutral": 0.9397426247596741,
                  "support": 0.055965688079595566
                },
                "stance_score": 0.05167401069775224,
                "evidence_contribution": 0.046094921798750244,
                "combined_rank_score": 0.8920329809188843
              }
            ]
          }
        },
        {
          "subclaim": "Transformer architectures scale efficiently",
          "verdict": "CONTRADICT",
          "controversial": true,
          "strengths": {
            "support": 0.9185155327256922,
            "contradict": 2.368504325180829,
            "total": 3.2870198579065213
          },
          "evidence": {
            "supporting": [
              {
                "id": 6300,
                "faiss_score": 0.9007487297058105,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0058963969349861145,
                  "neutral": 0.31589367985725403,
                  "support": 0.6782099008560181
                },
                "stance_score": 0.672313503921032,
                "evidence_contribution": 0.605585534620932,
                "combined_rank_score": 0.9007487297058105
              },
              {
                "id": 6275,
                "faiss_score": 0.8976442813873291,
                "faiss_rank": 4,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Instead of processing tokens sequentially, transformers process entire sequences in parallel, enabling efficient training on modern hardware.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.003980658017098904,
                  "neutral": 0.8544312715530396,
                  "support": 0.1415880173444748
                },
                "stance_score": 0.1376073593273759,
                "evidence_contribution": 0.12352245917703031,
                "combined_rank_score": 0.8976442813873291
              },
              {
                "id": 6296,
                "faiss_score": 0.8871057629585266,
                "faiss_rank": 12,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 35,
                "sentence": "The transformer architecture proved highly effective across a wide range of natural language processing tasks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0037631988525390625,
                  "neutral": 0.8799418807029724,
                  "support": 0.11629492044448853
                },
                "stance_score": 0.11253172159194946,
                "evidence_contribution": 0.09982753873986283,
                "combined_rank_score": 0.8871057629585266
              },
              {
                "id": 1759,
                "faiss_score": 0.8951883316040039,
                "faiss_rank": 6,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 27,
                "sentence": "As of 2024, the largest and most capable models are all based on the transformer architecture.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.0027968829963356256,
                  "neutral": 0.8943379521369934,
                  "support": 0.10286521166563034
                },
                "stance_score": 0.10006832866929471,
                "evidence_contribution": 0.08958000018786705,
                "combined_rank_score": 0.8951883316040039
              }
            ],
            "contradicting": [
              {
                "id": 6354,
                "faiss_score": 0.8869820237159729,
                "faiss_rank": 13,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 93,
                "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9340041875839233,
                  "neutral": 0.06165565177798271,
                  "support": 0.004340222105383873
                },
                "stance_score": -0.9296639654785395,
                "evidence_contribution": -0.8245952254759713,
                "combined_rank_score": 0.8869820237159729
              },
              {
                "id": 6426,
                "faiss_score": 0.8797202110290527,
                "faiss_rank": 19,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 165,
                "sentence": "This interdependence complicates efforts to simplify or interpret transformer architectures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8952831625938416,
                  "neutral": 0.09827237576246262,
                  "support": 0.006444440223276615
                },
                "stance_score": -0.8888387223705649,
                "evidence_contribution": -0.781929388414627,
                "combined_rank_score": 0.8797202110290527
              },
              {
                "id": 6351,
                "faiss_score": 0.9340454339981079,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 90,
                "sentence": "The architecture of transformers lends itself well to these approaches, but achieving efficient scaling still requires careful engineering.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7765777707099915,
                  "neutral": 0.14032764732837677,
                  "support": 0.08309459686279297
                },
                "stance_score": -0.6934831738471985,
                "evidence_contribution": -0.6477447920864918,
                "combined_rank_score": 0.9340454339981079
              },
              {
                "id": 6458,
                "faiss_score": 0.8864687085151672,
                "faiss_rank": 14,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 197,
                "sentence": "A balanced understanding requires examining both the strengths and limitations of transformers relative to alternative architectures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.13582396507263184,
                  "neutral": 0.8572172522544861,
                  "support": 0.006958819460123777
                },
                "stance_score": -0.12886514561250806,
                "evidence_contribution": -0.11423491920373899,
                "combined_rank_score": 0.8864687085151672
              }
            ],
            "neutral": [
              {
                "id": 3083,
                "faiss_score": 0.905130922794342,
                "faiss_rank": 2,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 138,
                "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.0027802942786365747,
                  "neutral": 0.9887701272964478,
                  "support": 0.008449570275843143
                },
                "stance_score": 0.005669275997206569,
                "evidence_contribution": 0.005131437014927395,
                "combined_rank_score": 0.905130922794342
              },
              {
                "id": 6304,
                "faiss_score": 0.8955011367797852,
                "faiss_rank": 5,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 43,
                "sentence": "To address these issues, numerous variants of the transformer architecture have been proposed.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.021592628210783005,
                  "neutral": 0.9746042490005493,
                  "support": 0.003803079714998603
                },
                "stance_score": -0.017789548495784402,
                "evidence_contribution": -0.01593056090077405,
                "combined_rank_score": 0.8955011367797852
              },
              {
                "id": 2987,
                "faiss_score": 0.8943012952804565,
                "faiss_rank": 7,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Transformer architecture is now used alongside many generative models that contribute to the ongoing AI boom.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.0007735576364211738,
                  "neutral": 0.9976523518562317,
                  "support": 0.0015741330571472645
                },
                "stance_score": 0.0008005754207260907,
                "evidence_contribution": 0.0007159556357250393,
                "combined_rank_score": 0.8943012952804565
              }
            ]
          }
        },
        {
          "subclaim": "Transformer architectures require large compute budgets",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 0.37746126873199515,
            "contradict": 0.09925296812278384,
            "total": 0.476714236854779
          },
          "evidence": {
            "supporting": [
              {
                "id": 2393,
                "faiss_score": 0.8968762159347534,
                "faiss_rank": 5,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 324,
                "sentence": "Large and effective neural networks require considerable computing resources.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.146491140127182,
                  "neutral": 0.2861555814743042,
                  "support": 0.5673533082008362
                },
                "stance_score": 0.4208621680736542,
                "evidence_contribution": 0.37746126873199515,
                "combined_rank_score": 0.8968762159347534
              }
            ],
            "contradicting": [
              {
                "id": 6435,
                "faiss_score": 0.9053575992584229,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 174,
                "sentence": "From an engineering perspective, deploying transformer-based systems requires careful consideration of resource constraints.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.11402056366205215,
                  "neutral": 0.8815873861312866,
                  "support": 0.004392093978822231
                },
                "stance_score": -0.10962846968322992,
                "evidence_contribution": -0.09925296812278384,
                "combined_rank_score": 0.9053575992584229
              }
            ],
            "neutral": [
              {
                "id": 6354,
                "faiss_score": 0.9239134192466736,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 93,
                "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0014876507921144366,
                  "neutral": 0.9060214757919312,
                  "support": 0.09249088913202286
                },
                "stance_score": 0.09100323833990842,
                "evidence_contribution": 0.08407911309714478,
                "combined_rank_score": 0.9239134192466736
              },
              {
                "id": 6351,
                "faiss_score": 0.9145227670669556,
                "faiss_rank": 2,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 90,
                "sentence": "The architecture of transformers lends itself well to these approaches, but achieving efficient scaling still requires careful engineering.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0020623886957764626,
                  "neutral": 0.9965948462486267,
                  "support": 0.0013428118545562029
                },
                "stance_score": -0.0007195768412202597,
                "evidence_contribution": -0.0006580694039500512,
                "combined_rank_score": 0.9145227670669556
              },
              {
                "id": 3083,
                "faiss_score": 0.9009952545166016,
                "faiss_rank": 4,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 138,
                "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.001218362944200635,
                  "neutral": 0.9977374076843262,
                  "support": 0.0010442466009408236
                },
                "stance_score": -0.0001741163432598114,
                "evidence_contribution": -0.00015687799901087374,
                "combined_rank_score": 0.9009952545166016
              }
            ]
          }
        },
        {
          "subclaim": "Transformer architectures are sensitive to hyperparameters",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 0.7964383671553368,
            "contradict": 0.15469500491806443,
            "total": 0.9511333720734012
          },
          "evidence": {
            "supporting": [
              {
                "id": 6345,
                "faiss_score": 0.8922547698020935,
                "faiss_rank": 11,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 84,
                "sentence": "Transformers also exhibit a strong dependence on optimization techniques.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.008120838552713394,
                  "neutral": 0.5745980143547058,
                  "support": 0.4172811806201935
                },
                "stance_score": 0.4091603420674801,
                "evidence_contribution": 0.3650752668235653,
                "combined_rank_score": 0.8922547698020935
              },
              {
                "id": 6375,
                "faiss_score": 0.9090120196342468,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 114,
                "sentence": "Transformer-based models can be sensitive to adversarial inputs, distribution shifts, and subtle perturbations.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.06621425598859787,
                  "neutral": 0.6238605380058289,
                  "support": 0.3099251985549927
                },
                "stance_score": 0.2437109425663948,
                "evidence_contribution": 0.22153617610924448,
                "combined_rank_score": 0.9090120196342468
              },
              {
                "id": 6427,
                "faiss_score": 0.8893992304801941,
                "faiss_rank": 17,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 166,
                "sentence": "Transformers are also sensitive to input formatting and prompting strategies.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.14572855830192566,
                  "neutral": 0.5844072103500366,
                  "support": 0.2698642611503601
                },
                "stance_score": 0.12413570284843445,
                "evidence_contribution": 0.11040619858851564,
                "combined_rank_score": 0.8893992304801941
              },
              {
                "id": 6408,
                "faiss_score": 0.8895968198776245,
                "faiss_rank": 16,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 147,
                "sentence": "One consequence of this data dependence is that transformers can perform well on surface-level tasks while struggling with deeper reasoning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04594160243868828,
                  "neutral": 0.7963574528694153,
                  "support": 0.15770091116428375
                },
                "stance_score": 0.11175930872559547,
                "evidence_contribution": 0.09942072563401139,
                "combined_rank_score": 0.8895968198776245
              }
            ],
            "contradicting": [
              {
                "id": 6341,
                "faiss_score": 0.9085462093353271,
                "faiss_rank": 2,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 80,
                "sentence": "One notable characteristic of transformers trained in this way is their sensitivity to data distribution.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3421061038970947,
                  "neutral": 0.48605436086654663,
                  "support": 0.17183957993984222
                },
                "stance_score": -0.1702665239572525,
                "evidence_contribution": -0.15469500491806443,
                "combined_rank_score": 0.9085462093353271
              }
            ],
            "neutral": [
              {
                "id": 6318,
                "faiss_score": 0.9083467721939087,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 57,
                "sentence": "The widespread deployment of transformer-based systems has also raised questions about robustness and interpretability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.013997501693665981,
                  "neutral": 0.9734272956848145,
                  "support": 0.012575263157486916
                },
                "stance_score": -0.0014222385361790657,
                "evidence_contribution": -0.001291885783628044,
                "combined_rank_score": 0.9083467721939087
              },
              {
                "id": 6458,
                "faiss_score": 0.9043031334877014,
                "faiss_rank": 4,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 197,
                "sentence": "A balanced understanding requires examining both the strengths and limitations of transformers relative to alternative architectures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.011928658001124859,
                  "neutral": 0.980444073677063,
                  "support": 0.007627241313457489
                },
                "stance_score": -0.00430141668766737,
                "evidence_contribution": -0.003889784589093892,
                "combined_rank_score": 0.9043031334877014
              },
              {
                "id": 6367,
                "faiss_score": 0.9034165143966675,
                "faiss_rank": 5,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 106,
                "sentence": "Interpretability remains a challenging aspect of transformer-based models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.012839163653552532,
                  "neutral": 0.8901380300521851,
                  "support": 0.09702283143997192
                },
                "stance_score": 0.08418366778641939,
                "evidence_contribution": 0.07605291572073403,
                "combined_rank_score": 0.9034165143966675
              }
            ]
          }
        },
        {
          "subclaim": "Transformer architectures struggle with very long contexts",
          "verdict": "CONTRADICT",
          "controversial": true,
          "strengths": {
            "support": 0.6505474895606671,
            "contradict": 1.2597630391328387,
            "total": 1.9103105286935058
          },
          "evidence": {
            "supporting": [
              {
                "id": 6354,
                "faiss_score": 0.9011918902397156,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 93,
                "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004106350243091583,
                  "neutral": 0.4961184859275818,
                  "support": 0.4997752010822296
                },
                "stance_score": 0.49566885083913803,
                "evidence_contribution": 0.44669274862067043,
                "combined_rank_score": 0.9011918902397156
              },
              {
                "id": 6410,
                "faiss_score": 0.8988044857978821,
                "faiss_rank": 6,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 149,
                "sentence": "While transformers can approximate reasoning patterns seen in training data, they lack explicit mechanisms for symbolic manipulation or long-term memory beyond the context window.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004727179650217295,
                  "neutral": 0.8721571564674377,
                  "support": 0.12311563640832901
                },
                "stance_score": 0.11838845675811172,
                "evidence_contribution": 0.1064080760008794,
                "combined_rank_score": 0.8988044857978821
              },
              {
                "id": 6308,
                "faiss_score": 0.8973833322525024,
                "faiss_rank": 8,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Another challenge associated with transformers is their reliance on large datasets for effective training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.03320769593119621,
                  "neutral": 0.8249948024749756,
                  "support": 0.1417974829673767
                },
                "stance_score": 0.1085897870361805,
                "evidence_contribution": 0.09744666493911724,
                "combined_rank_score": 0.8973833322525024
              }
            ],
            "contradicting": [
              {
                "id": 6351,
                "faiss_score": 0.903228759765625,
                "faiss_rank": 2,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 90,
                "sentence": "The architecture of transformers lends itself well to these approaches, but achieving efficient scaling still requires careful engineering.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7009249329566956,
                  "neutral": 0.2951323091983795,
                  "support": 0.00394277460873127
                },
                "stance_score": -0.6969821583479643,
                "evidence_contribution": -0.6295343304634002,
                "combined_rank_score": 0.903228759765625
              },
              {
                "id": 6333,
                "faiss_score": 0.8825433850288391,
                "faiss_rank": 20,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 72,
                "sentence": "The influence of transformer architectures is closely tied to their role in large-scale pretraining paradigms.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3231250047683716,
                  "neutral": 0.6701911091804504,
                  "support": 0.006683885585516691
                },
                "stance_score": -0.3164411191828549,
                "evidence_contribution": -0.27927301648595104,
                "combined_rank_score": 0.8825433850288391
              },
              {
                "id": 6452,
                "faiss_score": 0.883942723274231,
                "faiss_rank": 18,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 191,
                "sentence": "Theoretical analyses of transformers aim to explain why attention-based architectures perform so well.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.2664746344089508,
                  "neutral": 0.7282794117927551,
                  "support": 0.00524589978158474
                },
                "stance_score": -0.26122873462736607,
                "evidence_contribution": -0.23091123908399536,
                "combined_rank_score": 0.883942723274231
              },
              {
                "id": 2954,
                "faiss_score": 0.8992305994033813,
                "faiss_rank": 4,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 9,
                "sentence": "Modern transformers overcome this problem, but unlike RNNs, they require computation time that is quadratic in the size of the context window.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.21358922123908997,
                  "neutral": 0.7063183784484863,
                  "support": 0.08009237051010132
                },
                "stance_score": -0.13349685072898865,
                "evidence_contribution": -0.12004445309949219,
                "combined_rank_score": 0.8992305994033813
              }
            ],
            "neutral": [
              {
                "id": 6426,
                "faiss_score": 0.9080196022987366,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 165,
                "sentence": "This interdependence complicates efforts to simplify or interpret transformer architectures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005680007394403219,
                  "neutral": 0.9186755418777466,
                  "support": 0.07564450800418854
                },
                "stance_score": 0.06996450060978532,
                "evidence_contribution": 0.06352913801872698,
                "combined_rank_score": 0.9080196022987366
              },
              {
                "id": 6327,
                "faiss_score": 0.8989972472190857,
                "faiss_rank": 5,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 66,
                "sentence": "As transformers are applied to increasingly diverse tasks, their limitations become more apparent.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0018463677261024714,
                  "neutral": 0.9857475161552429,
                  "support": 0.012406127527356148
                },
                "stance_score": 0.010559759801253676,
                "evidence_contribution": 0.009493194992621815,
                "combined_rank_score": 0.8989972472190857
              },
              {
                "id": 6373,
                "faiss_score": 0.8981020450592041,
                "faiss_rank": 7,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 112,
                "sentence": "The complexity of transformers makes it difficult to draw definitive conclusions about how information is processed internally.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005705650895833969,
                  "neutral": 0.9217869639396667,
                  "support": 0.07250738888978958
                },
                "stance_score": 0.06680173799395561,
                "evidence_contribution": 0.05999477750588067,
                "combined_rank_score": 0.8981020450592041
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Transformer architectures require large compute budgets",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 2393,
                      "faiss_score": 0.8968762159347534,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 324,
                      "sentence": "Large and effective neural networks require considerable computing resources.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.146491140127182,
                        "neutral": 0.2861555814743042,
                        "support": 0.5673533082008362
                      },
                      "stance_score": 0.4208621680736542,
                      "evidence_contribution": 0.37746126873199515,
                      "combined_rank_score": 0.8968762159347534
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6435,
                      "faiss_score": 0.9053575992584229,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 174,
                      "sentence": "From an engineering perspective, deploying transformer-based systems requires careful consideration of resource constraints.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.11402056366205215,
                        "neutral": 0.8815873861312866,
                        "support": 0.004392093978822231
                      },
                      "stance_score": -0.10962846968322992,
                      "evidence_contribution": -0.09925296812278384,
                      "combined_rank_score": 0.9053575992584229
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6354,
                      "faiss_score": 0.9239134192466736,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 93,
                      "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0014876507921144366,
                        "neutral": 0.9060214757919312,
                        "support": 0.09249088913202286
                      },
                      "stance_score": 0.09100323833990842,
                      "evidence_contribution": 0.08407911309714478,
                      "combined_rank_score": 0.9239134192466736
                    },
                    {
                      "id": 6351,
                      "faiss_score": 0.9145227670669556,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 90,
                      "sentence": "The architecture of transformers lends itself well to these approaches, but achieving efficient scaling still requires careful engineering.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0020623886957764626,
                        "neutral": 0.9965948462486267,
                        "support": 0.0013428118545562029
                      },
                      "stance_score": -0.0007195768412202597,
                      "evidence_contribution": -0.0006580694039500512,
                      "combined_rank_score": 0.9145227670669556
                    },
                    {
                      "id": 3083,
                      "faiss_score": 0.9009952545166016,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 138,
                      "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "probs": {
                        "contradict": 0.001218362944200635,
                        "neutral": 0.9977374076843262,
                        "support": 0.0010442466009408236
                      },
                      "stance_score": -0.0001741163432598114,
                      "evidence_contribution": -0.00015687799901087374,
                      "combined_rank_score": 0.9009952545166016
                    }
                  ]
                }
              },
              {
                "subclaim": "Transformer architectures are sensitive to hyperparameters",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6375,
                      "faiss_score": 0.9090120196342468,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 114,
                      "sentence": "Transformer-based models can be sensitive to adversarial inputs, distribution shifts, and subtle perturbations.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.06621425598859787,
                        "neutral": 0.6238605380058289,
                        "support": 0.3099251985549927
                      },
                      "stance_score": 0.2437109425663948,
                      "evidence_contribution": 0.22153617610924448,
                      "combined_rank_score": 0.9090120196342468
                    },
                    {
                      "id": 6345,
                      "faiss_score": 0.8922547698020935,
                      "faiss_rank": 11,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 84,
                      "sentence": "Transformers also exhibit a strong dependence on optimization techniques.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.008120838552713394,
                        "neutral": 0.5745980143547058,
                        "support": 0.4172811806201935
                      },
                      "stance_score": 0.4091603420674801,
                      "evidence_contribution": 0.3650752668235653,
                      "combined_rank_score": 0.8922547698020935
                    },
                    {
                      "id": 6408,
                      "faiss_score": 0.8895968198776245,
                      "faiss_rank": 16,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 147,
                      "sentence": "One consequence of this data dependence is that transformers can perform well on surface-level tasks while struggling with deeper reasoning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.04594160243868828,
                        "neutral": 0.7963574528694153,
                        "support": 0.15770091116428375
                      },
                      "stance_score": 0.11175930872559547,
                      "evidence_contribution": 0.09942072563401139,
                      "combined_rank_score": 0.8895968198776245
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6341,
                      "faiss_score": 0.9085462093353271,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 80,
                      "sentence": "One notable characteristic of transformers trained in this way is their sensitivity to data distribution.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.3421061038970947,
                        "neutral": 0.48605436086654663,
                        "support": 0.17183957993984222
                      },
                      "stance_score": -0.1702665239572525,
                      "evidence_contribution": -0.15469500491806443,
                      "combined_rank_score": 0.9085462093353271
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6318,
                      "faiss_score": 0.9083467721939087,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 57,
                      "sentence": "The widespread deployment of transformer-based systems has also raised questions about robustness and interpretability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.013997501693665981,
                        "neutral": 0.9734272956848145,
                        "support": 0.012575263157486916
                      },
                      "stance_score": -0.0014222385361790657,
                      "evidence_contribution": -0.001291885783628044,
                      "combined_rank_score": 0.9083467721939087
                    },
                    {
                      "id": 6458,
                      "faiss_score": 0.9043031334877014,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "A balanced understanding requires examining both the strengths and limitations of transformers relative to alternative architectures.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.011928658001124859,
                        "neutral": 0.980444073677063,
                        "support": 0.007627241313457489
                      },
                      "stance_score": -0.00430141668766737,
                      "evidence_contribution": -0.003889784589093892,
                      "combined_rank_score": 0.9043031334877014
                    },
                    {
                      "id": 6367,
                      "faiss_score": 0.9034165143966675,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 106,
                      "sentence": "Interpretability remains a challenging aspect of transformer-based models.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.012839163653552532,
                        "neutral": 0.8901380300521851,
                        "support": 0.09702283143997192
                      },
                      "stance_score": 0.08418366778641939,
                      "evidence_contribution": 0.07605291572073403,
                      "combined_rank_score": 0.9034165143966675
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Transformer architectures scale efficiently",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6300,
                      "faiss_score": 0.9007487297058105,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0058963969349861145,
                        "neutral": 0.31589367985725403,
                        "support": 0.6782099008560181
                      },
                      "stance_score": 0.672313503921032,
                      "evidence_contribution": 0.605585534620932,
                      "combined_rank_score": 0.9007487297058105
                    },
                    {
                      "id": 6275,
                      "faiss_score": 0.8976442813873291,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Instead of processing tokens sequentially, transformers process entire sequences in parallel, enabling efficient training on modern hardware.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.003980658017098904,
                        "neutral": 0.8544312715530396,
                        "support": 0.1415880173444748
                      },
                      "stance_score": 0.1376073593273759,
                      "evidence_contribution": 0.12352245917703031,
                      "combined_rank_score": 0.8976442813873291
                    },
                    {
                      "id": 1759,
                      "faiss_score": 0.8951883316040039,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "As of 2024, the largest and most capable models are all based on the transformer architecture.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.0027968829963356256,
                        "neutral": 0.8943379521369934,
                        "support": 0.10286521166563034
                      },
                      "stance_score": 0.10006832866929471,
                      "evidence_contribution": 0.08958000018786705,
                      "combined_rank_score": 0.8951883316040039
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6351,
                      "faiss_score": 0.9340454339981079,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 90,
                      "sentence": "The architecture of transformers lends itself well to these approaches, but achieving efficient scaling still requires careful engineering.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.7765777707099915,
                        "neutral": 0.14032764732837677,
                        "support": 0.08309459686279297
                      },
                      "stance_score": -0.6934831738471985,
                      "evidence_contribution": -0.6477447920864918,
                      "combined_rank_score": 0.9340454339981079
                    },
                    {
                      "id": 6354,
                      "faiss_score": 0.8869820237159729,
                      "faiss_rank": 13,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 93,
                      "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9340041875839233,
                        "neutral": 0.06165565177798271,
                        "support": 0.004340222105383873
                      },
                      "stance_score": -0.9296639654785395,
                      "evidence_contribution": -0.8245952254759713,
                      "combined_rank_score": 0.8869820237159729
                    },
                    {
                      "id": 6458,
                      "faiss_score": 0.8864687085151672,
                      "faiss_rank": 14,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "A balanced understanding requires examining both the strengths and limitations of transformers relative to alternative architectures.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.13582396507263184,
                        "neutral": 0.8572172522544861,
                        "support": 0.006958819460123777
                      },
                      "stance_score": -0.12886514561250806,
                      "evidence_contribution": -0.11423491920373899,
                      "combined_rank_score": 0.8864687085151672
                    }
                  ],
                  "neutral": [
                    {
                      "id": 3083,
                      "faiss_score": 0.905130922794342,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 138,
                      "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "probs": {
                        "contradict": 0.0027802942786365747,
                        "neutral": 0.9887701272964478,
                        "support": 0.008449570275843143
                      },
                      "stance_score": 0.005669275997206569,
                      "evidence_contribution": 0.005131437014927395,
                      "combined_rank_score": 0.905130922794342
                    },
                    {
                      "id": 6304,
                      "faiss_score": 0.8955011367797852,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 43,
                      "sentence": "To address these issues, numerous variants of the transformer architecture have been proposed.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.021592628210783005,
                        "neutral": 0.9746042490005493,
                        "support": 0.003803079714998603
                      },
                      "stance_score": -0.017789548495784402,
                      "evidence_contribution": -0.01593056090077405,
                      "combined_rank_score": 0.8955011367797852
                    },
                    {
                      "id": 2987,
                      "faiss_score": 0.8943012952804565,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Transformer architecture is now used alongside many generative models that contribute to the ongoing AI boom.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "probs": {
                        "contradict": 0.0007735576364211738,
                        "neutral": 0.9976523518562317,
                        "support": 0.0015741330571472645
                      },
                      "stance_score": 0.0008005754207260907,
                      "evidence_contribution": 0.0007159556357250393,
                      "combined_rank_score": 0.8943012952804565
                    }
                  ]
                }
              },
              {
                "subclaim": "Transformer architectures struggle with very long contexts",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6354,
                      "faiss_score": 0.9011918902397156,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 93,
                      "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004106350243091583,
                        "neutral": 0.4961184859275818,
                        "support": 0.4997752010822296
                      },
                      "stance_score": 0.49566885083913803,
                      "evidence_contribution": 0.44669274862067043,
                      "combined_rank_score": 0.9011918902397156
                    },
                    {
                      "id": 6410,
                      "faiss_score": 0.8988044857978821,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 149,
                      "sentence": "While transformers can approximate reasoning patterns seen in training data, they lack explicit mechanisms for symbolic manipulation or long-term memory beyond the context window.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004727179650217295,
                        "neutral": 0.8721571564674377,
                        "support": 0.12311563640832901
                      },
                      "stance_score": 0.11838845675811172,
                      "evidence_contribution": 0.1064080760008794,
                      "combined_rank_score": 0.8988044857978821
                    },
                    {
                      "id": 6308,
                      "faiss_score": 0.8973833322525024,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 47,
                      "sentence": "Another challenge associated with transformers is their reliance on large datasets for effective training.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.03320769593119621,
                        "neutral": 0.8249948024749756,
                        "support": 0.1417974829673767
                      },
                      "stance_score": 0.1085897870361805,
                      "evidence_contribution": 0.09744666493911724,
                      "combined_rank_score": 0.8973833322525024
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6351,
                      "faiss_score": 0.903228759765625,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 90,
                      "sentence": "The architecture of transformers lends itself well to these approaches, but achieving efficient scaling still requires careful engineering.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.7009249329566956,
                        "neutral": 0.2951323091983795,
                        "support": 0.00394277460873127
                      },
                      "stance_score": -0.6969821583479643,
                      "evidence_contribution": -0.6295343304634002,
                      "combined_rank_score": 0.903228759765625
                    },
                    {
                      "id": 2954,
                      "faiss_score": 0.8992305994033813,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "Modern transformers overcome this problem, but unlike RNNs, they require computation time that is quadratic in the size of the context window.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "probs": {
                        "contradict": 0.21358922123908997,
                        "neutral": 0.7063183784484863,
                        "support": 0.08009237051010132
                      },
                      "stance_score": -0.13349685072898865,
                      "evidence_contribution": -0.12004445309949219,
                      "combined_rank_score": 0.8992305994033813
                    },
                    {
                      "id": 6452,
                      "faiss_score": 0.883942723274231,
                      "faiss_rank": 18,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 191,
                      "sentence": "Theoretical analyses of transformers aim to explain why attention-based architectures perform so well.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.2664746344089508,
                        "neutral": 0.7282794117927551,
                        "support": 0.00524589978158474
                      },
                      "stance_score": -0.26122873462736607,
                      "evidence_contribution": -0.23091123908399536,
                      "combined_rank_score": 0.883942723274231
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6426,
                      "faiss_score": 0.9080196022987366,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 165,
                      "sentence": "This interdependence complicates efforts to simplify or interpret transformer architectures.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005680007394403219,
                        "neutral": 0.9186755418777466,
                        "support": 0.07564450800418854
                      },
                      "stance_score": 0.06996450060978532,
                      "evidence_contribution": 0.06352913801872698,
                      "combined_rank_score": 0.9080196022987366
                    },
                    {
                      "id": 6327,
                      "faiss_score": 0.8989972472190857,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 66,
                      "sentence": "As transformers are applied to increasingly diverse tasks, their limitations become more apparent.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0018463677261024714,
                        "neutral": 0.9857475161552429,
                        "support": 0.012406127527356148
                      },
                      "stance_score": 0.010559759801253676,
                      "evidence_contribution": 0.009493194992621815,
                      "combined_rank_score": 0.8989972472190857
                    },
                    {
                      "id": 6373,
                      "faiss_score": 0.8981020450592041,
                      "faiss_rank": 7,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 112,
                      "sentence": "The complexity of transformers makes it difficult to draw definitive conclusions about how information is processed internally.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005705650895833969,
                        "neutral": 0.9217869639396667,
                        "support": 0.07250738888978958
                      },
                      "stance_score": 0.06680173799395561,
                      "evidence_contribution": 0.05999477750588067,
                      "combined_rank_score": 0.8981020450592041
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Transformer architectures improve parallelization",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6275,
                      "faiss_score": 0.9147120714187622,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Instead of processing tokens sequentially, transformers process entire sequences in parallel, enabling efficient training on modern hardware.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0016989217838272452,
                        "neutral": 0.43683573603630066,
                        "support": 0.561465322971344
                      },
                      "stance_score": 0.5597664011875167,
                      "evidence_contribution": 0.5120250843408594,
                      "combined_rank_score": 0.9147120714187622
                    },
                    {
                      "id": 6284,
                      "faiss_score": 0.8840556144714355,
                      "faiss_rank": 18,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 23,
                      "sentence": "Transformers typically employ multiple attention heads in parallel.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001994922524318099,
                        "neutral": 0.8282346129417419,
                        "support": 0.16977041959762573
                      },
                      "stance_score": 0.16777549707330763,
                      "evidence_contribution": 0.14832287015839352,
                      "combined_rank_score": 0.8840556144714355
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6426,
                      "faiss_score": 0.8849560618400574,
                      "faiss_rank": 16,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 165,
                      "sentence": "This interdependence complicates efforts to simplify or interpret transformer architectures.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.25036686658859253,
                        "neutral": 0.7427451610565186,
                        "support": 0.006887955591082573
                      },
                      "stance_score": -0.24347891099750996,
                      "evidence_contribution": -0.21546813821746225,
                      "combined_rank_score": 0.8849560618400574
                    },
                    {
                      "id": 6354,
                      "faiss_score": 0.8843683004379272,
                      "faiss_rank": 17,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 93,
                      "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.8079596757888794,
                        "neutral": 0.1881577968597412,
                        "support": 0.003882531775161624
                      },
                      "stance_score": -0.8040771440137178,
                      "evidence_contribution": -0.7111003372723941,
                      "combined_rank_score": 0.8843683004379272
                    }
                  ],
                  "neutral": [
                    {
                      "id": 3083,
                      "faiss_score": 0.9109269380569458,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 138,
                      "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "probs": {
                        "contradict": 0.0007497426704503596,
                        "neutral": 0.9901717305183411,
                        "support": 0.00907858181744814
                      },
                      "stance_score": 0.00832883914699778,
                      "evidence_contribution": 0.007586963941743512,
                      "combined_rank_score": 0.9109269380569458
                    },
                    {
                      "id": 6304,
                      "faiss_score": 0.909870982170105,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 43,
                      "sentence": "To address these issues, numerous variants of the transformer architecture have been proposed.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0011379255447536707,
                        "neutral": 0.9968006610870361,
                        "support": 0.0020614054519683123
                      },
                      "stance_score": 0.0009234799072146416,
                      "evidence_contribution": 0.0008402475701917433,
                      "combined_rank_score": 0.909870982170105
                    },
                    {
                      "id": 6351,
                      "faiss_score": 0.9036628603935242,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 90,
                      "sentence": "The architecture of transformers lends itself well to these approaches, but achieving efficient scaling still requires careful engineering.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0044351923279464245,
                        "neutral": 0.943244993686676,
                        "support": 0.05231977626681328
                      },
                      "stance_score": 0.047884583938866854,
                      "evidence_contribution": 0.04327152009095023,
                      "combined_rank_score": 0.9036628603935242
                    }
                  ]
                }
              },
              {
                "subclaim": "Transformer architectures capture long-range dependencies",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 1807,
                      "faiss_score": 0.9011234641075134,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "LLMs are generally based on the transformer architecture, which leverages an attention mechanism that enables the model to process relationships between all elements in a sequence simultaneously, regardless of their distance from each other.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.0071091135032474995,
                        "neutral": 0.7715122699737549,
                        "support": 0.22137866914272308
                      },
                      "stance_score": 0.21426955563947558,
                      "evidence_contribution": 0.19308332423062183,
                      "combined_rank_score": 0.9011234641075134
                    },
                    {
                      "id": 6333,
                      "faiss_score": 0.8927822113037109,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 72,
                      "sentence": "The influence of transformer architectures is closely tied to their role in large-scale pretraining paradigms.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.00578355323523283,
                        "neutral": 0.8242341876029968,
                        "support": 0.16998225450515747
                      },
                      "stance_score": 0.16419870126992464,
                      "evidence_contribution": 0.14659367961296077,
                      "combined_rank_score": 0.8927822113037109
                    },
                    {
                      "id": 6345,
                      "faiss_score": 0.8888646364212036,
                      "faiss_rank": 13,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 84,
                      "sentence": "Transformers also exhibit a strong dependence on optimization techniques.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.014505324885249138,
                        "neutral": 0.755142867565155,
                        "support": 0.23035182058811188
                      },
                      "stance_score": 0.21584649570286274,
                      "evidence_contribution": 0.19185831692571598,
                      "combined_rank_score": 0.8888646364212036
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6426,
                      "faiss_score": 0.9104562997817993,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 165,
                      "sentence": "This interdependence complicates efforts to simplify or interpret transformer architectures.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.6054443120956421,
                        "neutral": 0.32951802015304565,
                        "support": 0.06503769010305405
                      },
                      "stance_score": -0.540406621992588,
                      "evidence_contribution": -0.49201661343695324,
                      "combined_rank_score": 0.9104562997817993
                    },
                    {
                      "id": 6308,
                      "faiss_score": 0.8934979438781738,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 47,
                      "sentence": "Another challenge associated with transformers is their reliance on large datasets for effective training.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.2442263662815094,
                        "neutral": 0.6452279090881348,
                        "support": 0.11054568737745285
                      },
                      "stance_score": -0.13368067890405655,
                      "evidence_contribution": -0.1194434117370129,
                      "combined_rank_score": 0.8934979438781738
                    },
                    {
                      "id": 6408,
                      "faiss_score": 0.8920823335647583,
                      "faiss_rank": 7,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 147,
                      "sentence": "One consequence of this data dependence is that transformers can perform well on surface-level tasks while struggling with deeper reasoning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.795606791973114,
                        "neutral": 0.15556006133556366,
                        "support": 0.048833150416612625
                      },
                      "stance_score": -0.7467736415565014,
                      "evidence_contribution": -0.6661835728043761,
                      "combined_rank_score": 0.8920823335647583
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6351,
                      "faiss_score": 0.9003123044967651,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 90,
                      "sentence": "The architecture of transformers lends itself well to these approaches, but achieving efficient scaling still requires careful engineering.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.010348428040742874,
                        "neutral": 0.956598699092865,
                        "support": 0.03305292874574661
                      },
                      "stance_score": 0.02270450070500374,
                      "evidence_contribution": 0.020441141352170344,
                      "combined_rank_score": 0.9003123044967651
                    },
                    {
                      "id": 3083,
                      "faiss_score": 0.8960912823677063,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 138,
                      "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "probs": {
                        "contradict": 0.017301296815276146,
                        "neutral": 0.9663417935371399,
                        "support": 0.016356920823454857
                      },
                      "stance_score": -0.0009443759918212891,
                      "evidence_contribution": -0.0008462470935484134,
                      "combined_rank_score": 0.8960912823677063
                    },
                    {
                      "id": 6296,
                      "faiss_score": 0.8920329809188843,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 35,
                      "sentence": "The transformer architecture proved highly effective across a wide range of natural language processing tasks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0042916773818433285,
                        "neutral": 0.9397426247596741,
                        "support": 0.055965688079595566
                      },
                      "stance_score": 0.05167401069775224,
                      "evidence_contribution": 0.046094921798750244,
                      "combined_rank_score": 0.8920329809188843
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Distributed systems improve scalability, availability, and fault tolerance, but introduce coordination overhead, consistency challenges, debugging difficulty, and increased system complexity.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Distributed systems improve scalability",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 1.27381838622602,
            "contradict": 0.7142825961756749,
            "total": 1.9881009824016949
          },
          "evidence": {
            "supporting": [
              {
                "id": 499,
                "faiss_score": 0.9017831683158875,
                "faiss_rank": 10,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.0015425255987793207,
                  "neutral": 0.4211810231208801,
                  "support": 0.5772764086723328
                },
                "stance_score": 0.5757338830735534,
                "evidence_contribution": 0.5191871251848778,
                "combined_rank_score": 0.9017831683158875
              },
              {
                "id": 502,
                "faiss_score": 0.895154595375061,
                "faiss_rank": 13,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 78,
                "sentence": "Subsequently, Reactive systems are more flexible, loosely-coupled and scalable.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.009046770632266998,
                  "neutral": 0.5073032379150391,
                  "support": 0.48364999890327454
                },
                "stance_score": 0.47460322827100754,
                "evidence_contribution": 0.4248432607666315,
                "combined_rank_score": 0.895154595375061
              },
              {
                "id": 6684,
                "faiss_score": 0.9061692357063293,
                "faiss_rank": 3,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 16,
                "sentence": "By distributing work across multiple processors or machines, systems can handle more requests concurrently.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0014126799069344997,
                  "neutral": 0.6332381963729858,
                  "support": 0.3653491139411926
                },
                "stance_score": 0.3639364340342581,
                "evidence_contribution": 0.3297880002745106,
                "combined_rank_score": 0.9061692357063293
              }
            ],
            "contradicting": [
              {
                "id": 5658,
                "faiss_score": 0.9028811454772949,
                "faiss_rank": 9,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 61,
                "sentence": "Eventually consistent systems illustrate how relaxing guarantees can improve scalability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8435043692588806,
                  "neutral": 0.10410597920417786,
                  "support": 0.052389614284038544
                },
                "stance_score": -0.7911147549748421,
                "evidence_contribution": -0.7142825961756749,
                "combined_rank_score": 0.9028811454772949
              }
            ],
            "neutral": [
              {
                "id": 759,
                "faiss_score": 0.9175848364830017,
                "faiss_rank": 1,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 163,
                "sentence": "Meeting this scalability condition is possible for a wide range of systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0008614318794570863,
                  "neutral": 0.9977839589118958,
                  "support": 0.0013546152040362358
                },
                "stance_score": 0.0004931833245791495,
                "evidence_contribution": 0.00045253754024010204,
                "combined_rank_score": 0.9175848364830017
              },
              {
                "id": 445,
                "faiss_score": 0.9056973457336426,
                "faiss_rank": 4,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Distributed systems are groups of networked computers which share a common goal for their work.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.000767619232647121,
                  "neutral": 0.9977124929428101,
                  "support": 0.001519894110970199
                },
                "stance_score": 0.0007522748783230782,
                "evidence_contribution": 0.0006813333605593108,
                "combined_rank_score": 0.9056973457336426
              },
              {
                "id": 5646,
                "faiss_score": 0.9050657749176025,
                "faiss_rank": 7,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 49,
                "sentence": "The evolution of distributed systems has been driven by practical needs.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0006361278356052935,
                  "neutral": 0.9965994954109192,
                  "support": 0.002764445496723056
                },
                "stance_score": 0.0021283176611177623,
                "evidence_contribution": 0.001926267473230367,
                "combined_rank_score": 0.9050657749176025
              }
            ]
          }
        },
        {
          "subclaim": "Distributed systems improve availability",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 1.1745798602353945,
            "contradict": 0.3155167021878126,
            "total": 1.490096562423207
          },
          "evidence": {
            "supporting": [
              {
                "id": 5614,
                "faiss_score": 0.9020341634750366,
                "faiss_rank": 9,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 17,
                "sentence": "Replication is commonly used to improve fault tolerance and availability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001992239151149988,
                  "neutral": 0.6123042702674866,
                  "support": 0.3857034146785736
                },
                "stance_score": 0.3837111755274236,
                "evidence_contribution": 0.3461205892329025,
                "combined_rank_score": 0.9020341634750366
              },
              {
                "id": 498,
                "faiss_score": 0.907902717590332,
                "faiss_rank": 5,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 74,
                "sentence": "It can provide more reliability than a non-distributed system, as there is no single point of failure.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.006190187763422728,
                  "neutral": 0.6528412699699402,
                  "support": 0.34096860885620117
                },
                "stance_score": 0.33477842109277844,
                "evidence_contribution": 0.3039462383007341,
                "combined_rank_score": 0.907902717590332
              },
              {
                "id": 3817,
                "faiss_score": 0.8974882364273071,
                "faiss_rank": 11,
                "doc_id": "wiki_CAP_theorem",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Most modern distributed databases offer configuration options for both consistency and availability.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/CAP_theorem",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.00218738685362041,
                  "neutral": 0.6701467633247375,
                  "support": 0.3276658058166504
                },
                "stance_score": 0.32547841896303,
                "evidence_contribution": 0.29211305223027795,
                "combined_rank_score": 0.8974882364273071
              },
              {
                "id": 5615,
                "faiss_score": 0.8949296474456787,
                "faiss_rank": 17,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "By maintaining multiple copies of data across different nodes, a system can continue to operate even if some replicas fail.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0014519793912768364,
                  "neutral": 0.8389820456504822,
                  "support": 0.1595660001039505
                },
                "stance_score": 0.15811402071267366,
                "evidence_contribution": 0.14150092481261178,
                "combined_rank_score": 0.8949296474456787
              },
              {
                "id": 5668,
                "faiss_score": 0.8971213102340698,
                "faiss_rank": 12,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 71,
                "sentence": "Modern distributed systems increasingly rely on automation for deployment, scaling, and recovery.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0025057359598577023,
                  "neutral": 0.8936654329299927,
                  "support": 0.10382877290248871
                },
                "stance_score": 0.101323036942631,
                "evidence_contribution": 0.09089905565886819,
                "combined_rank_score": 0.8971213102340698
              }
            ],
            "contradicting": [
              {
                "id": 5605,
                "faiss_score": 0.9042737483978271,
                "faiss_rank": 8,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Failures are another fundamental aspect of distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.2072419673204422,
                  "neutral": 0.7761302590370178,
                  "support": 0.016627848148345947
                },
                "stance_score": -0.19061411917209625,
                "evidence_contribution": -0.1723673440413016,
                "combined_rank_score": 0.9042737483978271
              },
              {
                "id": 5650,
                "faiss_score": 0.9007853269577026,
                "faiss_rank": 10,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Distributed systems also intersect with security concerns.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.16322025656700134,
                  "neutral": 0.8324757218360901,
                  "support": 0.004304082132875919
                },
                "stance_score": -0.15891617443412542,
                "evidence_contribution": -0.14314935814651097,
                "combined_rank_score": 0.9007853269577026
              }
            ],
            "neutral": [
              {
                "id": 430,
                "faiss_score": 0.9117620587348938,
                "faiss_rank": 1,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 6,
                "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.0023098234087228775,
                  "neutral": 0.9925360679626465,
                  "support": 0.005154070444405079
                },
                "stance_score": 0.0028442470356822014,
                "evidence_contribution": 0.002593276532804223,
                "combined_rank_score": 0.9117620587348938
              },
              {
                "id": 5662,
                "faiss_score": 0.9096964597702026,
                "faiss_rank": 4,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 65,
                "sentence": "Distributed systems research emphasizes the importance of understanding failure modes.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0033991688396781683,
                  "neutral": 0.9939257502555847,
                  "support": 0.0026750725228339434
                },
                "stance_score": -0.0007240963168442249,
                "evidence_contribution": -0.0006587078559658344,
                "combined_rank_score": 0.9096964597702026
              },
              {
                "id": 5646,
                "faiss_score": 0.8958644270896912,
                "faiss_rank": 13,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 49,
                "sentence": "The evolution of distributed systems has been driven by practical needs.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0006776307127438486,
                  "neutral": 0.9960979223251343,
                  "support": 0.003224448300898075
                },
                "stance_score": 0.0025468175881542265,
                "evidence_contribution": 0.002281603279513735,
                "combined_rank_score": 0.8958644270896912
              }
            ]
          }
        },
        {
          "subclaim": "Distributed systems improve fault tolerance",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 0.7888913054755784,
            "contradict": 0.4344137730048635,
            "total": 1.223305078480442
          },
          "evidence": {
            "supporting": [
              {
                "id": 498,
                "faiss_score": 0.8959221243858337,
                "faiss_rank": 13,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 74,
                "sentence": "It can provide more reliability than a non-distributed system, as there is no single point of failure.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.003871267195791006,
                  "neutral": 0.5383682250976562,
                  "support": 0.4577604830265045
                },
                "stance_score": 0.4538892158307135,
                "evidence_contribution": 0.4066493904828731,
                "combined_rank_score": 0.8959221243858337
              },
              {
                "id": 5614,
                "faiss_score": 0.9063659906387329,
                "faiss_rank": 8,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 17,
                "sentence": "Replication is commonly used to improve fault tolerance and availability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0022014533169567585,
                  "neutral": 0.5738668441772461,
                  "support": 0.42393165826797485
                },
                "stance_score": 0.4217302049510181,
                "evidence_contribution": 0.3822419149927054,
                "combined_rank_score": 0.9063659906387329
              }
            ],
            "contradicting": [
              {
                "id": 568,
                "faiss_score": 0.9054936170578003,
                "faiss_rank": 9,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 144,
                "sentence": "There are also fundamental challenges that are unique to distributed computing, for example those related to fault-tolerance.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.38152015209198,
                  "neutral": 0.6146324276924133,
                  "support": 0.0038474525790661573
                },
                "stance_score": -0.3776726995129138,
                "evidence_contribution": -0.3419802187459321,
                "combined_rank_score": 0.9054936170578003
              },
              {
                "id": 5605,
                "faiss_score": 0.9076846241950989,
                "faiss_rank": 6,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Failures are another fundamental aspect of distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.11820482462644577,
                  "neutral": 0.8654248714447021,
                  "support": 0.016370385885238647
                },
                "stance_score": -0.10183443874120712,
                "evidence_contribution": -0.0924335542589314,
                "combined_rank_score": 0.9076846241950989
              }
            ],
            "neutral": [
              {
                "id": 430,
                "faiss_score": 0.9204719066619873,
                "faiss_rank": 1,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 6,
                "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.00475419033318758,
                  "neutral": 0.9388123750686646,
                  "support": 0.056433361023664474
                },
                "stance_score": 0.051679170690476894,
                "evidence_contribution": 0.04756922478017356,
                "combined_rank_score": 0.9204719066619873
              },
              {
                "id": 3457,
                "faiss_score": 0.9127100706100464,
                "faiss_rank": 4,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 28,
                "sentence": "Fault tolerance is notably successful in computer applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0009182387148030102,
                  "neutral": 0.9978187084197998,
                  "support": 0.0012630720157176256
                },
                "stance_score": 0.0003448333009146154,
                "evidence_contribution": 0.000314732826426474,
                "combined_rank_score": 0.9127100706100464
              },
              {
                "id": 5662,
                "faiss_score": 0.9125458002090454,
                "faiss_rank": 5,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 65,
                "sentence": "Distributed systems research emphasizes the importance of understanding failure modes.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00217837025411427,
                  "neutral": 0.9940716624259949,
                  "support": 0.0037499666213989258
                },
                "stance_score": 0.0015715963672846556,
                "evidence_contribution": 0.0014341536645894049,
                "combined_rank_score": 0.9125458002090454
              }
            ]
          }
        },
        {
          "subclaim": "Distributed systems introduce coordination overhead",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 2.9624569499220486,
            "contradict": 0.45905178307599,
            "total": 3.4215087329980385
          },
          "evidence": {
            "supporting": [
              {
                "id": 6685,
                "faiss_score": 0.9233837127685547,
                "faiss_rank": 1,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 17,
                "sentence": "However, parallelism introduces coordination overhead, synchronization costs, and contention for shared resources.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0018082939786836505,
                  "neutral": 0.06981738656759262,
                  "support": 0.9283743500709534
                },
                "stance_score": 0.9265660560922697,
                "evidence_contribution": 0.8555760049997969,
                "combined_rank_score": 0.9233837127685547
              },
              {
                "id": 5633,
                "faiss_score": 0.9139895439147949,
                "faiss_rank": 5,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 36,
                "sentence": "However, scaling introduces coordination overhead that can limit achievable gains.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.006788631435483694,
                  "neutral": 0.2813877463340759,
                  "support": 0.7118236422538757
                },
                "stance_score": 0.705035010818392,
                "evidence_contribution": 0.6443946279818646,
                "combined_rank_score": 0.9139895439147949
              },
              {
                "id": 5617,
                "faiss_score": 0.9007482528686523,
                "faiss_rank": 10,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 20,
                "sentence": "Coordinating updates across replicas requires communication and agreement, which can become a bottleneck as the system scales.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0017354578012600541,
                  "neutral": 0.3325953781604767,
                  "support": 0.6656691431999207
                },
                "stance_score": 0.6639336853986606,
                "evidence_contribution": 0.598037107143489,
                "combined_rank_score": 0.9007482528686523
              },
              {
                "id": 6490,
                "faiss_score": 0.9123440384864807,
                "faiss_rank": 9,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 19,
                "sentence": "Not all problems benefit equally from parallelism, and coordination overhead can limit gains.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0024735191836953163,
                  "neutral": 0.6057115197181702,
                  "support": 0.3918149769306183
                },
                "stance_score": 0.38934145774692297,
                "evidence_contribution": 0.3552133579110412,
                "combined_rank_score": 0.9123440384864807
              },
              {
                "id": 5634,
                "faiss_score": 0.8914949297904968,
                "faiss_rank": 14,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "State management is particularly challenging in distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0019658030942082405,
                  "neutral": 0.700286328792572,
                  "support": 0.2977478504180908
                },
                "stance_score": 0.2957820473238826,
                "evidence_contribution": 0.2636881955122941,
                "combined_rank_score": 0.8914949297904968
              },
              {
                "id": 5644,
                "faiss_score": 0.8900848627090454,
                "faiss_rank": 17,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Because failures and performance issues may arise from interactions between components, debugging distributed systems is notoriously difficult.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0036841926630586386,
                  "neutral": 0.8212850689888,
                  "support": 0.17503072321414948
                },
                "stance_score": 0.17134653055109084,
                "evidence_contribution": 0.15251295312123894,
                "combined_rank_score": 0.8900848627090454
              },
              {
                "id": 5671,
                "faiss_score": 0.897110104560852,
                "faiss_rank": 12,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 74,
                "sentence": "Ultimately, distributed systems are defined by trade-offs.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005296286195516586,
                  "neutral": 0.8857024908065796,
                  "support": 0.10900117456912994
                },
                "stance_score": 0.10370488837361336,
                "evidence_contribution": 0.09303470325232377,
                "combined_rank_score": 0.897110104560852
              }
            ],
            "contradicting": [
              {
                "id": 6684,
                "faiss_score": 0.8900929689407349,
                "faiss_rank": 16,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 16,
                "sentence": "By distributing work across multiple processors or machines, systems can handle more requests concurrently.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5222463011741638,
                  "neutral": 0.4712420403957367,
                  "support": 0.0065116542391479015
                },
                "stance_score": -0.5157346469350159,
                "evidence_contribution": -0.45905178307599,
                "combined_rank_score": 0.8900929689407349
              }
            ],
            "neutral": [
              {
                "id": 585,
                "faiss_score": 0.9145564436912537,
                "faiss_rank": 2,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 161,
                "sentence": "In order to perform coordination, distributed systems employ the concept of coordinators.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.21808390319347382,
                  "neutral": 0.6171427369117737,
                  "support": 0.1647733598947525
                },
                "stance_score": -0.053310543298721313,
                "evidence_contribution": -0.04875550089052716,
                "combined_rank_score": 0.9145564436912537
              },
              {
                "id": 542,
                "faiss_score": 0.9130808115005493,
                "faiss_rank": 6,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 118,
                "sentence": "The main focus is on coordinating the operation of an arbitrary distributed system.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.007331767585128546,
                  "neutral": 0.9015898108482361,
                  "support": 0.09107837826013565
                },
                "stance_score": 0.0837466106750071,
                "evidence_contribution": 0.07646742323555605,
                "combined_rank_score": 0.9130808115005493
              },
              {
                "id": 5597,
                "faiss_score": 0.8991247415542603,
                "faiss_rank": 11,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Distributed systems are collections of independent computing components that coordinate their actions through communication in order to achieve a common goal.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.07815498858690262,
                  "neutral": 0.9142075777053833,
                  "support": 0.007637408562004566
                },
                "stance_score": -0.07051758002489805,
                "evidence_contribution": -0.06340410091491833,
                "combined_rank_score": 0.8991247415542603
              }
            ]
          }
        },
        {
          "subclaim": "Distributed systems introduce consistency challenges",
          "verdict": "SUPPORT",
          "controversial": true,
          "strengths": {
            "support": 2.362180669374988,
            "contradict": 0.9007032584105141,
            "total": 3.262883927785502
          },
          "evidence": {
            "supporting": [
              {
                "id": 5618,
                "faiss_score": 0.8958674669265747,
                "faiss_rank": 11,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Consensus is a fundamental problem in distributed systems that captures the difficulty of agreement in the presence of failures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0027271497529000044,
                  "neutral": 0.3254675567150116,
                  "support": 0.6718052625656128
                },
                "stance_score": 0.6690781128127128,
                "evidence_contribution": 0.599405314101538,
                "combined_rank_score": 0.8958674669265747
              },
              {
                "id": 5600,
                "faiss_score": 0.8907561302185059,
                "faiss_rank": 16,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "Achieving this illusion of coherence in the presence of failures, delays, and partial information is the central challenge of distributed systems design.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005488081835210323,
                  "neutral": 0.5665578842163086,
                  "support": 0.4279540479183197
                },
                "stance_score": 0.4224659660831094,
                "evidence_contribution": 0.37631414909721306,
                "combined_rank_score": 0.8907561302185059
              },
              {
                "id": 5617,
                "faiss_score": 0.893808126449585,
                "faiss_rank": 13,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 20,
                "sentence": "Coordinating updates across replicas requires communication and agreement, which can become a bottleneck as the system scales.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0025332565419375896,
                  "neutral": 0.6845979690551758,
                  "support": 0.31286880373954773
                },
                "stance_score": 0.31033554719761014,
                "evidence_contribution": 0.27738043401140267,
                "combined_rank_score": 0.893808126449585
              },
              {
                "id": 5634,
                "faiss_score": 0.907062292098999,
                "faiss_rank": 3,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "State management is particularly challenging in distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0030246321111917496,
                  "neutral": 0.7135766744613647,
                  "support": 0.28339874744415283
                },
                "stance_score": 0.2803741153329611,
                "evidence_contribution": 0.2543167876991448,
                "combined_rank_score": 0.907062292098999
              },
              {
                "id": 5612,
                "faiss_score": 0.9273715019226074,
                "faiss_rank": 2,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 15,
                "sentence": "Strong consistency models aim to make distributed systems behave as if there were a single shared state, but enforcing such behavior requires coordination and synchronization, which can be expensive or impossible under certain failure conditions.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0031162735540419817,
                  "neutral": 0.731314480304718,
                  "support": 0.2655692398548126
                },
                "stance_score": 0.26245296630077064,
                "evidence_contribution": 0.24339140154238914,
                "combined_rank_score": 0.9273715019226074
              },
              {
                "id": 6617,
                "faiss_score": 0.888791561126709,
                "faiss_rank": 17,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 20,
                "sentence": "Weaker consistency models allow replicas to diverge temporarily, improving availability but shifting complexity to application logic.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0030914966482669115,
                  "neutral": 0.7353484630584717,
                  "support": 0.26156002283096313
                },
                "stance_score": 0.2584685261826962,
                "evidence_contribution": 0.22972464488803823,
                "combined_rank_score": 0.888791561126709
              },
              {
                "id": 5644,
                "faiss_score": 0.8880140781402588,
                "faiss_rank": 18,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Because failures and performance issues may arise from interactions between components, debugging distributed systems is notoriously difficult.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004031979478895664,
                  "neutral": 0.7364306449890137,
                  "support": 0.25953739881515503
                },
                "stance_score": 0.25550541933625937,
                "evidence_contribution": 0.2268924094117286,
                "combined_rank_score": 0.8880140781402588
              },
              {
                "id": 5622,
                "faiss_score": 0.8919827938079834,
                "faiss_rank": 15,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 25,
                "sentence": "Because perfect guarantees are often unattainable, distributed systems rely on trade-offs.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.008166512474417686,
                  "neutral": 0.8101708889007568,
                  "support": 0.18166260421276093
                },
                "stance_score": 0.17349609173834324,
                "evidence_contribution": 0.1547555286235336,
                "combined_rank_score": 0.8919827938079834
              }
            ],
            "contradicting": [
              {
                "id": 5658,
                "faiss_score": 0.8944575190544128,
                "faiss_rank": 12,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 61,
                "sentence": "Eventually consistent systems illustrate how relaxing guarantees can improve scalability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.4701039791107178,
                  "neutral": 0.5211150050163269,
                  "support": 0.00878104753792286
                },
                "stance_score": -0.4613229315727949,
                "evidence_contribution": -0.4126337648575108,
                "combined_rank_score": 0.8944575190544128
              },
              {
                "id": 3817,
                "faiss_score": 0.8984368443489075,
                "faiss_rank": 10,
                "doc_id": "wiki_CAP_theorem",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Most modern distributed databases offer configuration options for both consistency and availability.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/CAP_theorem",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.3348703682422638,
                  "neutral": 0.6467505693435669,
                  "support": 0.01837906427681446
                },
                "stance_score": -0.31649130396544933,
                "evidence_contribution": -0.28434744839858916,
                "combined_rank_score": 0.8984368443489075
              },
              {
                "id": 5610,
                "faiss_score": 0.9464955925941467,
                "faiss_rank": 1,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Consistency is a central concept in distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.2551124393939972,
                  "neutral": 0.7050133943557739,
                  "support": 0.03987419977784157
                },
                "stance_score": -0.21523823961615562,
                "evidence_contribution": -0.20372204515441417,
                "combined_rank_score": 0.9464955925941467
              }
            ],
            "neutral": [
              {
                "id": 568,
                "faiss_score": 0.9033069610595703,
                "faiss_rank": 4,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 144,
                "sentence": "There are also fundamental challenges that are unique to distributed computing, for example those related to fault-tolerance.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.006213893182575703,
                  "neutral": 0.8884377479553223,
                  "support": 0.10534839332103729
                },
                "stance_score": 0.09913450013846159,
                "evidence_contribution": 0.08954888405623329,
                "combined_rank_score": 0.9033069610595703
              },
              {
                "id": 5650,
                "faiss_score": 0.9012532830238342,
                "faiss_rank": 7,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Distributed systems also intersect with security concerns.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.045700471848249435,
                  "neutral": 0.8426495790481567,
                  "support": 0.11164990812540054
                },
                "stance_score": 0.06594943627715111,
                "evidence_contribution": 0.05943714595835359,
                "combined_rank_score": 0.9012532830238342
              },
              {
                "id": 6616,
                "faiss_score": 0.9006686806678772,
                "faiss_rank": 8,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 19,
                "sentence": "Strong consistency simplifies reasoning but requires coordination that may reduce availability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.011836410500109196,
                  "neutral": 0.96406489610672,
                  "support": 0.02409866265952587
                },
                "stance_score": 0.012262252159416676,
                "evidence_contribution": 0.011044226474438645,
                "combined_rank_score": 0.9006686806678772
              }
            ]
          }
        },
        {
          "subclaim": "Distributed systems introduce debugging difficulty",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 1.061006543488806,
            "contradict": 0.09262844165058581,
            "total": 1.1536349851393919
          },
          "evidence": {
            "supporting": [
              {
                "id": 5644,
                "faiss_score": 0.9589457511901855,
                "faiss_rank": 1,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Because failures and performance issues may arise from interactions between components, debugging distributed systems is notoriously difficult.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0014179548015818,
                  "neutral": 0.06682299822568893,
                  "support": 0.9317590594291687
                },
                "stance_score": 0.9303411046275869,
                "evidence_contribution": 0.8921466494402084,
                "combined_rank_score": 0.9589457511901855
              },
              {
                "id": 6619,
                "faiss_score": 0.9016984105110168,
                "faiss_rank": 3,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 22,
                "sentence": "In distributed systems, it is often impossible to distinguish between a failed component and a slow or unreachable one.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0018577711889520288,
                  "neutral": 0.8090157508850098,
                  "support": 0.18912647664546967
                },
                "stance_score": 0.18726870545651764,
                "evidence_contribution": 0.16885989404859775,
                "combined_rank_score": 0.9016984105110168
              }
            ],
            "contradicting": [
              {
                "id": 5662,
                "faiss_score": 0.9012587070465088,
                "faiss_rank": 4,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 65,
                "sentence": "Distributed systems research emphasizes the importance of understanding failure modes.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.10966315865516663,
                  "neutral": 0.8834505081176758,
                  "support": 0.006886407732963562
                },
                "stance_score": -0.10277675092220306,
                "evidence_contribution": -0.09262844165058581,
                "combined_rank_score": 0.9012587070465088
              }
            ],
            "neutral": [
              {
                "id": 5634,
                "faiss_score": 0.9050875306129456,
                "faiss_rank": 2,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "State management is particularly challenging in distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.012132744304835796,
                  "neutral": 0.9328728318214417,
                  "support": 0.05499438941478729
                },
                "stance_score": 0.042861645109951496,
                "evidence_contribution": 0.03879354053057443,
                "combined_rank_score": 0.9050875306129456
              },
              {
                "id": 5643,
                "faiss_score": 0.8992247581481934,
                "faiss_rank": 5,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 46,
                "sentence": "Understanding the behavior of a distributed system requires monitoring, logging, and tracing across multiple components.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.010863753966987133,
                  "neutral": 0.9625633955001831,
                  "support": 0.026572827249765396
                },
                "stance_score": 0.015709073282778263,
                "evidence_contribution": 0.01412598762343853,
                "combined_rank_score": 0.8992247581481934
              },
              {
                "id": 5605,
                "faiss_score": 0.8966373205184937,
                "faiss_rank": 6,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Failures are another fundamental aspect of distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0024339277297258377,
                  "neutral": 0.9677716493606567,
                  "support": 0.02979445643723011
                },
                "stance_score": 0.027360528707504272,
                "evidence_contribution": 0.024532471148265955,
                "combined_rank_score": 0.8966373205184937
              }
            ]
          }
        },
        {
          "subclaim": "Distributed systems introduce increased system complexity",
          "verdict": "SUPPORT",
          "controversial": true,
          "strengths": {
            "support": 1.6135396137421751,
            "contradict": 0.7403272035763246,
            "total": 2.3538668173185
          },
          "evidence": {
            "supporting": [
              {
                "id": 6234,
                "faiss_score": 0.8932847380638123,
                "faiss_rank": 12,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Distributed training introduces additional complexity into training dynamics.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001261566998437047,
                  "neutral": 0.04580743610858917,
                  "support": 0.9529309272766113
                },
                "stance_score": 0.9516693602781743,
                "evidence_contribution": 0.8501117152194447,
                "combined_rank_score": 0.8932847380638123
              },
              {
                "id": 5716,
                "faiss_score": 0.9051175117492676,
                "faiss_rank": 3,
                "doc_id": "local_math_computation_limits.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Communication complexity highlights situations where computation is distributed across multiple parties or components.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005169692449271679,
                  "neutral": 0.3870173990726471,
                  "support": 0.6078130006790161
                },
                "stance_score": 0.6026433082297444,
                "evidence_contribution": 0.5454630116172532,
                "combined_rank_score": 0.9051175117492676
              },
              {
                "id": 5674,
                "faiss_score": 0.9300456047058105,
                "faiss_rank": 1,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 77,
                "sentence": "Distributed systems exemplify the broader theme that complexity emerges from interaction.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.07227763533592224,
                  "neutral": 0.6210853457450867,
                  "support": 0.3066369891166687
                },
                "stance_score": 0.23435935378074646,
                "evidence_contribution": 0.21796488690547733,
                "combined_rank_score": 0.9300456047058105
              }
            ],
            "contradicting": [
              {
                "id": 499,
                "faiss_score": 0.8980528116226196,
                "faiss_rank": 5,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.8274977803230286,
                  "neutral": 0.16937381029129028,
                  "support": 0.0031284403521567583
                },
                "stance_score": -0.8243693399708718,
                "evidence_contribution": -0.7403272035763246,
                "combined_rank_score": 0.8980528116226196
              }
            ],
            "neutral": [
              {
                "id": 5650,
                "faiss_score": 0.9097122550010681,
                "faiss_rank": 2,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Distributed systems also intersect with security concerns.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005453850608319044,
                  "neutral": 0.9848649501800537,
                  "support": 0.009681235998868942
                },
                "stance_score": 0.004227385390549898,
                "evidence_contribution": 0.003845704296395719,
                "combined_rank_score": 0.9097122550010681
              },
              {
                "id": 5671,
                "faiss_score": 0.9003279209136963,
                "faiss_rank": 4,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 74,
                "sentence": "Ultimately, distributed systems are defined by trade-offs.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.010508965700864792,
                  "neutral": 0.9802647829055786,
                  "support": 0.009226307272911072
                },
                "stance_score": -0.00128265842795372,
                "evidence_contribution": -0.001154813195682003,
                "combined_rank_score": 0.9003279209136963
              },
              {
                "id": 433,
                "faiss_score": 0.8980212211608887,
                "faiss_rank": 8,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 9,
                "sentence": "The system may change during the execution of a distributed program.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "probs": {
                  "contradict": 0.00575619749724865,
                  "neutral": 0.9842450022697449,
                  "support": 0.009998817928135395
                },
                "stance_score": 0.0042426204308867455,
                "evidence_contribution": 0.003809963180267051,
                "combined_rank_score": 0.8980212211608887
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Distributed systems improve availability",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 498,
                      "faiss_score": 0.907902717590332,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 74,
                      "sentence": "It can provide more reliability than a non-distributed system, as there is no single point of failure.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.006190187763422728,
                        "neutral": 0.6528412699699402,
                        "support": 0.34096860885620117
                      },
                      "stance_score": 0.33477842109277844,
                      "evidence_contribution": 0.3039462383007341,
                      "combined_rank_score": 0.907902717590332
                    },
                    {
                      "id": 5614,
                      "faiss_score": 0.9020341634750366,
                      "faiss_rank": 9,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 17,
                      "sentence": "Replication is commonly used to improve fault tolerance and availability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001992239151149988,
                        "neutral": 0.6123042702674866,
                        "support": 0.3857034146785736
                      },
                      "stance_score": 0.3837111755274236,
                      "evidence_contribution": 0.3461205892329025,
                      "combined_rank_score": 0.9020341634750366
                    },
                    {
                      "id": 3817,
                      "faiss_score": 0.8974882364273071,
                      "faiss_rank": 11,
                      "doc_id": "wiki_CAP_theorem",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Most modern distributed databases offer configuration options for both consistency and availability.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/CAP_theorem",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.00218738685362041,
                        "neutral": 0.6701467633247375,
                        "support": 0.3276658058166504
                      },
                      "stance_score": 0.32547841896303,
                      "evidence_contribution": 0.29211305223027795,
                      "combined_rank_score": 0.8974882364273071
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5605,
                      "faiss_score": 0.9042737483978271,
                      "faiss_rank": 8,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Failures are another fundamental aspect of distributed systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.2072419673204422,
                        "neutral": 0.7761302590370178,
                        "support": 0.016627848148345947
                      },
                      "stance_score": -0.19061411917209625,
                      "evidence_contribution": -0.1723673440413016,
                      "combined_rank_score": 0.9042737483978271
                    },
                    {
                      "id": 5650,
                      "faiss_score": 0.9007853269577026,
                      "faiss_rank": 10,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "Distributed systems also intersect with security concerns.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.16322025656700134,
                        "neutral": 0.8324757218360901,
                        "support": 0.004304082132875919
                      },
                      "stance_score": -0.15891617443412542,
                      "evidence_contribution": -0.14314935814651097,
                      "combined_rank_score": 0.9007853269577026
                    }
                  ],
                  "neutral": [
                    {
                      "id": 430,
                      "faiss_score": 0.9117620587348938,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 6,
                      "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.0023098234087228775,
                        "neutral": 0.9925360679626465,
                        "support": 0.005154070444405079
                      },
                      "stance_score": 0.0028442470356822014,
                      "evidence_contribution": 0.002593276532804223,
                      "combined_rank_score": 0.9117620587348938
                    },
                    {
                      "id": 5662,
                      "faiss_score": 0.9096964597702026,
                      "faiss_rank": 4,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 65,
                      "sentence": "Distributed systems research emphasizes the importance of understanding failure modes.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0033991688396781683,
                        "neutral": 0.9939257502555847,
                        "support": 0.0026750725228339434
                      },
                      "stance_score": -0.0007240963168442249,
                      "evidence_contribution": -0.0006587078559658344,
                      "combined_rank_score": 0.9096964597702026
                    },
                    {
                      "id": 5646,
                      "faiss_score": 0.8958644270896912,
                      "faiss_rank": 13,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 49,
                      "sentence": "The evolution of distributed systems has been driven by practical needs.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0006776307127438486,
                        "neutral": 0.9960979223251343,
                        "support": 0.003224448300898075
                      },
                      "stance_score": 0.0025468175881542265,
                      "evidence_contribution": 0.002281603279513735,
                      "combined_rank_score": 0.8958644270896912
                    }
                  ]
                }
              },
              {
                "subclaim": "Distributed systems introduce coordination overhead",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6685,
                      "faiss_score": 0.9233837127685547,
                      "faiss_rank": 1,
                      "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                      "file_type": ".txt",
                      "position": 17,
                      "sentence": "However, parallelism introduces coordination overhead, synchronization costs, and contention for shared resources.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0018082939786836505,
                        "neutral": 0.06981738656759262,
                        "support": 0.9283743500709534
                      },
                      "stance_score": 0.9265660560922697,
                      "evidence_contribution": 0.8555760049997969,
                      "combined_rank_score": 0.9233837127685547
                    },
                    {
                      "id": 5633,
                      "faiss_score": 0.9139895439147949,
                      "faiss_rank": 5,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 36,
                      "sentence": "However, scaling introduces coordination overhead that can limit achievable gains.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.006788631435483694,
                        "neutral": 0.2813877463340759,
                        "support": 0.7118236422538757
                      },
                      "stance_score": 0.705035010818392,
                      "evidence_contribution": 0.6443946279818646,
                      "combined_rank_score": 0.9139895439147949
                    },
                    {
                      "id": 6490,
                      "faiss_score": 0.9123440384864807,
                      "faiss_rank": 9,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 19,
                      "sentence": "Not all problems benefit equally from parallelism, and coordination overhead can limit gains.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0024735191836953163,
                        "neutral": 0.6057115197181702,
                        "support": 0.3918149769306183
                      },
                      "stance_score": 0.38934145774692297,
                      "evidence_contribution": 0.3552133579110412,
                      "combined_rank_score": 0.9123440384864807
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6684,
                      "faiss_score": 0.8900929689407349,
                      "faiss_rank": 16,
                      "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                      "file_type": ".txt",
                      "position": 16,
                      "sentence": "By distributing work across multiple processors or machines, systems can handle more requests concurrently.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.5222463011741638,
                        "neutral": 0.4712420403957367,
                        "support": 0.0065116542391479015
                      },
                      "stance_score": -0.5157346469350159,
                      "evidence_contribution": -0.45905178307599,
                      "combined_rank_score": 0.8900929689407349
                    }
                  ],
                  "neutral": [
                    {
                      "id": 585,
                      "faiss_score": 0.9145564436912537,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 161,
                      "sentence": "In order to perform coordination, distributed systems employ the concept of coordinators.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.21808390319347382,
                        "neutral": 0.6171427369117737,
                        "support": 0.1647733598947525
                      },
                      "stance_score": -0.053310543298721313,
                      "evidence_contribution": -0.04875550089052716,
                      "combined_rank_score": 0.9145564436912537
                    },
                    {
                      "id": 542,
                      "faiss_score": 0.9130808115005493,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 118,
                      "sentence": "The main focus is on coordinating the operation of an arbitrary distributed system.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.007331767585128546,
                        "neutral": 0.9015898108482361,
                        "support": 0.09107837826013565
                      },
                      "stance_score": 0.0837466106750071,
                      "evidence_contribution": 0.07646742323555605,
                      "combined_rank_score": 0.9130808115005493
                    },
                    {
                      "id": 5597,
                      "faiss_score": 0.8991247415542603,
                      "faiss_rank": 11,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Distributed systems are collections of independent computing components that coordinate their actions through communication in order to achieve a common goal.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.07815498858690262,
                        "neutral": 0.9142075777053833,
                        "support": 0.007637408562004566
                      },
                      "stance_score": -0.07051758002489805,
                      "evidence_contribution": -0.06340410091491833,
                      "combined_rank_score": 0.8991247415542603
                    }
                  ]
                }
              },
              {
                "subclaim": "Distributed systems introduce consistency challenges",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5612,
                      "faiss_score": 0.9273715019226074,
                      "faiss_rank": 2,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 15,
                      "sentence": "Strong consistency models aim to make distributed systems behave as if there were a single shared state, but enforcing such behavior requires coordination and synchronization, which can be expensive or impossible under certain failure conditions.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0031162735540419817,
                        "neutral": 0.731314480304718,
                        "support": 0.2655692398548126
                      },
                      "stance_score": 0.26245296630077064,
                      "evidence_contribution": 0.24339140154238914,
                      "combined_rank_score": 0.9273715019226074
                    },
                    {
                      "id": 5634,
                      "faiss_score": 0.907062292098999,
                      "faiss_rank": 3,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 37,
                      "sentence": "State management is particularly challenging in distributed systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0030246321111917496,
                        "neutral": 0.7135766744613647,
                        "support": 0.28339874744415283
                      },
                      "stance_score": 0.2803741153329611,
                      "evidence_contribution": 0.2543167876991448,
                      "combined_rank_score": 0.907062292098999
                    },
                    {
                      "id": 5618,
                      "faiss_score": 0.8958674669265747,
                      "faiss_rank": 11,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "Consensus is a fundamental problem in distributed systems that captures the difficulty of agreement in the presence of failures.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0027271497529000044,
                        "neutral": 0.3254675567150116,
                        "support": 0.6718052625656128
                      },
                      "stance_score": 0.6690781128127128,
                      "evidence_contribution": 0.599405314101538,
                      "combined_rank_score": 0.8958674669265747
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5610,
                      "faiss_score": 0.9464955925941467,
                      "faiss_rank": 1,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Consistency is a central concept in distributed systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.2551124393939972,
                        "neutral": 0.7050133943557739,
                        "support": 0.03987419977784157
                      },
                      "stance_score": -0.21523823961615562,
                      "evidence_contribution": -0.20372204515441417,
                      "combined_rank_score": 0.9464955925941467
                    },
                    {
                      "id": 3817,
                      "faiss_score": 0.8984368443489075,
                      "faiss_rank": 10,
                      "doc_id": "wiki_CAP_theorem",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Most modern distributed databases offer configuration options for both consistency and availability.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/CAP_theorem",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.3348703682422638,
                        "neutral": 0.6467505693435669,
                        "support": 0.01837906427681446
                      },
                      "stance_score": -0.31649130396544933,
                      "evidence_contribution": -0.28434744839858916,
                      "combined_rank_score": 0.8984368443489075
                    },
                    {
                      "id": 5658,
                      "faiss_score": 0.8944575190544128,
                      "faiss_rank": 12,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 61,
                      "sentence": "Eventually consistent systems illustrate how relaxing guarantees can improve scalability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.4701039791107178,
                        "neutral": 0.5211150050163269,
                        "support": 0.00878104753792286
                      },
                      "stance_score": -0.4613229315727949,
                      "evidence_contribution": -0.4126337648575108,
                      "combined_rank_score": 0.8944575190544128
                    }
                  ],
                  "neutral": [
                    {
                      "id": 568,
                      "faiss_score": 0.9033069610595703,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 144,
                      "sentence": "There are also fundamental challenges that are unique to distributed computing, for example those related to fault-tolerance.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.006213893182575703,
                        "neutral": 0.8884377479553223,
                        "support": 0.10534839332103729
                      },
                      "stance_score": 0.09913450013846159,
                      "evidence_contribution": 0.08954888405623329,
                      "combined_rank_score": 0.9033069610595703
                    },
                    {
                      "id": 5650,
                      "faiss_score": 0.9012532830238342,
                      "faiss_rank": 7,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "Distributed systems also intersect with security concerns.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.045700471848249435,
                        "neutral": 0.8426495790481567,
                        "support": 0.11164990812540054
                      },
                      "stance_score": 0.06594943627715111,
                      "evidence_contribution": 0.05943714595835359,
                      "combined_rank_score": 0.9012532830238342
                    },
                    {
                      "id": 6616,
                      "faiss_score": 0.9006686806678772,
                      "faiss_rank": 8,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 19,
                      "sentence": "Strong consistency simplifies reasoning but requires coordination that may reduce availability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.011836410500109196,
                        "neutral": 0.96406489610672,
                        "support": 0.02409866265952587
                      },
                      "stance_score": 0.012262252159416676,
                      "evidence_contribution": 0.011044226474438645,
                      "combined_rank_score": 0.9006686806678772
                    }
                  ]
                }
              },
              {
                "subclaim": "Distributed systems introduce debugging difficulty",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5644,
                      "faiss_score": 0.9589457511901855,
                      "faiss_rank": 1,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 47,
                      "sentence": "Because failures and performance issues may arise from interactions between components, debugging distributed systems is notoriously difficult.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0014179548015818,
                        "neutral": 0.06682299822568893,
                        "support": 0.9317590594291687
                      },
                      "stance_score": 0.9303411046275869,
                      "evidence_contribution": 0.8921466494402084,
                      "combined_rank_score": 0.9589457511901855
                    },
                    {
                      "id": 6619,
                      "faiss_score": 0.9016984105110168,
                      "faiss_rank": 3,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 22,
                      "sentence": "In distributed systems, it is often impossible to distinguish between a failed component and a slow or unreachable one.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0018577711889520288,
                        "neutral": 0.8090157508850098,
                        "support": 0.18912647664546967
                      },
                      "stance_score": 0.18726870545651764,
                      "evidence_contribution": 0.16885989404859775,
                      "combined_rank_score": 0.9016984105110168
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5662,
                      "faiss_score": 0.9012587070465088,
                      "faiss_rank": 4,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 65,
                      "sentence": "Distributed systems research emphasizes the importance of understanding failure modes.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.10966315865516663,
                        "neutral": 0.8834505081176758,
                        "support": 0.006886407732963562
                      },
                      "stance_score": -0.10277675092220306,
                      "evidence_contribution": -0.09262844165058581,
                      "combined_rank_score": 0.9012587070465088
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5634,
                      "faiss_score": 0.9050875306129456,
                      "faiss_rank": 2,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 37,
                      "sentence": "State management is particularly challenging in distributed systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.012132744304835796,
                        "neutral": 0.9328728318214417,
                        "support": 0.05499438941478729
                      },
                      "stance_score": 0.042861645109951496,
                      "evidence_contribution": 0.03879354053057443,
                      "combined_rank_score": 0.9050875306129456
                    },
                    {
                      "id": 5643,
                      "faiss_score": 0.8992247581481934,
                      "faiss_rank": 5,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 46,
                      "sentence": "Understanding the behavior of a distributed system requires monitoring, logging, and tracing across multiple components.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.010863753966987133,
                        "neutral": 0.9625633955001831,
                        "support": 0.026572827249765396
                      },
                      "stance_score": 0.015709073282778263,
                      "evidence_contribution": 0.01412598762343853,
                      "combined_rank_score": 0.8992247581481934
                    },
                    {
                      "id": 5605,
                      "faiss_score": 0.8966373205184937,
                      "faiss_rank": 6,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Failures are another fundamental aspect of distributed systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0024339277297258377,
                        "neutral": 0.9677716493606567,
                        "support": 0.02979445643723011
                      },
                      "stance_score": 0.027360528707504272,
                      "evidence_contribution": 0.024532471148265955,
                      "combined_rank_score": 0.8966373205184937
                    }
                  ]
                }
              },
              {
                "subclaim": "Distributed systems introduce increased system complexity",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5674,
                      "faiss_score": 0.9300456047058105,
                      "faiss_rank": 1,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 77,
                      "sentence": "Distributed systems exemplify the broader theme that complexity emerges from interaction.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.07227763533592224,
                        "neutral": 0.6210853457450867,
                        "support": 0.3066369891166687
                      },
                      "stance_score": 0.23435935378074646,
                      "evidence_contribution": 0.21796488690547733,
                      "combined_rank_score": 0.9300456047058105
                    },
                    {
                      "id": 5716,
                      "faiss_score": 0.9051175117492676,
                      "faiss_rank": 3,
                      "doc_id": "local_math_computation_limits.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "Communication complexity highlights situations where computation is distributed across multiple parties or components.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005169692449271679,
                        "neutral": 0.3870173990726471,
                        "support": 0.6078130006790161
                      },
                      "stance_score": 0.6026433082297444,
                      "evidence_contribution": 0.5454630116172532,
                      "combined_rank_score": 0.9051175117492676
                    },
                    {
                      "id": 6234,
                      "faiss_score": 0.8932847380638123,
                      "faiss_rank": 12,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Distributed training introduces additional complexity into training dynamics.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001261566998437047,
                        "neutral": 0.04580743610858917,
                        "support": 0.9529309272766113
                      },
                      "stance_score": 0.9516693602781743,
                      "evidence_contribution": 0.8501117152194447,
                      "combined_rank_score": 0.8932847380638123
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 499,
                      "faiss_score": 0.8980528116226196,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.8274977803230286,
                        "neutral": 0.16937381029129028,
                        "support": 0.0031284403521567583
                      },
                      "stance_score": -0.8243693399708718,
                      "evidence_contribution": -0.7403272035763246,
                      "combined_rank_score": 0.8980528116226196
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5650,
                      "faiss_score": 0.9097122550010681,
                      "faiss_rank": 2,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "Distributed systems also intersect with security concerns.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005453850608319044,
                        "neutral": 0.9848649501800537,
                        "support": 0.009681235998868942
                      },
                      "stance_score": 0.004227385390549898,
                      "evidence_contribution": 0.003845704296395719,
                      "combined_rank_score": 0.9097122550010681
                    },
                    {
                      "id": 5671,
                      "faiss_score": 0.9003279209136963,
                      "faiss_rank": 4,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 74,
                      "sentence": "Ultimately, distributed systems are defined by trade-offs.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.010508965700864792,
                        "neutral": 0.9802647829055786,
                        "support": 0.009226307272911072
                      },
                      "stance_score": -0.00128265842795372,
                      "evidence_contribution": -0.001154813195682003,
                      "combined_rank_score": 0.9003279209136963
                    },
                    {
                      "id": 433,
                      "faiss_score": 0.8980212211608887,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "The system may change during the execution of a distributed program.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.00575619749724865,
                        "neutral": 0.9842450022697449,
                        "support": 0.009998817928135395
                      },
                      "stance_score": 0.0042426204308867455,
                      "evidence_contribution": 0.003809963180267051,
                      "combined_rank_score": 0.8980212211608887
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Distributed systems improve scalability",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6684,
                      "faiss_score": 0.9061692357063293,
                      "faiss_rank": 3,
                      "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                      "file_type": ".txt",
                      "position": 16,
                      "sentence": "By distributing work across multiple processors or machines, systems can handle more requests concurrently.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0014126799069344997,
                        "neutral": 0.6332381963729858,
                        "support": 0.3653491139411926
                      },
                      "stance_score": 0.3639364340342581,
                      "evidence_contribution": 0.3297880002745106,
                      "combined_rank_score": 0.9061692357063293
                    },
                    {
                      "id": 499,
                      "faiss_score": 0.9017831683158875,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.0015425255987793207,
                        "neutral": 0.4211810231208801,
                        "support": 0.5772764086723328
                      },
                      "stance_score": 0.5757338830735534,
                      "evidence_contribution": 0.5191871251848778,
                      "combined_rank_score": 0.9017831683158875
                    },
                    {
                      "id": 502,
                      "faiss_score": 0.895154595375061,
                      "faiss_rank": 13,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 78,
                      "sentence": "Subsequently, Reactive systems are more flexible, loosely-coupled and scalable.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.009046770632266998,
                        "neutral": 0.5073032379150391,
                        "support": 0.48364999890327454
                      },
                      "stance_score": 0.47460322827100754,
                      "evidence_contribution": 0.4248432607666315,
                      "combined_rank_score": 0.895154595375061
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5658,
                      "faiss_score": 0.9028811454772949,
                      "faiss_rank": 9,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 61,
                      "sentence": "Eventually consistent systems illustrate how relaxing guarantees can improve scalability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.8435043692588806,
                        "neutral": 0.10410597920417786,
                        "support": 0.052389614284038544
                      },
                      "stance_score": -0.7911147549748421,
                      "evidence_contribution": -0.7142825961756749,
                      "combined_rank_score": 0.9028811454772949
                    }
                  ],
                  "neutral": [
                    {
                      "id": 759,
                      "faiss_score": 0.9175848364830017,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 163,
                      "sentence": "Meeting this scalability condition is possible for a wide range of systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.0008614318794570863,
                        "neutral": 0.9977839589118958,
                        "support": 0.0013546152040362358
                      },
                      "stance_score": 0.0004931833245791495,
                      "evidence_contribution": 0.00045253754024010204,
                      "combined_rank_score": 0.9175848364830017
                    },
                    {
                      "id": 445,
                      "faiss_score": 0.9056973457336426,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "Distributed systems are groups of networked computers which share a common goal for their work.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.000767619232647121,
                        "neutral": 0.9977124929428101,
                        "support": 0.001519894110970199
                      },
                      "stance_score": 0.0007522748783230782,
                      "evidence_contribution": 0.0006813333605593108,
                      "combined_rank_score": 0.9056973457336426
                    },
                    {
                      "id": 5646,
                      "faiss_score": 0.9050657749176025,
                      "faiss_rank": 7,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 49,
                      "sentence": "The evolution of distributed systems has been driven by practical needs.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0006361278356052935,
                        "neutral": 0.9965994954109192,
                        "support": 0.002764445496723056
                      },
                      "stance_score": 0.0021283176611177623,
                      "evidence_contribution": 0.001926267473230367,
                      "combined_rank_score": 0.9050657749176025
                    }
                  ]
                }
              },
              {
                "subclaim": "Distributed systems improve fault tolerance",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5614,
                      "faiss_score": 0.9063659906387329,
                      "faiss_rank": 8,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 17,
                      "sentence": "Replication is commonly used to improve fault tolerance and availability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0022014533169567585,
                        "neutral": 0.5738668441772461,
                        "support": 0.42393165826797485
                      },
                      "stance_score": 0.4217302049510181,
                      "evidence_contribution": 0.3822419149927054,
                      "combined_rank_score": 0.9063659906387329
                    },
                    {
                      "id": 498,
                      "faiss_score": 0.8959221243858337,
                      "faiss_rank": 13,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 74,
                      "sentence": "It can provide more reliability than a non-distributed system, as there is no single point of failure.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.003871267195791006,
                        "neutral": 0.5383682250976562,
                        "support": 0.4577604830265045
                      },
                      "stance_score": 0.4538892158307135,
                      "evidence_contribution": 0.4066493904828731,
                      "combined_rank_score": 0.8959221243858337
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5605,
                      "faiss_score": 0.9076846241950989,
                      "faiss_rank": 6,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Failures are another fundamental aspect of distributed systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.11820482462644577,
                        "neutral": 0.8654248714447021,
                        "support": 0.016370385885238647
                      },
                      "stance_score": -0.10183443874120712,
                      "evidence_contribution": -0.0924335542589314,
                      "combined_rank_score": 0.9076846241950989
                    },
                    {
                      "id": 568,
                      "faiss_score": 0.9054936170578003,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 144,
                      "sentence": "There are also fundamental challenges that are unique to distributed computing, for example those related to fault-tolerance.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.38152015209198,
                        "neutral": 0.6146324276924133,
                        "support": 0.0038474525790661573
                      },
                      "stance_score": -0.3776726995129138,
                      "evidence_contribution": -0.3419802187459321,
                      "combined_rank_score": 0.9054936170578003
                    }
                  ],
                  "neutral": [
                    {
                      "id": 430,
                      "faiss_score": 0.9204719066619873,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 6,
                      "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "probs": {
                        "contradict": 0.00475419033318758,
                        "neutral": 0.9388123750686646,
                        "support": 0.056433361023664474
                      },
                      "stance_score": 0.051679170690476894,
                      "evidence_contribution": 0.04756922478017356,
                      "combined_rank_score": 0.9204719066619873
                    },
                    {
                      "id": 3457,
                      "faiss_score": 0.9127100706100464,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 28,
                      "sentence": "Fault tolerance is notably successful in computer applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.0009182387148030102,
                        "neutral": 0.9978187084197998,
                        "support": 0.0012630720157176256
                      },
                      "stance_score": 0.0003448333009146154,
                      "evidence_contribution": 0.000314732826426474,
                      "combined_rank_score": 0.9127100706100464
                    },
                    {
                      "id": 5662,
                      "faiss_score": 0.9125458002090454,
                      "faiss_rank": 5,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 65,
                      "sentence": "Distributed systems research emphasizes the importance of understanding failure modes.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.00217837025411427,
                        "neutral": 0.9940716624259949,
                        "support": 0.0037499666213989258
                      },
                      "stance_score": 0.0015715963672846556,
                      "evidence_contribution": 0.0014341536645894049,
                      "combined_rank_score": 0.9125458002090454
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Increasing dataset size improves model generalization, training stability, and robustness, but data collection is expensive, labeling is costly, noisy data degrades performance, and returns diminish beyond scale.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Increasing dataset size improves model generalization",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.2774210788280074,
            "contradict": 5.238488045822087,
            "total": 5.515909124650094
          },
          "evidence": {
            "supporting": [
              {
                "id": 6132,
                "faiss_score": 0.9014256596565247,
                "faiss_rank": 7,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Larger models have greater representational capacity, allowing them to fit more complex functions.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0038138218224048615,
                  "neutral": 0.6846141815185547,
                  "support": 0.31157195568084717
                },
                "stance_score": 0.3077581338584423,
                "evidence_contribution": 0.2774210788280074,
                "combined_rank_score": 0.9014256596565247
              }
            ],
            "contradicting": [
              {
                "id": 6213,
                "faiss_score": 0.8910093903541565,
                "faiss_rank": 12,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Large batches provide more accurate gradient estimates and better hardware utilization but can lead to sharp minima or reduced generalization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9904155731201172,
                  "neutral": 0.00799955241382122,
                  "support": 0.0015847948379814625
                },
                "stance_score": -0.9888307782821357,
                "evidence_contribution": -0.8810575089205919,
                "combined_rank_score": 0.8910093903541565
              },
              {
                "id": 6136,
                "faiss_score": 0.8861839175224304,
                "faiss_rank": 18,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.961361825466156,
                  "neutral": 0.03537741303443909,
                  "support": 0.0032607282046228647
                },
                "stance_score": -0.9581010972615331,
                "evidence_contribution": -0.8490537837537646,
                "combined_rank_score": 0.8861839175224304
              },
              {
                "id": 5941,
                "faiss_score": 0.905327558517456,
                "faiss_rank": 5,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 36,
                "sentence": "Smaller or compressed models may generalize better due to implicit regularization, but excessive compression can harm performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8726226687431335,
                  "neutral": 0.12322617322206497,
                  "support": 0.00415118969976902
                },
                "stance_score": -0.8684714790433645,
                "evidence_contribution": -0.7862511637643732,
                "combined_rank_score": 0.905327558517456
              },
              {
                "id": 5932,
                "faiss_score": 0.8860794901847839,
                "faiss_rank": 19,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Memory efficiency during training is a limiting factor for large models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.729663074016571,
                  "neutral": 0.26573440432548523,
                  "support": 0.0046024867333471775
                },
                "stance_score": -0.7250605872832239,
                "evidence_contribution": -0.642461315532999,
                "combined_rank_score": 0.8860794901847839
              },
              {
                "id": 6134,
                "faiss_score": 0.8899642825126648,
                "faiss_rank": 14,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 10,
                "sentence": "Large models are also more sensitive to optimization choices and require careful tuning to train effectively.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6757612228393555,
                  "neutral": 0.3165827989578247,
                  "support": 0.007656015921384096
                },
                "stance_score": -0.6681052069179714,
                "evidence_contribution": -0.5945897711177278,
                "combined_rank_score": 0.8899642825126648
              },
              {
                "id": 6086,
                "faiss_score": 0.8908407688140869,
                "faiss_rank": 13,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 46,
                "sentence": "This process involves updating model parameters using a smaller, task-specific dataset.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6685400605201721,
                  "neutral": 0.328482449054718,
                  "support": 0.002977431518957019
                },
                "stance_score": -0.6655626290012151,
                "evidence_contribution": -0.5929103241133673,
                "combined_rank_score": 0.8908407688140869
              },
              {
                "id": 6046,
                "faiss_score": 0.8923694491386414,
                "faiss_rank": 11,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 6,
                "sentence": "These include improved generalization, better handling of rare or ambiguous inputs, and the ability to adapt to new tasks with minimal additional data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5339111685752869,
                  "neutral": 0.46064701676368713,
                  "support": 0.005441853776574135
                },
                "stance_score": -0.5284693147987127,
                "evidence_contribution": -0.47158987133360253,
                "combined_rank_score": 0.8923694491386414
              },
              {
                "id": 1453,
                "faiss_score": 0.911958634853363,
                "faiss_rank": 3,
                "doc_id": "wiki_Regularization_(mathematics)",
                "file_type": ".txt",
                "position": 25,
                "sentence": "By regularizing for time, model complexity can be controlled, improving generalization.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Regularization_(mathematics)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.48357275128364563,
                  "neutral": 0.49403151869773865,
                  "support": 0.022395795211195946
                },
                "stance_score": -0.4611769560724497,
                "evidence_contribution": -0.4205743072856606,
                "combined_rank_score": 0.911958634853363
              }
            ],
            "neutral": [
              {
                "id": 6137,
                "faiss_score": 0.9258404970169067,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001429139287211001,
                  "neutral": 0.9253905415534973,
                  "support": 0.07318033277988434
                },
                "stance_score": 0.07175119349267334,
                "evidence_contribution": 0.06643016064481293,
                "combined_rank_score": 0.9258404970169067
              },
              {
                "id": 6211,
                "faiss_score": 0.9146623611450195,
                "faiss_rank": 2,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 19,
                "sentence": "Batch size influences both optimization efficiency and generalization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005423132795840502,
                  "neutral": 0.9795346260070801,
                  "support": 0.015042271465063095
                },
                "stance_score": 0.009619138669222593,
                "evidence_contribution": 0.008798264087372498,
                "combined_rank_score": 0.9146623611450195
              },
              {
                "id": 5728,
                "faiss_score": 0.9091782569885254,
                "faiss_rank": 4,
                "doc_id": "local_math_computation_limits.txt",
                "file_type": ".txt",
                "position": 51,
                "sentence": "Bounds on generalization depend on factors such as model capacity and data distribution.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.08435701578855515,
                  "neutral": 0.9136447310447693,
                  "support": 0.0019982256926596165
                },
                "stance_score": -0.08235879009589553,
                "evidence_contribution": -0.07487882122707012,
                "combined_rank_score": 0.9091782569885254
              }
            ]
          }
        },
        {
          "subclaim": "Increasing dataset size improves training stability",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.6179428676291886,
            "contradict": 4.554084194184546,
            "total": 5.1720270618137345
          },
          "evidence": {
            "supporting": [
              {
                "id": 2613,
                "faiss_score": 0.8831011056900024,
                "faiss_rank": 10,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 208,
                "sentence": "Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.004449686035513878,
                  "neutral": 0.5582360029220581,
                  "support": 0.43731430172920227
                },
                "stance_score": 0.4328646156936884,
                "evidence_contribution": 0.3822632207331742,
                "combined_rank_score": 0.8831011056900024
              },
              {
                "id": 1416,
                "faiss_score": 0.8797472715377808,
                "faiss_rank": 18,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 66,
                "sentence": "Increase the amount of training data: If the model is underfitting due to a lack of data, increasing the amount of training data may help.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0035214696545153856,
                  "neutral": 0.7250623106956482,
                  "support": 0.27141618728637695
                },
                "stance_score": 0.26789471763186157,
                "evidence_contribution": 0.23567964689601442,
                "combined_rank_score": 0.8797472715377808
              }
            ],
            "contradicting": [
              {
                "id": 6136,
                "faiss_score": 0.8894740343093872,
                "faiss_rank": 7,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9451566338539124,
                  "neutral": 0.05112721771001816,
                  "support": 0.003716180333867669
                },
                "stance_score": -0.9414404535200447,
                "evidence_contribution": -0.8373868382545333,
                "combined_rank_score": 0.8894740343093872
              },
              {
                "id": 6308,
                "faiss_score": 0.8807340860366821,
                "faiss_rank": 14,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Another challenge associated with transformers is their reliance on large datasets for effective training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7971049547195435,
                  "neutral": 0.1963687241077423,
                  "support": 0.0065263123251497746
                },
                "stance_score": -0.7905786423943937,
                "evidence_contribution": -0.6962895580493473,
                "combined_rank_score": 0.8807340860366821
              },
              {
                "id": 6349,
                "faiss_score": 0.8789517879486084,
                "faiss_rank": 19,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 88,
                "sentence": "As models scale, training efficiency becomes a primary concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7748454809188843,
                  "neutral": 0.20444639027118683,
                  "support": 0.020708171650767326
                },
                "stance_score": -0.754137309268117,
                "evidence_contribution": -0.662850336339964,
                "combined_rank_score": 0.8789517879486084
              },
              {
                "id": 6133,
                "faiss_score": 0.8990232944488525,
                "faiss_rank": 3,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7590318322181702,
                  "neutral": 0.217951238155365,
                  "support": 0.023016992956399918
                },
                "stance_score": -0.7360148392617702,
                "evidence_contribution": -0.6616944855563593,
                "combined_rank_score": 0.8990232944488525
              },
              {
                "id": 5932,
                "faiss_score": 0.8946778774261475,
                "faiss_rank": 4,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Memory efficiency during training is a limiting factor for large models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6858248710632324,
                  "neutral": 0.31039711833000183,
                  "support": 0.0037779605481773615
                },
                "stance_score": -0.6820469105150551,
                "evidence_contribution": -0.6102122822046709,
                "combined_rank_score": 0.8946778774261475
              },
              {
                "id": 1785,
                "faiss_score": 0.8818594813346863,
                "faiss_rank": 12,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Cleaned datasets can increase training efficiency and lead to improved downstream performance.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.4319572150707245,
                  "neutral": 0.5465472936630249,
                  "support": 0.021495435386896133
                },
                "stance_score": -0.41046177968382835,
                "evidence_contribution": -0.36196961213969314,
                "combined_rank_score": 0.8818594813346863
              },
              {
                "id": 6213,
                "faiss_score": 0.8780714273452759,
                "faiss_rank": 20,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Large batches provide more accurate gradient estimates and better hardware utilization but can lead to sharp minima or reduced generalization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.375297486782074,
                  "neutral": 0.6011395454406738,
                  "support": 0.023562930524349213
                },
                "stance_score": -0.35173455625772476,
                "evidence_contribution": -0.3088480638598776,
                "combined_rank_score": 0.8780714273452759
              },
              {
                "id": 5906,
                "faiss_score": 0.8880614638328552,
                "faiss_rank": 8,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Early successes in deep learning were often achieved by increasing model size and training data, but this approach quickly encounters practical limits.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3397914171218872,
                  "neutral": 0.648522138595581,
                  "support": 0.01168638002127409
                },
                "stance_score": -0.3281050371006131,
                "evidence_contribution": -0.29137743953850376,
                "combined_rank_score": 0.8880614638328552
              },
              {
                "id": 6352,
                "faiss_score": 0.901928722858429,
                "faiss_rank": 2,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 91,
                "sentence": "Communication overhead, memory constraints, and numerical stability all play important roles in large-scale training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.14073993265628815,
                  "neutral": 0.8553996682167053,
                  "support": 0.003860404249280691
                },
                "stance_score": -0.13687952840700746,
                "evidence_contribution": -0.12345557824159628,
                "combined_rank_score": 0.901928722858429
              }
            ],
            "neutral": [
              {
                "id": 6137,
                "faiss_score": 0.9186047315597534,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0020000473596155643,
                  "neutral": 0.9066423773765564,
                  "support": 0.09135754406452179
                },
                "stance_score": 0.08935749670490623,
                "evidence_contribution": 0.08208421927346193,
                "combined_rank_score": 0.9186047315597534
              },
              {
                "id": 6214,
                "faiss_score": 0.8926296234130859,
                "faiss_rank": 5,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 22,
                "sentence": "The interaction between batch size and learning rate is a key consideration in large-scale training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00976929534226656,
                  "neutral": 0.9842058420181274,
                  "support": 0.006024898495525122
                },
                "stance_score": -0.003744396846741438,
                "evidence_contribution": -0.003342359547215956,
                "combined_rank_score": 0.8926296234130859
              },
              {
                "id": 6044,
                "faiss_score": 0.8903433084487915,
                "faiss_rank": 6,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0027996383141726255,
                  "neutral": 0.9180957674980164,
                  "support": 0.07910455763339996
                },
                "stance_score": 0.07630491931922734,
                "evidence_contribution": 0.06793757431759898,
                "combined_rank_score": 0.8903433084487915
              }
            ]
          }
        },
        {
          "subclaim": "Increasing dataset size improves robustness",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.46895141061092527,
            "contradict": 3.881927951132086,
            "total": 4.3508793617430115
          },
          "evidence": {
            "supporting": [
              {
                "id": 2613,
                "faiss_score": 0.8810292482376099,
                "faiss_rank": 10,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 208,
                "sentence": "Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.005783679895102978,
                  "neutral": 0.6264408826828003,
                  "support": 0.36777544021606445
                },
                "stance_score": 0.3619917603209615,
                "evidence_contribution": 0.31892532846378574,
                "combined_rank_score": 0.8810292482376099
              },
              {
                "id": 6137,
                "faiss_score": 0.9264270067214966,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004063395783305168,
                  "neutral": 0.8299326300621033,
                  "support": 0.16600392758846283
                },
                "stance_score": 0.16194053180515766,
                "evidence_contribution": 0.15002608214713953,
                "combined_rank_score": 0.9264270067214966
              }
            ],
            "contradicting": [
              {
                "id": 6136,
                "faiss_score": 0.8797706961631775,
                "faiss_rank": 14,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9212777614593506,
                  "neutral": 0.07480716705322266,
                  "support": 0.003915078938007355
                },
                "stance_score": -0.9173626825213432,
                "evidence_contribution": -0.8070688058359221,
                "combined_rank_score": 0.8797706961631775
              },
              {
                "id": 6161,
                "faiss_score": 0.8941830396652222,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "Scaling affects robustness and generalization in nontrivial ways.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.7847391366958618,
                  "neutral": 0.2066025733947754,
                  "support": 0.008658240549266338
                },
                "stance_score": -0.7760808961465955,
                "evidence_contribution": -0.6939583747424724,
                "combined_rank_score": 0.8941830396652222
              },
              {
                "id": 6308,
                "faiss_score": 0.87834632396698,
                "faiss_rank": 16,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Another challenge associated with transformers is their reliance on large datasets for effective training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6750155091285706,
                  "neutral": 0.31688904762268066,
                  "support": 0.008095390163362026
                },
                "stance_score": -0.6669201189652085,
                "evidence_contribution": -0.5857868348727119,
                "combined_rank_score": 0.87834632396698
              },
              {
                "id": 6134,
                "faiss_score": 0.8815399408340454,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 10,
                "sentence": "Large models are also more sensitive to optimization choices and require careful tuning to train effectively.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.4778331220149994,
                  "neutral": 0.5161669850349426,
                  "support": 0.005999893881380558
                },
                "stance_score": -0.47183322813361883,
                "evidence_contribution": -0.415939836012447,
                "combined_rank_score": 0.8815399408340454
              },
              {
                "id": 6163,
                "faiss_score": 0.8769338130950928,
                "faiss_rank": 19,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Because they fit training data more closely, subtle biases or artifacts in the data can be amplified.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.4422004520893097,
                  "neutral": 0.5467835664749146,
                  "support": 0.01101602055132389
                },
                "stance_score": -0.4311844315379858,
                "evidence_contribution": -0.37812020769584587,
                "combined_rank_score": 0.8769338130950928
              },
              {
                "id": 6133,
                "faiss_score": 0.8859886527061462,
                "faiss_rank": 5,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.423473984003067,
                  "neutral": 0.5593301057815552,
                  "support": 0.01719595119357109
                },
                "stance_score": -0.4062780328094959,
                "evidence_contribution": -0.3599577269129888,
                "combined_rank_score": 0.8859886527061462
              },
              {
                "id": 6147,
                "faiss_score": 0.8822609782218933,
                "faiss_rank": 7,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 23,
                "sentence": "For example, increasing model size without increasing data may yield limited benefits, while increasing data without sufficient model capacity may fail to exploit the additional information.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.33419978618621826,
                  "neutral": 0.6566392183303833,
                  "support": 0.009161033667623997
                },
                "stance_score": -0.32503875251859426,
                "evidence_contribution": -0.28676900775707886,
                "combined_rank_score": 0.8822609782218933
              },
              {
                "id": 6374,
                "faiss_score": 0.8873706459999084,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 113,
                "sentence": "Robustness is another area of concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.2938911020755768,
                  "neutral": 0.7046731114387512,
                  "support": 0.0014357101172208786
                },
                "stance_score": -0.2924553919583559,
                "evidence_contribution": -0.2595163300882427,
                "combined_rank_score": 0.8873706459999084
              },
              {
                "id": 5906,
                "faiss_score": 0.8823684453964233,
                "faiss_rank": 6,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Early successes in deep learning were often achieved by increasing model size and training data, but this approach quickly encounters practical limits.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.11878746002912521,
                  "neutral": 0.869875431060791,
                  "support": 0.011337077245116234
                },
                "stance_score": -0.10745038278400898,
                "evidence_contribution": -0.09481082721437661,
                "combined_rank_score": 0.8823684453964233
              }
            ],
            "neutral": [
              {
                "id": 1394,
                "faiss_score": 0.8871293067932129,
                "faiss_rank": 4,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 44,
                "sentence": "The optimal function usually needs verification on bigger or completely new datasets.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.010466142557561398,
                  "neutral": 0.9807940721511841,
                  "support": 0.008739816956222057
                },
                "stance_score": -0.0017263256013393402,
                "evidence_contribution": -0.0015314740340155453,
                "combined_rank_score": 0.8871293067932129
              },
              {
                "id": 5786,
                "faiss_score": 0.8810343742370605,
                "faiss_rank": 9,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 34,
                "sentence": "This noise encourages models to learn robust features rather than brittle patterns.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0012816623784601688,
                  "neutral": 0.9959309697151184,
                  "support": 0.0027873709332197905
                },
                "stance_score": 0.0015057085547596216,
                "evidence_contribution": 0.001326580994326032,
                "combined_rank_score": 0.8810343742370605
              },
              {
                "id": 1385,
                "faiss_score": 0.880740225315094,
                "faiss_rank": 11,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 35,
                "sentence": "A learning algorithm that can reduce the risk of fitting noise is called \"robust.\"",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0030347779393196106,
                  "neutral": 0.9948742985725403,
                  "support": 0.0020909716840833426
                },
                "stance_score": -0.000943806255236268,
                "evidence_contribution": -0.0008312481338905858,
                "combined_rank_score": 0.880740225315094
              }
            ]
          }
        },
        {
          "subclaim": "Data collection is expensive",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 2.4292809530454424,
            "contradict": 0.0,
            "total": 2.4292809530454424
          },
          "evidence": {
            "supporting": [
              {
                "id": 6104,
                "faiss_score": 0.8590776920318604,
                "faiss_rank": 7,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 64,
                "sentence": "Human evaluation is often necessary but is expensive and subjective.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.015658235177397728,
                  "neutral": 0.3812158405780792,
                  "support": 0.6031259298324585
                },
                "stance_score": 0.5874676946550608,
                "evidence_contribution": 0.5046803912675473,
                "combined_rank_score": 0.8590776920318604
              },
              {
                "id": 6500,
                "faiss_score": 0.8686016201972961,
                "faiss_rank": 1,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 29,
                "sentence": "Accessing data from memory is often more expensive in terms of time and energy than performing arithmetic operations.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0024147434160113335,
                  "neutral": 0.5592390894889832,
                  "support": 0.4383462071418762
                },
                "stance_score": 0.4359314637258649,
                "evidence_contribution": 0.3786507756872651,
                "combined_rank_score": 0.8686016201972961
              },
              {
                "id": 1387,
                "faiss_score": 0.8628299832344055,
                "faiss_rank": 2,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 37,
                "sentence": "Other negative consequences include: A function that is overfitted is likely to request more information about each item in the validation dataset than does the optimal function; gathering this additional unneeded data can be expensive or error-prone, especially if each individual piece of information must be gathered by human observation and manual data entry.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0022822844330221415,
                  "neutral": 0.5705295205116272,
                  "support": 0.4271881878376007
                },
                "stance_score": 0.42490590340457857,
                "evidence_contribution": 0.36662155351077247,
                "combined_rank_score": 0.8628299832344055
              },
              {
                "id": 5950,
                "faiss_score": 0.8499007821083069,
                "faiss_rank": 19,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 45,
                "sentence": "Data preprocessing, communication overhead, and orchestration costs can dominate overall performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.003731388133019209,
                  "neutral": 0.6884207725524902,
                  "support": 0.30784788727760315
                },
                "stance_score": 0.30411649914458394,
                "evidence_contribution": 0.2584688504750221,
                "combined_rank_score": 0.8499007821083069
              },
              {
                "id": 5811,
                "faiss_score": 0.8624683618545532,
                "faiss_rank": 3,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 59,
                "sentence": "Transmitting, storing, and processing information consumes resources.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0020928301382809877,
                  "neutral": 0.7408831715583801,
                  "support": 0.25702401995658875
                },
                "stance_score": 0.25493118981830776,
                "evidence_contribution": 0.21987008566822805,
                "combined_rank_score": 0.8624683618545532
              },
              {
                "id": 2615,
                "faiss_score": 0.8492087721824646,
                "faiss_rank": 20,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 210,
                "sentence": "Sweeping through the parameter space for optimal parameters may not be feasible due to the cost in time and computational resources.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0030771316960453987,
                  "neutral": 0.8165972828865051,
                  "support": 0.18032559752464294
                },
                "stance_score": 0.17724846582859755,
                "evidence_contribution": 0.15052095203752885,
                "combined_rank_score": 0.8492087721824646
              },
              {
                "id": 6096,
                "faiss_score": 0.8513523936271667,
                "faiss_rank": 17,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 56,
                "sentence": "Inference costs are also significant, particularly for interactive applications.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.021079104393720627,
                  "neutral": 0.7834919095039368,
                  "support": 0.1954289972782135
                },
                "stance_score": 0.17434989288449287,
                "evidence_contribution": 0.14843319863585314,
                "combined_rank_score": 0.8513523936271667
              },
              {
                "id": 6092,
                "faiss_score": 0.8500581979751587,
                "faiss_rank": 18,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.010597540065646172,
                  "neutral": 0.8043184876441956,
                  "support": 0.1850840151309967
                },
                "stance_score": 0.17448647506535053,
                "evidence_contribution": 0.14832365856508933,
                "combined_rank_score": 0.8500581979751587
              },
              {
                "id": 5995,
                "faiss_score": 0.8537573218345642,
                "faiss_rank": 12,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "This technique reduces variance in evaluation estimates but increases computational cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004398607183247805,
                  "neutral": 0.8323123455047607,
                  "support": 0.16328909993171692
                },
                "stance_score": 0.15889049274846911,
                "evidence_contribution": 0.13565392155390724,
                "combined_rank_score": 0.8537573218345642
              },
              {
                "id": 6354,
                "faiss_score": 0.8548440337181091,
                "faiss_rank": 10,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 93,
                "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007638900075107813,
                  "neutral": 0.8466179370880127,
                  "support": 0.14574311673641205
                },
                "stance_score": 0.13810421666130424,
                "evidence_contribution": 0.118057565644229,
                "combined_rank_score": 0.8548440337181091
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 6094,
                "faiss_score": 0.8606000542640686,
                "faiss_rank": 4,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 54,
                "sentence": "These costs limit participation to well-resourced organizations and raise concerns about environmental impact.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002450440777465701,
                  "neutral": 0.9833494424819946,
                  "support": 0.014200104400515556
                },
                "stance_score": 0.011749663623049855,
                "evidence_contribution": 0.010111761151581258,
                "combined_rank_score": 0.8606000542640686
              },
              {
                "id": 377,
                "faiss_score": 0.860214114189148,
                "faiss_rank": 5,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 268,
                "sentence": "Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0020606666803359985,
                  "neutral": 0.9937606453895569,
                  "support": 0.004178634379059076
                },
                "stance_score": 0.0021179676987230778,
                "evidence_contribution": 0.0018219057078383005,
                "combined_rank_score": 0.860214114189148
              },
              {
                "id": 6138,
                "faiss_score": 0.8567302227020264,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "This observation has motivated large-scale data collection and curation efforts, as well as synthetic data generation in some settings.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0021278501953929663,
                  "neutral": 0.9968488812446594,
                  "support": 0.0010233029024675488
                },
                "stance_score": -0.0011045472929254174,
                "evidence_contribution": -0.0009462990482529132,
                "combined_rank_score": 0.8567302227020264
              }
            ]
          }
        },
        {
          "subclaim": "Labeling is costly",
          "verdict": "SUPPORT",
          "controversial": true,
          "strengths": {
            "support": 1.6664778884050906,
            "contradict": 0.5634073131404289,
            "total": 2.2298852015455193
          },
          "evidence": {
            "supporting": [
              {
                "id": 6104,
                "faiss_score": 0.8473619818687439,
                "faiss_rank": 4,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 64,
                "sentence": "Human evaluation is often necessary but is expensive and subjective.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004817895591259003,
                  "neutral": 0.11614442616701126,
                  "support": 0.8790376782417297
                },
                "stance_score": 0.8742197826504707,
                "evidence_contribution": 0.7407806076155654,
                "combined_rank_score": 0.8473619818687439
              },
              {
                "id": 2318,
                "faiss_score": 0.8671115636825562,
                "faiss_rank": 1,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 249,
                "sentence": "This approach directly quantifies predictive performance but may be impractical when labels are delayed or costly to obtain.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.005023222416639328,
                  "neutral": 0.5972570776939392,
                  "support": 0.39771971106529236
                },
                "stance_score": 0.39269648864865303,
                "evidence_contribution": 0.3405116663247827,
                "combined_rank_score": 0.8671115636825562
              },
              {
                "id": 6354,
                "faiss_score": 0.8329081535339355,
                "faiss_rank": 11,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 93,
                "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007945132441818714,
                  "neutral": 0.6579692363739014,
                  "support": 0.3340855538845062
                },
                "stance_score": 0.3261404214426875,
                "evidence_contribution": 0.2716450162166084,
                "combined_rank_score": 0.8329081535339355
              },
              {
                "id": 6092,
                "faiss_score": 0.8376576900482178,
                "faiss_rank": 8,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.08834005147218704,
                  "neutral": 0.6644766926765442,
                  "support": 0.24718329310417175
                },
                "stance_score": 0.1588432416319847,
                "evidence_contribution": 0.1330562628652192,
                "combined_rank_score": 0.8376576900482178
              },
              {
                "id": 5482,
                "faiss_score": 0.8428661227226257,
                "faiss_rank": 5,
                "doc_id": "local_bio_ethics_biotech.txt",
                "file_type": ".txt",
                "position": 28,
                "sentence": "Advanced biotechnological interventions are often expensive and resource-intensive.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\bio_ethics_biotech.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04173171892762184,
                  "neutral": 0.8021056652069092,
                  "support": 0.1561625897884369
                },
                "stance_score": 0.11443087086081505,
                "evidence_contribution": 0.09644990444222867,
                "combined_rank_score": 0.8428661227226257
              },
              {
                "id": 5995,
                "faiss_score": 0.8279998302459717,
                "faiss_rank": 17,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "This technique reduces variance in evaluation estimates but increases computational cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.018147123977541924,
                  "neutral": 0.8622148633003235,
                  "support": 0.11963800340890884
                },
                "stance_score": 0.10149087943136692,
                "evidence_contribution": 0.08403443094068619,
                "combined_rank_score": 0.8279998302459717
              }
            ],
            "contradicting": [
              {
                "id": 202,
                "faiss_score": 0.8283368945121765,
                "faiss_rank": 14,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 93,
                "sentence": "In weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.7162351608276367,
                  "neutral": 0.24769654870033264,
                  "support": 0.03606829047203064
                },
                "stance_score": -0.6801668703556061,
                "evidence_contribution": -0.5634073131404289,
                "combined_rank_score": 0.8283368945121765
              }
            ],
            "neutral": [
              {
                "id": 2587,
                "faiss_score": 0.856002926826477,
                "faiss_rank": 2,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 182,
                "sentence": "and return the proposed label.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0012090373784303665,
                  "neutral": 0.9970332384109497,
                  "support": 0.001757694291882217
                },
                "stance_score": 0.0005486569134518504,
                "evidence_contribution": 0.00046965192373836506,
                "combined_rank_score": 0.856002926826477
              },
              {
                "id": 2251,
                "faiss_score": 0.8548805713653564,
                "faiss_rank": 3,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 182,
                "sentence": "The cost function can be much more complicated.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.0012478599091991782,
                  "neutral": 0.9973701238632202,
                  "support": 0.001382032292895019
                },
                "stance_score": 0.00013417238369584084,
                "evidence_contribution": 0.00011470136403535225,
                "combined_rank_score": 0.8548805713653564
              },
              {
                "id": 3584,
                "faiss_score": 0.840117335319519,
                "faiss_rank": 6,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 155,
                "sentence": "This can be a purely economic cost or can include other measures, such as weight.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.012381319887936115,
                  "neutral": 0.9776540398597717,
                  "support": 0.009964688681066036
                },
                "stance_score": -0.002416631206870079,
                "evidence_contribution": -0.002030253769965684,
                "combined_rank_score": 0.840117335319519
              }
            ]
          }
        },
        {
          "subclaim": "Noisy data degrades performance",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 1.8095763718043252,
            "contradict": 1.221949564073587,
            "total": 3.0315259358779123
          },
          "evidence": {
            "supporting": [
              {
                "id": 4087,
                "faiss_score": 0.8815248608589172,
                "faiss_rank": 7,
                "doc_id": "wiki_Information_theory",
                "file_type": ".txt",
                "position": 81,
                "sentence": "However, channels often fail to produce exact reconstruction of a signal; noise, periods of silence, and other forms of signal corruption often degrade quality.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Information_theory",
                "primary_category": "all articles needing additional references",
                "probs": {
                  "contradict": 0.003933201543986797,
                  "neutral": 0.49653515219688416,
                  "support": 0.49953165650367737
                },
                "stance_score": 0.49559845495969057,
                "evidence_contribution": 0.4368823590502356,
                "combined_rank_score": 0.8815248608589172
              },
              {
                "id": 6217,
                "faiss_score": 0.8931040167808533,
                "faiss_rank": 3,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 25,
                "sentence": "However, excessive noise can destabilize training and prevent convergence.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002562792506068945,
                  "neutral": 0.5067336559295654,
                  "support": 0.4907035827636719
                },
                "stance_score": 0.48814079025760293,
                "evidence_contribution": 0.4359605005336452,
                "combined_rank_score": 0.8931040167808533
              },
              {
                "id": 6005,
                "faiss_score": 0.8975870013237,
                "faiss_rank": 2,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 31,
                "sentence": "Noisy labels, missing values, and biased sampling affect both training and evaluation.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001983974128961563,
                  "neutral": 0.5871595144271851,
                  "support": 0.41085657477378845
                },
                "stance_score": 0.4088726006448269,
                "evidence_contribution": 0.3669987315362129,
                "combined_rank_score": 0.8975870013237
              },
              {
                "id": 5808,
                "faiss_score": 0.8804681897163391,
                "faiss_rank": 8,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 56,
                "sentence": "Even with infinite computation and perfect optimization, performance is bounded by noise and ambiguity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00144195684697479,
                  "neutral": 0.7477361559867859,
                  "support": 0.25082188844680786
                },
                "stance_score": 0.24937993159983307,
                "evidence_contribution": 0.2195710969272895,
                "combined_rank_score": 0.8804681897163391
              },
              {
                "id": 5856,
                "faiss_score": 0.8756698369979858,
                "faiss_rank": 13,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 25,
                "sentence": "On the other hand, excessive noise may prevent convergence altogether.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0027674247976392508,
                  "neutral": 0.7518907785415649,
                  "support": 0.24534180760383606
                },
                "stance_score": 0.2425743828061968,
                "evidence_contribution": 0.21241507025178938,
                "combined_rank_score": 0.8756698369979858
              },
              {
                "id": 5784,
                "faiss_score": 0.8904547095298767,
                "faiss_rank": 4,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 32,
                "sentence": "On one hand, noise increases entropy and makes prediction harder.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004294100683182478,
                  "neutral": 0.8367171287536621,
                  "support": 0.15898878872394562
                },
                "stance_score": 0.15469468804076314,
                "evidence_contribution": 0.13774861350515263,
                "combined_rank_score": 0.8904547095298767
              }
            ],
            "contradicting": [
              {
                "id": 5854,
                "faiss_score": 0.884116530418396,
                "faiss_rank": 6,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 23,
                "sentence": "Noise in optimization can be both beneficial and harmful.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6732237339019775,
                  "neutral": 0.28176796436309814,
                  "support": 0.04500836506485939
                },
                "stance_score": -0.6282153688371181,
                "evidence_contribution": -0.5554155922517858,
                "combined_rank_score": 0.884116530418396
              },
              {
                "id": 6212,
                "faiss_score": 0.8693752288818359,
                "faiss_rank": 20,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 20,
                "sentence": "Small batches introduce more noise into gradient estimates, which can help exploration and reduce overfitting but may slow convergence.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6025785207748413,
                  "neutral": 0.3827839493751526,
                  "support": 0.014637491665780544
                },
                "stance_score": -0.5879410291090608,
                "evidence_contribution": -0.5111413667507119,
                "combined_rank_score": 0.8693752288818359
              },
              {
                "id": 1785,
                "faiss_score": 0.8795800805091858,
                "faiss_rank": 9,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Cleaned datasets can increase training efficiency and lead to improved downstream performance.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.18365582823753357,
                  "neutral": 0.8093551397323608,
                  "support": 0.006989020388573408
                },
                "stance_score": -0.17666680784896016,
                "evidence_contribution": -0.15539260507108923,
                "combined_rank_score": 0.8795800805091858
              }
            ],
            "neutral": [
              {
                "id": 5998,
                "faiss_score": 0.9058985114097595,
                "faiss_rank": 1,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 24,
                "sentence": "When deployment data differs from training data, performance may degrade unpredictably.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.008945327252149582,
                  "neutral": 0.9763994812965393,
                  "support": 0.014655262231826782
                },
                "stance_score": 0.0057099349796772,
                "evidence_contribution": 0.005172621598336091,
                "combined_rank_score": 0.9058985114097595
              },
              {
                "id": 6436,
                "faiss_score": 0.8874707221984863,
                "faiss_rank": 5,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 175,
                "sentence": "Memory usage, latency, and throughput must be balanced against accuracy and robustness.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005644329357892275,
                  "neutral": 0.9925962090492249,
                  "support": 0.0017594806849956512
                },
                "stance_score": -0.0038848486728966236,
                "evidence_contribution": -0.0034476894573673977,
                "combined_rank_score": 0.8874707221984863
              },
              {
                "id": 5769,
                "faiss_score": 0.8786929249763489,
                "faiss_rank": 10,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 17,
                "sentence": "The model memorizes noise rather than structure.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.019698455929756165,
                  "neutral": 0.9747886657714844,
                  "support": 0.005512891802936792
                },
                "stance_score": -0.014185564126819372,
                "evidence_contribution": -0.01246475483503448,
                "combined_rank_score": 0.8786929249763489
              }
            ]
          }
        },
        {
          "subclaim": "Returns diminish beyond scale",
          "verdict": "SUPPORT",
          "controversial": true,
          "strengths": {
            "support": 1.5768859421765973,
            "contradict": 0.5643550785403653,
            "total": 2.1412410207169623
          },
          "evidence": {
            "supporting": [
              {
                "id": 6133,
                "faiss_score": 0.8767734169960022,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002733273431658745,
                  "neutral": 0.3507341742515564,
                  "support": 0.6465325355529785
                },
                "stance_score": 0.6437992621213198,
                "evidence_contribution": 0.5644660789096144,
                "combined_rank_score": 0.8767734169960022
              },
              {
                "id": 6178,
                "faiss_score": 0.8914539217948914,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 54,
                "sentence": "While scaling has delivered consistent gains, it may encounter diminishing returns or external constraints that necessitate new approaches.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04899430647492409,
                  "neutral": 0.5350538492202759,
                  "support": 0.41595181822776794
                },
                "stance_score": 0.36695751175284386,
                "evidence_contribution": 0.3271257129841676,
                "combined_rank_score": 0.8914539217948914
              },
              {
                "id": 6170,
                "faiss_score": 0.8499006032943726,
                "faiss_rank": 16,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 46,
                "sentence": "Experiments become more expensive and slower to iterate, reducing the ability to explore many alternatives.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007931001484394073,
                  "neutral": 0.7737475633621216,
                  "support": 0.21832142770290375
                },
                "stance_score": 0.21039042621850967,
                "evidence_contribution": 0.17881095017047155,
                "combined_rank_score": 0.8499006032943726
              },
              {
                "id": 5633,
                "faiss_score": 0.8463342189788818,
                "faiss_rank": 20,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 36,
                "sentence": "However, scaling introduces coordination overhead that can limit achievable gains.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0371006615459919,
                  "neutral": 0.7580291032791138,
                  "support": 0.20487017929553986
                },
                "stance_score": 0.16776951774954796,
                "evidence_contribution": 0.14198908377302732,
                "combined_rank_score": 0.8463342189788818
              },
              {
                "id": 5849,
                "faiss_score": 0.8561608791351318,
                "faiss_rank": 6,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "If it is too small, convergence may be slow or stall entirely.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.03462636470794678,
                  "neutral": 0.7758088707923889,
                  "support": 0.1895647943019867
                },
                "stance_score": 0.15493842959403992,
                "evidence_contribution": 0.13265222209304994,
                "combined_rank_score": 0.8561608791351318
              },
              {
                "id": 6414,
                "faiss_score": 0.8572297096252441,
                "faiss_rank": 5,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 153,
                "sentence": "Although larger models often support longer contexts, this approach scales poorly due to the quadratic cost of attention.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.006133015733212233,
                  "neutral": 0.837619423866272,
                  "support": 0.15624749660491943
                },
                "stance_score": 0.1501144808717072,
                "evidence_contribution": 0.12868259284819783,
                "combined_rank_score": 0.8572297096252441
              },
              {
                "id": 5729,
                "faiss_score": 0.8505622148513794,
                "faiss_rank": 15,
                "doc_id": "local_math_computation_limits.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "These results place limits on what can be inferred from finite data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.009552570059895515,
                  "neutral": 0.8596112132072449,
                  "support": 0.13083623349666595
                },
                "stance_score": 0.12128366343677044,
                "evidence_contribution": 0.10315930139806873,
                "combined_rank_score": 0.8505622148513794
              }
            ],
            "contradicting": [
              {
                "id": 6169,
                "faiss_score": 0.8464234471321106,
                "faiss_rank": 19,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 45,
                "sentence": "Scaling also influences research methodology.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3049299418926239,
                  "neutral": 0.6891443133354187,
                  "support": 0.005925755016505718
                },
                "stance_score": -0.2990041868761182,
                "evidence_contribution": -0.25308415456261774,
                "combined_rank_score": 0.8464234471321106
              },
              {
                "id": 6161,
                "faiss_score": 0.848158061504364,
                "faiss_rank": 17,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "Scaling affects robustness and generalization in nontrivial ways.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.1861957162618637,
                  "neutral": 0.7812544107437134,
                  "support": 0.03254988044500351
                },
                "stance_score": -0.1536458358168602,
                "evidence_contribution": -0.13031595426464593,
                "combined_rank_score": 0.848158061504364
              },
              {
                "id": 6157,
                "faiss_score": 0.8606178760528564,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 33,
                "sentence": "Inference efficiency is another scaling concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.13407321274280548,
                  "neutral": 0.8408279418945312,
                  "support": 0.025098849087953568
                },
                "stance_score": -0.10897436365485191,
                "evidence_contribution": -0.09378528539285025,
                "combined_rank_score": 0.8606178760528564
              },
              {
                "id": 6212,
                "faiss_score": 0.8468236923217773,
                "faiss_rank": 18,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 20,
                "sentence": "Small batches introduce more noise into gradient estimates, which can help exploration and reduce overfitting but may slow convergence.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.13060362637043,
                  "neutral": 0.841729998588562,
                  "support": 0.027666397392749786
                },
                "stance_score": -0.1029372289776802,
                "evidence_contribution": -0.0871696843202514,
                "combined_rank_score": 0.8468236923217773
              }
            ],
            "neutral": [
              {
                "id": 6186,
                "faiss_score": 0.8617356419563293,
                "faiss_rank": 3,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 62,
                "sentence": "Ultimately, scaling is a powerful but blunt tool.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.025735752657055855,
                  "neutral": 0.8864394426345825,
                  "support": 0.0878247618675232
                },
                "stance_score": 0.06208900921046734,
                "evidence_contribution": 0.05350431221041452,
                "combined_rank_score": 0.8617356419563293
              },
              {
                "id": 6021,
                "faiss_score": 0.8548541069030762,
                "faiss_rank": 7,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Performance estimates are subject to variance due to finite data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.08714761584997177,
                  "neutral": 0.8800191283226013,
                  "support": 0.03283325955271721
                },
                "stance_score": -0.05431435629725456,
                "evidence_contribution": -0.04643085054450502,
                "combined_rank_score": 0.8548541069030762
              },
              {
                "id": 6183,
                "faiss_score": 0.8544989228248596,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 59,
                "sentence": "As models grow, traditional benchmarks may saturate, providing limited insight into real-world performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.03954518586397171,
                  "neutral": 0.9247549176216125,
                  "support": 0.035699956119060516
                },
                "stance_score": -0.003845229744911194,
                "evidence_contribution": -0.003285744675040725,
                "combined_rank_score": 0.8544989228248596
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Data collection is expensive",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6500,
                      "faiss_score": 0.8686016201972961,
                      "faiss_rank": 1,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 29,
                      "sentence": "Accessing data from memory is often more expensive in terms of time and energy than performing arithmetic operations.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0024147434160113335,
                        "neutral": 0.5592390894889832,
                        "support": 0.4383462071418762
                      },
                      "stance_score": 0.4359314637258649,
                      "evidence_contribution": 0.3786507756872651,
                      "combined_rank_score": 0.8686016201972961
                    },
                    {
                      "id": 1387,
                      "faiss_score": 0.8628299832344055,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Overfitting",
                      "file_type": ".txt",
                      "position": 37,
                      "sentence": "Other negative consequences include: A function that is overfitted is likely to request more information about each item in the validation dataset than does the optimal function; gathering this additional unneeded data can be expensive or error-prone, especially if each individual piece of information must be gathered by human observation and manual data entry.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.0022822844330221415,
                        "neutral": 0.5705295205116272,
                        "support": 0.4271881878376007
                      },
                      "stance_score": 0.42490590340457857,
                      "evidence_contribution": 0.36662155351077247,
                      "combined_rank_score": 0.8628299832344055
                    },
                    {
                      "id": 5811,
                      "faiss_score": 0.8624683618545532,
                      "faiss_rank": 3,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 59,
                      "sentence": "Transmitting, storing, and processing information consumes resources.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0020928301382809877,
                        "neutral": 0.7408831715583801,
                        "support": 0.25702401995658875
                      },
                      "stance_score": 0.25493118981830776,
                      "evidence_contribution": 0.21987008566822805,
                      "combined_rank_score": 0.8624683618545532
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 6094,
                      "faiss_score": 0.8606000542640686,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 54,
                      "sentence": "These costs limit participation to well-resourced organizations and raise concerns about environmental impact.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.002450440777465701,
                        "neutral": 0.9833494424819946,
                        "support": 0.014200104400515556
                      },
                      "stance_score": 0.011749663623049855,
                      "evidence_contribution": 0.010111761151581258,
                      "combined_rank_score": 0.8606000542640686
                    },
                    {
                      "id": 377,
                      "faiss_score": 0.860214114189148,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 268,
                      "sentence": "Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.0020606666803359985,
                        "neutral": 0.9937606453895569,
                        "support": 0.004178634379059076
                      },
                      "stance_score": 0.0021179676987230778,
                      "evidence_contribution": 0.0018219057078383005,
                      "combined_rank_score": 0.860214114189148
                    },
                    {
                      "id": 6138,
                      "faiss_score": 0.8567302227020264,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "This observation has motivated large-scale data collection and curation efforts, as well as synthetic data generation in some settings.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0021278501953929663,
                        "neutral": 0.9968488812446594,
                        "support": 0.0010233029024675488
                      },
                      "stance_score": -0.0011045472929254174,
                      "evidence_contribution": -0.0009462990482529132,
                      "combined_rank_score": 0.8567302227020264
                    }
                  ]
                }
              },
              {
                "subclaim": "Labeling is costly",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 2318,
                      "faiss_score": 0.8671115636825562,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 249,
                      "sentence": "This approach directly quantifies predictive performance but may be impractical when labels are delayed or costly to obtain.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.005023222416639328,
                        "neutral": 0.5972570776939392,
                        "support": 0.39771971106529236
                      },
                      "stance_score": 0.39269648864865303,
                      "evidence_contribution": 0.3405116663247827,
                      "combined_rank_score": 0.8671115636825562
                    },
                    {
                      "id": 6104,
                      "faiss_score": 0.8473619818687439,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 64,
                      "sentence": "Human evaluation is often necessary but is expensive and subjective.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004817895591259003,
                        "neutral": 0.11614442616701126,
                        "support": 0.8790376782417297
                      },
                      "stance_score": 0.8742197826504707,
                      "evidence_contribution": 0.7407806076155654,
                      "combined_rank_score": 0.8473619818687439
                    },
                    {
                      "id": 5482,
                      "faiss_score": 0.8428661227226257,
                      "faiss_rank": 5,
                      "doc_id": "local_bio_ethics_biotech.txt",
                      "file_type": ".txt",
                      "position": 28,
                      "sentence": "Advanced biotechnological interventions are often expensive and resource-intensive.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\bio_ethics_biotech.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.04173171892762184,
                        "neutral": 0.8021056652069092,
                        "support": 0.1561625897884369
                      },
                      "stance_score": 0.11443087086081505,
                      "evidence_contribution": 0.09644990444222867,
                      "combined_rank_score": 0.8428661227226257
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 202,
                      "faiss_score": 0.8283368945121765,
                      "faiss_rank": 14,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 93,
                      "sentence": "In weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.7162351608276367,
                        "neutral": 0.24769654870033264,
                        "support": 0.03606829047203064
                      },
                      "stance_score": -0.6801668703556061,
                      "evidence_contribution": -0.5634073131404289,
                      "combined_rank_score": 0.8283368945121765
                    }
                  ],
                  "neutral": [
                    {
                      "id": 2587,
                      "faiss_score": 0.856002926826477,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 182,
                      "sentence": "and return the proposed label.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.0012090373784303665,
                        "neutral": 0.9970332384109497,
                        "support": 0.001757694291882217
                      },
                      "stance_score": 0.0005486569134518504,
                      "evidence_contribution": 0.00046965192373836506,
                      "combined_rank_score": 0.856002926826477
                    },
                    {
                      "id": 2251,
                      "faiss_score": 0.8548805713653564,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 182,
                      "sentence": "The cost function can be much more complicated.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.0012478599091991782,
                        "neutral": 0.9973701238632202,
                        "support": 0.001382032292895019
                      },
                      "stance_score": 0.00013417238369584084,
                      "evidence_contribution": 0.00011470136403535225,
                      "combined_rank_score": 0.8548805713653564
                    },
                    {
                      "id": 3584,
                      "faiss_score": 0.840117335319519,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 155,
                      "sentence": "This can be a purely economic cost or can include other measures, such as weight.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.012381319887936115,
                        "neutral": 0.9776540398597717,
                        "support": 0.009964688681066036
                      },
                      "stance_score": -0.002416631206870079,
                      "evidence_contribution": -0.002030253769965684,
                      "combined_rank_score": 0.840117335319519
                    }
                  ]
                }
              },
              {
                "subclaim": "Returns diminish beyond scale",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6178,
                      "faiss_score": 0.8914539217948914,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 54,
                      "sentence": "While scaling has delivered consistent gains, it may encounter diminishing returns or external constraints that necessitate new approaches.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.04899430647492409,
                        "neutral": 0.5350538492202759,
                        "support": 0.41595181822776794
                      },
                      "stance_score": 0.36695751175284386,
                      "evidence_contribution": 0.3271257129841676,
                      "combined_rank_score": 0.8914539217948914
                    },
                    {
                      "id": 6133,
                      "faiss_score": 0.8767734169960022,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.002733273431658745,
                        "neutral": 0.3507341742515564,
                        "support": 0.6465325355529785
                      },
                      "stance_score": 0.6437992621213198,
                      "evidence_contribution": 0.5644660789096144,
                      "combined_rank_score": 0.8767734169960022
                    },
                    {
                      "id": 6414,
                      "faiss_score": 0.8572297096252441,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 153,
                      "sentence": "Although larger models often support longer contexts, this approach scales poorly due to the quadratic cost of attention.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.006133015733212233,
                        "neutral": 0.837619423866272,
                        "support": 0.15624749660491943
                      },
                      "stance_score": 0.1501144808717072,
                      "evidence_contribution": 0.12868259284819783,
                      "combined_rank_score": 0.8572297096252441
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6157,
                      "faiss_score": 0.8606178760528564,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 33,
                      "sentence": "Inference efficiency is another scaling concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.13407321274280548,
                        "neutral": 0.8408279418945312,
                        "support": 0.025098849087953568
                      },
                      "stance_score": -0.10897436365485191,
                      "evidence_contribution": -0.09378528539285025,
                      "combined_rank_score": 0.8606178760528564
                    },
                    {
                      "id": 6161,
                      "faiss_score": 0.848158061504364,
                      "faiss_rank": 17,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 37,
                      "sentence": "Scaling affects robustness and generalization in nontrivial ways.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.1861957162618637,
                        "neutral": 0.7812544107437134,
                        "support": 0.03254988044500351
                      },
                      "stance_score": -0.1536458358168602,
                      "evidence_contribution": -0.13031595426464593,
                      "combined_rank_score": 0.848158061504364
                    },
                    {
                      "id": 6212,
                      "faiss_score": 0.8468236923217773,
                      "faiss_rank": 18,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 20,
                      "sentence": "Small batches introduce more noise into gradient estimates, which can help exploration and reduce overfitting but may slow convergence.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.13060362637043,
                        "neutral": 0.841729998588562,
                        "support": 0.027666397392749786
                      },
                      "stance_score": -0.1029372289776802,
                      "evidence_contribution": -0.0871696843202514,
                      "combined_rank_score": 0.8468236923217773
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6186,
                      "faiss_score": 0.8617356419563293,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 62,
                      "sentence": "Ultimately, scaling is a powerful but blunt tool.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.025735752657055855,
                        "neutral": 0.8864394426345825,
                        "support": 0.0878247618675232
                      },
                      "stance_score": 0.06208900921046734,
                      "evidence_contribution": 0.05350431221041452,
                      "combined_rank_score": 0.8617356419563293
                    },
                    {
                      "id": 6021,
                      "faiss_score": 0.8548541069030762,
                      "faiss_rank": 7,
                      "doc_id": "local_ml_evaluation_and_generalization.txt",
                      "file_type": ".txt",
                      "position": 47,
                      "sentence": "Performance estimates are subject to variance due to finite data.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.08714761584997177,
                        "neutral": 0.8800191283226013,
                        "support": 0.03283325955271721
                      },
                      "stance_score": -0.05431435629725456,
                      "evidence_contribution": -0.04643085054450502,
                      "combined_rank_score": 0.8548541069030762
                    },
                    {
                      "id": 6183,
                      "faiss_score": 0.8544989228248596,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 59,
                      "sentence": "As models grow, traditional benchmarks may saturate, providing limited insight into real-world performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.03954518586397171,
                        "neutral": 0.9247549176216125,
                        "support": 0.035699956119060516
                      },
                      "stance_score": -0.003845229744911194,
                      "evidence_contribution": -0.003285744675040725,
                      "combined_rank_score": 0.8544989228248596
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Increasing dataset size improves model generalization",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6132,
                      "faiss_score": 0.9014256596565247,
                      "faiss_rank": 7,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Larger models have greater representational capacity, allowing them to fit more complex functions.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0038138218224048615,
                        "neutral": 0.6846141815185547,
                        "support": 0.31157195568084717
                      },
                      "stance_score": 0.3077581338584423,
                      "evidence_contribution": 0.2774210788280074,
                      "combined_rank_score": 0.9014256596565247
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 1453,
                      "faiss_score": 0.911958634853363,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Regularization_(mathematics)",
                      "file_type": ".txt",
                      "position": 25,
                      "sentence": "By regularizing for time, model complexity can be controlled, improving generalization.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Regularization_(mathematics)",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.48357275128364563,
                        "neutral": 0.49403151869773865,
                        "support": 0.022395795211195946
                      },
                      "stance_score": -0.4611769560724497,
                      "evidence_contribution": -0.4205743072856606,
                      "combined_rank_score": 0.911958634853363
                    },
                    {
                      "id": 5941,
                      "faiss_score": 0.905327558517456,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 36,
                      "sentence": "Smaller or compressed models may generalize better due to implicit regularization, but excessive compression can harm performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.8726226687431335,
                        "neutral": 0.12322617322206497,
                        "support": 0.00415118969976902
                      },
                      "stance_score": -0.8684714790433645,
                      "evidence_contribution": -0.7862511637643732,
                      "combined_rank_score": 0.905327558517456
                    },
                    {
                      "id": 6046,
                      "faiss_score": 0.8923694491386414,
                      "faiss_rank": 11,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 6,
                      "sentence": "These include improved generalization, better handling of rare or ambiguous inputs, and the ability to adapt to new tasks with minimal additional data.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.5339111685752869,
                        "neutral": 0.46064701676368713,
                        "support": 0.005441853776574135
                      },
                      "stance_score": -0.5284693147987127,
                      "evidence_contribution": -0.47158987133360253,
                      "combined_rank_score": 0.8923694491386414
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6137,
                      "faiss_score": 0.9258404970169067,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001429139287211001,
                        "neutral": 0.9253905415534973,
                        "support": 0.07318033277988434
                      },
                      "stance_score": 0.07175119349267334,
                      "evidence_contribution": 0.06643016064481293,
                      "combined_rank_score": 0.9258404970169067
                    },
                    {
                      "id": 6211,
                      "faiss_score": 0.9146623611450195,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 19,
                      "sentence": "Batch size influences both optimization efficiency and generalization.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005423132795840502,
                        "neutral": 0.9795346260070801,
                        "support": 0.015042271465063095
                      },
                      "stance_score": 0.009619138669222593,
                      "evidence_contribution": 0.008798264087372498,
                      "combined_rank_score": 0.9146623611450195
                    },
                    {
                      "id": 5728,
                      "faiss_score": 0.9091782569885254,
                      "faiss_rank": 4,
                      "doc_id": "local_math_computation_limits.txt",
                      "file_type": ".txt",
                      "position": 51,
                      "sentence": "Bounds on generalization depend on factors such as model capacity and data distribution.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.08435701578855515,
                        "neutral": 0.9136447310447693,
                        "support": 0.0019982256926596165
                      },
                      "stance_score": -0.08235879009589553,
                      "evidence_contribution": -0.07487882122707012,
                      "combined_rank_score": 0.9091782569885254
                    }
                  ]
                }
              },
              {
                "subclaim": "Increasing dataset size improves training stability",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 2613,
                      "faiss_score": 0.8831011056900024,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 208,
                      "sentence": "Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.004449686035513878,
                        "neutral": 0.5582360029220581,
                        "support": 0.43731430172920227
                      },
                      "stance_score": 0.4328646156936884,
                      "evidence_contribution": 0.3822632207331742,
                      "combined_rank_score": 0.8831011056900024
                    },
                    {
                      "id": 1416,
                      "faiss_score": 0.8797472715377808,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Overfitting",
                      "file_type": ".txt",
                      "position": 66,
                      "sentence": "Increase the amount of training data: If the model is underfitting due to a lack of data, increasing the amount of training data may help.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.0035214696545153856,
                        "neutral": 0.7250623106956482,
                        "support": 0.27141618728637695
                      },
                      "stance_score": 0.26789471763186157,
                      "evidence_contribution": 0.23567964689601442,
                      "combined_rank_score": 0.8797472715377808
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6352,
                      "faiss_score": 0.901928722858429,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 91,
                      "sentence": "Communication overhead, memory constraints, and numerical stability all play important roles in large-scale training.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.14073993265628815,
                        "neutral": 0.8553996682167053,
                        "support": 0.003860404249280691
                      },
                      "stance_score": -0.13687952840700746,
                      "evidence_contribution": -0.12345557824159628,
                      "combined_rank_score": 0.901928722858429
                    },
                    {
                      "id": 6133,
                      "faiss_score": 0.8990232944488525,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.7590318322181702,
                        "neutral": 0.217951238155365,
                        "support": 0.023016992956399918
                      },
                      "stance_score": -0.7360148392617702,
                      "evidence_contribution": -0.6616944855563593,
                      "combined_rank_score": 0.8990232944488525
                    },
                    {
                      "id": 5932,
                      "faiss_score": 0.8946778774261475,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "Memory efficiency during training is a limiting factor for large models.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.6858248710632324,
                        "neutral": 0.31039711833000183,
                        "support": 0.0037779605481773615
                      },
                      "stance_score": -0.6820469105150551,
                      "evidence_contribution": -0.6102122822046709,
                      "combined_rank_score": 0.8946778774261475
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6137,
                      "faiss_score": 0.9186047315597534,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0020000473596155643,
                        "neutral": 0.9066423773765564,
                        "support": 0.09135754406452179
                      },
                      "stance_score": 0.08935749670490623,
                      "evidence_contribution": 0.08208421927346193,
                      "combined_rank_score": 0.9186047315597534
                    },
                    {
                      "id": 6214,
                      "faiss_score": 0.8926296234130859,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 22,
                      "sentence": "The interaction between batch size and learning rate is a key consideration in large-scale training.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.00976929534226656,
                        "neutral": 0.9842058420181274,
                        "support": 0.006024898495525122
                      },
                      "stance_score": -0.003744396846741438,
                      "evidence_contribution": -0.003342359547215956,
                      "combined_rank_score": 0.8926296234130859
                    },
                    {
                      "id": 6044,
                      "faiss_score": 0.8903433084487915,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 4,
                      "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0027996383141726255,
                        "neutral": 0.9180957674980164,
                        "support": 0.07910455763339996
                      },
                      "stance_score": 0.07630491931922734,
                      "evidence_contribution": 0.06793757431759898,
                      "combined_rank_score": 0.8903433084487915
                    }
                  ]
                }
              },
              {
                "subclaim": "Increasing dataset size improves robustness",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6137,
                      "faiss_score": 0.9264270067214966,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004063395783305168,
                        "neutral": 0.8299326300621033,
                        "support": 0.16600392758846283
                      },
                      "stance_score": 0.16194053180515766,
                      "evidence_contribution": 0.15002608214713953,
                      "combined_rank_score": 0.9264270067214966
                    },
                    {
                      "id": 2613,
                      "faiss_score": 0.8810292482376099,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 208,
                      "sentence": "Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.005783679895102978,
                        "neutral": 0.6264408826828003,
                        "support": 0.36777544021606445
                      },
                      "stance_score": 0.3619917603209615,
                      "evidence_contribution": 0.31892532846378574,
                      "combined_rank_score": 0.8810292482376099
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6161,
                      "faiss_score": 0.8941830396652222,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 37,
                      "sentence": "Scaling affects robustness and generalization in nontrivial ways.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.7847391366958618,
                        "neutral": 0.2066025733947754,
                        "support": 0.008658240549266338
                      },
                      "stance_score": -0.7760808961465955,
                      "evidence_contribution": -0.6939583747424724,
                      "combined_rank_score": 0.8941830396652222
                    },
                    {
                      "id": 6374,
                      "faiss_score": 0.8873706459999084,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 113,
                      "sentence": "Robustness is another area of concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.2938911020755768,
                        "neutral": 0.7046731114387512,
                        "support": 0.0014357101172208786
                      },
                      "stance_score": -0.2924553919583559,
                      "evidence_contribution": -0.2595163300882427,
                      "combined_rank_score": 0.8873706459999084
                    },
                    {
                      "id": 6133,
                      "faiss_score": 0.8859886527061462,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.423473984003067,
                        "neutral": 0.5593301057815552,
                        "support": 0.01719595119357109
                      },
                      "stance_score": -0.4062780328094959,
                      "evidence_contribution": -0.3599577269129888,
                      "combined_rank_score": 0.8859886527061462
                    }
                  ],
                  "neutral": [
                    {
                      "id": 1394,
                      "faiss_score": 0.8871293067932129,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Overfitting",
                      "file_type": ".txt",
                      "position": 44,
                      "sentence": "The optimal function usually needs verification on bigger or completely new datasets.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.010466142557561398,
                        "neutral": 0.9807940721511841,
                        "support": 0.008739816956222057
                      },
                      "stance_score": -0.0017263256013393402,
                      "evidence_contribution": -0.0015314740340155453,
                      "combined_rank_score": 0.8871293067932129
                    },
                    {
                      "id": 5786,
                      "faiss_score": 0.8810343742370605,
                      "faiss_rank": 9,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 34,
                      "sentence": "This noise encourages models to learn robust features rather than brittle patterns.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0012816623784601688,
                        "neutral": 0.9959309697151184,
                        "support": 0.0027873709332197905
                      },
                      "stance_score": 0.0015057085547596216,
                      "evidence_contribution": 0.001326580994326032,
                      "combined_rank_score": 0.8810343742370605
                    },
                    {
                      "id": 1385,
                      "faiss_score": 0.880740225315094,
                      "faiss_rank": 11,
                      "doc_id": "wiki_Overfitting",
                      "file_type": ".txt",
                      "position": 35,
                      "sentence": "A learning algorithm that can reduce the risk of fitting noise is called \"robust.\"",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.0030347779393196106,
                        "neutral": 0.9948742985725403,
                        "support": 0.0020909716840833426
                      },
                      "stance_score": -0.000943806255236268,
                      "evidence_contribution": -0.0008312481338905858,
                      "combined_rank_score": 0.880740225315094
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Noisy data degrades performance",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6005,
                      "faiss_score": 0.8975870013237,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_evaluation_and_generalization.txt",
                      "file_type": ".txt",
                      "position": 31,
                      "sentence": "Noisy labels, missing values, and biased sampling affect both training and evaluation.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001983974128961563,
                        "neutral": 0.5871595144271851,
                        "support": 0.41085657477378845
                      },
                      "stance_score": 0.4088726006448269,
                      "evidence_contribution": 0.3669987315362129,
                      "combined_rank_score": 0.8975870013237
                    },
                    {
                      "id": 6217,
                      "faiss_score": 0.8931040167808533,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 25,
                      "sentence": "However, excessive noise can destabilize training and prevent convergence.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.002562792506068945,
                        "neutral": 0.5067336559295654,
                        "support": 0.4907035827636719
                      },
                      "stance_score": 0.48814079025760293,
                      "evidence_contribution": 0.4359605005336452,
                      "combined_rank_score": 0.8931040167808533
                    },
                    {
                      "id": 5784,
                      "faiss_score": 0.8904547095298767,
                      "faiss_rank": 4,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 32,
                      "sentence": "On one hand, noise increases entropy and makes prediction harder.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004294100683182478,
                        "neutral": 0.8367171287536621,
                        "support": 0.15898878872394562
                      },
                      "stance_score": 0.15469468804076314,
                      "evidence_contribution": 0.13774861350515263,
                      "combined_rank_score": 0.8904547095298767
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5854,
                      "faiss_score": 0.884116530418396,
                      "faiss_rank": 6,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 23,
                      "sentence": "Noise in optimization can be both beneficial and harmful.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.6732237339019775,
                        "neutral": 0.28176796436309814,
                        "support": 0.04500836506485939
                      },
                      "stance_score": -0.6282153688371181,
                      "evidence_contribution": -0.5554155922517858,
                      "combined_rank_score": 0.884116530418396
                    },
                    {
                      "id": 1785,
                      "faiss_score": 0.8795800805091858,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "Cleaned datasets can increase training efficiency and lead to improved downstream performance.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.18365582823753357,
                        "neutral": 0.8093551397323608,
                        "support": 0.006989020388573408
                      },
                      "stance_score": -0.17666680784896016,
                      "evidence_contribution": -0.15539260507108923,
                      "combined_rank_score": 0.8795800805091858
                    },
                    {
                      "id": 6212,
                      "faiss_score": 0.8693752288818359,
                      "faiss_rank": 20,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 20,
                      "sentence": "Small batches introduce more noise into gradient estimates, which can help exploration and reduce overfitting but may slow convergence.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.6025785207748413,
                        "neutral": 0.3827839493751526,
                        "support": 0.014637491665780544
                      },
                      "stance_score": -0.5879410291090608,
                      "evidence_contribution": -0.5111413667507119,
                      "combined_rank_score": 0.8693752288818359
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5998,
                      "faiss_score": 0.9058985114097595,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_evaluation_and_generalization.txt",
                      "file_type": ".txt",
                      "position": 24,
                      "sentence": "When deployment data differs from training data, performance may degrade unpredictably.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.008945327252149582,
                        "neutral": 0.9763994812965393,
                        "support": 0.014655262231826782
                      },
                      "stance_score": 0.0057099349796772,
                      "evidence_contribution": 0.005172621598336091,
                      "combined_rank_score": 0.9058985114097595
                    },
                    {
                      "id": 6436,
                      "faiss_score": 0.8874707221984863,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 175,
                      "sentence": "Memory usage, latency, and throughput must be balanced against accuracy and robustness.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005644329357892275,
                        "neutral": 0.9925962090492249,
                        "support": 0.0017594806849956512
                      },
                      "stance_score": -0.0038848486728966236,
                      "evidence_contribution": -0.0034476894573673977,
                      "combined_rank_score": 0.8874707221984863
                    },
                    {
                      "id": 5769,
                      "faiss_score": 0.8786929249763489,
                      "faiss_rank": 10,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 17,
                      "sentence": "The model memorizes noise rather than structure.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.019698455929756165,
                        "neutral": 0.9747886657714844,
                        "support": 0.005512891802936792
                      },
                      "stance_score": -0.014185564126819372,
                      "evidence_contribution": -0.01246475483503448,
                      "combined_rank_score": 0.8786929249763489
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Quantum error correction enables reliable quantum computation and scalability, but requires many physical qubits, introduces large overhead, limits near-term feasibility, and increases system complexity.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Quantum error correction enables reliable quantum computation",
          "verdict": "CONTRADICT",
          "controversial": true,
          "strengths": {
            "support": 0.8793022954764868,
            "contradict": 2.0263225270052083,
            "total": 2.905624822481695
          },
          "evidence": {
            "supporting": [
              {
                "id": 4795,
                "faiss_score": 0.8979429006576538,
                "faiss_rank": 15,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.018803942948579788,
                  "neutral": 0.6484461426734924,
                  "support": 0.3327498435974121
                },
                "stance_score": 0.3139459006488323,
                "evidence_contribution": 0.2819054926781921,
                "combined_rank_score": 0.8979429006576538
              },
              {
                "id": 6553,
                "faiss_score": 0.9209411144256592,
                "faiss_rank": 1,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.048989973962306976,
                  "neutral": 0.6064528226852417,
                  "support": 0.3445571959018707
                },
                "stance_score": 0.29556722193956375,
                "evidence_contribution": 0.272200006760718,
                "combined_rank_score": 0.9209411144256592
              },
              {
                "id": 4765,
                "faiss_score": 0.8944282531738281,
                "faiss_rank": 18,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 12,
                "sentence": "For QECCs implemented on qubit-based platforms, fault tolerance additionally accounts for imperfect quantum gates, faulty state preparation, and measurement errors.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.0027476276736706495,
                  "neutral": 0.8061369061470032,
                  "support": 0.19111545383930206
                },
                "stance_score": 0.1883678261656314,
                "evidence_contribution": 0.16848150571147702,
                "combined_rank_score": 0.8944282531738281
              },
              {
                "id": 671,
                "faiss_score": 0.9041642546653748,
                "faiss_rank": 6,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Scientists at Harvard University successfully created \"quantum circuits\" that correct errors more efficiently than alternative methods, which may potentially remove a major obstacle to practical quantum computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.01669440232217312,
                  "neutral": 0.793285071849823,
                  "support": 0.19002053141593933
                },
                "stance_score": 0.1733261290937662,
                "evidence_contribution": 0.15671529032609965,
                "combined_rank_score": 0.9041642546653748
              }
            ],
            "contradicting": [
              {
                "id": 6561,
                "faiss_score": 0.8965035080909729,
                "faiss_rank": 17,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Small errors accumulate quickly in quantum circuits, limiting the depth of computations that can be performed reliably.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.958782434463501,
                  "neutral": 0.03789343684911728,
                  "support": 0.0033241594210267067
                },
                "stance_score": -0.9554582750424743,
                "evidence_contribution": -0.8565716954101279,
                "combined_rank_score": 0.8965035080909729
              },
              {
                "id": 4719,
                "faiss_score": 0.9038070440292358,
                "faiss_rank": 9,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.7934035658836365,
                  "neutral": 0.1942514181137085,
                  "support": 0.012345007620751858
                },
                "stance_score": -0.7810585582628846,
                "evidence_contribution": -0.7059262267573144,
                "combined_rank_score": 0.9038070440292358
              },
              {
                "id": 764,
                "faiss_score": 0.8990681171417236,
                "faiss_rank": 13,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 168,
                "sentence": "However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.36493411660194397,
                  "neutral": 0.6159495115280151,
                  "support": 0.01911640353500843
                },
                "stance_score": -0.34581771306693554,
                "evidence_contribution": -0.3109136801613466,
                "combined_rank_score": 0.8990681171417236
              },
              {
                "id": 4764,
                "faiss_score": 0.9096908569335938,
                "faiss_rank": 5,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 11,
                "sentence": "Compared with quantum memory, where channel-induced errors are the primary concern, the frequent application of quantum gates in quantum computation necessitates fault-tolerant design.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.1984490305185318,
                  "neutral": 0.7711930274963379,
                  "support": 0.03035794384777546
                },
                "stance_score": -0.16809108667075634,
                "evidence_contribution": -0.1529109246764193,
                "combined_rank_score": 0.9096908569335938
              }
            ],
            "neutral": [
              {
                "id": 4862,
                "faiss_score": 0.920432448387146,
                "faiss_rank": 2,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 109,
                "sentence": "Quantum error correction can be applied to quantum metrology.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.007816636003553867,
                  "neutral": 0.962035059928894,
                  "support": 0.03014826402068138
                },
                "stance_score": 0.022331628017127514,
                "evidence_contribution": 0.020554755052275664,
                "combined_rank_score": 0.920432448387146
              },
              {
                "id": 6554,
                "faiss_score": 0.9117580652236938,
                "faiss_rank": 3,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007408167701214552,
                  "neutral": 0.9875391721725464,
                  "support": 0.00505262054502964
                },
                "stance_score": -0.0023555471561849117,
                "evidence_contribution": -0.0021476891176663293,
                "combined_rank_score": 0.9117580652236938
              },
              {
                "id": 4866,
                "faiss_score": 0.9103487730026245,
                "faiss_rank": 4,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 113,
                "sentence": "In this scheme, the errors can be detected, and corrected following the general rules of quantum error correction.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.0011656888527795672,
                  "neutral": 0.9959039092063904,
                  "support": 0.0029304130002856255
                },
                "stance_score": 0.0017647241475060582,
                "evidence_contribution": 0.0016065144623702426,
                "combined_rank_score": 0.9103487730026245
              }
            ]
          }
        },
        {
          "subclaim": "Quantum error correction requires many physical qubits",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 3.143359487914476,
            "contradict": 0.5085692523311884,
            "total": 3.6519287402456646
          },
          "evidence": {
            "supporting": [
              {
                "id": 6554,
                "faiss_score": 0.9731938242912292,
                "faiss_rank": 1,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009988424135372043,
                  "neutral": 0.005816575605422258,
                  "support": 0.9931846261024475
                },
                "stance_score": 0.9921857836889103,
                "evidence_contribution": 0.965589077235601,
                "combined_rank_score": 0.9731938242912292
              },
              {
                "id": 4792,
                "faiss_score": 0.9309069514274597,
                "faiss_rank": 2,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 39,
                "sentence": "According to the quantum Hamming bound, encoding a single logical qubit with the ability to correct any single-qubit error requires at least five physical qubits.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.003476664423942566,
                  "neutral": 0.07948478311300278,
                  "support": 0.9170385003089905
                },
                "stance_score": 0.9135618358850479,
                "evidence_contribution": 0.8504410635842232,
                "combined_rank_score": 0.9309069514274597
              },
              {
                "id": 765,
                "faiss_score": 0.9033190608024597,
                "faiss_rank": 13,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 169,
                "sentence": "Careful estimates show that at least 3 million physical qubits would factor 2,048-bit integer in 5 months on a fully error-corrected trapped-ion quantum computer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0012221212964504957,
                  "neutral": 0.220154270529747,
                  "support": 0.7786235809326172
                },
                "stance_score": 0.7774014596361667,
                "evidence_contribution": 0.7022415563850034,
                "combined_rank_score": 0.9033190608024597
              },
              {
                "id": 6555,
                "faiss_score": 0.9088551998138428,
                "faiss_rank": 8,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 15,
                "sentence": "This overhead means that a useful, fault-tolerant quantum computer would need orders of magnitude more qubits than are currently available.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00799689069390297,
                  "neutral": 0.6586214303970337,
                  "support": 0.33338168263435364
                },
                "stance_score": 0.32538479194045067,
                "evidence_contribution": 0.29572766009542395,
                "combined_rank_score": 0.9088551998138428
              },
              {
                "id": 768,
                "faiss_score": 0.9034212827682495,
                "faiss_rank": 11,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 172,
                "sentence": "Implementing 100 logical qubits with 768 cat qubits could reduce the error rate to one part in 108 per cycle per bit.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.040194373577833176,
                  "neutral": 0.7223184704780579,
                  "support": 0.23748718202114105
                },
                "stance_score": 0.19729280844330788,
                "evidence_contribution": 0.17823852208480373,
                "combined_rank_score": 0.9034212827682495
              },
              {
                "id": 4839,
                "faiss_score": 0.8980914354324341,
                "faiss_rank": 17,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 86,
                "sentence": "This challenge is overcome by encoding the logical information of a single qubit into a highly entangled state of multiple physical qubits.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.00503403227776289,
                  "neutral": 0.821662187576294,
                  "support": 0.1733037680387497
                },
                "stance_score": 0.1682697357609868,
                "evidence_contribution": 0.15112160852942103,
                "combined_rank_score": 0.8980914354324341
              }
            ],
            "contradicting": [
              {
                "id": 4774,
                "faiss_score": 0.8971900939941406,
                "faiss_rank": 18,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Consequently, errors on an n-qubit system can be described by a binary string of length 2n, allowing classical error-correction techniques to be applied under suitable constraints.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.44234442710876465,
                  "neutral": 0.5252451300621033,
                  "support": 0.032410457730293274
                },
                "stance_score": -0.4099339693784714,
                "evidence_contribution": -0.3677886965180619,
                "combined_rank_score": 0.8971900939941406
              },
              {
                "id": 4795,
                "faiss_score": 0.8958277702331543,
                "faiss_rank": 19,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.2773669958114624,
                  "neutral": 0.6024173498153687,
                  "support": 0.12021563202142715
                },
                "stance_score": -0.15715136379003525,
                "evidence_contribution": -0.14078055581312654,
                "combined_rank_score": 0.8958277702331543
              }
            ],
            "neutral": [
              {
                "id": 760,
                "faiss_score": 0.9304232597351074,
                "faiss_rank": 3,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 164,
                "sentence": "However, the use of error correction brings with it the cost of a greatly increased number of required qubits.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0037514108698815107,
                  "neutral": 0.9413119554519653,
                  "support": 0.05493664741516113
                },
                "stance_score": 0.05118523654527962,
                "evidence_contribution": 0.047623934636771614,
                "combined_rank_score": 0.9304232597351074
              },
              {
                "id": 6553,
                "faiss_score": 0.9282425045967102,
                "faiss_rank": 5,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001498967525549233,
                  "neutral": 0.9972496628761292,
                  "support": 0.0012513796100392938
                },
                "stance_score": -0.0002475879155099392,
                "evidence_contribution": -0.00022982162680082463,
                "combined_rank_score": 0.9282425045967102
              },
              {
                "id": 4719,
                "faiss_score": 0.9088607430458069,
                "faiss_rank": 6,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.003241618163883686,
                  "neutral": 0.990568220615387,
                  "support": 0.006190212909132242
                },
                "stance_score": 0.002948594745248556,
                "evidence_contribution": 0.0026798620111075644,
                "combined_rank_score": 0.9088607430458069
              }
            ]
          }
        },
        {
          "subclaim": "Quantum error correction introduces large overhead",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 2.7293016151492746,
            "contradict": 0.36964455943774943,
            "total": 3.098946174587024
          },
          "evidence": {
            "supporting": [
              {
                "id": 793,
                "faiss_score": 0.9589597582817078,
                "faiss_rank": 1,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0015836000675335526,
                  "neutral": 0.13629405200481415,
                  "support": 0.8621222972869873
                },
                "stance_score": 0.8605386972194538,
                "evidence_contribution": 0.8252219810776231,
                "combined_rank_score": 0.9589597582817078
              },
              {
                "id": 764,
                "faiss_score": 0.9220078587532043,
                "faiss_rank": 6,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 168,
                "sentence": "However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0018393112113699317,
                  "neutral": 0.101406030356884,
                  "support": 0.8967546820640564
                },
                "stance_score": 0.8949153708526865,
                "evidence_contribution": 0.8251190048452153,
                "combined_rank_score": 0.9220078587532043
              },
              {
                "id": 6553,
                "faiss_score": 0.9579821825027466,
                "faiss_rank": 3,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0016034289728850126,
                  "neutral": 0.17472197115421295,
                  "support": 0.8236745595932007
                },
                "stance_score": 0.8220711306203157,
                "evidence_contribution": 0.7875294958841504,
                "combined_rank_score": 0.9579821825027466
              },
              {
                "id": 760,
                "faiss_score": 0.9312670230865479,
                "faiss_rank": 4,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 164,
                "sentence": "However, the use of error correction brings with it the cost of a greatly increased number of required qubits.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.006438628304749727,
                  "neutral": 0.6741822957992554,
                  "support": 0.3193790912628174
                },
                "stance_score": 0.31294046295806766,
                "evidence_contribution": 0.29143113334228576,
                "combined_rank_score": 0.9312670230865479
              }
            ],
            "contradicting": [
              {
                "id": 4824,
                "faiss_score": 0.8887735605239868,
                "faiss_rank": 18,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 71,
                "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.2573750913143158,
                  "neutral": 0.7392532229423523,
                  "support": 0.00337165012024343
                },
                "stance_score": -0.25400344119407237,
                "evidence_contribution": -0.2257515428154008,
                "combined_rank_score": 0.8887735605239868
              },
              {
                "id": 4795,
                "faiss_score": 0.8939375281333923,
                "faiss_rank": 12,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.1697005182504654,
                  "neutral": 0.8215643763542175,
                  "support": 0.008735112845897675
                },
                "stance_score": -0.16096540540456772,
                "evidence_contribution": -0.14389301662234866,
                "combined_rank_score": 0.8939375281333923
              }
            ],
            "neutral": [
              {
                "id": 6554,
                "faiss_score": 0.9196069836616516,
                "faiss_rank": 8,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002062471816316247,
                  "neutral": 0.9819877743721008,
                  "support": 0.015949703752994537
                },
                "stance_score": 0.01388723193667829,
                "evidence_contribution": 0.012770795472698479,
                "combined_rank_score": 0.9196069836616516
              },
              {
                "id": 6555,
                "faiss_score": 0.9095394611358643,
                "faiss_rank": 9,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 15,
                "sentence": "This overhead means that a useful, fault-tolerant quantum computer would need orders of magnitude more qubits than are currently available.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005107593722641468,
                  "neutral": 0.9913631677627563,
                  "support": 0.003529252950102091
                },
                "stance_score": -0.0015783407725393772,
                "evidence_contribution": -0.0014355632157442288,
                "combined_rank_score": 0.9095394611358643
              },
              {
                "id": 6519,
                "faiss_score": 0.8995538353919983,
                "faiss_rank": 10,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "However, practical quantum systems face substantial obstacles, including noise, error correction, and scalability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0017497721128165722,
                  "neutral": 0.9313904643058777,
                  "support": 0.06685975193977356
                },
                "stance_score": 0.06510997982695699,
                "evidence_contribution": 0.058569932075634795,
                "combined_rank_score": 0.8995538353919983
              }
            ]
          }
        },
        {
          "subclaim": "Quantum error correction limits near-term feasibility",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 2.1064493906821156,
            "contradict": 0.4370688371056931,
            "total": 2.543518227787809
          },
          "evidence": {
            "supporting": [
              {
                "id": 6562,
                "faiss_score": 0.9053820371627808,
                "faiss_rank": 5,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 22,
                "sentence": "This constraint has motivated interest in near-term quantum devices that operate without full error correction, often referred to as noisy intermediate-scale quantum systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.03480833023786545,
                  "neutral": 0.36403393745422363,
                  "support": 0.6011576652526855
                },
                "stance_score": 0.5663493350148201,
                "evidence_contribution": 0.512762514681504,
                "combined_rank_score": 0.9053820371627808
              },
              {
                "id": 669,
                "faiss_score": 0.8864734172821045,
                "faiss_rank": 18,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 73,
                "sentence": "The threshold theorem shows how increasing the number of qubits can mitigate errors, yet fully fault-tolerant quantum computing remains \"a rather distant dream\".",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.007670248858630657,
                  "neutral": 0.41306838393211365,
                  "support": 0.5792613625526428
                },
                "stance_score": 0.5715911136940122,
                "evidence_contribution": 0.5067003278444149,
                "combined_rank_score": 0.8864734172821045
              },
              {
                "id": 6561,
                "faiss_score": 0.9045618176460266,
                "faiss_rank": 6,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Small errors accumulate quickly in quantum circuits, limiting the depth of computations that can be performed reliably.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.018533242866396904,
                  "neutral": 0.6083608269691467,
                  "support": 0.3731059432029724
                },
                "stance_score": 0.3545727003365755,
                "evidence_contribution": 0.32073292630411265,
                "combined_rank_score": 0.9045618176460266
              },
              {
                "id": 793,
                "faiss_score": 0.9205553531646729,
                "faiss_rank": 2,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.006018023006618023,
                  "neutral": 0.7036983370780945,
                  "support": 0.29028359055519104
                },
                "stance_score": 0.284265567548573,
                "evidence_contribution": 0.2616821899272328,
                "combined_rank_score": 0.9205553531646729
              },
              {
                "id": 6553,
                "faiss_score": 0.9212385416030884,
                "faiss_rank": 1,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.06996207684278488,
                  "neutral": 0.5819587111473083,
                  "support": 0.34807923436164856
                },
                "stance_score": 0.2781171575188637,
                "evidence_contribution": 0.2562122445874744,
                "combined_rank_score": 0.9212385416030884
              },
              {
                "id": 6519,
                "faiss_score": 0.9157370328903198,
                "faiss_rank": 4,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "However, practical quantum systems face substantial obstacles, including noise, error correction, and scalability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0018688690615817904,
                  "neutral": 0.7250498533248901,
                  "support": 0.2730812132358551
                },
                "stance_score": 0.2712123441742733,
                "evidence_contribution": 0.24835918733737727,
                "combined_rank_score": 0.9157370328903198
              }
            ],
            "contradicting": [
              {
                "id": 4795,
                "faiss_score": 0.8939117193222046,
                "faiss_rank": 10,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.3718124032020569,
                  "neutral": 0.5707080364227295,
                  "support": 0.057479534298181534
                },
                "stance_score": -0.31433286890387535,
                "evidence_contribution": -0.28098583528134435,
                "combined_rank_score": 0.8939117193222046
              },
              {
                "id": 4824,
                "faiss_score": 0.8983690738677979,
                "faiss_rank": 8,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 71,
                "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.1801389753818512,
                  "neutral": 0.813462495803833,
                  "support": 0.006398575846105814
                },
                "stance_score": -0.17374039953574538,
                "evidence_contribution": -0.15608300182434875,
                "combined_rank_score": 0.8983690738677979
              }
            ],
            "neutral": [
              {
                "id": 6554,
                "faiss_score": 0.8998539447784424,
                "faiss_rank": 7,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0015734165208414197,
                  "neutral": 0.9968135952949524,
                  "support": 0.0016129479045048356
                },
                "stance_score": 3.953138366341591e-05,
                "evidence_contribution": 3.557247153207488e-05,
                "combined_rank_score": 0.8998539447784424
              },
              {
                "id": 6576,
                "faiss_score": 0.8960012197494507,
                "faiss_rank": 9,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 36,
                "sentence": "Timelines for large-scale quantum computing remain highly uncertain.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0051073054783046246,
                  "neutral": 0.990530788898468,
                  "support": 0.004361878149211407
                },
                "stance_score": -0.0007454273290932178,
                "evidence_contribution": -0.0006679037961020984,
                "combined_rank_score": 0.8960012197494507
              },
              {
                "id": 4862,
                "faiss_score": 0.8929986357688904,
                "faiss_rank": 11,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 109,
                "sentence": "Quantum error correction can be applied to quantum metrology.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.0033798974473029375,
                  "neutral": 0.9954323768615723,
                  "support": 0.0011877332581207156
                },
                "stance_score": -0.002192164189182222,
                "evidence_contribution": -0.00195759963032114,
                "combined_rank_score": 0.8929986357688904
              }
            ]
          }
        },
        {
          "subclaim": "Quantum error correction increases system complexity",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 1.4384038630233538,
            "contradict": 0.830016918139345,
            "total": 2.268420781162699
          },
          "evidence": {
            "supporting": [
              {
                "id": 764,
                "faiss_score": 0.9119178056716919,
                "faiss_rank": 7,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 168,
                "sentence": "However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.007853573188185692,
                  "neutral": 0.3639184236526489,
                  "support": 0.6282280087471008
                },
                "stance_score": 0.6203744355589151,
                "evidence_contribution": 0.5657304939697003,
                "combined_rank_score": 0.9119178056716919
              },
              {
                "id": 793,
                "faiss_score": 0.9260589480400085,
                "faiss_rank": 4,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.025753580033779144,
                  "neutral": 0.47671034932136536,
                  "support": 0.4975360333919525
                },
                "stance_score": 0.47178245335817337,
                "evidence_contribution": 0.43689836246060443,
                "combined_rank_score": 0.9260589480400085
              },
              {
                "id": 760,
                "faiss_score": 0.9287818670272827,
                "faiss_rank": 1,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 164,
                "sentence": "However, the use of error correction brings with it the cost of a greatly increased number of required qubits.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.008020526729524136,
                  "neutral": 0.6548252701759338,
                  "support": 0.33715423941612244
                },
                "stance_score": 0.3291337126865983,
                "evidence_contribution": 0.30569342417068,
                "combined_rank_score": 0.9287818670272827
              },
              {
                "id": 6552,
                "faiss_score": 0.8881083726882935,
                "faiss_rank": 20,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "As a result, maintaining coherent qubit states for long periods is difficult, especially as system size increases.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007358034141361713,
                  "neutral": 0.8388134837150574,
                  "support": 0.153828427195549
                },
                "stance_score": 0.1464703930541873,
                "evidence_contribution": 0.130081582422369,
                "combined_rank_score": 0.8881083726882935
              }
            ],
            "contradicting": [
              {
                "id": 757,
                "faiss_score": 0.8908348679542542,
                "faiss_rank": 12,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 161,
                "sentence": "This allows the total calculation time to be longer than the decoherence time if the error correction scheme can correct errors faster than decoherence introduces them.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.5106908082962036,
                  "neutral": 0.4831364154815674,
                  "support": 0.006172753404825926
                },
                "stance_score": -0.5045180548913777,
                "evidence_contribution": -0.44944227480969756,
                "combined_rank_score": 0.8908348679542542
              },
              {
                "id": 4842,
                "faiss_score": 0.8927061557769775,
                "faiss_rank": 11,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 89,
                "sentence": "We can however improve on this number by encoding the state into a greater number of qubits, in such a way that errors in the corresponding logical qubits can be detected and corrected.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.19818539917469025,
                  "neutral": 0.796204149723053,
                  "support": 0.005610405933111906
                },
                "stance_score": -0.19257499324157834,
                "evidence_contribution": -0.17191288191546683,
                "combined_rank_score": 0.8927061557769775
              },
              {
                "id": 4862,
                "faiss_score": 0.8882696628570557,
                "faiss_rank": 18,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 109,
                "sentence": "Quantum error correction can be applied to quantum metrology.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.12550652027130127,
                  "neutral": 0.870574414730072,
                  "support": 0.00391906825825572
                },
                "stance_score": -0.12158745201304555,
                "evidence_contribution": -0.1080024450072764,
                "combined_rank_score": 0.8882696628570557
              },
              {
                "id": 4786,
                "faiss_score": 0.8890231847763062,
                "faiss_rank": 15,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 33,
                "sentence": "It states that errors can be corrected by recursively concatenating quantum codes\u2014such as CSS codes\u2014across logarithmically many levels, provided the error rate of individual quantum gates remains below a certain threshold.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.11752313375473022,
                  "neutral": 0.8781783580780029,
                  "support": 0.00429850909858942
                },
                "stance_score": -0.1132246246561408,
                "evidence_contribution": -0.10065931640690418,
                "combined_rank_score": 0.8890231847763062
              }
            ],
            "neutral": [
              {
                "id": 6553,
                "faiss_score": 0.9282435178756714,
                "faiss_rank": 3,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.12731100618839264,
                  "neutral": 0.6538717150688171,
                  "support": 0.21881726384162903
                },
                "stance_score": 0.09150625765323639,
                "evidence_contribution": 0.08494009051167772,
                "combined_rank_score": 0.9282435178756714
              },
              {
                "id": 6554,
                "faiss_score": 0.9244345426559448,
                "faiss_rank": 6,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007600029930472374,
                  "neutral": 0.9813321828842163,
                  "support": 0.0110678281635046
                },
                "stance_score": 0.0034677982330322266,
                "evidence_contribution": 0.00320575247357624,
                "combined_rank_score": 0.9244345426559448
              },
              {
                "id": 6519,
                "faiss_score": 0.9061214923858643,
                "faiss_rank": 9,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "However, practical quantum systems face substantial obstacles, including noise, error correction, and scalability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004262776114046574,
                  "neutral": 0.9861917495727539,
                  "support": 0.009545507840812206
                },
                "stance_score": 0.005282731726765633,
                "evidence_contribution": 0.004786796756131029,
                "combined_rank_score": 0.9061214923858643
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Quantum error correction requires many physical qubits",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6554,
                      "faiss_score": 0.9731938242912292,
                      "faiss_rank": 1,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0009988424135372043,
                        "neutral": 0.005816575605422258,
                        "support": 0.9931846261024475
                      },
                      "stance_score": 0.9921857836889103,
                      "evidence_contribution": 0.965589077235601,
                      "combined_rank_score": 0.9731938242912292
                    },
                    {
                      "id": 4792,
                      "faiss_score": 0.9309069514274597,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "According to the quantum Hamming bound, encoding a single logical qubit with the ability to correct any single-qubit error requires at least five physical qubits.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.003476664423942566,
                        "neutral": 0.07948478311300278,
                        "support": 0.9170385003089905
                      },
                      "stance_score": 0.9135618358850479,
                      "evidence_contribution": 0.8504410635842232,
                      "combined_rank_score": 0.9309069514274597
                    },
                    {
                      "id": 6555,
                      "faiss_score": 0.9088551998138428,
                      "faiss_rank": 8,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 15,
                      "sentence": "This overhead means that a useful, fault-tolerant quantum computer would need orders of magnitude more qubits than are currently available.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.00799689069390297,
                        "neutral": 0.6586214303970337,
                        "support": 0.33338168263435364
                      },
                      "stance_score": 0.32538479194045067,
                      "evidence_contribution": 0.29572766009542395,
                      "combined_rank_score": 0.9088551998138428
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 4774,
                      "faiss_score": 0.8971900939941406,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "Consequently, errors on an n-qubit system can be described by a binary string of length 2n, allowing classical error-correction techniques to be applied under suitable constraints.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.44234442710876465,
                        "neutral": 0.5252451300621033,
                        "support": 0.032410457730293274
                      },
                      "stance_score": -0.4099339693784714,
                      "evidence_contribution": -0.3677886965180619,
                      "combined_rank_score": 0.8971900939941406
                    },
                    {
                      "id": 4795,
                      "faiss_score": 0.8958277702331543,
                      "faiss_rank": 19,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.2773669958114624,
                        "neutral": 0.6024173498153687,
                        "support": 0.12021563202142715
                      },
                      "stance_score": -0.15715136379003525,
                      "evidence_contribution": -0.14078055581312654,
                      "combined_rank_score": 0.8958277702331543
                    }
                  ],
                  "neutral": [
                    {
                      "id": 760,
                      "faiss_score": 0.9304232597351074,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 164,
                      "sentence": "However, the use of error correction brings with it the cost of a greatly increased number of required qubits.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.0037514108698815107,
                        "neutral": 0.9413119554519653,
                        "support": 0.05493664741516113
                      },
                      "stance_score": 0.05118523654527962,
                      "evidence_contribution": 0.047623934636771614,
                      "combined_rank_score": 0.9304232597351074
                    },
                    {
                      "id": 6553,
                      "faiss_score": 0.9282425045967102,
                      "faiss_rank": 5,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001498967525549233,
                        "neutral": 0.9972496628761292,
                        "support": 0.0012513796100392938
                      },
                      "stance_score": -0.0002475879155099392,
                      "evidence_contribution": -0.00022982162680082463,
                      "combined_rank_score": 0.9282425045967102
                    },
                    {
                      "id": 4719,
                      "faiss_score": 0.9088607430458069,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.003241618163883686,
                        "neutral": 0.990568220615387,
                        "support": 0.006190212909132242
                      },
                      "stance_score": 0.002948594745248556,
                      "evidence_contribution": 0.0026798620111075644,
                      "combined_rank_score": 0.9088607430458069
                    }
                  ]
                }
              },
              {
                "subclaim": "Quantum error correction introduces large overhead",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 793,
                      "faiss_score": 0.9589597582817078,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.0015836000675335526,
                        "neutral": 0.13629405200481415,
                        "support": 0.8621222972869873
                      },
                      "stance_score": 0.8605386972194538,
                      "evidence_contribution": 0.8252219810776231,
                      "combined_rank_score": 0.9589597582817078
                    },
                    {
                      "id": 6553,
                      "faiss_score": 0.9579821825027466,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0016034289728850126,
                        "neutral": 0.17472197115421295,
                        "support": 0.8236745595932007
                      },
                      "stance_score": 0.8220711306203157,
                      "evidence_contribution": 0.7875294958841504,
                      "combined_rank_score": 0.9579821825027466
                    },
                    {
                      "id": 760,
                      "faiss_score": 0.9312670230865479,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 164,
                      "sentence": "However, the use of error correction brings with it the cost of a greatly increased number of required qubits.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.006438628304749727,
                        "neutral": 0.6741822957992554,
                        "support": 0.3193790912628174
                      },
                      "stance_score": 0.31294046295806766,
                      "evidence_contribution": 0.29143113334228576,
                      "combined_rank_score": 0.9312670230865479
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 4795,
                      "faiss_score": 0.8939375281333923,
                      "faiss_rank": 12,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.1697005182504654,
                        "neutral": 0.8215643763542175,
                        "support": 0.008735112845897675
                      },
                      "stance_score": -0.16096540540456772,
                      "evidence_contribution": -0.14389301662234866,
                      "combined_rank_score": 0.8939375281333923
                    },
                    {
                      "id": 4824,
                      "faiss_score": 0.8887735605239868,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 71,
                      "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.2573750913143158,
                        "neutral": 0.7392532229423523,
                        "support": 0.00337165012024343
                      },
                      "stance_score": -0.25400344119407237,
                      "evidence_contribution": -0.2257515428154008,
                      "combined_rank_score": 0.8887735605239868
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6554,
                      "faiss_score": 0.9196069836616516,
                      "faiss_rank": 8,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.002062471816316247,
                        "neutral": 0.9819877743721008,
                        "support": 0.015949703752994537
                      },
                      "stance_score": 0.01388723193667829,
                      "evidence_contribution": 0.012770795472698479,
                      "combined_rank_score": 0.9196069836616516
                    },
                    {
                      "id": 6555,
                      "faiss_score": 0.9095394611358643,
                      "faiss_rank": 9,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 15,
                      "sentence": "This overhead means that a useful, fault-tolerant quantum computer would need orders of magnitude more qubits than are currently available.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005107593722641468,
                        "neutral": 0.9913631677627563,
                        "support": 0.003529252950102091
                      },
                      "stance_score": -0.0015783407725393772,
                      "evidence_contribution": -0.0014355632157442288,
                      "combined_rank_score": 0.9095394611358643
                    },
                    {
                      "id": 6519,
                      "faiss_score": 0.8995538353919983,
                      "faiss_rank": 10,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 48,
                      "sentence": "However, practical quantum systems face substantial obstacles, including noise, error correction, and scalability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0017497721128165722,
                        "neutral": 0.9313904643058777,
                        "support": 0.06685975193977356
                      },
                      "stance_score": 0.06510997982695699,
                      "evidence_contribution": 0.058569932075634795,
                      "combined_rank_score": 0.8995538353919983
                    }
                  ]
                }
              },
              {
                "subclaim": "Quantum error correction limits near-term feasibility",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6553,
                      "faiss_score": 0.9212385416030884,
                      "faiss_rank": 1,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.06996207684278488,
                        "neutral": 0.5819587111473083,
                        "support": 0.34807923436164856
                      },
                      "stance_score": 0.2781171575188637,
                      "evidence_contribution": 0.2562122445874744,
                      "combined_rank_score": 0.9212385416030884
                    },
                    {
                      "id": 793,
                      "faiss_score": 0.9205553531646729,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.006018023006618023,
                        "neutral": 0.7036983370780945,
                        "support": 0.29028359055519104
                      },
                      "stance_score": 0.284265567548573,
                      "evidence_contribution": 0.2616821899272328,
                      "combined_rank_score": 0.9205553531646729
                    },
                    {
                      "id": 6519,
                      "faiss_score": 0.9157370328903198,
                      "faiss_rank": 4,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 48,
                      "sentence": "However, practical quantum systems face substantial obstacles, including noise, error correction, and scalability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0018688690615817904,
                        "neutral": 0.7250498533248901,
                        "support": 0.2730812132358551
                      },
                      "stance_score": 0.2712123441742733,
                      "evidence_contribution": 0.24835918733737727,
                      "combined_rank_score": 0.9157370328903198
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 4824,
                      "faiss_score": 0.8983690738677979,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 71,
                      "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.1801389753818512,
                        "neutral": 0.813462495803833,
                        "support": 0.006398575846105814
                      },
                      "stance_score": -0.17374039953574538,
                      "evidence_contribution": -0.15608300182434875,
                      "combined_rank_score": 0.8983690738677979
                    },
                    {
                      "id": 4795,
                      "faiss_score": 0.8939117193222046,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.3718124032020569,
                        "neutral": 0.5707080364227295,
                        "support": 0.057479534298181534
                      },
                      "stance_score": -0.31433286890387535,
                      "evidence_contribution": -0.28098583528134435,
                      "combined_rank_score": 0.8939117193222046
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6554,
                      "faiss_score": 0.8998539447784424,
                      "faiss_rank": 7,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0015734165208414197,
                        "neutral": 0.9968135952949524,
                        "support": 0.0016129479045048356
                      },
                      "stance_score": 3.953138366341591e-05,
                      "evidence_contribution": 3.557247153207488e-05,
                      "combined_rank_score": 0.8998539447784424
                    },
                    {
                      "id": 6576,
                      "faiss_score": 0.8960012197494507,
                      "faiss_rank": 9,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 36,
                      "sentence": "Timelines for large-scale quantum computing remain highly uncertain.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0051073054783046246,
                        "neutral": 0.990530788898468,
                        "support": 0.004361878149211407
                      },
                      "stance_score": -0.0007454273290932178,
                      "evidence_contribution": -0.0006679037961020984,
                      "combined_rank_score": 0.8960012197494507
                    },
                    {
                      "id": 4862,
                      "faiss_score": 0.8929986357688904,
                      "faiss_rank": 11,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 109,
                      "sentence": "Quantum error correction can be applied to quantum metrology.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.0033798974473029375,
                        "neutral": 0.9954323768615723,
                        "support": 0.0011877332581207156
                      },
                      "stance_score": -0.002192164189182222,
                      "evidence_contribution": -0.00195759963032114,
                      "combined_rank_score": 0.8929986357688904
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Quantum error correction enables reliable quantum computation",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6553,
                      "faiss_score": 0.9209411144256592,
                      "faiss_rank": 1,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.048989973962306976,
                        "neutral": 0.6064528226852417,
                        "support": 0.3445571959018707
                      },
                      "stance_score": 0.29556722193956375,
                      "evidence_contribution": 0.272200006760718,
                      "combined_rank_score": 0.9209411144256592
                    },
                    {
                      "id": 671,
                      "faiss_score": 0.9041642546653748,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "Scientists at Harvard University successfully created \"quantum circuits\" that correct errors more efficiently than alternative methods, which may potentially remove a major obstacle to practical quantum computers.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.01669440232217312,
                        "neutral": 0.793285071849823,
                        "support": 0.19002053141593933
                      },
                      "stance_score": 0.1733261290937662,
                      "evidence_contribution": 0.15671529032609965,
                      "combined_rank_score": 0.9041642546653748
                    },
                    {
                      "id": 4795,
                      "faiss_score": 0.8979429006576538,
                      "faiss_rank": 15,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.018803942948579788,
                        "neutral": 0.6484461426734924,
                        "support": 0.3327498435974121
                      },
                      "stance_score": 0.3139459006488323,
                      "evidence_contribution": 0.2819054926781921,
                      "combined_rank_score": 0.8979429006576538
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 4764,
                      "faiss_score": 0.9096908569335938,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 11,
                      "sentence": "Compared with quantum memory, where channel-induced errors are the primary concern, the frequent application of quantum gates in quantum computation necessitates fault-tolerant design.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.1984490305185318,
                        "neutral": 0.7711930274963379,
                        "support": 0.03035794384777546
                      },
                      "stance_score": -0.16809108667075634,
                      "evidence_contribution": -0.1529109246764193,
                      "combined_rank_score": 0.9096908569335938
                    },
                    {
                      "id": 4719,
                      "faiss_score": 0.9038070440292358,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.7934035658836365,
                        "neutral": 0.1942514181137085,
                        "support": 0.012345007620751858
                      },
                      "stance_score": -0.7810585582628846,
                      "evidence_contribution": -0.7059262267573144,
                      "combined_rank_score": 0.9038070440292358
                    },
                    {
                      "id": 764,
                      "faiss_score": 0.8990681171417236,
                      "faiss_rank": 13,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 168,
                      "sentence": "However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.36493411660194397,
                        "neutral": 0.6159495115280151,
                        "support": 0.01911640353500843
                      },
                      "stance_score": -0.34581771306693554,
                      "evidence_contribution": -0.3109136801613466,
                      "combined_rank_score": 0.8990681171417236
                    }
                  ],
                  "neutral": [
                    {
                      "id": 4862,
                      "faiss_score": 0.920432448387146,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 109,
                      "sentence": "Quantum error correction can be applied to quantum metrology.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.007816636003553867,
                        "neutral": 0.962035059928894,
                        "support": 0.03014826402068138
                      },
                      "stance_score": 0.022331628017127514,
                      "evidence_contribution": 0.020554755052275664,
                      "combined_rank_score": 0.920432448387146
                    },
                    {
                      "id": 6554,
                      "faiss_score": 0.9117580652236938,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.007408167701214552,
                        "neutral": 0.9875391721725464,
                        "support": 0.00505262054502964
                      },
                      "stance_score": -0.0023555471561849117,
                      "evidence_contribution": -0.0021476891176663293,
                      "combined_rank_score": 0.9117580652236938
                    },
                    {
                      "id": 4866,
                      "faiss_score": 0.9103487730026245,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 113,
                      "sentence": "In this scheme, the errors can be detected, and corrected following the general rules of quantum error correction.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.0011656888527795672,
                        "neutral": 0.9959039092063904,
                        "support": 0.0029304130002856255
                      },
                      "stance_score": 0.0017647241475060582,
                      "evidence_contribution": 0.0016065144623702426,
                      "combined_rank_score": 0.9103487730026245
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Quantum error correction increases system complexity",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 760,
                      "faiss_score": 0.9287818670272827,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 164,
                      "sentence": "However, the use of error correction brings with it the cost of a greatly increased number of required qubits.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.008020526729524136,
                        "neutral": 0.6548252701759338,
                        "support": 0.33715423941612244
                      },
                      "stance_score": 0.3291337126865983,
                      "evidence_contribution": 0.30569342417068,
                      "combined_rank_score": 0.9287818670272827
                    },
                    {
                      "id": 793,
                      "faiss_score": 0.9260589480400085,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.025753580033779144,
                        "neutral": 0.47671034932136536,
                        "support": 0.4975360333919525
                      },
                      "stance_score": 0.47178245335817337,
                      "evidence_contribution": 0.43689836246060443,
                      "combined_rank_score": 0.9260589480400085
                    },
                    {
                      "id": 764,
                      "faiss_score": 0.9119178056716919,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 168,
                      "sentence": "However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.007853573188185692,
                        "neutral": 0.3639184236526489,
                        "support": 0.6282280087471008
                      },
                      "stance_score": 0.6203744355589151,
                      "evidence_contribution": 0.5657304939697003,
                      "combined_rank_score": 0.9119178056716919
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 4842,
                      "faiss_score": 0.8927061557769775,
                      "faiss_rank": 11,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 89,
                      "sentence": "We can however improve on this number by encoding the state into a greater number of qubits, in such a way that errors in the corresponding logical qubits can be detected and corrected.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.19818539917469025,
                        "neutral": 0.796204149723053,
                        "support": 0.005610405933111906
                      },
                      "stance_score": -0.19257499324157834,
                      "evidence_contribution": -0.17191288191546683,
                      "combined_rank_score": 0.8927061557769775
                    },
                    {
                      "id": 757,
                      "faiss_score": 0.8908348679542542,
                      "faiss_rank": 12,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 161,
                      "sentence": "This allows the total calculation time to be longer than the decoherence time if the error correction scheme can correct errors faster than decoherence introduces them.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.5106908082962036,
                        "neutral": 0.4831364154815674,
                        "support": 0.006172753404825926
                      },
                      "stance_score": -0.5045180548913777,
                      "evidence_contribution": -0.44944227480969756,
                      "combined_rank_score": 0.8908348679542542
                    },
                    {
                      "id": 4786,
                      "faiss_score": 0.8890231847763062,
                      "faiss_rank": 15,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 33,
                      "sentence": "It states that errors can be corrected by recursively concatenating quantum codes\u2014such as CSS codes\u2014across logarithmically many levels, provided the error rate of individual quantum gates remains below a certain threshold.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.11752313375473022,
                        "neutral": 0.8781783580780029,
                        "support": 0.00429850909858942
                      },
                      "stance_score": -0.1132246246561408,
                      "evidence_contribution": -0.10065931640690418,
                      "combined_rank_score": 0.8890231847763062
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6553,
                      "faiss_score": 0.9282435178756714,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.12731100618839264,
                        "neutral": 0.6538717150688171,
                        "support": 0.21881726384162903
                      },
                      "stance_score": 0.09150625765323639,
                      "evidence_contribution": 0.08494009051167772,
                      "combined_rank_score": 0.9282435178756714
                    },
                    {
                      "id": 6554,
                      "faiss_score": 0.9244345426559448,
                      "faiss_rank": 6,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.007600029930472374,
                        "neutral": 0.9813321828842163,
                        "support": 0.0110678281635046
                      },
                      "stance_score": 0.0034677982330322266,
                      "evidence_contribution": 0.00320575247357624,
                      "combined_rank_score": 0.9244345426559448
                    },
                    {
                      "id": 6519,
                      "faiss_score": 0.9061214923858643,
                      "faiss_rank": 9,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 48,
                      "sentence": "However, practical quantum systems face substantial obstacles, including noise, error correction, and scalability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004262776114046574,
                        "neutral": 0.9861917495727539,
                        "support": 0.009545507840812206
                      },
                      "stance_score": 0.005282731726765633,
                      "evidence_contribution": 0.004786796756131029,
                      "combined_rank_score": 0.9061214923858643
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Large language models generate fluent text, perform many tasks, and generalize across domains, but hallucinate facts, encode societal biases, lack grounded reasoning, and require massive datasets.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Large language models generate fluent text",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.30059383234981585,
            "contradict": 3.347856992412601,
            "total": 3.648450824762417
          },
          "evidence": {
            "supporting": [
              {
                "id": 6042,
                "faiss_score": 0.8820071816444397,
                "faiss_rank": 8,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "This simple training signal, when combined with large datasets and high model capacity, produces systems that can generate coherent text, answer questions, summarize documents, and perform a wide variety of language-related tasks without explicit task-specific programming.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.008569732308387756,
                  "neutral": 0.6420539617538452,
                  "support": 0.34937629103660583
                },
                "stance_score": 0.3408065587282181,
                "evidence_contribution": 0.30059383234981585,
                "combined_rank_score": 0.8820071816444397
              }
            ],
            "contradicting": [
              {
                "id": 6072,
                "faiss_score": 0.8710505366325378,
                "faiss_rank": 17,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 32,
                "sentence": "Another limitation of large language models is their lack of persistent memory beyond the context window.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.8763479590415955,
                  "neutral": 0.11980066448450089,
                  "support": 0.003851353656500578
                },
                "stance_score": -0.8724966053850949,
                "evidence_contribution": -0.7599886363307545,
                "combined_rank_score": 0.8710505366325378
              },
              {
                "id": 2011,
                "faiss_score": 0.8802152872085571,
                "faiss_rank": 9,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 279,
                "sentence": "The incorrect completions were generated by sampling from a language model.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.8098839521408081,
                  "neutral": 0.18671365082263947,
                  "support": 0.003402373054996133
                },
                "stance_score": -0.806481579085812,
                "evidence_contribution": -0.7098774147634287,
                "combined_rank_score": 0.8802152872085571
              },
              {
                "id": 2020,
                "faiss_score": 0.872475266456604,
                "faiss_rank": 15,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 288,
                "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.6882504224777222,
                  "neutral": 0.30820220708847046,
                  "support": 0.0035474055912345648
                },
                "stance_score": -0.6847030168864876,
                "evidence_contribution": -0.5973864471016789,
                "combined_rank_score": 0.872475266456604
              },
              {
                "id": 6121,
                "faiss_score": 0.9008355140686035,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3488886058330536,
                  "neutral": 0.6439270973205566,
                  "support": 0.00718427961692214
                },
                "stance_score": -0.34170432621613145,
                "evidence_contribution": -0.30781939236637457,
                "combined_rank_score": 0.9008355140686035
              },
              {
                "id": 6050,
                "faiss_score": 0.8771013021469116,
                "faiss_rank": 12,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 10,
                "sentence": "When generating text, the model selects outputs based on likelihoods learned during training, which means that fluency does not guarantee correctness.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.35186097025871277,
                  "neutral": 0.6431497931480408,
                  "support": 0.004989230073988438
                },
                "stance_score": -0.34687174018472433,
                "evidence_contribution": -0.3042416549939869,
                "combined_rank_score": 0.8771013021469116
              },
              {
                "id": 6092,
                "faiss_score": 0.8773564696311951,
                "faiss_rank": 11,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.29577165842056274,
                  "neutral": 0.6983305215835571,
                  "support": 0.005897819064557552
                },
                "stance_score": -0.2898738393560052,
                "evidence_contribution": -0.2543226883358249,
                "combined_rank_score": 0.8773564696311951
              },
              {
                "id": 6102,
                "faiss_score": 0.8786517381668091,
                "faiss_rank": 10,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 62,
                "sentence": "Evaluation of large language models presents its own challenges.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.19376330077648163,
                  "neutral": 0.7993516325950623,
                  "support": 0.006885080598294735
                },
                "stance_score": -0.1868782201781869,
                "evidence_contribution": -0.16420087298508357,
                "combined_rank_score": 0.8786517381668091
              },
              {
                "id": 6047,
                "faiss_score": 0.8832986354827881,
                "faiss_rank": 7,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Despite these capabilities, the behavior of large language models remains fundamentally probabilistic.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.18742139637470245,
                  "neutral": 0.8073830604553223,
                  "support": 0.005195515230298042
                },
                "stance_score": -0.1822258811444044,
                "evidence_contribution": -0.16095987216450114,
                "combined_rank_score": 0.8832986354827881
              },
              {
                "id": 6067,
                "faiss_score": 0.8767494559288025,
                "faiss_rank": 14,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Large language models are also sensitive to the distribution of their training data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.10843688994646072,
                  "neutral": 0.8847060203552246,
                  "support": 0.006857113912701607
                },
                "stance_score": -0.10157977603375912,
                "evidence_contribution": -0.08906001337096792,
                "combined_rank_score": 0.8767494559288025
              }
            ],
            "neutral": [
              {
                "id": 6040,
                "faiss_score": 0.9094253778457642,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.01122680027037859,
                  "neutral": 0.9780644178390503,
                  "support": 0.010708799585700035
                },
                "stance_score": -0.0005180006846785545,
                "evidence_contribution": -0.000471082968388159,
                "combined_rank_score": 0.9094253778457642
              },
              {
                "id": 6043,
                "faiss_score": 0.8940900564193726,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.06802935898303986,
                  "neutral": 0.9228030443191528,
                  "support": 0.009167566895484924
                },
                "stance_score": -0.05886179208755493,
                "evidence_contribution": -0.052627743008507366,
                "combined_rank_score": 0.8940900564193726
              },
              {
                "id": 6115,
                "faiss_score": 0.8894862532615662,
                "faiss_rank": 4,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Large language models also influence how users interact with technology.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.021805865690112114,
                  "neutral": 0.9743995666503906,
                  "support": 0.0037945706862956285
                },
                "stance_score": -0.018011295003816485,
                "evidence_contribution": -0.01602079930933349,
                "combined_rank_score": 0.8894862532615662
              }
            ]
          }
        },
        {
          "subclaim": "perform many tasks",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 5.895832993527951,
            "contradict": 0.0,
            "total": 5.895832993527951
          },
          "evidence": {
            "supporting": [
              {
                "id": 3888,
                "faiss_score": 0.8647795915603638,
                "faiss_rank": 3,
                "doc_id": "wiki_Latency_(engineering)",
                "file_type": ".txt",
                "position": 57,
                "sentence": "In the context of computer multitasking, the execution of the process can be postponed if other processes are also executing.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Latency_(engineering)",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.002972701331600547,
                  "neutral": 0.20477400720119476,
                  "support": 0.792253315448761
                },
                "stance_score": 0.7892806141171604,
                "evidence_contribution": 0.6825537671027511,
                "combined_rank_score": 0.8647795915603638
              },
              {
                "id": 6166,
                "faiss_score": 0.8380985856056213,
                "faiss_rank": 14,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Data ingestion, storage, preprocessing, training, evaluation, and deployment must all operate at scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001423306530341506,
                  "neutral": 0.22919942438602448,
                  "support": 0.7693772912025452
                },
                "stance_score": 0.7679539846722037,
                "evidence_contribution": 0.6436211483639749,
                "combined_rank_score": 0.8380985856056213
              },
              {
                "id": 6707,
                "faiss_score": 0.8720545768737793,
                "faiss_rank": 1,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Some workloads consist of many small, independent requests, while others involve long-running operations.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0020800072234123945,
                  "neutral": 0.29610347747802734,
                  "support": 0.7018164396286011
                },
                "stance_score": 0.6997364324051887,
                "evidence_contribution": 0.6102083584842747,
                "combined_rank_score": 0.8720545768737793
              },
              {
                "id": 6684,
                "faiss_score": 0.8688691258430481,
                "faiss_rank": 2,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 16,
                "sentence": "By distributing work across multiple processors or machines, systems can handle more requests concurrently.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0014955847291275859,
                  "neutral": 0.36917710304260254,
                  "support": 0.6293273568153381
                },
                "stance_score": 0.6278317720862105,
                "evidence_contribution": 0.5455036429890375,
                "combined_rank_score": 0.8688691258430481
              },
              {
                "id": 5648,
                "faiss_score": 0.8359513282775879,
                "faiss_rank": 20,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 51,
                "sentence": "Modern systems operate at global scale, supporting millions of users and handling diverse workloads.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0011182717280462384,
                  "neutral": 0.3523786664009094,
                  "support": 0.6465030908584595
                },
                "stance_score": 0.6453848191304132,
                "evidence_contribution": 0.5395102968022598,
                "combined_rank_score": 0.8359513282775879
              },
              {
                "id": 6676,
                "faiss_score": 0.8492976427078247,
                "faiss_rank": 6,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "By grouping multiple requests together, a system can process them more efficiently, amortizing overhead across many operations.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0035567604936659336,
                  "neutral": 0.4435800611972809,
                  "support": 0.5528631210327148
                },
                "stance_score": 0.5493063605390489,
                "evidence_contribution": 0.4665245971302287,
                "combined_rank_score": 0.8492976427078247
              },
              {
                "id": 6672,
                "faiss_score": 0.8468485474586487,
                "faiss_rank": 7,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Faster execution reduces waiting time and allows more work to be completed.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0016028325771912932,
                  "neutral": 0.4825626611709595,
                  "support": 0.5158345103263855
                },
                "stance_score": 0.5142316777491942,
                "evidence_contribution": 0.43547634935912904,
                "combined_rank_score": 0.8468485474586487
              },
              {
                "id": 3881,
                "faiss_score": 0.8591969013214111,
                "faiss_rank": 4,
                "doc_id": "wiki_Latency_(engineering)",
                "file_type": ".txt",
                "position": 50,
                "sentence": "When all of the tasks are done at the same time, however, it is possible to reduce the latency to the length of the longest task.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Latency_(engineering)",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.005307700484991074,
                  "neutral": 0.5157715082168579,
                  "support": 0.47892075777053833
                },
                "stance_score": 0.47361305728554726,
                "evidence_contribution": 0.4069268712451022,
                "combined_rank_score": 0.8591969013214111
              },
              {
                "id": 5691,
                "faiss_score": 0.8415981531143188,
                "faiss_rank": 8,
                "doc_id": "local_math_computation_limits.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Many important computational tasks fall into classes that are believed to be hard.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.006888913922011852,
                  "neutral": 0.5298597812652588,
                  "support": 0.4632512927055359
                },
                "stance_score": 0.45636237878352404,
                "evidence_contribution": 0.38407373513507104,
                "combined_rank_score": 0.8415981531143188
              },
              {
                "id": 6434,
                "faiss_score": 0.8501757383346558,
                "faiss_rank": 5,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 173,
                "sentence": "Ensuring consistent behavior across tasks remains challenging.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0040571861900389194,
                  "neutral": 0.6257938146591187,
                  "support": 0.37014898657798767
                },
                "stance_score": 0.36609180038794875,
                "evidence_contribution": 0.31124236669308775,
                "combined_rank_score": 0.8501757383346558
              },
              {
                "id": 1871,
                "faiss_score": 0.8370813727378845,
                "faiss_rank": 17,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 139,
                "sentence": "Alternatively, it can propose increasingly difficult tasks for curriculum learning.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.010847136378288269,
                  "neutral": 0.6954389810562134,
                  "support": 0.29371392726898193
                },
                "stance_score": 0.28286679089069366,
                "evidence_contribution": 0.23678252162074198,
                "combined_rank_score": 0.8370813727378845
              },
              {
                "id": 5713,
                "faiss_score": 0.8411245942115784,
                "faiss_rank": 11,
                "doc_id": "local_math_computation_limits.txt",
                "file_type": ".txt",
                "position": 36,
                "sentence": "Some problems can be efficiently parallelized, allowing multiple processors to work simultaneously.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0033423779532313347,
                  "neutral": 0.7269369959831238,
                  "support": 0.26972058415412903
                },
                "stance_score": 0.2663782062008977,
                "evidence_contribution": 0.22405726059753822,
                "combined_rank_score": 0.8411245942115784
              },
              {
                "id": 3882,
                "faiss_score": 0.836106538772583,
                "faiss_rank": 18,
                "doc_id": "wiki_Latency_(engineering)",
                "file_type": ".txt",
                "position": 51,
                "sentence": "If some steps have prerequisites, it becomes more difficult to perform all steps in parallel.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Latency_(engineering)",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.010015279054641724,
                  "neutral": 0.7556588053703308,
                  "support": 0.2343258261680603
                },
                "stance_score": 0.22431054711341858,
                "evidence_contribution": 0.18754751515718482,
                "combined_rank_score": 0.836106538772583
              },
              {
                "id": 6706,
                "faiss_score": 0.8399161696434021,
                "faiss_rank": 13,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 38,
                "sentence": "In real systems, workload characteristics matter greatly.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0037292875349521637,
                  "neutral": 0.8331853747367859,
                  "support": 0.16308535635471344
                },
                "stance_score": 0.15935606881976128,
                "evidence_contribution": 0.13384573893252427,
                "combined_rank_score": 0.8399161696434021
              },
              {
                "id": 790,
                "faiss_score": 0.8379898071289062,
                "faiss_rank": 15,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 194,
                "sentence": "Some promising tasks and applications require resources far beyond those available today.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.02995305135846138,
                  "neutral": 0.8351297974586487,
                  "support": 0.13491712510585785
                },
                "stance_score": 0.10496407374739647,
                "evidence_contribution": 0.08795882391504506,
                "combined_rank_score": 0.8379898071289062
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 6110,
                "faiss_score": 0.8411685824394226,
                "faiss_rank": 9,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 70,
                "sentence": "Tasks that once required specialized pipelines can now be addressed using general-purpose models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007752911187708378,
                  "neutral": 0.9306866526603699,
                  "support": 0.06156041473150253
                },
                "stance_score": 0.053807503543794155,
                "evidence_contribution": 0.04526118148053754,
                "combined_rank_score": 0.8411685824394226
              },
              {
                "id": 3889,
                "faiss_score": 0.8411526679992676,
                "faiss_rank": 10,
                "doc_id": "wiki_Latency_(engineering)",
                "file_type": ".txt",
                "position": 58,
                "sentence": "In addition, the operating system can schedule when to perform the action that the process is commanding.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Latency_(engineering)",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.0023500462993979454,
                  "neutral": 0.9915545582771301,
                  "support": 0.00609543127939105
                },
                "stance_score": 0.003745384979993105,
                "evidence_contribution": 0.0031504405686055836,
                "combined_rank_score": 0.8411526679992676
              },
              {
                "id": 2193,
                "faiss_score": 0.8400170803070068,
                "faiss_rank": 12,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 124,
                "sentence": "All the nodes connected by links take in some data and use it to perform specific operations and tasks on the data.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.001011320622637868,
                  "neutral": 0.9790430068969727,
                  "support": 0.01994563639163971
                },
                "stance_score": 0.01893431576900184,
                "evidence_contribution": 0.015905148649887846,
                "combined_rank_score": 0.8400170803070068
              }
            ]
          }
        },
        {
          "subclaim": "generalize across domains",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 4.010502481116797,
            "contradict": 0.46639947531311776,
            "total": 4.476901956429915
          },
          "evidence": {
            "supporting": [
              {
                "id": 6128,
                "faiss_score": 0.875458836555481,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "These trends have been observed across different domains and architectures, suggesting that scaling captures general properties of learning systems rather than task-specific quirks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.006305638700723648,
                  "neutral": 0.11608841270208359,
                  "support": 0.8776058554649353
                },
                "stance_score": 0.8713002167642117,
                "evidence_contribution": 0.7627874740589351,
                "combined_rank_score": 0.875458836555481
              },
              {
                "id": 6405,
                "faiss_score": 0.8751733899116516,
                "faiss_rank": 6,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 144,
                "sentence": "These representations encode statistical regularities of language and sequence structure, allowing models to generalize across contexts.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.008740616962313652,
                  "neutral": 0.12911827862262726,
                  "support": 0.8621411323547363
                },
                "stance_score": 0.8534005153924227,
                "evidence_contribution": 0.7468734220083372,
                "combined_rank_score": 0.8751733899116516
              },
              {
                "id": 4323,
                "faiss_score": 0.8630200624465942,
                "faiss_rank": 16,
                "doc_id": "wiki_No_free_lunch_theorem",
                "file_type": ".txt",
                "position": 34,
                "sentence": "Moreover, the Kolmogorov complexity of machine learning models can be upper bounded through compressions of their data labeling, and it is possible to produce non-vacuous cross-domain generalization bounds via Kolmogorov complexity.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/No_free_lunch_theorem",
                "primary_category": "all articles needing additional references",
                "probs": {
                  "contradict": 0.011967157945036888,
                  "neutral": 0.14573383331298828,
                  "support": 0.8422990441322327
                },
                "stance_score": 0.8303318861871958,
                "evidence_contribution": 0.7165930762686721,
                "combined_rank_score": 0.8630200624465942
              },
              {
                "id": 6079,
                "faiss_score": 0.8609956502914429,
                "faiss_rank": 18,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Large language models are often described as general-purpose systems because they can be adapted to many tasks with minimal fine-tuning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0034194558393210173,
                  "neutral": 0.4510444700717926,
                  "support": 0.5455361008644104
                },
                "stance_score": 0.5421166450250894,
                "evidence_contribution": 0.46676007331719216,
                "combined_rank_score": 0.8609956502914429
              },
              {
                "id": 2363,
                "faiss_score": 0.8626672625541687,
                "faiss_rank": 17,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 294,
                "sentence": "Applications whose goal is to create a system that generalizes well to unseen examples, face the possibility of over-training.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.022231891751289368,
                  "neutral": 0.4892544448375702,
                  "support": 0.4885135889053345
                },
                "stance_score": 0.4662816971540451,
                "evidence_contribution": 0.402245955262992,
                "combined_rank_score": 0.8626672625541687
              },
              {
                "id": 2072,
                "faiss_score": 0.8717225790023804,
                "faiss_rank": 8,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 3,
                "sentence": "This method allows the network to generalize to unseen data.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.015541942790150642,
                  "neutral": 0.7024780511856079,
                  "support": 0.281980037689209
                },
                "stance_score": 0.26643809489905834,
                "evidence_contribution": 0.2322601032298881,
                "combined_rank_score": 0.8717225790023804
              },
              {
                "id": 1443,
                "faiss_score": 0.86568284034729,
                "faiss_rank": 12,
                "doc_id": "wiki_Regularization_(mathematics)",
                "file_type": ".txt",
                "position": 15,
                "sentence": "Regularization can be motivated as a technique to improve the generalizability of a learned model.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Regularization_(mathematics)",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.005486487876623869,
                  "neutral": 0.776395320892334,
                  "support": 0.21811825037002563
                },
                "stance_score": 0.21263176249340177,
                "evidence_contribution": 0.18407166810333842,
                "combined_rank_score": 0.86568284034729
              },
              {
                "id": 5976,
                "faiss_score": 0.8663370609283447,
                "faiss_rank": 11,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "The gap between training performance and real-world behavior reflects the challenge of generalization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.10078410804271698,
                  "neutral": 0.6001803278923035,
                  "support": 0.29903554916381836
                },
                "stance_score": 0.19825144112110138,
                "evidence_contribution": 0.17175257082566375,
                "combined_rank_score": 0.8663370609283447
              },
              {
                "id": 159,
                "faiss_score": 0.8602029085159302,
                "faiss_rank": 19,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 50,
                "sentence": "A core objective of a learner is to generalise from its experience.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0037227689754217863,
                  "neutral": 0.7958906888961792,
                  "support": 0.20038655400276184
                },
                "stance_score": 0.19666378502734005,
                "evidence_contribution": 0.16917075988026956,
                "combined_rank_score": 0.8602029085159302
              },
              {
                "id": 6221,
                "faiss_score": 0.8701233267784119,
                "faiss_rank": 10,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 29,
                "sentence": "Surprisingly, such models can still generalize well.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0015089970547705889,
                  "neutral": 0.8154131174087524,
                  "support": 0.18307794630527496
                },
                "stance_score": 0.18156894925050437,
                "evidence_contribution": 0.15798737816150948,
                "combined_rank_score": 0.8701233267784119
              }
            ],
            "contradicting": [
              {
                "id": 6018,
                "faiss_score": 0.8650850057601929,
                "faiss_rank": 15,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 44,
                "sentence": "A model trained and evaluated in one environment may generalize poorly in another due to subtle differences.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5686880350112915,
                  "neutral": 0.18720504641532898,
                  "support": 0.24410688877105713
                },
                "stance_score": -0.3245811462402344,
                "evidence_contribution": -0.28079028276488316,
                "combined_rank_score": 0.8650850057601929
              },
              {
                "id": 5562,
                "faiss_score": 0.8713772296905518,
                "faiss_rank": 9,
                "doc_id": "local_bio_gene_editing.txt",
                "file_type": ".txt",
                "position": 35,
                "sentence": "These factors complicate efforts to generalize results across systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\bio_gene_editing.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.4898774325847626,
                  "neutral": 0.23325194418430328,
                  "support": 0.2768707275390625
                },
                "stance_score": -0.21300670504570007,
                "evidence_contribution": -0.1856091925482346,
                "combined_rank_score": 0.8713772296905518
              }
            ],
            "neutral": [
              {
                "id": 5977,
                "faiss_score": 0.8809024095535278,
                "faiss_rank": 1,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "Generalization refers to a model\u2019s ability to perform well on data drawn from the same underlying process as the training data, even when individual examples differ.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004105135798454285,
                  "neutral": 0.9529510736465454,
                  "support": 0.042943768203258514
                },
                "stance_score": 0.03883863240480423,
                "evidence_contribution": 0.03421304486915577,
                "combined_rank_score": 0.8809024095535278
              },
              {
                "id": 5770,
                "faiss_score": 0.8777358531951904,
                "faiss_rank": 2,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "Generalization requires extracting information that is predictive of unseen data while discarding irrelevant details.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004218193702399731,
                  "neutral": 0.9678018093109131,
                  "support": 0.027980053797364235
                },
                "stance_score": 0.023761860094964504,
                "evidence_contribution": 0.020856636543958418,
                "combined_rank_score": 0.8777358531951904
              },
              {
                "id": 6004,
                "faiss_score": 0.876814603805542,
                "faiss_rank": 3,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 30,
                "sentence": "Generalization is also influenced by data quality.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.021363889798521996,
                  "neutral": 0.923850417137146,
                  "support": 0.054785650223493576
                },
                "stance_score": 0.03342176042497158,
                "evidence_contribution": 0.0293046876255052,
                "combined_rank_score": 0.876814603805542
              }
            ]
          }
        },
        {
          "subclaim": "hallucinate facts",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.5234018297159384,
            "contradict": 4.889892521857734,
            "total": 5.413294351573672
          },
          "evidence": {
            "supporting": [
              {
                "id": 1958,
                "faiss_score": 0.8864883184432983,
                "faiss_rank": 2,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 226,
                "sentence": "Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\".",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.1281960904598236,
                  "neutral": 0.25289106369018555,
                  "support": 0.6189128756523132
                },
                "stance_score": 0.4907167851924896,
                "evidence_contribution": 0.43501469773719137,
                "combined_rank_score": 0.8864883184432983
              },
              {
                "id": 6062,
                "faiss_score": 0.8709315061569214,
                "faiss_rank": 6,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 22,
                "sentence": "Hallucinations can occur even when the model has seen relevant information during training, as generation depends on local likelihood rather than global verification.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.16398467123508453,
                  "neutral": 0.570544958114624,
                  "support": 0.265470415353775
                },
                "stance_score": 0.10148574411869049,
                "evidence_contribution": 0.08838713197874704,
                "combined_rank_score": 0.8709315061569214
              }
            ],
            "contradicting": [
              {
                "id": 1959,
                "faiss_score": 0.8755703568458557,
                "faiss_rank": 5,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 227,
                "sentence": "Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.9376419186592102,
                  "neutral": 0.04097185656428337,
                  "support": 0.021386215463280678
                },
                "stance_score": -0.9162557031959295,
                "evidence_contribution": -0.8022463330093105,
                "combined_rank_score": 0.8755703568458557
              },
              {
                "id": 2022,
                "faiss_score": 0.8594096899032593,
                "faiss_rank": 7,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 290,
                "sentence": "These hallucinations arise partly through memorization of training data combined with extrapolation beyond factual boundaries, with evaluations demonstrating that models can output verbatim passages from training data, when subjected to specific prompting sequences.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.8523752093315125,
                  "neutral": 0.1056460589170456,
                  "support": 0.04197878763079643
                },
                "stance_score": -0.810396421700716,
                "evidence_contribution": -0.6964625374725233,
                "combined_rank_score": 0.8594096899032593
              },
              {
                "id": 1961,
                "faiss_score": 0.8519169688224792,
                "faiss_rank": 8,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 229,
                "sentence": "Efforts to reduce or compensate for hallucinations have employed automated reasoning, retrieval-augmented generation (RAG), fine-tuning, and other methods.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.7880223393440247,
                  "neutral": 0.18474780023097992,
                  "support": 0.02722986228764057
                },
                "stance_score": -0.7607924770563841,
                "evidence_contribution": -0.6481320209568203,
                "combined_rank_score": 0.8519169688224792
              },
              {
                "id": 1544,
                "faiss_score": 0.8064035177230835,
                "faiss_rank": 13,
                "doc_id": "wiki_Loss_function",
                "file_type": ".txt",
                "position": 44,
                "sentence": "observations, the principle of complete information, and some others.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Loss_function",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.6349360346794128,
                  "neutral": 0.3464200794696808,
                  "support": 0.018643902614712715
                },
                "stance_score": -0.6162921320647001,
                "evidence_contribution": -0.4969801432420333,
                "combined_rank_score": 0.8064035177230835
              },
              {
                "id": 2021,
                "faiss_score": 0.8814721703529358,
                "faiss_rank": 3,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 289,
                "sentence": "Hallucinations represent a fundamental challenge, wherein models generate syntactically fluent text that appears factually sound, but is internally inconsistent with training data or factually incorrect.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.6222884654998779,
                  "neutral": 0.27321556210517883,
                  "support": 0.10449595004320145
                },
                "stance_score": -0.5177925154566765,
                "evidence_contribution": -0.45641969239210267,
                "combined_rank_score": 0.8814721703529358
              },
              {
                "id": 6048,
                "faiss_score": 0.8023523092269897,
                "faiss_rank": 15,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "They do not store explicit facts or rules in a symbolic form.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5973492860794067,
                  "neutral": 0.3601573705673218,
                  "support": 0.04249336197972298
                },
                "stance_score": -0.5548559240996838,
                "evidence_contribution": -0.4451899319896566,
                "combined_rank_score": 0.8023523092269897
              },
              {
                "id": 6065,
                "faiss_score": 0.838513195514679,
                "faiss_rank": 9,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 25,
                "sentence": "Conversely, conservative decoding may reduce hallucination but lead to repetitive or overly cautious outputs.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.495147705078125,
                  "neutral": 0.4244162440299988,
                  "support": 0.08043601363897324
                },
                "stance_score": -0.41471169143915176,
                "evidence_contribution": -0.3477412256059407,
                "combined_rank_score": 0.838513195514679
              },
              {
                "id": 5153,
                "faiss_score": 0.8208348155021667,
                "faiss_rank": 10,
                "doc_id": "wiki_NP-completeness",
                "file_type": ".txt",
                "position": 59,
                "sentence": "The following misconceptions are frequent.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/NP-completeness",
                "primary_category": "1971 in computing",
                "probs": {
                  "contradict": 0.5551048517227173,
                  "neutral": 0.2802315652370453,
                  "support": 0.16466356813907623
                },
                "stance_score": -0.39044128358364105,
                "evidence_contribution": -0.32048779897480717,
                "combined_rank_score": 0.8208348155021667
              },
              {
                "id": 5071,
                "faiss_score": 0.8065730333328247,
                "faiss_rank": 12,
                "doc_id": "wiki_Church\u2013Turing_thesis",
                "file_type": ".txt",
                "position": 111,
                "sentence": "B. Jack Copeland states that it is an open empirical question whether there are actual deterministic physical processes that, in the long run, elude simulation by a Turing machine; furthermore, he states that it is an open empirical question whether any such processes are involved in the working of the human brain.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis",
                "primary_category": "alan turing",
                "probs": {
                  "contradict": 0.2784322202205658,
                  "neutral": 0.6776465177536011,
                  "support": 0.043921228498220444
                },
                "stance_score": -0.23451099172234535,
                "evidence_contribution": -0.18915024194338104,
                "combined_rank_score": 0.8065730333328247
              },
              {
                "id": 1790,
                "faiss_score": 0.8042306900024414,
                "faiss_rank": 14,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 58,
                "sentence": "In these cases, synthetic data might be used.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.23420459032058716,
                  "neutral": 0.7251050472259521,
                  "support": 0.04069039970636368
                },
                "stance_score": -0.19351419061422348,
                "evidence_contribution": -0.15563005104294092,
                "combined_rank_score": 0.8042306900024414
              },
              {
                "id": 5249,
                "faiss_score": 0.8071879744529724,
                "faiss_rank": 11,
                "doc_id": "wiki_P_versus_NP_problem",
                "file_type": ".txt",
                "position": 74,
                "sentence": "First, it can be false in practice.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/P_versus_NP_problem",
                "primary_category": "1956 in computing",
                "probs": {
                  "contradict": 0.21242617070674896,
                  "neutral": 0.7285987734794617,
                  "support": 0.058975085616111755
                },
                "stance_score": -0.1534510850906372,
                "evidence_contribution": -0.12386387055192216,
                "combined_rank_score": 0.8071879744529724
              },
              {
                "id": 6063,
                "faiss_score": 0.8869999647140503,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 23,
                "sentence": "The tendency to hallucinate is influenced by prompting, context length, and decoding strategies.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.28592926263809204,
                  "neutral": 0.5544893145561218,
                  "support": 0.15958142280578613
                },
                "stance_score": -0.1263478398323059,
                "evidence_contribution": -0.11207052947295182,
                "combined_rank_score": 0.8869999647140503
              },
              {
                "id": 4176,
                "faiss_score": 0.8001145124435425,
                "faiss_rank": 17,
                "doc_id": "wiki_Entropy_(information_theory)",
                "file_type": ".txt",
                "position": 39,
                "sentence": "I(1) = 0: events that always occur do not communicate information.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Entropy_(information_theory)",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.18018576502799988,
                  "neutral": 0.7590091228485107,
                  "support": 0.060805171728134155
                },
                "stance_score": -0.11938059329986572,
                "evidence_contribution": -0.0955181452033429,
                "combined_rank_score": 0.8001145124435425
              }
            ],
            "neutral": [
              {
                "id": 6060,
                "faiss_score": 0.8803726434707642,
                "faiss_rank": 4,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 20,
                "sentence": "Hallucination is one of the most widely discussed failure modes of large language models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.2402685284614563,
                  "neutral": 0.5552210211753845,
                  "support": 0.20451043546199799
                },
                "stance_score": -0.03575809299945831,
                "evidence_contribution": -0.03148044685940654,
                "combined_rank_score": 0.8803726434707642
              },
              {
                "id": 5769,
                "faiss_score": 0.801109790802002,
                "faiss_rank": 16,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 17,
                "sentence": "The model memorizes noise rather than structure.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.15454168617725372,
                  "neutral": 0.7853820323944092,
                  "support": 0.06007632240653038
                },
                "stance_score": -0.09446536377072334,
                "evidence_contribution": -0.07567712780839919,
                "combined_rank_score": 0.801109790802002
              },
              {
                "id": 4080,
                "faiss_score": 0.7994356155395508,
                "faiss_rank": 18,
                "doc_id": "wiki_Information_theory",
                "file_type": ".txt",
                "position": 74,
                "sentence": "All such sources are stochastic.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Information_theory",
                "primary_category": "all articles needing additional references",
                "probs": {
                  "contradict": 0.17223607003688812,
                  "neutral": 0.7325766682624817,
                  "support": 0.09518726170063019
                },
                "stance_score": -0.07704880833625793,
                "evidence_contribution": -0.06159556151888523,
                "combined_rank_score": 0.7994356155395508
              }
            ]
          }
        },
        {
          "subclaim": "encode societal biases",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 3.321344002611573,
            "contradict": 2.292621734046343,
            "total": 5.613965736657915
          },
          "evidence": {
            "supporting": [
              {
                "id": 412,
                "faiss_score": 0.911769449710846,
                "faiss_rank": 3,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 303,
                "sentence": "Systems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitising cultural prejudices.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0075705829076468945,
                  "neutral": 0.11338216811418533,
                  "support": 0.8790472149848938
                },
                "stance_score": 0.8714766320772469,
                "evidence_contribution": 0.7945857692649327,
                "combined_rank_score": 0.911769449710846
              },
              {
                "id": 411,
                "faiss_score": 0.9120092988014221,
                "faiss_rank": 1,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 302,
                "sentence": "When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.04815658554434776,
                  "neutral": 0.2623845934867859,
                  "support": 0.6894589066505432
                },
                "stance_score": 0.6413023211061954,
                "evidence_contribution": 0.5848736801917858,
                "combined_rank_score": 0.9120092988014221
              },
              {
                "id": 2029,
                "faiss_score": 0.8689141869544983,
                "faiss_rank": 10,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 297,
                "sentence": "AI models can reinforce a wide range of stereotypes due to generalization, including those based on gender, ethnicity, age, nationality, religion, or occupation.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.015892989933490753,
                  "neutral": 0.30270856618881226,
                  "support": 0.6813983917236328
                },
                "stance_score": 0.6655054017901421,
                "evidence_contribution": 0.578267085110308,
                "combined_rank_score": 0.8689141869544983
              },
              {
                "id": 2024,
                "faiss_score": 0.878750205039978,
                "faiss_rank": 6,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 292,
                "sentence": "This can manifest in skewed representations or unfair treatment of different demographics, such as those based on race, gender, language, and cultural groups.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.06153199449181557,
                  "neutral": 0.42110925912857056,
                  "support": 0.5173587799072266
                },
                "stance_score": 0.455826785415411,
                "evidence_contribution": 0.4005578811465065,
                "combined_rank_score": 0.878750205039978
              },
              {
                "id": 6070,
                "faiss_score": 0.8645083904266357,
                "faiss_rank": 15,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 30,
                "sentence": "As a result, they may reflect dominant narratives, reproduce stereotypes, or overrepresent certain perspectives.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005162056069821119,
                  "neutral": 0.5611896514892578,
                  "support": 0.4336482882499695
                },
                "stance_score": 0.42848623218014836,
                "evidence_contribution": 0.3704299429020338,
                "combined_rank_score": 0.8645083904266357
              },
              {
                "id": 6460,
                "faiss_score": 0.8655024766921997,
                "faiss_rank": 13,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 199,
                "sentence": "Models trained on large-scale data may inadvertently reproduce harmful stereotypes or sensitive information.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.04152972251176834,
                  "neutral": 0.6016649007797241,
                  "support": 0.35680535435676575
                },
                "stance_score": 0.3152756318449974,
                "evidence_contribution": 0.2728718402025434,
                "combined_rank_score": 0.8655024766921997
              },
              {
                "id": 1286,
                "faiss_score": 0.8673373460769653,
                "faiss_rank": 11,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 311,
                "sentence": "Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.02771516516804695,
                  "neutral": 0.7168781161308289,
                  "support": 0.25540676712989807
                },
                "stance_score": 0.22769160196185112,
                "evidence_contribution": 0.1974854297696047,
                "combined_rank_score": 0.8673373460769653
              },
              {
                "id": 419,
                "faiss_score": 0.8740242719650269,
                "faiss_rank": 8,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 310,
                "sentence": "Language models learned from data have been shown to contain human-like biases.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.046064868569374084,
                  "neutral": 0.7679744362831116,
                  "support": 0.18596072494983673
                },
                "stance_score": 0.13989585638046265,
                "evidence_contribution": 0.12227237402385782,
                "combined_rank_score": 0.8740242719650269
              }
            ],
            "contradicting": [
              {
                "id": 2038,
                "faiss_score": 0.8740885257720947,
                "faiss_rank": 7,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 306,
                "sentence": "Political bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.9876894950866699,
                  "neutral": 0.010320872068405151,
                  "support": 0.001989632612094283
                },
                "stance_score": -0.9856998624745756,
                "evidence_contribution": -0.8615889396441583,
                "combined_rank_score": 0.8740885257720947
              },
              {
                "id": 1990,
                "faiss_score": 0.8573331236839294,
                "faiss_rank": 20,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 258,
                "sentence": "LLM bias may be assessed through benchmarks such as CrowS-Pairs (Crowdsourced Stereotype Pairs), Stereo Set, and Parity Benchmark.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.6490700840950012,
                  "neutral": 0.24730299413204193,
                  "support": 0.10362697392702103
                },
                "stance_score": -0.5454431101679802,
                "evidence_contribution": -0.4676264454321921,
                "combined_rank_score": 0.8573331236839294
              },
              {
                "id": 2026,
                "faiss_score": 0.8653594851493835,
                "faiss_rank": 14,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 294,
                "sentence": "Language-based bias emerges from overrepresentation of English text in training corpora, which systematically downplays non-English perspectives and imposes English-centric worldviews through default response patterns.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.5331867337226868,
                  "neutral": 0.3443293571472168,
                  "support": 0.12248389422893524
                },
                "stance_score": -0.4107028394937515,
                "evidence_contribution": -0.3554055977337027,
                "combined_rank_score": 0.8653594851493835
              },
              {
                "id": 6343,
                "faiss_score": 0.8611011505126953,
                "faiss_rank": 19,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 82,
                "sentence": "This has implications for fairness, robustness, and generalization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.41697368025779724,
                  "neutral": 0.5448744297027588,
                  "support": 0.03815186023712158
                },
                "stance_score": -0.37882182002067566,
                "evidence_contribution": -0.326203905059117,
                "combined_rank_score": 0.8611011505126953
              },
              {
                "id": 2039,
                "faiss_score": 0.8821737170219421,
                "faiss_rank": 5,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 307,
                "sentence": "Language models may also exhibit political biases.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.5698038339614868,
                  "neutral": 0.17982693016529083,
                  "support": 0.25036919116973877
                },
                "stance_score": -0.31943464279174805,
                "evidence_contribution": -0.2817968461771727,
                "combined_rank_score": 0.8821737170219421
              }
            ],
            "neutral": [
              {
                "id": 354,
                "faiss_score": 0.8632741570472717,
                "faiss_rank": 16,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 245,
                "sentence": "Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.23116815090179443,
                  "neutral": 0.47713980078697205,
                  "support": 0.2916921079158783
                },
                "stance_score": 0.06052395701408386,
                "evidence_contribution": 0.052248767972498555,
                "combined_rank_score": 0.8632741570472717
              },
              {
                "id": 2023,
                "faiss_score": 0.8627463579177856,
                "faiss_rank": 18,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 291,
                "sentence": "While LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to inheriting and amplifying biases present in their training data.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.009690002538263798,
                  "neutral": 0.8865801095962524,
                  "support": 0.10372987389564514
                },
                "stance_score": 0.09403987135738134,
                "evidence_contribution": 0.08113255651263784,
                "combined_rank_score": 0.8627463579177856
              }
            ]
          }
        },
        {
          "subclaim": "lack grounded reasoning",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 4.074163112985782,
            "contradict": 1.3306618671332513,
            "total": 5.404824980119034
          },
          "evidence": {
            "supporting": [
              {
                "id": 2754,
                "faiss_score": 0.8560482859611511,
                "faiss_rank": 5,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 349,
                "sentence": "A main criticism concerns the lack of theory surrounding some methods.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0030245366506278515,
                  "neutral": 0.24703992903232574,
                  "support": 0.7499355673789978
                },
                "stance_score": 0.74691103072837,
                "evidence_contribution": 0.6393919076204978,
                "combined_rank_score": 0.8560482859611511
              },
              {
                "id": 6376,
                "faiss_score": 0.848895788192749,
                "faiss_rank": 9,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 115,
                "sentence": "This vulnerability arises in part from their reliance on statistical patterns rather than explicit reasoning mechanisms.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0039749909192323685,
                  "neutral": 0.31459662318229675,
                  "support": 0.6814284920692444
                },
                "stance_score": 0.677453501150012,
                "evidence_contribution": 0.5750874238226769,
                "combined_rank_score": 0.848895788192749
              },
              {
                "id": 5265,
                "faiss_score": 0.846418023109436,
                "faiss_rank": 12,
                "doc_id": "wiki_P_versus_NP_problem",
                "file_type": ".txt",
                "position": 90,
                "sentence": "This is, in my opinion, a very weak argument.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/P_versus_NP_problem",
                "primary_category": "1956 in computing",
                "probs": {
                  "contradict": 0.0017298628808930516,
                  "neutral": 0.4352908432483673,
                  "support": 0.5629792213439941
                },
                "stance_score": 0.5612493584631011,
                "evidence_contribution": 0.47505157246177726,
                "combined_rank_score": 0.846418023109436
              },
              {
                "id": 6054,
                "faiss_score": 0.8733642101287842,
                "faiss_rank": 4,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Others counter that any appearance of understanding is an artifact of training on massive datasets and that the models lack grounding in real-world experience.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.011887310072779655,
                  "neutral": 0.4753391742706299,
                  "support": 0.5127735137939453
                },
                "stance_score": 0.5008862037211657,
                "evidence_contribution": 0.4374560836773411,
                "combined_rank_score": 0.8733642101287842
              },
              {
                "id": 6122,
                "faiss_score": 0.8488896489143372,
                "faiss_rank": 10,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 82,
                "sentence": "Their strengths lie in flexibility, fluency, and scalability, while their weaknesses center on grounding, reliability, and interpretability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00916263833642006,
                  "neutral": 0.5942029356956482,
                  "support": 0.39663445949554443
                },
                "stance_score": 0.3874718211591244,
                "evidence_contribution": 0.3289208182279679,
                "combined_rank_score": 0.8488896489143372
              },
              {
                "id": 5268,
                "faiss_score": 0.8427004814147949,
                "faiss_rank": 14,
                "doc_id": "wiki_P_versus_NP_problem",
                "file_type": ".txt",
                "position": 93,
                "sentence": "Being attached to a speculation is not a good guide to research planning.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/P_versus_NP_problem",
                "primary_category": "1956 in computing",
                "probs": {
                  "contradict": 0.004860588349401951,
                  "neutral": 0.6108795404434204,
                  "support": 0.3842599093914032
                },
                "stance_score": 0.37939932104200125,
                "evidence_contribution": 0.3197199904905408,
                "combined_rank_score": 0.8427004814147949
              },
              {
                "id": 1956,
                "faiss_score": 0.8405802249908447,
                "faiss_rank": 17,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 224,
                "sentence": "In contrast, some skeptics of LLM understanding believe that existing LLMs are \"simply remixing and recombining existing writing\", a phenomenon known as stochastic parrot, or they point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.012527014128863811,
                  "neutral": 0.624691367149353,
                  "support": 0.3627816140651703
                },
                "stance_score": 0.3502545999363065,
                "evidence_contribution": 0.2944170904185388,
                "combined_rank_score": 0.8405802249908447
              },
              {
                "id": 6187,
                "faiss_score": 0.8757100701332092,
                "faiss_rank": 3,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 63,
                "sentence": "It can unlock capabilities that are difficult to achieve otherwise, but it does not solve fundamental problems related to understanding, grounding, or reasoning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.09269913285970688,
                  "neutral": 0.4912792444229126,
                  "support": 0.4160216450691223
                },
                "stance_score": 0.32332251220941544,
                "evidence_contribution": 0.2831367798425526,
                "combined_rank_score": 0.8757100701332092
              },
              {
                "id": 6117,
                "faiss_score": 0.8418884873390198,
                "faiss_rank": 16,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 77,
                "sentence": "Users may attribute understanding or intent to models that operate purely on statistical principles, leading to misplaced trust.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.05127658694982529,
                  "neutral": 0.57462078332901,
                  "support": 0.3741026222705841
                },
                "stance_score": 0.3228260353207588,
                "evidence_contribution": 0.2717835225498466,
                "combined_rank_score": 0.8418884873390198
              },
              {
                "id": 6111,
                "faiss_score": 0.8929279446601868,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 71,
                "sentence": "At the same time, this progress has highlighted fundamental limitations related to grounding, reasoning, and reliability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.09977399557828903,
                  "neutral": 0.6214102506637573,
                  "support": 0.27881574630737305
                },
                "stance_score": 0.17904175072908401,
                "evidence_contribution": 0.15987138248688249,
                "combined_rank_score": 0.8929279446601868
              },
              {
                "id": 4138,
                "faiss_score": 0.8389129638671875,
                "faiss_rank": 19,
                "doc_id": "wiki_Entropy_(information_theory)",
                "file_type": ".txt",
                "position": 1,
                "sentence": "If a highly likely event occurs, the message carries very little information.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Entropy_(information_theory)",
                "primary_category": "all wikipedia articles written in american english",
                "probs": {
                  "contradict": 0.004779502283781767,
                  "neutral": 0.8637316226959229,
                  "support": 0.1314888596534729
                },
                "stance_score": 0.12670935736969113,
                "evidence_contribution": 0.10629812254071425,
                "combined_rank_score": 0.8389129638671875
              },
              {
                "id": 1876,
                "faiss_score": 0.8455052375793457,
                "faiss_rank": 13,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 144,
                "sentence": "As a result, their performance tends to be subpar on complex questions requiring (at least in humans) intermediate steps of thought.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.005309476982802153,
                  "neutral": 0.8784682750701904,
                  "support": 0.11622219532728195
                },
                "stance_score": 0.1109127183444798,
                "evidence_contribution": 0.09377728427442045,
                "combined_rank_score": 0.8455052375793457
              },
              {
                "id": 6048,
                "faiss_score": 0.8500901460647583,
                "faiss_rank": 7,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "They do not store explicit facts or rules in a symbolic form.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.012029810808598995,
                  "neutral": 0.8709501624107361,
                  "support": 0.11702001094818115
                },
                "stance_score": 0.10499020013958216,
                "evidence_contribution": 0.0892511345720256,
                "combined_rank_score": 0.8500901460647583
              }
            ],
            "contradicting": [
              {
                "id": 5745,
                "faiss_score": 0.8376482725143433,
                "faiss_rank": 20,
                "doc_id": "local_math_computation_limits.txt",
                "file_type": ".txt",
                "position": 68,
                "sentence": "While theory does not predict all future discoveries, it provides a framework for skepticism grounded in evidence.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_computation_limits.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9659310579299927,
                  "neutral": 0.031816720962524414,
                  "support": 0.0022521638311445713
                },
                "stance_score": -0.9636788940988481,
                "evidence_contribution": -0.8072239609004328,
                "combined_rank_score": 0.8376482725143433
              },
              {
                "id": 6409,
                "faiss_score": 0.8798010349273682,
                "faiss_rank": 2,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 148,
                "sentence": "Tasks that require multi-step inference, logical consistency, or grounding in external reality often expose limitations.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.4127979576587677,
                  "neutral": 0.5286512970924377,
                  "support": 0.05855078622698784
                },
                "stance_score": -0.35424717143177986,
                "evidence_contribution": -0.31166702804577273,
                "combined_rank_score": 0.8798010349273682
              },
              {
                "id": 6257,
                "faiss_score": 0.851122260093689,
                "faiss_rank": 6,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 65,
                "sentence": "However, reliance on heuristics can limit understanding and transferability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.22396555542945862,
                  "neutral": 0.6896719932556152,
                  "support": 0.08636243641376495
                },
                "stance_score": -0.13760311901569366,
                "evidence_contribution": -0.11711707765257806,
                "combined_rank_score": 0.851122260093689
              },
              {
                "id": 4980,
                "faiss_score": 0.8499214053153992,
                "faiss_rank": 8,
                "doc_id": "wiki_Church\u2013Turing_thesis",
                "file_type": ".txt",
                "position": 20,
                "sentence": "But he did not think that the two ideas could be satisfactorily identified \"except heuristically\".",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis",
                "primary_category": "alan turing",
                "probs": {
                  "contradict": 0.18368926644325256,
                  "neutral": 0.7439891695976257,
                  "support": 0.07232155650854111
                },
                "stance_score": -0.11136770993471146,
                "evidence_contribution": -0.0946538005344677,
                "combined_rank_score": 0.8499214053153992
              }
            ],
            "neutral": [
              {
                "id": 6316,
                "faiss_score": 0.8470757007598877,
                "faiss_rank": 11,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 55,
                "sentence": "They may be combined with retrieval mechanisms, symbolic components, or task-specific modules to address shortcomings related to grounding and factual accuracy.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.1106201559305191,
                  "neutral": 0.7101302742958069,
                  "support": 0.17924952507019043
                },
                "stance_score": 0.06862936913967133,
                "evidence_contribution": 0.0581342709566961,
                "combined_rank_score": 0.8470757007598877
              },
              {
                "id": 6319,
                "faiss_score": 0.8424455523490906,
                "faiss_rank": 15,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 58,
                "sentence": "While attention weights offer some insight into model behavior, they do not provide a complete explanation of decision-making processes.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.01719685271382332,
                  "neutral": 0.9187061786651611,
                  "support": 0.06409695744514465
                },
                "stance_score": 0.046900104731321335,
                "evidence_contribution": 0.0395107846356082,
                "combined_rank_score": 0.8424455523490906
              },
              {
                "id": 1605,
                "faiss_score": 0.8396142721176147,
                "faiss_rank": 18,
                "doc_id": "wiki_Optimization_(mathematics)",
                "file_type": ".txt",
                "position": 54,
                "sentence": "Usually, heuristics do not guarantee that any optimal solution need be found.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                "primary_category": "all articles with style issues",
                "probs": {
                  "contradict": 0.15037643909454346,
                  "neutral": 0.7374339699745178,
                  "support": 0.11218959838151932
                },
                "stance_score": -0.03818684071302414,
                "evidence_contribution": -0.03206221646973706,
                "combined_rank_score": 0.8396142721176147
              }
            ]
          }
        },
        {
          "subclaim": "require massive datasets",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 4.574271546941361,
            "contradict": 0.0,
            "total": 4.574271546941361
          },
          "evidence": {
            "supporting": [
              {
                "id": 6308,
                "faiss_score": 0.8858730792999268,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Another challenge associated with transformers is their reliance on large datasets for effective training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0018392824567854404,
                  "neutral": 0.18031391501426697,
                  "support": 0.8178468942642212
                },
                "stance_score": 0.8160076118074358,
                "evidence_contribution": 0.7228791758040324,
                "combined_rank_score": 0.8858730792999268
              },
              {
                "id": 6309,
                "faiss_score": 0.8829025030136108,
                "faiss_rank": 2,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "High-capacity models are prone to overfitting when data is scarce, and strong generalization typically requires pretraining on massive corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.002582910005003214,
                  "neutral": 0.23085328936576843,
                  "support": 0.7665637731552124
                },
                "stance_score": 0.7639808631502092,
                "evidence_contribution": 0.6745206163298185,
                "combined_rank_score": 0.8829025030136108
              },
              {
                "id": 3968,
                "faiss_score": 0.8802938461303711,
                "faiss_rank": 4,
                "doc_id": "wiki_Throughput",
                "file_type": ".txt",
                "position": 63,
                "sentence": "Large data loads that require processing impose data processing requirements on hardware.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Network_throughput",
                "primary_category": "all articles needing additional references",
                "probs": {
                  "contradict": 0.007633762899786234,
                  "neutral": 0.2982155978679657,
                  "support": 0.6941506266593933
                },
                "stance_score": 0.6865168637596071,
                "evidence_contribution": 0.6043365704323045,
                "combined_rank_score": 0.8802938461303711
              },
              {
                "id": 350,
                "faiss_score": 0.8709700107574463,
                "faiss_rank": 10,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 241,
                "sentence": "When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.001810239045880735,
                  "neutral": 0.35577476024627686,
                  "support": 0.6424149870872498
                },
                "stance_score": 0.640604748041369,
                "evidence_contribution": 0.5579475242928623,
                "combined_rank_score": 0.8709700107574463
              },
              {
                "id": 1394,
                "faiss_score": 0.8828780651092529,
                "faiss_rank": 3,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 44,
                "sentence": "The optimal function usually needs verification on bigger or completely new datasets.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.005039381794631481,
                  "neutral": 0.569232702255249,
                  "support": 0.42572787404060364
                },
                "stance_score": 0.42068849224597216,
                "evidence_contribution": 0.37141664204785285,
                "combined_rank_score": 0.8828780651092529
              },
              {
                "id": 1789,
                "faiss_score": 0.8626959919929504,
                "faiss_rank": 19,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 57,
                "sentence": "Training of largest language models might need more linguistic data than naturally available, or that the naturally occurring data is of insufficient quality.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.005022028926759958,
                  "neutral": 0.6281405091285706,
                  "support": 0.3668374717235565
                },
                "stance_score": 0.36181544279679656,
                "evidence_contribution": 0.31213673234195105,
                "combined_rank_score": 0.8626959919929504
              },
              {
                "id": 6138,
                "faiss_score": 0.8628324270248413,
                "faiss_rank": 18,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "This observation has motivated large-scale data collection and curation efforts, as well as synthetic data generation in some settings.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0027826400473713875,
                  "neutral": 0.6612303853034973,
                  "support": 0.3359869420528412
                },
                "stance_score": 0.3332043020054698,
                "evidence_contribution": 0.2874994765944977,
                "combined_rank_score": 0.8628324270248413
              },
              {
                "id": 349,
                "faiss_score": 0.870810866355896,
                "faiss_rank": 12,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 240,
                "sentence": "Typically, machine learning models require a high quantity of reliable data to perform accurate predictions.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "probs": {
                  "contradict": 0.0017575575038790703,
                  "neutral": 0.7200695276260376,
                  "support": 0.27817291021347046
                },
                "stance_score": 0.2764153527095914,
                "evidence_contribution": 0.24070549276710984,
                "combined_rank_score": 0.870810866355896
              },
              {
                "id": 3002,
                "faiss_score": 0.8612390756607056,
                "faiss_rank": 20,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 57,
                "sentence": "The pretrain dataset is typically an unlabeled large corpus, such as The Pile.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "probs": {
                  "contradict": 0.011000572703778744,
                  "neutral": 0.7051967978477478,
                  "support": 0.28380265831947327
                },
                "stance_score": 0.2728020856156945,
                "evidence_contribution": 0.2349478160539734,
                "combined_rank_score": 0.8612390756607056
              },
              {
                "id": 6166,
                "faiss_score": 0.8723924160003662,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Data ingestion, storage, preprocessing, training, evaluation, and deployment must all operate at scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004240347538143396,
                  "neutral": 0.7538668513298035,
                  "support": 0.24189281463623047
                },
                "stance_score": 0.23765246709808707,
                "evidence_contribution": 0.20732620994014772,
                "combined_rank_score": 0.8723924160003662
              },
              {
                "id": 6150,
                "faiss_score": 0.8673204779624939,
                "faiss_rank": 15,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 26,
                "sentence": "Large models require distributed training across multiple devices, which introduces communication overhead and synchronization complexity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004209737293422222,
                  "neutral": 0.8323524594306946,
                  "support": 0.1634378284215927
                },
                "stance_score": 0.1592280911281705,
                "evidence_contribution": 0.13810178410234036,
                "combined_rank_score": 0.8673204779624939
              },
              {
                "id": 6136,
                "faiss_score": 0.8720614314079285,
                "faiss_rank": 9,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.07444310933351517,
                  "neutral": 0.7212331891059875,
                  "support": 0.2043236792087555
                },
                "stance_score": 0.12988056987524033,
                "evidence_contribution": 0.11326383567747955,
                "combined_rank_score": 0.8720614314079285
              },
              {
                "id": 5907,
                "faiss_score": 0.873874306678772,
                "faiss_rank": 6,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0055964053608477116,
                  "neutral": 0.8638582825660706,
                  "support": 0.13054534792900085
                },
                "stance_score": 0.12494894256815314,
                "evidence_contribution": 0.10918967055699053,
                "combined_rank_score": 0.873874306678772
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 5929,
                "faiss_score": 0.8740013241767883,
                "faiss_rank": 5,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 24,
                "sentence": "Large models require many iterations to converge, consuming significant compute.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005193229299038649,
                  "neutral": 0.9560596346855164,
                  "support": 0.03874707594513893
                },
                "stance_score": 0.03355384664610028,
                "evidence_contribution": 0.029326106399916535,
                "combined_rank_score": 0.8740013241767883
              },
              {
                "id": 5792,
                "faiss_score": 0.8738172054290771,
                "faiss_rank": 7,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 40,
                "sentence": "The amount of data required to learn a task depends on how much information must be extracted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.009939578361809254,
                  "neutral": 0.9424147605895996,
                  "support": 0.047645680606365204
                },
                "stance_score": 0.03770610224455595,
                "evidence_contribution": 0.032948240890960934,
                "combined_rank_score": 0.8738172054290771
              },
              {
                "id": 1795,
                "faiss_score": 0.8695147037506104,
                "faiss_rank": 14,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 63,
                "sentence": "Substantial infrastructure is necessary for training the largest models.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.008260958828032017,
                  "neutral": 0.8914207220077515,
                  "support": 0.1003183126449585
                },
                "stance_score": 0.09205735381692648,
                "evidence_contribution": 0.08004522273218995,
                "combined_rank_score": 0.8695147037506104
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "perform many tasks",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6707,
                      "faiss_score": 0.8720545768737793,
                      "faiss_rank": 1,
                      "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "Some workloads consist of many small, independent requests, while others involve long-running operations.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0020800072234123945,
                        "neutral": 0.29610347747802734,
                        "support": 0.7018164396286011
                      },
                      "stance_score": 0.6997364324051887,
                      "evidence_contribution": 0.6102083584842747,
                      "combined_rank_score": 0.8720545768737793
                    },
                    {
                      "id": 6684,
                      "faiss_score": 0.8688691258430481,
                      "faiss_rank": 2,
                      "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                      "file_type": ".txt",
                      "position": 16,
                      "sentence": "By distributing work across multiple processors or machines, systems can handle more requests concurrently.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0014955847291275859,
                        "neutral": 0.36917710304260254,
                        "support": 0.6293273568153381
                      },
                      "stance_score": 0.6278317720862105,
                      "evidence_contribution": 0.5455036429890375,
                      "combined_rank_score": 0.8688691258430481
                    },
                    {
                      "id": 3888,
                      "faiss_score": 0.8647795915603638,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Latency_(engineering)",
                      "file_type": ".txt",
                      "position": 57,
                      "sentence": "In the context of computer multitasking, the execution of the process can be postponed if other processes are also executing.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Latency_(engineering)",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.002972701331600547,
                        "neutral": 0.20477400720119476,
                        "support": 0.792253315448761
                      },
                      "stance_score": 0.7892806141171604,
                      "evidence_contribution": 0.6825537671027511,
                      "combined_rank_score": 0.8647795915603638
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 6110,
                      "faiss_score": 0.8411685824394226,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 70,
                      "sentence": "Tasks that once required specialized pipelines can now be addressed using general-purpose models.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.007752911187708378,
                        "neutral": 0.9306866526603699,
                        "support": 0.06156041473150253
                      },
                      "stance_score": 0.053807503543794155,
                      "evidence_contribution": 0.04526118148053754,
                      "combined_rank_score": 0.8411685824394226
                    },
                    {
                      "id": 3889,
                      "faiss_score": 0.8411526679992676,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Latency_(engineering)",
                      "file_type": ".txt",
                      "position": 58,
                      "sentence": "In addition, the operating system can schedule when to perform the action that the process is commanding.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Latency_(engineering)",
                      "primary_category": "all wikipedia articles written in american english",
                      "probs": {
                        "contradict": 0.0023500462993979454,
                        "neutral": 0.9915545582771301,
                        "support": 0.00609543127939105
                      },
                      "stance_score": 0.003745384979993105,
                      "evidence_contribution": 0.0031504405686055836,
                      "combined_rank_score": 0.8411526679992676
                    },
                    {
                      "id": 2193,
                      "faiss_score": 0.8400170803070068,
                      "faiss_rank": 12,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 124,
                      "sentence": "All the nodes connected by links take in some data and use it to perform specific operations and tasks on the data.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.001011320622637868,
                        "neutral": 0.9790430068969727,
                        "support": 0.01994563639163971
                      },
                      "stance_score": 0.01893431576900184,
                      "evidence_contribution": 0.015905148649887846,
                      "combined_rank_score": 0.8400170803070068
                    }
                  ]
                }
              },
              {
                "subclaim": "generalize across domains",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6128,
                      "faiss_score": 0.875458836555481,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 4,
                      "sentence": "These trends have been observed across different domains and architectures, suggesting that scaling captures general properties of learning systems rather than task-specific quirks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.006305638700723648,
                        "neutral": 0.11608841270208359,
                        "support": 0.8776058554649353
                      },
                      "stance_score": 0.8713002167642117,
                      "evidence_contribution": 0.7627874740589351,
                      "combined_rank_score": 0.875458836555481
                    },
                    {
                      "id": 6405,
                      "faiss_score": 0.8751733899116516,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 144,
                      "sentence": "These representations encode statistical regularities of language and sequence structure, allowing models to generalize across contexts.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.008740616962313652,
                        "neutral": 0.12911827862262726,
                        "support": 0.8621411323547363
                      },
                      "stance_score": 0.8534005153924227,
                      "evidence_contribution": 0.7468734220083372,
                      "combined_rank_score": 0.8751733899116516
                    },
                    {
                      "id": 2072,
                      "faiss_score": 0.8717225790023804,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "This method allows the network to generalize to unseen data.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.015541942790150642,
                        "neutral": 0.7024780511856079,
                        "support": 0.281980037689209
                      },
                      "stance_score": 0.26643809489905834,
                      "evidence_contribution": 0.2322601032298881,
                      "combined_rank_score": 0.8717225790023804
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5562,
                      "faiss_score": 0.8713772296905518,
                      "faiss_rank": 9,
                      "doc_id": "local_bio_gene_editing.txt",
                      "file_type": ".txt",
                      "position": 35,
                      "sentence": "These factors complicate efforts to generalize results across systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\bio_gene_editing.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.4898774325847626,
                        "neutral": 0.23325194418430328,
                        "support": 0.2768707275390625
                      },
                      "stance_score": -0.21300670504570007,
                      "evidence_contribution": -0.1856091925482346,
                      "combined_rank_score": 0.8713772296905518
                    },
                    {
                      "id": 6018,
                      "faiss_score": 0.8650850057601929,
                      "faiss_rank": 15,
                      "doc_id": "local_ml_evaluation_and_generalization.txt",
                      "file_type": ".txt",
                      "position": 44,
                      "sentence": "A model trained and evaluated in one environment may generalize poorly in another due to subtle differences.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.5686880350112915,
                        "neutral": 0.18720504641532898,
                        "support": 0.24410688877105713
                      },
                      "stance_score": -0.3245811462402344,
                      "evidence_contribution": -0.28079028276488316,
                      "combined_rank_score": 0.8650850057601929
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5977,
                      "faiss_score": 0.8809024095535278,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_evaluation_and_generalization.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "Generalization refers to a model\u2019s ability to perform well on data drawn from the same underlying process as the training data, even when individual examples differ.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004105135798454285,
                        "neutral": 0.9529510736465454,
                        "support": 0.042943768203258514
                      },
                      "stance_score": 0.03883863240480423,
                      "evidence_contribution": 0.03421304486915577,
                      "combined_rank_score": 0.8809024095535278
                    },
                    {
                      "id": 5770,
                      "faiss_score": 0.8777358531951904,
                      "faiss_rank": 2,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "Generalization requires extracting information that is predictive of unseen data while discarding irrelevant details.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004218193702399731,
                        "neutral": 0.9678018093109131,
                        "support": 0.027980053797364235
                      },
                      "stance_score": 0.023761860094964504,
                      "evidence_contribution": 0.020856636543958418,
                      "combined_rank_score": 0.8777358531951904
                    },
                    {
                      "id": 6004,
                      "faiss_score": 0.876814603805542,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_evaluation_and_generalization.txt",
                      "file_type": ".txt",
                      "position": 30,
                      "sentence": "Generalization is also influenced by data quality.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.021363889798521996,
                        "neutral": 0.923850417137146,
                        "support": 0.054785650223493576
                      },
                      "stance_score": 0.03342176042497158,
                      "evidence_contribution": 0.0293046876255052,
                      "combined_rank_score": 0.876814603805542
                    }
                  ]
                }
              },
              {
                "subclaim": "lack grounded reasoning",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6111,
                      "faiss_score": 0.8929279446601868,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 71,
                      "sentence": "At the same time, this progress has highlighted fundamental limitations related to grounding, reasoning, and reliability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.09977399557828903,
                        "neutral": 0.6214102506637573,
                        "support": 0.27881574630737305
                      },
                      "stance_score": 0.17904175072908401,
                      "evidence_contribution": 0.15987138248688249,
                      "combined_rank_score": 0.8929279446601868
                    },
                    {
                      "id": 6187,
                      "faiss_score": 0.8757100701332092,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "It can unlock capabilities that are difficult to achieve otherwise, but it does not solve fundamental problems related to understanding, grounding, or reasoning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.09269913285970688,
                        "neutral": 0.4912792444229126,
                        "support": 0.4160216450691223
                      },
                      "stance_score": 0.32332251220941544,
                      "evidence_contribution": 0.2831367798425526,
                      "combined_rank_score": 0.8757100701332092
                    },
                    {
                      "id": 6054,
                      "faiss_score": 0.8733642101287842,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Others counter that any appearance of understanding is an artifact of training on massive datasets and that the models lack grounding in real-world experience.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.011887310072779655,
                        "neutral": 0.4753391742706299,
                        "support": 0.5127735137939453
                      },
                      "stance_score": 0.5008862037211657,
                      "evidence_contribution": 0.4374560836773411,
                      "combined_rank_score": 0.8733642101287842
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6409,
                      "faiss_score": 0.8798010349273682,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 148,
                      "sentence": "Tasks that require multi-step inference, logical consistency, or grounding in external reality often expose limitations.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.4127979576587677,
                        "neutral": 0.5286512970924377,
                        "support": 0.05855078622698784
                      },
                      "stance_score": -0.35424717143177986,
                      "evidence_contribution": -0.31166702804577273,
                      "combined_rank_score": 0.8798010349273682
                    },
                    {
                      "id": 6257,
                      "faiss_score": 0.851122260093689,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 65,
                      "sentence": "However, reliance on heuristics can limit understanding and transferability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.22396555542945862,
                        "neutral": 0.6896719932556152,
                        "support": 0.08636243641376495
                      },
                      "stance_score": -0.13760311901569366,
                      "evidence_contribution": -0.11711707765257806,
                      "combined_rank_score": 0.851122260093689
                    },
                    {
                      "id": 4980,
                      "faiss_score": 0.8499214053153992,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Church\u2013Turing_thesis",
                      "file_type": ".txt",
                      "position": 20,
                      "sentence": "But he did not think that the two ideas could be satisfactorily identified \"except heuristically\".",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis",
                      "primary_category": "alan turing",
                      "probs": {
                        "contradict": 0.18368926644325256,
                        "neutral": 0.7439891695976257,
                        "support": 0.07232155650854111
                      },
                      "stance_score": -0.11136770993471146,
                      "evidence_contribution": -0.0946538005344677,
                      "combined_rank_score": 0.8499214053153992
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6316,
                      "faiss_score": 0.8470757007598877,
                      "faiss_rank": 11,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 55,
                      "sentence": "They may be combined with retrieval mechanisms, symbolic components, or task-specific modules to address shortcomings related to grounding and factual accuracy.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.1106201559305191,
                        "neutral": 0.7101302742958069,
                        "support": 0.17924952507019043
                      },
                      "stance_score": 0.06862936913967133,
                      "evidence_contribution": 0.0581342709566961,
                      "combined_rank_score": 0.8470757007598877
                    },
                    {
                      "id": 6319,
                      "faiss_score": 0.8424455523490906,
                      "faiss_rank": 15,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 58,
                      "sentence": "While attention weights offer some insight into model behavior, they do not provide a complete explanation of decision-making processes.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.01719685271382332,
                        "neutral": 0.9187061786651611,
                        "support": 0.06409695744514465
                      },
                      "stance_score": 0.046900104731321335,
                      "evidence_contribution": 0.0395107846356082,
                      "combined_rank_score": 0.8424455523490906
                    },
                    {
                      "id": 1605,
                      "faiss_score": 0.8396142721176147,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Optimization_(mathematics)",
                      "file_type": ".txt",
                      "position": 54,
                      "sentence": "Usually, heuristics do not guarantee that any optimal solution need be found.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                      "primary_category": "all articles with style issues",
                      "probs": {
                        "contradict": 0.15037643909454346,
                        "neutral": 0.7374339699745178,
                        "support": 0.11218959838151932
                      },
                      "stance_score": -0.03818684071302414,
                      "evidence_contribution": -0.03206221646973706,
                      "combined_rank_score": 0.8396142721176147
                    }
                  ]
                }
              },
              {
                "subclaim": "require massive datasets",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6308,
                      "faiss_score": 0.8858730792999268,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 47,
                      "sentence": "Another challenge associated with transformers is their reliance on large datasets for effective training.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0018392824567854404,
                        "neutral": 0.18031391501426697,
                        "support": 0.8178468942642212
                      },
                      "stance_score": 0.8160076118074358,
                      "evidence_contribution": 0.7228791758040324,
                      "combined_rank_score": 0.8858730792999268
                    },
                    {
                      "id": 6309,
                      "faiss_score": 0.8829025030136108,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 48,
                      "sentence": "High-capacity models are prone to overfitting when data is scarce, and strong generalization typically requires pretraining on massive corpora.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.002582910005003214,
                        "neutral": 0.23085328936576843,
                        "support": 0.7665637731552124
                      },
                      "stance_score": 0.7639808631502092,
                      "evidence_contribution": 0.6745206163298185,
                      "combined_rank_score": 0.8829025030136108
                    },
                    {
                      "id": 1394,
                      "faiss_score": 0.8828780651092529,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Overfitting",
                      "file_type": ".txt",
                      "position": 44,
                      "sentence": "The optimal function usually needs verification on bigger or completely new datasets.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.005039381794631481,
                        "neutral": 0.569232702255249,
                        "support": 0.42572787404060364
                      },
                      "stance_score": 0.42068849224597216,
                      "evidence_contribution": 0.37141664204785285,
                      "combined_rank_score": 0.8828780651092529
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 5929,
                      "faiss_score": 0.8740013241767883,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 24,
                      "sentence": "Large models require many iterations to converge, consuming significant compute.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005193229299038649,
                        "neutral": 0.9560596346855164,
                        "support": 0.03874707594513893
                      },
                      "stance_score": 0.03355384664610028,
                      "evidence_contribution": 0.029326106399916535,
                      "combined_rank_score": 0.8740013241767883
                    },
                    {
                      "id": 5792,
                      "faiss_score": 0.8738172054290771,
                      "faiss_rank": 7,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 40,
                      "sentence": "The amount of data required to learn a task depends on how much information must be extracted.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.009939578361809254,
                        "neutral": 0.9424147605895996,
                        "support": 0.047645680606365204
                      },
                      "stance_score": 0.03770610224455595,
                      "evidence_contribution": 0.032948240890960934,
                      "combined_rank_score": 0.8738172054290771
                    },
                    {
                      "id": 1795,
                      "faiss_score": 0.8695147037506104,
                      "faiss_rank": 14,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "Substantial infrastructure is necessary for training the largest models.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.008260958828032017,
                        "neutral": 0.8914207220077515,
                        "support": 0.1003183126449585
                      },
                      "stance_score": 0.09205735381692648,
                      "evidence_contribution": 0.08004522273218995,
                      "combined_rank_score": 0.8695147037506104
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Large language models generate fluent text",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6042,
                      "faiss_score": 0.8820071816444397,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 2,
                      "sentence": "This simple training signal, when combined with large datasets and high model capacity, produces systems that can generate coherent text, answer questions, summarize documents, and perform a wide variety of language-related tasks without explicit task-specific programming.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.008569732308387756,
                        "neutral": 0.6420539617538452,
                        "support": 0.34937629103660583
                      },
                      "stance_score": 0.3408065587282181,
                      "evidence_contribution": 0.30059383234981585,
                      "combined_rank_score": 0.8820071816444397
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6121,
                      "faiss_score": 0.9008355140686035,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.3488886058330536,
                        "neutral": 0.6439270973205566,
                        "support": 0.00718427961692214
                      },
                      "stance_score": -0.34170432621613145,
                      "evidence_contribution": -0.30781939236637457,
                      "combined_rank_score": 0.9008355140686035
                    },
                    {
                      "id": 6047,
                      "faiss_score": 0.8832986354827881,
                      "faiss_rank": 7,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Despite these capabilities, the behavior of large language models remains fundamentally probabilistic.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.18742139637470245,
                        "neutral": 0.8073830604553223,
                        "support": 0.005195515230298042
                      },
                      "stance_score": -0.1822258811444044,
                      "evidence_contribution": -0.16095987216450114,
                      "combined_rank_score": 0.8832986354827881
                    },
                    {
                      "id": 2011,
                      "faiss_score": 0.8802152872085571,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 279,
                      "sentence": "The incorrect completions were generated by sampling from a language model.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.8098839521408081,
                        "neutral": 0.18671365082263947,
                        "support": 0.003402373054996133
                      },
                      "stance_score": -0.806481579085812,
                      "evidence_contribution": -0.7098774147634287,
                      "combined_rank_score": 0.8802152872085571
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6040,
                      "faiss_score": 0.9094253778457642,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.01122680027037859,
                        "neutral": 0.9780644178390503,
                        "support": 0.010708799585700035
                      },
                      "stance_score": -0.0005180006846785545,
                      "evidence_contribution": -0.000471082968388159,
                      "combined_rank_score": 0.9094253778457642
                    },
                    {
                      "id": 6043,
                      "faiss_score": 0.8940900564193726,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.06802935898303986,
                        "neutral": 0.9228030443191528,
                        "support": 0.009167566895484924
                      },
                      "stance_score": -0.05886179208755493,
                      "evidence_contribution": -0.052627743008507366,
                      "combined_rank_score": 0.8940900564193726
                    },
                    {
                      "id": 6115,
                      "faiss_score": 0.8894862532615662,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "Large language models also influence how users interact with technology.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.021805865690112114,
                        "neutral": 0.9743995666503906,
                        "support": 0.0037945706862956285
                      },
                      "stance_score": -0.018011295003816485,
                      "evidence_contribution": -0.01602079930933349,
                      "combined_rank_score": 0.8894862532615662
                    }
                  ]
                }
              },
              {
                "subclaim": "hallucinate facts",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 1958,
                      "faiss_score": 0.8864883184432983,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 226,
                      "sentence": "Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \"hallucination\".",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.1281960904598236,
                        "neutral": 0.25289106369018555,
                        "support": 0.6189128756523132
                      },
                      "stance_score": 0.4907167851924896,
                      "evidence_contribution": 0.43501469773719137,
                      "combined_rank_score": 0.8864883184432983
                    },
                    {
                      "id": 6062,
                      "faiss_score": 0.8709315061569214,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 22,
                      "sentence": "Hallucinations can occur even when the model has seen relevant information during training, as generation depends on local likelihood rather than global verification.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.16398467123508453,
                        "neutral": 0.570544958114624,
                        "support": 0.265470415353775
                      },
                      "stance_score": 0.10148574411869049,
                      "evidence_contribution": 0.08838713197874704,
                      "combined_rank_score": 0.8709315061569214
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6063,
                      "faiss_score": 0.8869999647140503,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 23,
                      "sentence": "The tendency to hallucinate is influenced by prompting, context length, and decoding strategies.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.28592926263809204,
                        "neutral": 0.5544893145561218,
                        "support": 0.15958142280578613
                      },
                      "stance_score": -0.1263478398323059,
                      "evidence_contribution": -0.11207052947295182,
                      "combined_rank_score": 0.8869999647140503
                    },
                    {
                      "id": 2021,
                      "faiss_score": 0.8814721703529358,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 289,
                      "sentence": "Hallucinations represent a fundamental challenge, wherein models generate syntactically fluent text that appears factually sound, but is internally inconsistent with training data or factually incorrect.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.6222884654998779,
                        "neutral": 0.27321556210517883,
                        "support": 0.10449595004320145
                      },
                      "stance_score": -0.5177925154566765,
                      "evidence_contribution": -0.45641969239210267,
                      "combined_rank_score": 0.8814721703529358
                    },
                    {
                      "id": 1959,
                      "faiss_score": 0.8755703568458557,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 227,
                      "sentence": "Specifically, hallucinations in the context of LLMs correspond to the generation of text or responses that seem syntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the provided source input.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.9376419186592102,
                        "neutral": 0.04097185656428337,
                        "support": 0.021386215463280678
                      },
                      "stance_score": -0.9162557031959295,
                      "evidence_contribution": -0.8022463330093105,
                      "combined_rank_score": 0.8755703568458557
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6060,
                      "faiss_score": 0.8803726434707642,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 20,
                      "sentence": "Hallucination is one of the most widely discussed failure modes of large language models.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.2402685284614563,
                        "neutral": 0.5552210211753845,
                        "support": 0.20451043546199799
                      },
                      "stance_score": -0.03575809299945831,
                      "evidence_contribution": -0.03148044685940654,
                      "combined_rank_score": 0.8803726434707642
                    },
                    {
                      "id": 5769,
                      "faiss_score": 0.801109790802002,
                      "faiss_rank": 16,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 17,
                      "sentence": "The model memorizes noise rather than structure.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.15454168617725372,
                        "neutral": 0.7853820323944092,
                        "support": 0.06007632240653038
                      },
                      "stance_score": -0.09446536377072334,
                      "evidence_contribution": -0.07567712780839919,
                      "combined_rank_score": 0.801109790802002
                    },
                    {
                      "id": 4080,
                      "faiss_score": 0.7994356155395508,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Information_theory",
                      "file_type": ".txt",
                      "position": 74,
                      "sentence": "All such sources are stochastic.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Information_theory",
                      "primary_category": "all articles needing additional references",
                      "probs": {
                        "contradict": 0.17223607003688812,
                        "neutral": 0.7325766682624817,
                        "support": 0.09518726170063019
                      },
                      "stance_score": -0.07704880833625793,
                      "evidence_contribution": -0.06159556151888523,
                      "combined_rank_score": 0.7994356155395508
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "encode societal biases",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 411,
                      "faiss_score": 0.9120092988014221,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 302,
                      "sentence": "When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.04815658554434776,
                        "neutral": 0.2623845934867859,
                        "support": 0.6894589066505432
                      },
                      "stance_score": 0.6413023211061954,
                      "evidence_contribution": 0.5848736801917858,
                      "combined_rank_score": 0.9120092988014221
                    },
                    {
                      "id": 412,
                      "faiss_score": 0.911769449710846,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 303,
                      "sentence": "Systems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitising cultural prejudices.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.0075705829076468945,
                        "neutral": 0.11338216811418533,
                        "support": 0.8790472149848938
                      },
                      "stance_score": 0.8714766320772469,
                      "evidence_contribution": 0.7945857692649327,
                      "combined_rank_score": 0.911769449710846
                    },
                    {
                      "id": 2024,
                      "faiss_score": 0.878750205039978,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 292,
                      "sentence": "This can manifest in skewed representations or unfair treatment of different demographics, such as those based on race, gender, language, and cultural groups.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.06153199449181557,
                        "neutral": 0.42110925912857056,
                        "support": 0.5173587799072266
                      },
                      "stance_score": 0.455826785415411,
                      "evidence_contribution": 0.4005578811465065,
                      "combined_rank_score": 0.878750205039978
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 2039,
                      "faiss_score": 0.8821737170219421,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 307,
                      "sentence": "Language models may also exhibit political biases.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.5698038339614868,
                        "neutral": 0.17982693016529083,
                        "support": 0.25036919116973877
                      },
                      "stance_score": -0.31943464279174805,
                      "evidence_contribution": -0.2817968461771727,
                      "combined_rank_score": 0.8821737170219421
                    },
                    {
                      "id": 2038,
                      "faiss_score": 0.8740885257720947,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 306,
                      "sentence": "Political bias refers to the tendency of algorithms to systematically favor certain political viewpoints, ideologies, or outcomes over others.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.9876894950866699,
                        "neutral": 0.010320872068405151,
                        "support": 0.001989632612094283
                      },
                      "stance_score": -0.9856998624745756,
                      "evidence_contribution": -0.8615889396441583,
                      "combined_rank_score": 0.8740885257720947
                    },
                    {
                      "id": 2026,
                      "faiss_score": 0.8653594851493835,
                      "faiss_rank": 14,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 294,
                      "sentence": "Language-based bias emerges from overrepresentation of English text in training corpora, which systematically downplays non-English perspectives and imposes English-centric worldviews through default response patterns.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.5331867337226868,
                        "neutral": 0.3443293571472168,
                        "support": 0.12248389422893524
                      },
                      "stance_score": -0.4107028394937515,
                      "evidence_contribution": -0.3554055977337027,
                      "combined_rank_score": 0.8653594851493835
                    }
                  ],
                  "neutral": [
                    {
                      "id": 354,
                      "faiss_score": 0.8632741570472717,
                      "faiss_rank": 16,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 245,
                      "sentence": "Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "probs": {
                        "contradict": 0.23116815090179443,
                        "neutral": 0.47713980078697205,
                        "support": 0.2916921079158783
                      },
                      "stance_score": 0.06052395701408386,
                      "evidence_contribution": 0.052248767972498555,
                      "combined_rank_score": 0.8632741570472717
                    },
                    {
                      "id": 2023,
                      "faiss_score": 0.8627463579177856,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 291,
                      "sentence": "While LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to inheriting and amplifying biases present in their training data.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.009690002538263798,
                        "neutral": 0.8865801095962524,
                        "support": 0.10372987389564514
                      },
                      "stance_score": 0.09403987135738134,
                      "evidence_contribution": 0.08113255651263784,
                      "combined_rank_score": 0.8627463579177856
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Increasing computational resources improves deep learning training speed, enables larger models, and stabilizes optimization, but increases cost, energy usage, hardware dependence, and environmental impact.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Increasing computational resources improves deep learning training speed",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.6764493959718474,
            "contradict": 3.2220499982790223,
            "total": 3.8984993942508694
          },
          "evidence": {
            "supporting": [
              {
                "id": 2625,
                "faiss_score": 0.87431401014328,
                "faiss_rank": 14,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 220,
                "sentence": "Special electronic circuits called deep learning processors were designed to speed up deep learning algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.003962540999054909,
                  "neutral": 0.5770430564880371,
                  "support": 0.41899439692497253
                },
                "stance_score": 0.4150318559259176,
                "evidence_contribution": 0.3628681662917971,
                "combined_rank_score": 0.87431401014328
              },
              {
                "id": 2160,
                "faiss_score": 0.8728535175323486,
                "faiss_rank": 15,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 91,
                "sentence": "They also showed how max-pooling CNNs on GPU improved performance significantly.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.001898330869153142,
                  "neutral": 0.862531304359436,
                  "support": 0.13557033240795135
                },
                "stance_score": 0.1336720015387982,
                "evidence_contribution": 0.11667607673872954,
                "combined_rank_score": 0.8728535175323486
              },
              {
                "id": 2164,
                "faiss_score": 0.8744220733642578,
                "faiss_rank": 13,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 95,
                "sentence": "Unsupervised pre-training and increased computing power from GPUs and distributed computing allowed the use of larger networks, particularly in image and visual recognition problems, which became known as \"deep learning\".",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.0037023804616183043,
                  "neutral": 0.8704550266265869,
                  "support": 0.1258426308631897
                },
                "stance_score": 0.12214025040157139,
                "evidence_contribution": 0.10680213099737168,
                "combined_rank_score": 0.8744220733642578
              },
              {
                "id": 1901,
                "faiss_score": 0.8789441585540771,
                "faiss_rank": 9,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 169,
                "sentence": "OptiLLM demonstrates that strategic application of computational resources at inference time can substantially improve model performance across diverse tasks, achieving significant improvements on benchmarks such as the AIME 2024 mathematics competition and various coding challenges.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.005857494659721851,
                  "neutral": 0.885772168636322,
                  "support": 0.10837028920650482
                },
                "stance_score": 0.10251279454678297,
                "evidence_contribution": 0.09010302194394915,
                "combined_rank_score": 0.8789441585540771
              }
            ],
            "contradicting": [
              {
                "id": 6246,
                "faiss_score": 0.8795201778411865,
                "faiss_rank": 7,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 54,
                "sentence": "By halting training when performance on a validation set stops improving, systems can avoid overfitting and reduce resource usage.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9828004837036133,
                  "neutral": 0.015793360769748688,
                  "support": 0.0014060891699045897
                },
                "stance_score": -0.9813943945337087,
                "evidence_contribution": -0.8631561724126311,
                "combined_rank_score": 0.8795201778411865
              },
              {
                "id": 5905,
                "faiss_score": 0.8791102170944214,
                "faiss_rank": 8,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.682704746723175,
                  "neutral": 0.3102189600467682,
                  "support": 0.00707629369571805
                },
                "stance_score": -0.675628453027457,
                "evidence_contribution": -0.5939518760161357,
                "combined_rank_score": 0.8791102170944214
              },
              {
                "id": 5952,
                "faiss_score": 0.8759465217590332,
                "faiss_rank": 11,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Energy efficiency has become increasingly important as machine learning workloads scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6455092430114746,
                  "neutral": 0.3458738625049591,
                  "support": 0.008616907522082329
                },
                "stance_score": -0.6368923354893923,
                "evidence_contribution": -0.5578836260069204,
                "combined_rank_score": 0.8759465217590332
              },
              {
                "id": 6092,
                "faiss_score": 0.871161937713623,
                "faiss_rank": 18,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.4916369318962097,
                  "neutral": 0.5053229331970215,
                  "support": 0.003040109295397997
                },
                "stance_score": -0.4885968226008117,
                "evidence_contribution": -0.42564695473764247,
                "combined_rank_score": 0.871161937713623
              },
              {
                "id": 5907,
                "faiss_score": 0.8837117552757263,
                "faiss_rank": 6,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.45006662607192993,
                  "neutral": 0.5438736081123352,
                  "support": 0.006059776060283184
                },
                "stance_score": -0.44400685001164675,
                "evidence_contribution": -0.3923740727782385,
                "combined_rank_score": 0.8837117552757263
              },
              {
                "id": 5906,
                "faiss_score": 0.877042293548584,
                "faiss_rank": 10,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Early successes in deep learning were often achieved by increasing model size and training data, but this approach quickly encounters practical limits.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.29159143567085266,
                  "neutral": 0.7015077471733093,
                  "support": 0.006900775246322155
                },
                "stance_score": -0.2846906604245305,
                "evidence_contribution": -0.24968574977059133,
                "combined_rank_score": 0.877042293548584
              },
              {
                "id": 6352,
                "faiss_score": 0.8695347905158997,
                "faiss_rank": 20,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 91,
                "sentence": "Communication overhead, memory constraints, and numerical stability all play important roles in large-scale training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.16435949504375458,
                  "neutral": 0.8315408825874329,
                  "support": 0.004099608864635229
                },
                "stance_score": -0.16025988617911935,
                "evidence_contribution": -0.13935154655686247,
                "combined_rank_score": 0.8695347905158997
              }
            ],
            "neutral": [
              {
                "id": 2393,
                "faiss_score": 0.8931306600570679,
                "faiss_rank": 1,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 324,
                "sentence": "Large and effective neural networks require considerable computing resources.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.05511556938290596,
                  "neutral": 0.9371413588523865,
                  "support": 0.007743130438029766
                },
                "stance_score": -0.047372438944876194,
                "evidence_contribution": -0.04230977766335042,
                "combined_rank_score": 0.8931306600570679
              },
              {
                "id": 2622,
                "faiss_score": 0.892419695854187,
                "faiss_rank": 2,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 217,
                "sentence": "Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0014016155619174242,
                  "neutral": 0.9192524552345276,
                  "support": 0.0793459415435791
                },
                "stance_score": 0.07794432598166168,
                "evidence_contribution": 0.06955905168611412,
                "combined_rank_score": 0.892419695854187
              },
              {
                "id": 6044,
                "faiss_score": 0.890583872795105,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0011553606018424034,
                  "neutral": 0.9447371959686279,
                  "support": 0.0541074313223362
                },
                "stance_score": 0.052952070720493793,
                "evidence_contribution": 0.04715826021477765,
                "combined_rank_score": 0.890583872795105
              }
            ]
          }
        },
        {
          "subclaim": "Increasing computational resources enables larger models",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 0.8549248171617397,
            "contradict": 1.000700346701591,
            "total": 1.8556251638633308
          },
          "evidence": {
            "supporting": [
              {
                "id": 1795,
                "faiss_score": 0.8900411128997803,
                "faiss_rank": 16,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 63,
                "sentence": "Substantial infrastructure is necessary for training the largest models.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "probs": {
                  "contradict": 0.00380844553001225,
                  "neutral": 0.4181954264640808,
                  "support": 0.5779961347579956
                },
                "stance_score": 0.5741876892279834,
                "evidence_contribution": 0.5110506499338274,
                "combined_rank_score": 0.8900411128997803
              },
              {
                "id": 6131,
                "faiss_score": 0.8856824636459351,
                "faiss_rank": 20,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0036448510363698006,
                  "neutral": 0.844368040561676,
                  "support": 0.15198716521263123
                },
                "stance_score": 0.14834231417626143,
                "evidence_contribution": 0.13138418628257054,
                "combined_rank_score": 0.8856824636459351
              },
              {
                "id": 6349,
                "faiss_score": 0.893662691116333,
                "faiss_rank": 11,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 88,
                "sentence": "As models scale, training efficiency becomes a primary concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0023103414569050074,
                  "neutral": 0.8747334480285645,
                  "support": 0.12295623868703842
                },
                "stance_score": 0.12064589723013341,
                "evidence_contribution": 0.10781673719082557,
                "combined_rank_score": 0.893662691116333
              },
              {
                "id": 2393,
                "faiss_score": 0.8888487815856934,
                "faiss_rank": 17,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 324,
                "sentence": "Large and effective neural networks require considerable computing resources.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.021992327645421028,
                  "neutral": 0.8382526636123657,
                  "support": 0.1397550404071808
                },
                "stance_score": 0.11776271276175976,
                "evidence_contribution": 0.10467324375451614,
                "combined_rank_score": 0.8888487815856934
              }
            ],
            "contradicting": [
              {
                "id": 6153,
                "faiss_score": 0.9159849882125854,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 29,
                "sentence": "Memory constraints become significant as models grow.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6809476613998413,
                  "neutral": 0.3112615942955017,
                  "support": 0.007790726143866777
                },
                "stance_score": -0.6731569352559745,
                "evidence_contribution": -0.6166016474056639,
                "combined_rank_score": 0.9159849882125854
              },
              {
                "id": 6147,
                "faiss_score": 0.88716059923172,
                "faiss_rank": 19,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 23,
                "sentence": "For example, increasing model size without increasing data may yield limited benefits, while increasing data without sufficient model capacity may fail to exploit the additional information.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3358306884765625,
                  "neutral": 0.6573573350906372,
                  "support": 0.006811974570155144
                },
                "stance_score": -0.32901871390640736,
                "evidence_contribution": -0.2918924393876582,
                "combined_rank_score": 0.88716059923172
              },
              {
                "id": 5968,
                "faiss_score": 0.9140965342521667,
                "faiss_rank": 3,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 63,
                "sentence": "As models continue to scale, new bottlenecks emerge.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.10449454933404922,
                  "neutral": 0.8918824195861816,
                  "support": 0.003623080672696233
                },
                "stance_score": -0.10087146866135299,
                "evidence_contribution": -0.09220625990826882,
                "combined_rank_score": 0.9140965342521667
              }
            ],
            "neutral": [
              {
                "id": 6132,
                "faiss_score": 0.9344620704650879,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Larger models have greater representational capacity, allowing them to fit more complex functions.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0012542104814201593,
                  "neutral": 0.9608927369117737,
                  "support": 0.03785300627350807
                },
                "stance_score": 0.03659879579208791,
                "evidence_contribution": 0.03420018649240342,
                "combined_rank_score": 0.9344620704650879
              },
              {
                "id": 6137,
                "faiss_score": 0.9030450582504272,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0010076063917949796,
                  "neutral": 0.9832544922828674,
                  "support": 0.01573786325752735
                },
                "stance_score": 0.014730256865732372,
                "evidence_contribution": 0.013302085669359046,
                "combined_rank_score": 0.9030450582504272
              },
              {
                "id": 1676,
                "faiss_score": 0.9014084339141846,
                "faiss_rank": 5,
                "doc_id": "wiki_Optimization_(mathematics)",
                "file_type": ".txt",
                "position": 125,
                "sentence": "Some versions can handle large-dimensional problems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                "primary_category": "all articles with style issues",
                "probs": {
                  "contradict": 0.000795436033513397,
                  "neutral": 0.9977479577064514,
                  "support": 0.0014566174941137433
                },
                "stance_score": 0.0006611814606003463,
                "evidence_contribution": 0.0005959945449328513,
                "combined_rank_score": 0.9014084339141846
              }
            ]
          }
        },
        {
          "subclaim": "Increasing computational resources stabilizes optimization",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 3.015526693691172,
            "total": 3.015526693691172
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 5890,
                "faiss_score": 0.8737372756004333,
                "faiss_rank": 15,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 59,
                "sentence": "Asynchronous optimization can improve throughput but may slow convergence or introduce bias.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6580743789672852,
                  "neutral": 0.33626577258110046,
                  "support": 0.005659839604049921
                },
                "stance_score": -0.6524145393632352,
                "evidence_contribution": -0.5700389021853448,
                "combined_rank_score": 0.8737372756004333
              },
              {
                "id": 5888,
                "faiss_score": 0.8729196786880493,
                "faiss_rank": 17,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 57,
                "sentence": "In distributed and parallel optimization, convergence is further complicated by communication delays and stale updates.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.6513517498970032,
                  "neutral": 0.3461077809333801,
                  "support": 0.0025404777843505144
                },
                "stance_score": -0.6488112721126527,
                "evidence_contribution": -0.5663601271817613,
                "combined_rank_score": 0.8729196786880493
              },
              {
                "id": 1670,
                "faiss_score": 0.8721450567245483,
                "faiss_rank": 20,
                "doc_id": "wiki_Optimization_(mathematics)",
                "file_type": ".txt",
                "position": 119,
                "sentence": "One major criterion for optimizers is just the number of required function evaluations as this often is already a large computational effort, usually much more effort than within the optimizer itself, which mainly has to operate over the N variables.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                "primary_category": "all articles with style issues",
                "probs": {
                  "contradict": 0.48692089319229126,
                  "neutral": 0.5009967684745789,
                  "support": 0.012082327157258987
                },
                "stance_score": -0.4748385660350323,
                "evidence_contribution": -0.4141281081096264,
                "combined_rank_score": 0.8721450567245483
              },
              {
                "id": 79,
                "faiss_score": 0.8764380216598511,
                "faiss_rank": 10,
                "doc_id": "openreview_ztgT8Iok130",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Computational methods have achieved initial success but still struggle with simultaneously optimizing multiple competing properties in a sample-efficient manner.",
                "source_type": "openreview",
                "credibility": 0.7,
                "source_url": "https://openreview.net/forum?id=ztgT8Iok130",
                "primary_category": null,
                "probs": {
                  "contradict": 0.3723789155483246,
                  "neutral": 0.6259058713912964,
                  "support": 0.001715235412120819
                },
                "stance_score": -0.37066368013620377,
                "evidence_contribution": -0.32486374251973427,
                "combined_rank_score": 0.8764380216598511
              },
              {
                "id": 5901,
                "faiss_score": 0.874020516872406,
                "faiss_rank": 12,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 70,
                "sentence": "Optimizing these factors often requires algorithmic compromises.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.34476158022880554,
                  "neutral": 0.6531848907470703,
                  "support": 0.00205355416983366
                },
                "stance_score": -0.3427080260589719,
                "evidence_contribution": -0.2995338460723846,
                "combined_rank_score": 0.874020516872406
              },
              {
                "id": 6352,
                "faiss_score": 0.8738290071487427,
                "faiss_rank": 14,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 91,
                "sentence": "Communication overhead, memory constraints, and numerical stability all play important roles in large-scale training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.33023399114608765,
                  "neutral": 0.6632477641105652,
                  "support": 0.006518249399960041
                },
                "stance_score": -0.3237157417461276,
                "evidence_contribution": -0.2828722052084375,
                "combined_rank_score": 0.8738290071487427
              },
              {
                "id": 5854,
                "faiss_score": 0.882411003112793,
                "faiss_rank": 6,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 23,
                "sentence": "Noise in optimization can be both beneficial and harmful.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.2581842541694641,
                  "neutral": 0.7393684387207031,
                  "support": 0.002447310136631131
                },
                "stance_score": -0.255736944032833,
                "evidence_contribution": -0.22566509331701234,
                "combined_rank_score": 0.882411003112793
              },
              {
                "id": 6134,
                "faiss_score": 0.8739696145057678,
                "faiss_rank": 13,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 10,
                "sentence": "Large models are also more sensitive to optimization choices and require careful tuning to train effectively.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.15146659314632416,
                  "neutral": 0.8450122475624084,
                  "support": 0.003521142527461052
                },
                "stance_score": -0.1479454506188631,
                "evidence_contribution": -0.1292998284452499,
                "combined_rank_score": 0.8739696145057678
              },
              {
                "id": 6196,
                "faiss_score": 0.8736796379089355,
                "faiss_rank": 16,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Initialization affects the early stages of optimization by shaping gradient magnitudes and conditioning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.12532155215740204,
                  "neutral": 0.8724360466003418,
                  "support": 0.0022424007765948772
                },
                "stance_score": -0.12307915138080716,
                "evidence_contribution": -0.10753174841252267,
                "combined_rank_score": 0.8736796379089355
              },
              {
                "id": 5863,
                "faiss_score": 0.8726218938827515,
                "faiss_rank": 18,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 32,
                "sentence": "Initialization influences optimization outcomes in non-convex problems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.11333110183477402,
                  "neutral": 0.8824722170829773,
                  "support": 0.004196672700345516
                },
                "stance_score": -0.1091344291344285,
                "evidence_contribution": -0.09523309223909793,
                "combined_rank_score": 0.8726218938827515
              }
            ],
            "neutral": [
              {
                "id": 5879,
                "faiss_score": 0.907509446144104,
                "faiss_rank": 1,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "Optimization is closely linked to numerical stability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00287438090890646,
                  "neutral": 0.9955047965049744,
                  "support": 0.0016208672896027565
                },
                "stance_score": -0.0012535136193037033,
                "evidence_contribution": -0.001137575450388395,
                "combined_rank_score": 0.907509446144104
              },
              {
                "id": 5857,
                "faiss_score": 0.8886821269989014,
                "faiss_rank": 2,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 26,
                "sentence": "Balancing exploration and stability is a recurring theme in optimization theory and practice.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.004754449240863323,
                  "neutral": 0.9945986270904541,
                  "support": 0.0006469713989645243
                },
                "stance_score": -0.004107477841898799,
                "evidence_contribution": -0.0036502421451394818,
                "combined_rank_score": 0.8886821269989014
              },
              {
                "id": 5892,
                "faiss_score": 0.8834568858146667,
                "faiss_rank": 3,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 61,
                "sentence": "Optimization also interacts with data properties.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.007102190982550383,
                  "neutral": 0.9921365976333618,
                  "support": 0.0007611767505295575
                },
                "stance_score": -0.006341014232020825,
                "evidence_contribution": -0.005602012686327599,
                "combined_rank_score": 0.8834568858146667
              }
            ]
          }
        },
        {
          "subclaim": "Increasing computational resources increases cost",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 1.1792803382778576,
            "contradict": 0.09691826277698068,
            "total": 1.2761986010548383
          },
          "evidence": {
            "supporting": [
              {
                "id": 5995,
                "faiss_score": 0.8827309012413025,
                "faiss_rank": 5,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "This technique reduces variance in evaluation estimates but increases computational cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001421174150891602,
                  "neutral": 0.3918896019458771,
                  "support": 0.6066892743110657
                },
                "stance_score": 0.6052681001601741,
                "evidence_contribution": 0.5342888555470015,
                "combined_rank_score": 0.8827309012413025
              },
              {
                "id": 6651,
                "faiss_score": 0.8786903619766235,
                "faiss_rank": 13,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 54,
                "sentence": "Adding redundancy increases cost and complexity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0019581627566367388,
                  "neutral": 0.4421144723892212,
                  "support": 0.5559273958206177
                },
                "stance_score": 0.5539692330639809,
                "evidence_contribution": 0.48676742592490196,
                "combined_rank_score": 0.8786903619766235
              },
              {
                "id": 2503,
                "faiss_score": 0.881470799446106,
                "faiss_rank": 7,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 98,
                "sentence": "However, those were more computationally expensive compared to backpropagation.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "probs": {
                  "contradict": 0.0016182546969503164,
                  "neutral": 0.8172633647918701,
                  "support": 0.18111830949783325
                },
                "stance_score": 0.17950005480088294,
                "evidence_contribution": 0.1582240568059541,
                "combined_rank_score": 0.881470799446106
              }
            ],
            "contradicting": [
              {
                "id": 5923,
                "faiss_score": 0.8798081874847412,
                "faiss_rank": 8,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "This technique shifts computational cost from deployment to training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.14017978310585022,
                  "neutral": 0.8297988176345825,
                  "support": 0.030021382495760918
                },
                "stance_score": -0.1101584006100893,
                "evidence_contribution": -0.09691826277698068,
                "combined_rank_score": 0.8798081874847412
              }
            ],
            "neutral": [
              {
                "id": 6354,
                "faiss_score": 0.8871214985847473,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 93,
                "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009665526449680328,
                  "neutral": 0.9539660811424255,
                  "support": 0.045067429542541504
                },
                "stance_score": 0.04410087689757347,
                "evidence_contribution": 0.03912283600227684,
                "combined_rank_score": 0.8871214985847473
              },
              {
                "id": 2393,
                "faiss_score": 0.8848891854286194,
                "faiss_rank": 2,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 324,
                "sentence": "Large and effective neural networks require considerable computing resources.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.0009062131284736097,
                  "neutral": 0.9973904490470886,
                  "support": 0.0017033421900123358
                },
                "stance_score": 0.0007971290615387261,
                "evidence_contribution": 0.0007053708859464831,
                "combined_rank_score": 0.8848891854286194
              },
              {
                "id": 6527,
                "faiss_score": 0.8844648003578186,
                "faiss_rank": 3,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 56,
                "sentence": "Software plays a critical role in determining how effectively computational resources are used.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.00802410114556551,
                  "neutral": 0.9895147085189819,
                  "support": 0.002461161930114031
                },
                "stance_score": -0.005562939215451479,
                "evidence_contribution": -0.004920223922596972,
                "combined_rank_score": 0.8844648003578186
              }
            ]
          }
        },
        {
          "subclaim": "Increasing computational resources increases energy usage",
          "verdict": "SUPPORT",
          "controversial": true,
          "strengths": {
            "support": 2.6845338452522864,
            "contradict": 1.383117478716394,
            "total": 4.067651323968681
          },
          "evidence": {
            "supporting": [
              {
                "id": 6484,
                "faiss_score": 0.8717974424362183,
                "faiss_rank": 13,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Increasing clock speeds leads to higher energy dissipation, which must be managed to prevent overheating.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001851145876571536,
                  "neutral": 0.1359056979417801,
                  "support": 0.8622431755065918
                },
                "stance_score": 0.8603920296300203,
                "evidence_contribution": 0.7500875709239586,
                "combined_rank_score": 0.8717974424362183
              },
              {
                "id": 5953,
                "faiss_score": 0.8869898319244385,
                "faiss_rank": 5,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "Training and deploying large models consume substantial energy, raising concerns about sustainability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0013868703972548246,
                  "neutral": 0.3060925304889679,
                  "support": 0.6925206184387207
                },
                "stance_score": 0.6911337480414659,
                "evidence_contribution": 0.613028607012607,
                "combined_rank_score": 0.8869898319244385
              },
              {
                "id": 6093,
                "faiss_score": 0.8679570555686951,
                "faiss_rank": 15,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Training requires specialized hardware, large-scale infrastructure, and significant energy consumption.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0016751564107835293,
                  "neutral": 0.6045272946357727,
                  "support": 0.3937976062297821
                },
                "stance_score": 0.3921224498189986,
                "evidence_contribution": 0.3403454469672814,
                "combined_rank_score": 0.8679570555686951
              },
              {
                "id": 5432,
                "faiss_score": 0.9075989723205566,
                "faiss_rank": 2,
                "doc_id": "wiki_Landauer's_principle",
                "file_type": ".txt",
                "position": 2,
                "sentence": "As of 2012, modern computers use about a billion times as much energy per operation.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Landauer%27s_principle",
                "primary_category": "all articles containing potentially dated statements",
                "probs": {
                  "contradict": 0.0011741387424990535,
                  "neutral": 0.6837896704673767,
                  "support": 0.31503620743751526
                },
                "stance_score": 0.3138620686950162,
                "evidence_contribution": 0.28486089099800066,
                "combined_rank_score": 0.9075989723205566
              },
              {
                "id": 5952,
                "faiss_score": 0.909400463104248,
                "faiss_rank": 1,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Energy efficiency has become increasingly important as machine learning workloads scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.09253448247909546,
                  "neutral": 0.5258767008781433,
                  "support": 0.38158881664276123
                },
                "stance_score": 0.28905433416366577,
                "evidence_contribution": 0.2628661453507277,
                "combined_rank_score": 0.909400463104248
              },
              {
                "id": 5381,
                "faiss_score": 0.8766747713088989,
                "faiss_rank": 11,
                "doc_id": "wiki_Reversible_computing",
                "file_type": ".txt",
                "position": 6,
                "sentence": "Reversible computing proponents argue that a significant portion of this energy consumption is due to architectural overheads.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Reversible_computing",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.03369560465216637,
                  "neutral": 0.725196897983551,
                  "support": 0.24110743403434753
                },
                "stance_score": 0.20741182938218117,
                "evidence_contribution": 0.18183271809038404,
                "combined_rank_score": 0.8766747713088989
              },
              {
                "id": 6483,
                "faiss_score": 0.8976882696151733,
                "faiss_rank": 3,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "Power consumption has emerged as a dominant constraint in modern computing systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.001076680375263095,
                  "neutral": 0.8365802764892578,
                  "support": 0.16234302520751953
                },
                "stance_score": 0.16126634483225644,
                "evidence_contribution": 0.14476690603963213,
                "combined_rank_score": 0.8976882696151733
              },
              {
                "id": 5907,
                "faiss_score": 0.8672863245010376,
                "faiss_rank": 16,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.011085989885032177,
                  "neutral": 0.8547480702400208,
                  "support": 0.1341659426689148
                },
                "stance_score": 0.12307995278388262,
                "evidence_contribution": 0.1067455598696948,
                "combined_rank_score": 0.8672863245010376
              }
            ],
            "contradicting": [
              {
                "id": 5954,
                "faiss_score": 0.8787448406219482,
                "faiss_rank": 8,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 49,
                "sentence": "Techniques that reduce computation or enable reuse of pretrained components can lower energy consumption.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.9419150948524475,
                  "neutral": 0.05364186316728592,
                  "support": 0.004443134646862745
                },
                "stance_score": -0.9374719602055848,
                "evidence_contribution": -0.823798648258402,
                "combined_rank_score": 0.8787448406219482
              },
              {
                "id": 6534,
                "faiss_score": 0.8766908645629883,
                "faiss_rank": 10,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 63,
                "sentence": "Research in computation increasingly emphasizes efficiency and sustainability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.5082404017448425,
                  "neutral": 0.4863085150718689,
                  "support": 0.005451128352433443
                },
                "stance_score": -0.5027892733924091,
                "evidence_contribution": -0.4407907627833878,
                "combined_rank_score": 0.8766908645629883
              },
              {
                "id": 5380,
                "faiss_score": 0.8628027439117432,
                "faiss_rank": 20,
                "doc_id": "wiki_Reversible_computing",
                "file_type": ".txt",
                "position": 5,
                "sentence": "The Landauer limit was millions of times below the energy consumption of computers in the 2000s and thousands of times less in the 2010s.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Reversible_computing",
                "primary_category": "articles with short description",
                "probs": {
                  "contradict": 0.1545737087726593,
                  "neutral": 0.8282281756401062,
                  "support": 0.01719808205962181
                },
                "stance_score": -0.1373756267130375,
                "evidence_contribution": -0.11852806767460411,
                "combined_rank_score": 0.8628027439117432
              }
            ],
            "neutral": [
              {
                "id": 5811,
                "faiss_score": 0.8877684473991394,
                "faiss_rank": 4,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 59,
                "sentence": "Transmitting, storing, and processing information consumes resources.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0013512123841792345,
                  "neutral": 0.9518593549728394,
                  "support": 0.04678938910365105
                },
                "stance_score": 0.04543817671947181,
                "evidence_contribution": 0.04033857959889321,
                "combined_rank_score": 0.8877684473991394
              },
              {
                "id": 6527,
                "faiss_score": 0.8845221996307373,
                "faiss_rank": 6,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 56,
                "sentence": "Software plays a critical role in determining how effectively computational resources are used.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0268668495118618,
                  "neutral": 0.9703036546707153,
                  "support": 0.002829460659995675
                },
                "stance_score": -0.024037388851866126,
                "evidence_contribution": -0.02126160406063199,
                "combined_rank_score": 0.8845221996307373
              },
              {
                "id": 5955,
                "faiss_score": 0.8817934989929199,
                "faiss_rank": 7,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 50,
                "sentence": "However, measuring energy efficiency accurately is challenging and depends on hardware and workload characteristics.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.024682439863681793,
                  "neutral": 0.9693470001220703,
                  "support": 0.005970512982457876
                },
                "stance_score": -0.018711926881223917,
                "evidence_contribution": -0.016500055477494113,
                "combined_rank_score": 0.8817934989929199
              }
            ]
          }
        },
        {
          "subclaim": "Increasing computational resources increases hardware dependence",
          "verdict": "SUPPORT",
          "controversial": true,
          "strengths": {
            "support": 0.80483156092219,
            "contradict": 0.29337671227174933,
            "total": 1.0982082731939393
          },
          "evidence": {
            "supporting": [
              {
                "id": 3968,
                "faiss_score": 0.8974432945251465,
                "faiss_rank": 1,
                "doc_id": "wiki_Throughput",
                "file_type": ".txt",
                "position": 63,
                "sentence": "Large data loads that require processing impose data processing requirements on hardware.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Network_throughput",
                "primary_category": "all articles needing additional references",
                "probs": {
                  "contradict": 0.0016102350782603025,
                  "neutral": 0.21818585693836212,
                  "support": 0.7802038788795471
                },
                "stance_score": 0.7785936438012868,
                "evidence_contribution": 0.6987436447893652,
                "combined_rank_score": 0.8974432945251465
              },
              {
                "id": 6153,
                "faiss_score": 0.8885191679000854,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 29,
                "sentence": "Memory constraints become significant as models grow.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.046569954603910446,
                  "neutral": 0.787461519241333,
                  "support": 0.16596852242946625
                },
                "stance_score": 0.1193985678255558,
                "evidence_contribution": 0.10608791613282476,
                "combined_rank_score": 0.8885191679000854
              }
            ],
            "contradicting": [
              {
                "id": 6495,
                "faiss_score": 0.872918426990509,
                "faiss_rank": 20,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 24,
                "sentence": "The design of computing systems increasingly involves co-optimization of hardware and software.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.36655545234680176,
                  "neutral": 0.6029763221740723,
                  "support": 0.030468249693512917
                },
                "stance_score": -0.33608720265328884,
                "evidence_contribution": -0.29337671227174933,
                "combined_rank_score": 0.872918426990509
              }
            ],
            "neutral": [
              {
                "id": 2393,
                "faiss_score": 0.8905734419822693,
                "faiss_rank": 2,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 324,
                "sentence": "Large and effective neural networks require considerable computing resources.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "probs": {
                  "contradict": 0.005744169000536203,
                  "neutral": 0.9915649890899658,
                  "support": 0.0026908337604254484
                },
                "stance_score": -0.003053335240110755,
                "evidence_contribution": -0.0027192192743111937,
                "combined_rank_score": 0.8905734419822693
              },
              {
                "id": 6494,
                "faiss_score": 0.8897414207458496,
                "faiss_rank": 3,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 23,
                "sentence": "Their effectiveness depends on matching hardware capabilities to algorithmic structure.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0009690516162663698,
                  "neutral": 0.9976824522018433,
                  "support": 0.0013484186492860317
                },
                "stance_score": 0.0003793670330196619,
                "evidence_contribution": 0.0003375385629430516,
                "combined_rank_score": 0.8897414207458496
              },
              {
                "id": 5944,
                "faiss_score": 0.8837687969207764,
                "faiss_rank": 5,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Hardware plays a significant role in shaping efficiency strategies.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0010084060486406088,
                  "neutral": 0.9978429079055786,
                  "support": 0.0011486936127766967
                },
                "stance_score": 0.0001402875641360879,
                "evidence_contribution": 0.00012398177177949665,
                "combined_rank_score": 0.8837687969207764
              }
            ]
          }
        },
        {
          "subclaim": "Increasing computational resources increases environmental impact",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 0.3409093385212074,
            "contradict": 0.5100679425785537,
            "total": 0.8509772810997611
          },
          "evidence": {
            "supporting": [
              {
                "id": 5953,
                "faiss_score": 0.8912315368652344,
                "faiss_rank": 3,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "Training and deploying large models consume substantial energy, raising concerns about sustainability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.005032865330576897,
                  "neutral": 0.6074193120002747,
                  "support": 0.3875477612018585
                },
                "stance_score": 0.3825148958712816,
                "evidence_contribution": 0.3409093385212074,
                "combined_rank_score": 0.8912315368652344
              }
            ],
            "contradicting": [
              {
                "id": 6534,
                "faiss_score": 0.8964979648590088,
                "faiss_rank": 1,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 63,
                "sentence": "Research in computation increasingly emphasizes efficiency and sustainability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.28368353843688965,
                  "neutral": 0.7062990665435791,
                  "support": 0.010017365217208862
                },
                "stance_score": -0.2736661732196808,
                "evidence_contribution": -0.2453411673421968,
                "combined_rank_score": 0.8964979648590088
              },
              {
                "id": 5908,
                "faiss_score": 0.8638582229614258,
                "faiss_rank": 13,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "Efficiency-oriented research aims to address these challenges by reducing resource requirements while preserving useful performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.17572131752967834,
                  "neutral": 0.8179425001144409,
                  "support": 0.006336221005767584
                },
                "stance_score": -0.16938509652391076,
                "evidence_contribution": -0.14632470847929513,
                "combined_rank_score": 0.8638582229614258
              },
              {
                "id": 6190,
                "faiss_score": 0.8634030818939209,
                "faiss_rank": 14,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 66,
                "sentence": "Performance improvements emerge from the interaction of models, data, compute, and systems infrastructure.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.14386358857154846,
                  "neutral": 0.8494069576263428,
                  "support": 0.00672941654920578
                },
                "stance_score": -0.13713417202234268,
                "evidence_contribution": -0.11840206675706177,
                "combined_rank_score": 0.8634030818939209
              }
            ],
            "neutral": [
              {
                "id": 6527,
                "faiss_score": 0.8915075063705444,
                "faiss_rank": 2,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 56,
                "sentence": "Software plays a critical role in determining how effectively computational resources are used.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.030519379302859306,
                  "neutral": 0.9640657305717468,
                  "support": 0.005414888262748718
                },
                "stance_score": -0.025104491040110588,
                "evidence_contribution": -0.022380842205870666,
                "combined_rank_score": 0.8915075063705444
              },
              {
                "id": 5811,
                "faiss_score": 0.8786616325378418,
                "faiss_rank": 4,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 59,
                "sentence": "Transmitting, storing, and processing information consumes resources.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "probs": {
                  "contradict": 0.0014276072615757585,
                  "neutral": 0.9975448250770569,
                  "support": 0.0010275111999362707
                },
                "stance_score": -0.00040009606163948774,
                "evidence_contribution": -0.0003515490586921133,
                "combined_rank_score": 0.8786616325378418
              },
              {
                "id": 5432,
                "faiss_score": 0.8761302828788757,
                "faiss_rank": 5,
                "doc_id": "wiki_Landauer's_principle",
                "file_type": ".txt",
                "position": 2,
                "sentence": "As of 2012, modern computers use about a billion times as much energy per operation.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Landauer%27s_principle",
                "primary_category": "all articles containing potentially dated statements",
                "probs": {
                  "contradict": 0.0010007243836298585,
                  "neutral": 0.9972208738327026,
                  "support": 0.0017783649964258075
                },
                "stance_score": 0.000777640612795949,
                "evidence_contribution": 0.000681314490067017,
                "combined_rank_score": 0.8761302828788757
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Increasing computational resources increases cost",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5995,
                      "faiss_score": 0.8827309012413025,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_evaluation_and_generalization.txt",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "This technique reduces variance in evaluation estimates but increases computational cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001421174150891602,
                        "neutral": 0.3918896019458771,
                        "support": 0.6066892743110657
                      },
                      "stance_score": 0.6052681001601741,
                      "evidence_contribution": 0.5342888555470015,
                      "combined_rank_score": 0.8827309012413025
                    },
                    {
                      "id": 2503,
                      "faiss_score": 0.881470799446106,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 98,
                      "sentence": "However, those were more computationally expensive compared to backpropagation.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.0016182546969503164,
                        "neutral": 0.8172633647918701,
                        "support": 0.18111830949783325
                      },
                      "stance_score": 0.17950005480088294,
                      "evidence_contribution": 0.1582240568059541,
                      "combined_rank_score": 0.881470799446106
                    },
                    {
                      "id": 6651,
                      "faiss_score": 0.8786903619766235,
                      "faiss_rank": 13,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 54,
                      "sentence": "Adding redundancy increases cost and complexity.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0019581627566367388,
                        "neutral": 0.4421144723892212,
                        "support": 0.5559273958206177
                      },
                      "stance_score": 0.5539692330639809,
                      "evidence_contribution": 0.48676742592490196,
                      "combined_rank_score": 0.8786903619766235
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5923,
                      "faiss_score": 0.8798081874847412,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "This technique shifts computational cost from deployment to training.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.14017978310585022,
                        "neutral": 0.8297988176345825,
                        "support": 0.030021382495760918
                      },
                      "stance_score": -0.1101584006100893,
                      "evidence_contribution": -0.09691826277698068,
                      "combined_rank_score": 0.8798081874847412
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6354,
                      "faiss_score": 0.8871214985847473,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 93,
                      "sentence": "Transformer-based models can be computationally expensive at inference time, particularly when generating long outputs or processing large batches.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0009665526449680328,
                        "neutral": 0.9539660811424255,
                        "support": 0.045067429542541504
                      },
                      "stance_score": 0.04410087689757347,
                      "evidence_contribution": 0.03912283600227684,
                      "combined_rank_score": 0.8871214985847473
                    },
                    {
                      "id": 2393,
                      "faiss_score": 0.8848891854286194,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 324,
                      "sentence": "Large and effective neural networks require considerable computing resources.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.0009062131284736097,
                        "neutral": 0.9973904490470886,
                        "support": 0.0017033421900123358
                      },
                      "stance_score": 0.0007971290615387261,
                      "evidence_contribution": 0.0007053708859464831,
                      "combined_rank_score": 0.8848891854286194
                    },
                    {
                      "id": 6527,
                      "faiss_score": 0.8844648003578186,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 56,
                      "sentence": "Software plays a critical role in determining how effectively computational resources are used.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.00802410114556551,
                        "neutral": 0.9895147085189819,
                        "support": 0.002461161930114031
                      },
                      "stance_score": -0.005562939215451479,
                      "evidence_contribution": -0.004920223922596972,
                      "combined_rank_score": 0.8844648003578186
                    }
                  ]
                }
              },
              {
                "subclaim": "Increasing computational resources increases energy usage",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5952,
                      "faiss_score": 0.909400463104248,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 47,
                      "sentence": "Energy efficiency has become increasingly important as machine learning workloads scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.09253448247909546,
                        "neutral": 0.5258767008781433,
                        "support": 0.38158881664276123
                      },
                      "stance_score": 0.28905433416366577,
                      "evidence_contribution": 0.2628661453507277,
                      "combined_rank_score": 0.909400463104248
                    },
                    {
                      "id": 5432,
                      "faiss_score": 0.9075989723205566,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Landauer's_principle",
                      "file_type": ".txt",
                      "position": 2,
                      "sentence": "As of 2012, modern computers use about a billion times as much energy per operation.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Landauer%27s_principle",
                      "primary_category": "all articles containing potentially dated statements",
                      "probs": {
                        "contradict": 0.0011741387424990535,
                        "neutral": 0.6837896704673767,
                        "support": 0.31503620743751526
                      },
                      "stance_score": 0.3138620686950162,
                      "evidence_contribution": 0.28486089099800066,
                      "combined_rank_score": 0.9075989723205566
                    },
                    {
                      "id": 6483,
                      "faiss_score": 0.8976882696151733,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 12,
                      "sentence": "Power consumption has emerged as a dominant constraint in modern computing systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.001076680375263095,
                        "neutral": 0.8365802764892578,
                        "support": 0.16234302520751953
                      },
                      "stance_score": 0.16126634483225644,
                      "evidence_contribution": 0.14476690603963213,
                      "combined_rank_score": 0.8976882696151733
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5954,
                      "faiss_score": 0.8787448406219482,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 49,
                      "sentence": "Techniques that reduce computation or enable reuse of pretrained components can lower energy consumption.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9419150948524475,
                        "neutral": 0.05364186316728592,
                        "support": 0.004443134646862745
                      },
                      "stance_score": -0.9374719602055848,
                      "evidence_contribution": -0.823798648258402,
                      "combined_rank_score": 0.8787448406219482
                    },
                    {
                      "id": 6534,
                      "faiss_score": 0.8766908645629883,
                      "faiss_rank": 10,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "Research in computation increasingly emphasizes efficiency and sustainability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.5082404017448425,
                        "neutral": 0.4863085150718689,
                        "support": 0.005451128352433443
                      },
                      "stance_score": -0.5027892733924091,
                      "evidence_contribution": -0.4407907627833878,
                      "combined_rank_score": 0.8766908645629883
                    },
                    {
                      "id": 5380,
                      "faiss_score": 0.8628027439117432,
                      "faiss_rank": 20,
                      "doc_id": "wiki_Reversible_computing",
                      "file_type": ".txt",
                      "position": 5,
                      "sentence": "The Landauer limit was millions of times below the energy consumption of computers in the 2000s and thousands of times less in the 2010s.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Reversible_computing",
                      "primary_category": "articles with short description",
                      "probs": {
                        "contradict": 0.1545737087726593,
                        "neutral": 0.8282281756401062,
                        "support": 0.01719808205962181
                      },
                      "stance_score": -0.1373756267130375,
                      "evidence_contribution": -0.11852806767460411,
                      "combined_rank_score": 0.8628027439117432
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5811,
                      "faiss_score": 0.8877684473991394,
                      "faiss_rank": 4,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 59,
                      "sentence": "Transmitting, storing, and processing information consumes resources.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0013512123841792345,
                        "neutral": 0.9518593549728394,
                        "support": 0.04678938910365105
                      },
                      "stance_score": 0.04543817671947181,
                      "evidence_contribution": 0.04033857959889321,
                      "combined_rank_score": 0.8877684473991394
                    },
                    {
                      "id": 6527,
                      "faiss_score": 0.8845221996307373,
                      "faiss_rank": 6,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 56,
                      "sentence": "Software plays a critical role in determining how effectively computational resources are used.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0268668495118618,
                        "neutral": 0.9703036546707153,
                        "support": 0.002829460659995675
                      },
                      "stance_score": -0.024037388851866126,
                      "evidence_contribution": -0.02126160406063199,
                      "combined_rank_score": 0.8845221996307373
                    },
                    {
                      "id": 5955,
                      "faiss_score": 0.8817934989929199,
                      "faiss_rank": 7,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 50,
                      "sentence": "However, measuring energy efficiency accurately is challenging and depends on hardware and workload characteristics.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.024682439863681793,
                        "neutral": 0.9693470001220703,
                        "support": 0.005970512982457876
                      },
                      "stance_score": -0.018711926881223917,
                      "evidence_contribution": -0.016500055477494113,
                      "combined_rank_score": 0.8817934989929199
                    }
                  ]
                }
              },
              {
                "subclaim": "Increasing computational resources increases hardware dependence",
                "verdict": "SUPPORT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 3968,
                      "faiss_score": 0.8974432945251465,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Throughput",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "Large data loads that require processing impose data processing requirements on hardware.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Network_throughput",
                      "primary_category": "all articles needing additional references",
                      "probs": {
                        "contradict": 0.0016102350782603025,
                        "neutral": 0.21818585693836212,
                        "support": 0.7802038788795471
                      },
                      "stance_score": 0.7785936438012868,
                      "evidence_contribution": 0.6987436447893652,
                      "combined_rank_score": 0.8974432945251465
                    },
                    {
                      "id": 6153,
                      "faiss_score": 0.8885191679000854,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 29,
                      "sentence": "Memory constraints become significant as models grow.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.046569954603910446,
                        "neutral": 0.787461519241333,
                        "support": 0.16596852242946625
                      },
                      "stance_score": 0.1193985678255558,
                      "evidence_contribution": 0.10608791613282476,
                      "combined_rank_score": 0.8885191679000854
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6495,
                      "faiss_score": 0.872918426990509,
                      "faiss_rank": 20,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 24,
                      "sentence": "The design of computing systems increasingly involves co-optimization of hardware and software.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.36655545234680176,
                        "neutral": 0.6029763221740723,
                        "support": 0.030468249693512917
                      },
                      "stance_score": -0.33608720265328884,
                      "evidence_contribution": -0.29337671227174933,
                      "combined_rank_score": 0.872918426990509
                    }
                  ],
                  "neutral": [
                    {
                      "id": 2393,
                      "faiss_score": 0.8905734419822693,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 324,
                      "sentence": "Large and effective neural networks require considerable computing resources.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.005744169000536203,
                        "neutral": 0.9915649890899658,
                        "support": 0.0026908337604254484
                      },
                      "stance_score": -0.003053335240110755,
                      "evidence_contribution": -0.0027192192743111937,
                      "combined_rank_score": 0.8905734419822693
                    },
                    {
                      "id": 6494,
                      "faiss_score": 0.8897414207458496,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 23,
                      "sentence": "Their effectiveness depends on matching hardware capabilities to algorithmic structure.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0009690516162663698,
                        "neutral": 0.9976824522018433,
                        "support": 0.0013484186492860317
                      },
                      "stance_score": 0.0003793670330196619,
                      "evidence_contribution": 0.0003375385629430516,
                      "combined_rank_score": 0.8897414207458496
                    },
                    {
                      "id": 5944,
                      "faiss_score": 0.8837687969207764,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "Hardware plays a significant role in shaping efficiency strategies.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0010084060486406088,
                        "neutral": 0.9978429079055786,
                        "support": 0.0011486936127766967
                      },
                      "stance_score": 0.0001402875641360879,
                      "evidence_contribution": 0.00012398177177949665,
                      "combined_rank_score": 0.8837687969207764
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Increasing computational resources improves deep learning training speed",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 1901,
                      "faiss_score": 0.8789441585540771,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 169,
                      "sentence": "OptiLLM demonstrates that strategic application of computational resources at inference time can substantially improve model performance across diverse tasks, achieving significant improvements on benchmarks such as the AIME 2024 mathematics competition and various coding challenges.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.005857494659721851,
                        "neutral": 0.885772168636322,
                        "support": 0.10837028920650482
                      },
                      "stance_score": 0.10251279454678297,
                      "evidence_contribution": 0.09010302194394915,
                      "combined_rank_score": 0.8789441585540771
                    },
                    {
                      "id": 2164,
                      "faiss_score": 0.8744220733642578,
                      "faiss_rank": 13,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 95,
                      "sentence": "Unsupervised pre-training and increased computing power from GPUs and distributed computing allowed the use of larger networks, particularly in image and visual recognition problems, which became known as \"deep learning\".",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.0037023804616183043,
                        "neutral": 0.8704550266265869,
                        "support": 0.1258426308631897
                      },
                      "stance_score": 0.12214025040157139,
                      "evidence_contribution": 0.10680213099737168,
                      "combined_rank_score": 0.8744220733642578
                    },
                    {
                      "id": 2625,
                      "faiss_score": 0.87431401014328,
                      "faiss_rank": 14,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 220,
                      "sentence": "Special electronic circuits called deep learning processors were designed to speed up deep learning algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.003962540999054909,
                        "neutral": 0.5770430564880371,
                        "support": 0.41899439692497253
                      },
                      "stance_score": 0.4150318559259176,
                      "evidence_contribution": 0.3628681662917971,
                      "combined_rank_score": 0.87431401014328
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5907,
                      "faiss_score": 0.8837117552757263,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 2,
                      "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.45006662607192993,
                        "neutral": 0.5438736081123352,
                        "support": 0.006059776060283184
                      },
                      "stance_score": -0.44400685001164675,
                      "evidence_contribution": -0.3923740727782385,
                      "combined_rank_score": 0.8837117552757263
                    },
                    {
                      "id": 6246,
                      "faiss_score": 0.8795201778411865,
                      "faiss_rank": 7,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 54,
                      "sentence": "By halting training when performance on a validation set stops improving, systems can avoid overfitting and reduce resource usage.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.9828004837036133,
                        "neutral": 0.015793360769748688,
                        "support": 0.0014060891699045897
                      },
                      "stance_score": -0.9813943945337087,
                      "evidence_contribution": -0.8631561724126311,
                      "combined_rank_score": 0.8795201778411865
                    },
                    {
                      "id": 5905,
                      "faiss_score": 0.8791102170944214,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.682704746723175,
                        "neutral": 0.3102189600467682,
                        "support": 0.00707629369571805
                      },
                      "stance_score": -0.675628453027457,
                      "evidence_contribution": -0.5939518760161357,
                      "combined_rank_score": 0.8791102170944214
                    }
                  ],
                  "neutral": [
                    {
                      "id": 2393,
                      "faiss_score": 0.8931306600570679,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 324,
                      "sentence": "Large and effective neural networks require considerable computing resources.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.05511556938290596,
                        "neutral": 0.9371413588523865,
                        "support": 0.007743130438029766
                      },
                      "stance_score": -0.047372438944876194,
                      "evidence_contribution": -0.04230977766335042,
                      "combined_rank_score": 0.8931306600570679
                    },
                    {
                      "id": 2622,
                      "faiss_score": 0.892419695854187,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 217,
                      "sentence": "Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "probs": {
                        "contradict": 0.0014016155619174242,
                        "neutral": 0.9192524552345276,
                        "support": 0.0793459415435791
                      },
                      "stance_score": 0.07794432598166168,
                      "evidence_contribution": 0.06955905168611412,
                      "combined_rank_score": 0.892419695854187
                    },
                    {
                      "id": 6044,
                      "faiss_score": 0.890583872795105,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 4,
                      "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0011553606018424034,
                        "neutral": 0.9447371959686279,
                        "support": 0.0541074313223362
                      },
                      "stance_score": 0.052952070720493793,
                      "evidence_contribution": 0.04715826021477765,
                      "combined_rank_score": 0.890583872795105
                    }
                  ]
                }
              },
              {
                "subclaim": "Increasing computational resources stabilizes optimization",
                "verdict": "CONTRADICT",
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 5854,
                      "faiss_score": 0.882411003112793,
                      "faiss_rank": 6,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 23,
                      "sentence": "Noise in optimization can be both beneficial and harmful.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.2581842541694641,
                        "neutral": 0.7393684387207031,
                        "support": 0.002447310136631131
                      },
                      "stance_score": -0.255736944032833,
                      "evidence_contribution": -0.22566509331701234,
                      "combined_rank_score": 0.882411003112793
                    },
                    {
                      "id": 79,
                      "faiss_score": 0.8764380216598511,
                      "faiss_rank": 10,
                      "doc_id": "openreview_ztgT8Iok130",
                      "file_type": ".txt",
                      "position": 1,
                      "sentence": "Computational methods have achieved initial success but still struggle with simultaneously optimizing multiple competing properties in a sample-efficient manner.",
                      "source_type": "openreview",
                      "credibility": 0.7,
                      "source_url": "https://openreview.net/forum?id=ztgT8Iok130",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.3723789155483246,
                        "neutral": 0.6259058713912964,
                        "support": 0.001715235412120819
                      },
                      "stance_score": -0.37066368013620377,
                      "evidence_contribution": -0.32486374251973427,
                      "combined_rank_score": 0.8764380216598511
                    },
                    {
                      "id": 5901,
                      "faiss_score": 0.874020516872406,
                      "faiss_rank": 12,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 70,
                      "sentence": "Optimizing these factors often requires algorithmic compromises.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.34476158022880554,
                        "neutral": 0.6531848907470703,
                        "support": 0.00205355416983366
                      },
                      "stance_score": -0.3427080260589719,
                      "evidence_contribution": -0.2995338460723846,
                      "combined_rank_score": 0.874020516872406
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5879,
                      "faiss_score": 0.907509446144104,
                      "faiss_rank": 1,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 48,
                      "sentence": "Optimization is closely linked to numerical stability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.00287438090890646,
                        "neutral": 0.9955047965049744,
                        "support": 0.0016208672896027565
                      },
                      "stance_score": -0.0012535136193037033,
                      "evidence_contribution": -0.001137575450388395,
                      "combined_rank_score": 0.907509446144104
                    },
                    {
                      "id": 5857,
                      "faiss_score": 0.8886821269989014,
                      "faiss_rank": 2,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 26,
                      "sentence": "Balancing exploration and stability is a recurring theme in optimization theory and practice.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.004754449240863323,
                        "neutral": 0.9945986270904541,
                        "support": 0.0006469713989645243
                      },
                      "stance_score": -0.004107477841898799,
                      "evidence_contribution": -0.0036502421451394818,
                      "combined_rank_score": 0.8886821269989014
                    },
                    {
                      "id": 5892,
                      "faiss_score": 0.8834568858146667,
                      "faiss_rank": 3,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 61,
                      "sentence": "Optimization also interacts with data properties.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.007102190982550383,
                        "neutral": 0.9921365976333618,
                        "support": 0.0007611767505295575
                      },
                      "stance_score": -0.006341014232020825,
                      "evidence_contribution": -0.005602012686327599,
                      "combined_rank_score": 0.8834568858146667
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Increasing computational resources enables larger models",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6349,
                      "faiss_score": 0.893662691116333,
                      "faiss_rank": 11,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 88,
                      "sentence": "As models scale, training efficiency becomes a primary concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0023103414569050074,
                        "neutral": 0.8747334480285645,
                        "support": 0.12295623868703842
                      },
                      "stance_score": 0.12064589723013341,
                      "evidence_contribution": 0.10781673719082557,
                      "combined_rank_score": 0.893662691116333
                    },
                    {
                      "id": 1795,
                      "faiss_score": 0.8900411128997803,
                      "faiss_rank": 16,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "Substantial infrastructure is necessary for training the largest models.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "probs": {
                        "contradict": 0.00380844553001225,
                        "neutral": 0.4181954264640808,
                        "support": 0.5779961347579956
                      },
                      "stance_score": 0.5741876892279834,
                      "evidence_contribution": 0.5110506499338274,
                      "combined_rank_score": 0.8900411128997803
                    },
                    {
                      "id": 2393,
                      "faiss_score": 0.8888487815856934,
                      "faiss_rank": 17,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 324,
                      "sentence": "Large and effective neural networks require considerable computing resources.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "probs": {
                        "contradict": 0.021992327645421028,
                        "neutral": 0.8382526636123657,
                        "support": 0.1397550404071808
                      },
                      "stance_score": 0.11776271276175976,
                      "evidence_contribution": 0.10467324375451614,
                      "combined_rank_score": 0.8888487815856934
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6153,
                      "faiss_score": 0.9159849882125854,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 29,
                      "sentence": "Memory constraints become significant as models grow.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.6809476613998413,
                        "neutral": 0.3112615942955017,
                        "support": 0.007790726143866777
                      },
                      "stance_score": -0.6731569352559745,
                      "evidence_contribution": -0.6166016474056639,
                      "combined_rank_score": 0.9159849882125854
                    },
                    {
                      "id": 5968,
                      "faiss_score": 0.9140965342521667,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "As models continue to scale, new bottlenecks emerge.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.10449454933404922,
                        "neutral": 0.8918824195861816,
                        "support": 0.003623080672696233
                      },
                      "stance_score": -0.10087146866135299,
                      "evidence_contribution": -0.09220625990826882,
                      "combined_rank_score": 0.9140965342521667
                    },
                    {
                      "id": 6147,
                      "faiss_score": 0.88716059923172,
                      "faiss_rank": 19,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 23,
                      "sentence": "For example, increasing model size without increasing data may yield limited benefits, while increasing data without sufficient model capacity may fail to exploit the additional information.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.3358306884765625,
                        "neutral": 0.6573573350906372,
                        "support": 0.006811974570155144
                      },
                      "stance_score": -0.32901871390640736,
                      "evidence_contribution": -0.2918924393876582,
                      "combined_rank_score": 0.88716059923172
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6132,
                      "faiss_score": 0.9344620704650879,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Larger models have greater representational capacity, allowing them to fit more complex functions.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0012542104814201593,
                        "neutral": 0.9608927369117737,
                        "support": 0.03785300627350807
                      },
                      "stance_score": 0.03659879579208791,
                      "evidence_contribution": 0.03420018649240342,
                      "combined_rank_score": 0.9344620704650879
                    },
                    {
                      "id": 6137,
                      "faiss_score": 0.9030450582504272,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0010076063917949796,
                        "neutral": 0.9832544922828674,
                        "support": 0.01573786325752735
                      },
                      "stance_score": 0.014730256865732372,
                      "evidence_contribution": 0.013302085669359046,
                      "combined_rank_score": 0.9030450582504272
                    },
                    {
                      "id": 1676,
                      "faiss_score": 0.9014084339141846,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Optimization_(mathematics)",
                      "file_type": ".txt",
                      "position": 125,
                      "sentence": "Some versions can handle large-dimensional problems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                      "primary_category": "all articles with style issues",
                      "probs": {
                        "contradict": 0.000795436033513397,
                        "neutral": 0.9977479577064514,
                        "support": 0.0014566174941137433
                      },
                      "stance_score": 0.0006611814606003463,
                      "evidence_contribution": 0.0005959945449328513,
                      "combined_rank_score": 0.9014084339141846
                    }
                  ]
                }
              },
              {
                "subclaim": "Increasing computational resources increases environmental impact",
                "verdict": "MIXED",
                "strength_summary": {
                  "support": "weak",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5953,
                      "faiss_score": 0.8912315368652344,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 48,
                      "sentence": "Training and deploying large models consume substantial energy, raising concerns about sustainability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.005032865330576897,
                        "neutral": 0.6074193120002747,
                        "support": 0.3875477612018585
                      },
                      "stance_score": 0.3825148958712816,
                      "evidence_contribution": 0.3409093385212074,
                      "combined_rank_score": 0.8912315368652344
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6534,
                      "faiss_score": 0.8964979648590088,
                      "faiss_rank": 1,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "Research in computation increasingly emphasizes efficiency and sustainability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.28368353843688965,
                        "neutral": 0.7062990665435791,
                        "support": 0.010017365217208862
                      },
                      "stance_score": -0.2736661732196808,
                      "evidence_contribution": -0.2453411673421968,
                      "combined_rank_score": 0.8964979648590088
                    },
                    {
                      "id": 5908,
                      "faiss_score": 0.8638582229614258,
                      "faiss_rank": 13,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "Efficiency-oriented research aims to address these challenges by reducing resource requirements while preserving useful performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.17572131752967834,
                        "neutral": 0.8179425001144409,
                        "support": 0.006336221005767584
                      },
                      "stance_score": -0.16938509652391076,
                      "evidence_contribution": -0.14632470847929513,
                      "combined_rank_score": 0.8638582229614258
                    },
                    {
                      "id": 6190,
                      "faiss_score": 0.8634030818939209,
                      "faiss_rank": 14,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 66,
                      "sentence": "Performance improvements emerge from the interaction of models, data, compute, and systems infrastructure.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.14386358857154846,
                        "neutral": 0.8494069576263428,
                        "support": 0.00672941654920578
                      },
                      "stance_score": -0.13713417202234268,
                      "evidence_contribution": -0.11840206675706177,
                      "combined_rank_score": 0.8634030818939209
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6527,
                      "faiss_score": 0.8915075063705444,
                      "faiss_rank": 2,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 56,
                      "sentence": "Software plays a critical role in determining how effectively computational resources are used.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.030519379302859306,
                        "neutral": 0.9640657305717468,
                        "support": 0.005414888262748718
                      },
                      "stance_score": -0.025104491040110588,
                      "evidence_contribution": -0.022380842205870666,
                      "combined_rank_score": 0.8915075063705444
                    },
                    {
                      "id": 5811,
                      "faiss_score": 0.8786616325378418,
                      "faiss_rank": 4,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 59,
                      "sentence": "Transmitting, storing, and processing information consumes resources.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "probs": {
                        "contradict": 0.0014276072615757585,
                        "neutral": 0.9975448250770569,
                        "support": 0.0010275111999362707
                      },
                      "stance_score": -0.00040009606163948774,
                      "evidence_contribution": -0.0003515490586921133,
                      "combined_rank_score": 0.8786616325378418
                    },
                    {
                      "id": 5432,
                      "faiss_score": 0.8761302828788757,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Landauer's_principle",
                      "file_type": ".txt",
                      "position": 2,
                      "sentence": "As of 2012, modern computers use about a billion times as much energy per operation.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Landauer%27s_principle",
                      "primary_category": "all articles containing potentially dated statements",
                      "probs": {
                        "contradict": 0.0010007243836298585,
                        "neutral": 0.9972208738327026,
                        "support": 0.0017783649964258075
                      },
                      "stance_score": 0.000777640612795949,
                      "evidence_contribution": 0.000681314490067017,
                      "combined_rank_score": 0.8761302828788757
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    }
  ],
  "metrics": {
    "final_accuracy": 0.3333333333333333,
    "confusion_matrix": {
      "SUPPORT": {
        "SUPPORT": 4,
        "CONTRADICT": 2,
        "MIXED": 0,
        "INCONCLUSIVE": 0
      },
      "CONTRADICT": {
        "SUPPORT": 1,
        "CONTRADICT": 5,
        "MIXED": 0,
        "INCONCLUSIVE": 0
      },
      "MIXED": {
        "SUPPORT": 5,
        "CONTRADICT": 6,
        "MIXED": 0,
        "INCONCLUSIVE": 0
      },
      "INCONCLUSIVE": {
        "SUPPORT": 0,
        "CONTRADICT": 4,
        "MIXED": 0,
        "INCONCLUSIVE": 0
      }
    },
    "precision_recall_f1": {
      "per_class": {
        "SUPPORT": {
          "precision": 0.4,
          "recall": 0.6666666666666666,
          "f1": 0.5
        },
        "CONTRADICT": {
          "precision": 0.29411764705882354,
          "recall": 0.8333333333333334,
          "f1": 0.4347826086956522
        },
        "MIXED": {
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0
        },
        "INCONCLUSIVE": {
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0
        }
      },
      "macro_f1": 0.23369565217391305
    },
    "subclaim_accuracy": null,
    "decomposition_stats": {
      "avg_subclaims_per_claim": 2.8518518518518516,
      "min_subclaims": 1,
      "max_subclaims": 7
    }
  }
}