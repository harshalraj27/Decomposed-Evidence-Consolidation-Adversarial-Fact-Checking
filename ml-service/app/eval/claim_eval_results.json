{
  "results": [
    {
      "claim": "Scaling laws indicate that increasing model size and data generally improves language model performance.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Scaling laws indicate that increasing model size improves language model performance.",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 0.7753959966549218,
            "contradict": 0.0,
            "total": 0.7753959966549218
          },
          "evidence": {
            "supporting": [
              {
                "id": 6300,
                "faiss_score": 0.8919124603271484,
                "faiss_rank": 18,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 1.1516189575195312,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.019933873787522316,
                  "neutral": 0.28682276606559753,
                  "support": 0.6932433843612671
                },
                "stance_score": 0.6733095105737448,
                "evidence_contribution": 0.7753959966549218,
                "combined_rank_score": 2.0435314178466797
              }
            ],
            "contradicting": [
              {
                "id": 6121,
                "faiss_score": 0.8985731601715088,
                "faiss_rank": 9,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": -0.8732558488845825,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.45808807015419006,
                  "neutral": 0.5354201197624207,
                  "support": 0.006491828244179487
                },
                "stance_score": -0.4515962419100106,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.02531731128692627
              }
            ],
            "neutral": [
              {
                "id": 6142,
                "faiss_score": 0.9138842225074768,
                "faiss_rank": 6,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 5.783466339111328,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.0020528091117739677,
                  "neutral": 0.9971649050712585,
                  "support": 0.0007822587504051626
                },
                "stance_score": -0.0012705503613688052,
                "evidence_contribution": -0.007348185247122219,
                "combined_rank_score": 6.697350561618805
              },
              {
                "id": 6124,
                "faiss_score": 0.8996810913085938,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 5.338567733764648,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.0030547380447387695,
                  "neutral": 0.9952334761619568,
                  "support": 0.001711796852760017
                },
                "stance_score": -0.0013429411919787526,
                "evidence_contribution": -0.007169382515841205,
                "combined_rank_score": 6.238248825073242
              },
              {
                "id": 6133,
                "faiss_score": 0.8973473310470581,
                "faiss_rank": 10,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 4.928947925567627,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.007783351466059685,
                  "neutral": 0.9895959496498108,
                  "support": 0.002620717976242304
                },
                "stance_score": -0.005162633489817381,
                "evidence_contribution": -0.025446351630101338,
                "combined_rank_score": 5.826295256614685
              }
            ]
          }
        },
        {
          "subclaim": "Scaling laws indicate that increasing data generally improves language model performance.",
          "verdict": "INCONCLUSIVE",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 0.0,
            "total": 0.0
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6121,
                "faiss_score": 0.8885934352874756,
                "faiss_rank": 13,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": -2.486970901489258,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.11388173699378967,
                  "neutral": 0.8839079141616821,
                  "support": 0.0022103756200522184
                },
                "stance_score": -0.11167136137373745,
                "evidence_contribution": -0.0,
                "combined_rank_score": -1.5983774662017822
              }
            ],
            "neutral": [
              {
                "id": 6127,
                "faiss_score": 0.9171009063720703,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 4.851520538330078,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.004043751861900091,
                  "neutral": 0.9890744090080261,
                  "support": 0.006881888955831528
                },
                "stance_score": 0.0028381370939314365,
                "evidence_contribution": 0.013769280401804807,
                "combined_rank_score": 5.768621444702148
              },
              {
                "id": 6142,
                "faiss_score": 0.9079248309135437,
                "faiss_rank": 5,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 4.8335371017456055,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.0016234064241871238,
                  "neutral": 0.997517466545105,
                  "support": 0.0008592000813223422
                },
                "stance_score": -0.0007642063428647816,
                "evidence_contribution": -0.003693819711626245,
                "combined_rank_score": 5.741461932659149
              },
              {
                "id": 6124,
                "faiss_score": 0.8999987840652466,
                "faiss_rank": 9,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 4.305981636047363,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.002156906295567751,
                  "neutral": 0.9965866804122925,
                  "support": 0.0012564564822241664
                },
                "stance_score": -0.0009004498133435845,
                "evidence_contribution": -0.003877320360439751,
                "combined_rank_score": 5.20598042011261
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Scaling laws indicate that increasing model size improves language model performance.",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6300,
                      "faiss_score": 0.8919124603271484,
                      "faiss_rank": 18,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": 1.1516189575195312,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.019933873787522316,
                        "neutral": 0.28682276606559753,
                        "support": 0.6932433843612671
                      },
                      "stance_score": 0.6733095105737448,
                      "evidence_contribution": 0.7753959966549218,
                      "combined_rank_score": 2.0435314178466797
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6121,
                      "faiss_score": 0.8985731601715088,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": -0.8732558488845825,
                      "rerank_rank": 10,
                      "probs": {
                        "contradict": 0.45808807015419006,
                        "neutral": 0.5354201197624207,
                        "support": 0.006491828244179487
                      },
                      "stance_score": -0.4515962419100106,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.02531731128692627
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6142,
                      "faiss_score": 0.9138842225074768,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 5.783466339111328,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.0020528091117739677,
                        "neutral": 0.9971649050712585,
                        "support": 0.0007822587504051626
                      },
                      "stance_score": -0.0012705503613688052,
                      "evidence_contribution": -0.007348185247122219,
                      "combined_rank_score": 6.697350561618805
                    },
                    {
                      "id": 6124,
                      "faiss_score": 0.8996810913085938,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 5.338567733764648,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.0030547380447387695,
                        "neutral": 0.9952334761619568,
                        "support": 0.001711796852760017
                      },
                      "stance_score": -0.0013429411919787526,
                      "evidence_contribution": -0.007169382515841205,
                      "combined_rank_score": 6.238248825073242
                    },
                    {
                      "id": 6133,
                      "faiss_score": 0.8973473310470581,
                      "faiss_rank": 10,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 4.928947925567627,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.007783351466059685,
                        "neutral": 0.9895959496498108,
                        "support": 0.002620717976242304
                      },
                      "stance_score": -0.005162633489817381,
                      "evidence_contribution": -0.025446351630101338,
                      "combined_rank_score": 5.826295256614685
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "EVIDENCE_LIMITATIONS",
            "items": [
              {
                "subclaim": "Scaling laws indicate that increasing data generally improves language model performance.",
                "verdict": "INCONCLUSIVE",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6121,
                      "faiss_score": 0.8885934352874756,
                      "faiss_rank": 13,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": -2.486970901489258,
                      "rerank_rank": 10,
                      "probs": {
                        "contradict": 0.11388173699378967,
                        "neutral": 0.8839079141616821,
                        "support": 0.0022103756200522184
                      },
                      "stance_score": -0.11167136137373745,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -1.5983774662017822
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6127,
                      "faiss_score": 0.9171009063720703,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 4.851520538330078,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.004043751861900091,
                        "neutral": 0.9890744090080261,
                        "support": 0.006881888955831528
                      },
                      "stance_score": 0.0028381370939314365,
                      "evidence_contribution": 0.013769280401804807,
                      "combined_rank_score": 5.768621444702148
                    },
                    {
                      "id": 6142,
                      "faiss_score": 0.9079248309135437,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 4.8335371017456055,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.0016234064241871238,
                        "neutral": 0.997517466545105,
                        "support": 0.0008592000813223422
                      },
                      "stance_score": -0.0007642063428647816,
                      "evidence_contribution": -0.003693819711626245,
                      "combined_rank_score": 5.741461932659149
                    },
                    {
                      "id": 6124,
                      "faiss_score": 0.8999987840652466,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 4.305981636047363,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.002156906295567751,
                        "neutral": 0.9965866804122925,
                        "support": 0.0012564564822241664
                      },
                      "stance_score": -0.0009004498133435845,
                      "evidence_contribution": -0.003877320360439751,
                      "combined_rank_score": 5.20598042011261
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Transformer architectures enabled significant improvements in natural language processing tasks.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Transformer architectures were used in natural language processing tasks.",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 14.348367211160701,
            "contradict": 0.4050704516570928,
            "total": 14.753437662817793
          },
          "evidence": {
            "supporting": [
              {
                "id": 6296,
                "faiss_score": 0.9599642753601074,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 35,
                "sentence": "The transformer architecture proved highly effective across a wide range of natural language processing tasks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 9.242033958435059,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.0064346035942435265,
                  "neutral": 0.011724923737347126,
                  "support": 0.9818404316902161
                },
                "stance_score": 0.9754058280959725,
                "evidence_contribution": 9.014733786518448,
                "combined_rank_score": 10.201998233795166
              },
              {
                "id": 2184,
                "faiss_score": 0.9435071349143982,
                "faiss_rank": 2,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 115,
                "sentence": "Transformers have increasingly become the model of choice for natural language processing.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "rerank_score": 4.645409107208252,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.001396269304677844,
                  "neutral": 0.01836763694882393,
                  "support": 0.9802360534667969
                },
                "stance_score": 0.978839784162119,
                "evidence_contribution": 4.547111247844468,
                "combined_rank_score": 5.58891624212265
              },
              {
                "id": 3003,
                "faiss_score": 0.8870973587036133,
                "faiss_rank": 17,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 58,
                "sentence": "Tasks for pretraining and fine-tuning commonly include: language modeling next-sentence prediction question answering reading comprehension sentiment analysis paraphrasing The T5 transformer report documents a large number of natural language pretraining tasks.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "rerank_score": 3.4558331966400146,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.013680233620107174,
                  "neutral": 0.745046854019165,
                  "support": 0.24127286672592163
                },
                "stance_score": 0.22759263310581446,
                "evidence_contribution": 0.7865221767977848,
                "combined_rank_score": 4.342930555343628
              },
              {
                "id": 3025,
                "faiss_score": 0.8943243622779846,
                "faiss_rank": 11,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 80,
                "sentence": "Transformer layers, which carry out repeated transformations on the vector representations, extracting more and more linguistic information.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "rerank_score": -0.1328548789024353,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.003647217759862542,
                  "neutral": 0.8628968596458435,
                  "support": 0.13345587253570557
                },
                "stance_score": 0.12980865477584302,
                "evidence_contribution": 0.0,
                "combined_rank_score": 0.7614694833755493
              }
            ],
            "contradicting": [
              {
                "id": 2987,
                "faiss_score": 0.8978081941604614,
                "faiss_rank": 8,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Transformer architecture is now used alongside many generative models that contribute to the ongoing AI boom.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "rerank_score": 0.8487489819526672,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.31608426570892334,
                  "neutral": 0.6735674142837524,
                  "support": 0.010348307900130749
                },
                "stance_score": -0.3057359578087926,
                "evidence_contribution": -0.25949308293653633,
                "combined_rank_score": 1.7465571761131287
              },
              {
                "id": 1807,
                "faiss_score": 0.9014351963996887,
                "faiss_rank": 7,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 75,
                "sentence": "LLMs are generally based on the transformer architecture, which leverages an attention mechanism that enables the model to process relationships between all elements in a sequence simultaneously, regardless of their distance from each other.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "rerank_score": 0.8668583035469055,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.1701473444700241,
                  "neutral": 0.7902719378471375,
                  "support": 0.03958071395754814
                },
                "stance_score": -0.13056663051247597,
                "evidence_contribution": -0.11318276782588055,
                "combined_rank_score": 1.7682934999465942
              },
              {
                "id": 6261,
                "faiss_score": 0.9068849682807922,
                "faiss_rank": 5,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Transformer-based neural network architectures emerged from a broader effort to overcome structural limitations present in earlier approaches to sequence modeling.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 0.053444553166627884,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.6116482615470886,
                  "neutral": 0.38283827900886536,
                  "support": 0.005513511132448912
                },
                "stance_score": -0.6061347504146397,
                "evidence_contribution": -0.03239460089467593,
                "combined_rank_score": 0.9603295214474201
              }
            ],
            "neutral": [
              {
                "id": 6334,
                "faiss_score": 0.8871206045150757,
                "faiss_rank": 16,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 73,
                "sentence": "Rather than training models from scratch for each individual task, practitioners increasingly rely on pretrained transformer backbones that capture broad linguistic or sequential knowledge.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 0.6710541248321533,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.003452342702075839,
                  "neutral": 0.908929169178009,
                  "support": 0.08761847019195557
                },
                "stance_score": 0.08416612748987973,
                "evidence_contribution": 0.05648002702323268,
                "combined_rank_score": 1.558174729347229
              },
              {
                "id": 3083,
                "faiss_score": 0.8949947357177734,
                "faiss_rank": 10,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 138,
                "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "rerank_score": 0.5777134895324707,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.06788498163223267,
                  "neutral": 0.9225779175758362,
                  "support": 0.009537145495414734
                },
                "stance_score": -0.05834783613681793,
                "evidence_contribution": -0.03370833202126988,
                "combined_rank_score": 1.4727082252502441
              },
              {
                "id": 6273,
                "faiss_score": 0.8904296159744263,
                "faiss_rank": 15,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "The transformer architecture generalized this concept by eliminating recurrence entirely and relying solely on attention mechanisms to model relationships within a sequence.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 0.10180939733982086,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.015106219798326492,
                  "neutral": 0.9824913144111633,
                  "support": 0.0024024825543165207
                },
                "stance_score": -0.012703737244009972,
                "evidence_contribution": -0.001293359832776092,
                "combined_rank_score": 0.9922390133142471
              }
            ]
          }
        },
        {
          "subclaim": "These tasks saw significant improvements.",
          "verdict": "INCONCLUSIVE",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 0.0,
            "total": 0.0
          },
          "evidence": {
            "supporting": [
              {
                "id": 5586,
                "faiss_score": 0.868844747543335,
                "faiss_rank": 11,
                "doc_id": "local_bio_gene_editing.txt",
                "file_type": ".txt",
                "position": 59,
                "sentence": "Improvements in precision, delivery, and control have expanded the range of possible applications.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\bio_gene_editing.txt",
                "primary_category": null,
                "rerank_score": -1.6070451736450195,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.0007949198479764163,
                  "neutral": 0.13771769404411316,
                  "support": 0.8614874482154846
                },
                "stance_score": 0.8606925283675082,
                "evidence_contribution": 0.0,
                "combined_rank_score": -0.7382004261016846
              },
              {
                "id": 6046,
                "faiss_score": 0.8739926815032959,
                "faiss_rank": 5,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 6,
                "sentence": "These include improved generalization, better handling of rare or ambiguous inputs, and the ability to adapt to new tasks with minimal additional data.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": -2.1880946159362793,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0016440394101664424,
                  "neutral": 0.4812794029712677,
                  "support": 0.5170766115188599
                },
                "stance_score": 0.5154325721086934,
                "evidence_contribution": 0.0,
                "combined_rank_score": -1.3141019344329834
              },
              {
                "id": 6399,
                "faiss_score": 0.8873401880264282,
                "faiss_rank": 1,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 138,
                "sentence": "Improvements in efficiency, training stability, and integration with other components are expected to yield practical gains.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": -2.438533306121826,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.0021322567481547594,
                  "neutral": 0.6527662873268127,
                  "support": 0.3451014459133148
                },
                "stance_score": 0.34296918916516006,
                "evidence_contribution": 0.0,
                "combined_rank_score": -1.551193118095398
              },
              {
                "id": 5589,
                "faiss_score": 0.8712761402130127,
                "faiss_rank": 6,
                "doc_id": "local_bio_gene_editing.txt",
                "file_type": ".txt",
                "position": 62,
                "sentence": "Small improvements in efficiency or specificity can have meaningful impacts when translated into clinical or agricultural settings.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\bio_gene_editing.txt",
                "primary_category": null,
                "rerank_score": -3.2599258422851562,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.028195634484291077,
                  "neutral": 0.5434474945068359,
                  "support": 0.4283568263053894
                },
                "stance_score": 0.4001611918210983,
                "evidence_contribution": 0.0,
                "combined_rank_score": -2.3886497020721436
              },
              {
                "id": 6044,
                "faiss_score": 0.8646043539047241,
                "faiss_rank": 14,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": -4.22540807723999,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.000817636027932167,
                  "neutral": 0.1027408242225647,
                  "support": 0.8964415788650513
                },
                "stance_score": 0.8956239428371191,
                "evidence_contribution": 0.0,
                "combined_rank_score": -3.360803723335266
              }
            ],
            "contradicting": [
              {
                "id": 5969,
                "faiss_score": 0.8760039806365967,
                "faiss_rank": 3,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 64,
                "sentence": "Improvements in one area may expose constraints elsewhere.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": -5.354757785797119,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.3850768208503723,
                  "neutral": 0.5729495286941528,
                  "support": 0.04197365790605545
                },
                "stance_score": -0.34310316294431686,
                "evidence_contribution": -0.0,
                "combined_rank_score": -4.4787538051605225
              },
              {
                "id": 6728,
                "faiss_score": 0.8701443076133728,
                "faiss_rank": 7,
                "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                "file_type": ".txt",
                "position": 60,
                "sentence": "Assertions that a system improves both metrics simultaneously should be examined carefully, as such improvements usually depend on changing assumptions or workloads.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                "primary_category": null,
                "rerank_score": -6.235987663269043,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.2782565951347351,
                  "neutral": 0.683676540851593,
                  "support": 0.03806686028838158
                },
                "stance_score": -0.24018973484635353,
                "evidence_contribution": -0.0,
                "combined_rank_score": -5.36584335565567
              }
            ],
            "neutral": [
              {
                "id": 1877,
                "faiss_score": 0.8633498549461365,
                "faiss_rank": 15,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 145,
                "sentence": "Early research demonstrated that inserting intermediate \"scratchpad\" computations could improve performance on such tasks.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "rerank_score": -2.0456624031066895,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.00309790694154799,
                  "neutral": 0.9512084126472473,
                  "support": 0.045693691819906235
                },
                "stance_score": 0.042595784878358245,
                "evidence_contribution": 0.0,
                "combined_rank_score": -1.182312548160553
              },
              {
                "id": 2232,
                "faiss_score": 0.8614091277122498,
                "faiss_rank": 18,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 163,
                "sentence": "Optimizations such as Quickprop are primarily aimed at speeding up error minimization, while other improvements mainly try to increase reliability.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "rerank_score": -4.753089427947998,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.003027374157682061,
                  "neutral": 0.9957343935966492,
                  "support": 0.0012382006971165538
                },
                "stance_score": -0.0017891734605655074,
                "evidence_contribution": -0.0,
                "combined_rank_score": -3.8916803002357483
              },
              {
                "id": 1785,
                "faiss_score": 0.8570448756217957,
                "faiss_rank": 19,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Cleaned datasets can increase training efficiency and lead to improved downstream performance.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "rerank_score": -7.232579231262207,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.003309796331450343,
                  "neutral": 0.9835056662559509,
                  "support": 0.01318448968231678
                },
                "stance_score": 0.009874693350866437,
                "evidence_contribution": 0.0,
                "combined_rank_score": -6.375534355640411
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Transformer architectures were used in natural language processing tasks.",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "weak"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6296,
                      "faiss_score": 0.9599642753601074,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 35,
                      "sentence": "The transformer architecture proved highly effective across a wide range of natural language processing tasks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": 9.242033958435059,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.0064346035942435265,
                        "neutral": 0.011724923737347126,
                        "support": 0.9818404316902161
                      },
                      "stance_score": 0.9754058280959725,
                      "evidence_contribution": 9.014733786518448,
                      "combined_rank_score": 10.201998233795166
                    },
                    {
                      "id": 2184,
                      "faiss_score": 0.9435071349143982,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 115,
                      "sentence": "Transformers have increasingly become the model of choice for natural language processing.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "rerank_score": 4.645409107208252,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.001396269304677844,
                        "neutral": 0.01836763694882393,
                        "support": 0.9802360534667969
                      },
                      "stance_score": 0.978839784162119,
                      "evidence_contribution": 4.547111247844468,
                      "combined_rank_score": 5.58891624212265
                    },
                    {
                      "id": 3003,
                      "faiss_score": 0.8870973587036133,
                      "faiss_rank": 17,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 58,
                      "sentence": "Tasks for pretraining and fine-tuning commonly include: language modeling next-sentence prediction question answering reading comprehension sentiment analysis paraphrasing The T5 transformer report documents a large number of natural language pretraining tasks.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "rerank_score": 3.4558331966400146,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.013680233620107174,
                        "neutral": 0.745046854019165,
                        "support": 0.24127286672592163
                      },
                      "stance_score": 0.22759263310581446,
                      "evidence_contribution": 0.7865221767977848,
                      "combined_rank_score": 4.342930555343628
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 1807,
                      "faiss_score": 0.9014351963996887,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "LLMs are generally based on the transformer architecture, which leverages an attention mechanism that enables the model to process relationships between all elements in a sequence simultaneously, regardless of their distance from each other.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "rerank_score": 0.8668583035469055,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.1701473444700241,
                        "neutral": 0.7902719378471375,
                        "support": 0.03958071395754814
                      },
                      "stance_score": -0.13056663051247597,
                      "evidence_contribution": -0.11318276782588055,
                      "combined_rank_score": 1.7682934999465942
                    },
                    {
                      "id": 2987,
                      "faiss_score": 0.8978081941604614,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Transformer architecture is now used alongside many generative models that contribute to the ongoing AI boom.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "rerank_score": 0.8487489819526672,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.31608426570892334,
                        "neutral": 0.6735674142837524,
                        "support": 0.010348307900130749
                      },
                      "stance_score": -0.3057359578087926,
                      "evidence_contribution": -0.25949308293653633,
                      "combined_rank_score": 1.7465571761131287
                    },
                    {
                      "id": 6261,
                      "faiss_score": 0.9068849682807922,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Transformer-based neural network architectures emerged from a broader effort to overcome structural limitations present in earlier approaches to sequence modeling.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": 0.053444553166627884,
                      "rerank_rank": 9,
                      "probs": {
                        "contradict": 0.6116482615470886,
                        "neutral": 0.38283827900886536,
                        "support": 0.005513511132448912
                      },
                      "stance_score": -0.6061347504146397,
                      "evidence_contribution": -0.03239460089467593,
                      "combined_rank_score": 0.9603295214474201
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6334,
                      "faiss_score": 0.8871206045150757,
                      "faiss_rank": 16,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 73,
                      "sentence": "Rather than training models from scratch for each individual task, practitioners increasingly rely on pretrained transformer backbones that capture broad linguistic or sequential knowledge.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": 0.6710541248321533,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.003452342702075839,
                        "neutral": 0.908929169178009,
                        "support": 0.08761847019195557
                      },
                      "stance_score": 0.08416612748987973,
                      "evidence_contribution": 0.05648002702323268,
                      "combined_rank_score": 1.558174729347229
                    },
                    {
                      "id": 3083,
                      "faiss_score": 0.8949947357177734,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 138,
                      "sentence": "The transformer architecture is constructed to calculate output tokens iteratively.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "rerank_score": 0.5777134895324707,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.06788498163223267,
                        "neutral": 0.9225779175758362,
                        "support": 0.009537145495414734
                      },
                      "stance_score": -0.05834783613681793,
                      "evidence_contribution": -0.03370833202126988,
                      "combined_rank_score": 1.4727082252502441
                    },
                    {
                      "id": 6273,
                      "faiss_score": 0.8904296159744263,
                      "faiss_rank": 15,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 12,
                      "sentence": "The transformer architecture generalized this concept by eliminating recurrence entirely and relying solely on attention mechanisms to model relationships within a sequence.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": 0.10180939733982086,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.015106219798326492,
                        "neutral": 0.9824913144111633,
                        "support": 0.0024024825543165207
                      },
                      "stance_score": -0.012703737244009972,
                      "evidence_contribution": -0.001293359832776092,
                      "combined_rank_score": 0.9922390133142471
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "EVIDENCE_LIMITATIONS",
            "items": [
              {
                "subclaim": "These tasks saw significant improvements.",
                "verdict": "INCONCLUSIVE",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5586,
                      "faiss_score": 0.868844747543335,
                      "faiss_rank": 11,
                      "doc_id": "local_bio_gene_editing.txt",
                      "file_type": ".txt",
                      "position": 59,
                      "sentence": "Improvements in precision, delivery, and control have expanded the range of possible applications.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\bio_gene_editing.txt",
                      "primary_category": null,
                      "rerank_score": -1.6070451736450195,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.0007949198479764163,
                        "neutral": 0.13771769404411316,
                        "support": 0.8614874482154846
                      },
                      "stance_score": 0.8606925283675082,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -0.7382004261016846
                    },
                    {
                      "id": 6046,
                      "faiss_score": 0.8739926815032959,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 6,
                      "sentence": "These include improved generalization, better handling of rare or ambiguous inputs, and the ability to adapt to new tasks with minimal additional data.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": -2.1880946159362793,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0016440394101664424,
                        "neutral": 0.4812794029712677,
                        "support": 0.5170766115188599
                      },
                      "stance_score": 0.5154325721086934,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -1.3141019344329834
                    },
                    {
                      "id": 6399,
                      "faiss_score": 0.8873401880264282,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 138,
                      "sentence": "Improvements in efficiency, training stability, and integration with other components are expected to yield practical gains.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": -2.438533306121826,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.0021322567481547594,
                        "neutral": 0.6527662873268127,
                        "support": 0.3451014459133148
                      },
                      "stance_score": 0.34296918916516006,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -1.551193118095398
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5969,
                      "faiss_score": 0.8760039806365967,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 64,
                      "sentence": "Improvements in one area may expose constraints elsewhere.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "rerank_score": -5.354757785797119,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.3850768208503723,
                        "neutral": 0.5729495286941528,
                        "support": 0.04197365790605545
                      },
                      "stance_score": -0.34310316294431686,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -4.4787538051605225
                    },
                    {
                      "id": 6728,
                      "faiss_score": 0.8701443076133728,
                      "faiss_rank": 7,
                      "doc_id": "local_systems_latency_throughput_tradeoffs.txt",
                      "file_type": ".txt",
                      "position": 60,
                      "sentence": "Assertions that a system improves both metrics simultaneously should be examined carefully, as such improvements usually depend on changing assumptions or workloads.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_latency_throughput_tradeoffs.txt",
                      "primary_category": null,
                      "rerank_score": -6.235987663269043,
                      "rerank_rank": 9,
                      "probs": {
                        "contradict": 0.2782565951347351,
                        "neutral": 0.683676540851593,
                        "support": 0.03806686028838158
                      },
                      "stance_score": -0.24018973484635353,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -5.36584335565567
                    }
                  ],
                  "neutral": [
                    {
                      "id": 1877,
                      "faiss_score": 0.8633498549461365,
                      "faiss_rank": 15,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 145,
                      "sentence": "Early research demonstrated that inserting intermediate \"scratchpad\" computations could improve performance on such tasks.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "rerank_score": -2.0456624031066895,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.00309790694154799,
                        "neutral": 0.9512084126472473,
                        "support": 0.045693691819906235
                      },
                      "stance_score": 0.042595784878358245,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -1.182312548160553
                    },
                    {
                      "id": 2232,
                      "faiss_score": 0.8614091277122498,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Artificial_neural_network",
                      "file_type": ".txt",
                      "position": 163,
                      "sentence": "Optimizations such as Quickprop are primarily aimed at speeding up error minimization, while other improvements mainly try to increase reliability.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                      "primary_category": "neural networks",
                      "rerank_score": -4.753089427947998,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.003027374157682061,
                        "neutral": 0.9957343935966492,
                        "support": 0.0012382006971165538
                      },
                      "stance_score": -0.0017891734605655074,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -3.8916803002357483
                    },
                    {
                      "id": 1785,
                      "faiss_score": 0.8570448756217957,
                      "faiss_rank": 19,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "Cleaned datasets can increase training efficiency and lead to improved downstream performance.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "rerank_score": -7.232579231262207,
                      "rerank_rank": 10,
                      "probs": {
                        "contradict": 0.003309796331450343,
                        "neutral": 0.9835056662559509,
                        "support": 0.01318448968231678
                      },
                      "stance_score": 0.009874693350866437,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -6.375534355640411
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Fault tolerance is a fundamental requirement for reliable distributed systems.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Fault tolerance is a fundamental requirement for reliable distributed systems.",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 1.7173915604469325,
            "contradict": 1.9065610618419537,
            "total": 3.6239526222888863
          },
          "evidence": {
            "supporting": [
              {
                "id": 3508,
                "faiss_score": 0.9106696844100952,
                "faiss_rank": 13,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 79,
                "sentence": "The basic characteristics of fault tolerance require: No single point of failure \u2013 If a system experiences a failure, it must continue to operate without interruption during the repair process.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 3.6346070766448975,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.0023842875380069017,
                  "neutral": 0.8007035255432129,
                  "support": 0.19691221415996552
                },
                "stance_score": 0.1945279266219586,
                "evidence_contribution": 0.7070325787052301,
                "combined_rank_score": 4.545276761054993
              },
              {
                "id": 6597,
                "faiss_score": 0.9170854091644287,
                "faiss_rank": 10,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Fault tolerance and reliability describe a system\u2019s ability to continue operating correctly in the presence of failures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "rerank_score": 5.004147529602051,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.002577927429229021,
                  "neutral": 0.8689212799072266,
                  "support": 0.1285007894039154
                },
                "stance_score": 0.12592286197468638,
                "evidence_contribution": 0.6301365786710469,
                "combined_rank_score": 5.9212329387664795
              },
              {
                "id": 6610,
                "faiss_score": 0.9200949668884277,
                "faiss_rank": 9,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Redundancy is a fundamental technique for achieving fault tolerance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "rerank_score": 2.504101514816284,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.004990473855286837,
                  "neutral": 0.8381791710853577,
                  "support": 0.1568303257226944
                },
                "stance_score": 0.15183985186740756,
                "evidence_contribution": 0.38022240307065547,
                "combined_rank_score": 3.424196481704712
              }
            ],
            "contradicting": [
              {
                "id": 6601,
                "faiss_score": 0.9003157615661621,
                "faiss_rank": 16,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Fault tolerance focuses on how systems respond to failures, while reliability concerns the probability that a system performs its intended function over time.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "rerank_score": 4.317968368530273,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.45627206563949585,
                  "neutral": 0.5289970636367798,
                  "support": 0.014730836264789104
                },
                "stance_score": -0.44154122937470675,
                "evidence_contribution": -1.9065610618419537,
                "combined_rank_score": 5.2182841300964355
              }
            ],
            "neutral": [
              {
                "id": 568,
                "faiss_score": 0.9223860502243042,
                "faiss_rank": 6,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 144,
                "sentence": "There are also fundamental challenges that are unique to distributed computing, for example those related to fault-tolerance.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "rerank_score": 4.329262733459473,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.0938965231180191,
                  "neutral": 0.8450294137001038,
                  "support": 0.061074014753103256
                },
                "stance_score": -0.03282250836491585,
                "evidence_contribution": -0.142097262282892,
                "combined_rank_score": 5.251648783683777
              },
              {
                "id": 3525,
                "faiss_score": 0.8951352834701538,
                "faiss_rank": 18,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 96,
                "sentence": "Spare components address the first fundamental characteristic of fault tolerance in three ways: Replication: Providing multiple identical instances of the same system or subsystem, directing tasks or requests to all of them in parallel, and choosing the correct result on the basis of a quorum; Redundancy: Providing multiple identical instances of the same system and switching to one of the remaining instances in case of a failure (failover); Diversity: Providing multiple different implementations of the same specification, and using them like replicated systems to cope with errors in a specific implementation.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 3.751453399658203,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.002626709407195449,
                  "neutral": 0.9082320332527161,
                  "support": 0.08914132416248322
                },
                "stance_score": 0.08651461475528777,
                "evidence_contribution": 0.32455554564384403,
                "combined_rank_score": 4.646588683128357
              },
              {
                "id": 3738,
                "faiss_score": 0.8935599327087402,
                "faiss_rank": 20,
                "doc_id": "wiki_Byzantine_fault",
                "file_type": ".txt",
                "position": 28,
                "sentence": "The objective of Byzantine fault tolerance is to be able to defend against failures of system components with or without symptoms that prevent other components of the system from reaching an agreement among themselves, where such an agreement is needed for the correct operation of the system.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Byzantine_fault",
                "primary_category": "all accuracy disputes",
                "rerank_score": 2.5237598419189453,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.007628699764609337,
                  "neutral": 0.9567516446113586,
                  "support": 0.03561968356370926
                },
                "stance_score": 0.027990983799099922,
                "evidence_contribution": 0.07064252084797218,
                "combined_rank_score": 3.4173197746276855
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Fault tolerance is a fundamental requirement for reliable distributed systems.",
                "verdict": "MIXED",
                "controversial": true,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6597,
                      "faiss_score": 0.9170854091644287,
                      "faiss_rank": 10,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Fault tolerance and reliability describe a system\u2019s ability to continue operating correctly in the presence of failures.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "rerank_score": 5.004147529602051,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.002577927429229021,
                        "neutral": 0.8689212799072266,
                        "support": 0.1285007894039154
                      },
                      "stance_score": 0.12592286197468638,
                      "evidence_contribution": 0.6301365786710469,
                      "combined_rank_score": 5.9212329387664795
                    },
                    {
                      "id": 3508,
                      "faiss_score": 0.9106696844100952,
                      "faiss_rank": 13,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 79,
                      "sentence": "The basic characteristics of fault tolerance require: No single point of failure \u2013 If a system experiences a failure, it must continue to operate without interruption during the repair process.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 3.6346070766448975,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.0023842875380069017,
                        "neutral": 0.8007035255432129,
                        "support": 0.19691221415996552
                      },
                      "stance_score": 0.1945279266219586,
                      "evidence_contribution": 0.7070325787052301,
                      "combined_rank_score": 4.545276761054993
                    },
                    {
                      "id": 6610,
                      "faiss_score": 0.9200949668884277,
                      "faiss_rank": 9,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Redundancy is a fundamental technique for achieving fault tolerance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "rerank_score": 2.504101514816284,
                      "rerank_rank": 9,
                      "probs": {
                        "contradict": 0.004990473855286837,
                        "neutral": 0.8381791710853577,
                        "support": 0.1568303257226944
                      },
                      "stance_score": 0.15183985186740756,
                      "evidence_contribution": 0.38022240307065547,
                      "combined_rank_score": 3.424196481704712
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6601,
                      "faiss_score": 0.9003157615661621,
                      "faiss_rank": 16,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 4,
                      "sentence": "Fault tolerance focuses on how systems respond to failures, while reliability concerns the probability that a system performs its intended function over time.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "rerank_score": 4.317968368530273,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.45627206563949585,
                        "neutral": 0.5289970636367798,
                        "support": 0.014730836264789104
                      },
                      "stance_score": -0.44154122937470675,
                      "evidence_contribution": -1.9065610618419537,
                      "combined_rank_score": 5.2182841300964355
                    }
                  ],
                  "neutral": [
                    {
                      "id": 568,
                      "faiss_score": 0.9223860502243042,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 144,
                      "sentence": "There are also fundamental challenges that are unique to distributed computing, for example those related to fault-tolerance.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "rerank_score": 4.329262733459473,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.0938965231180191,
                        "neutral": 0.8450294137001038,
                        "support": 0.061074014753103256
                      },
                      "stance_score": -0.03282250836491585,
                      "evidence_contribution": -0.142097262282892,
                      "combined_rank_score": 5.251648783683777
                    },
                    {
                      "id": 3525,
                      "faiss_score": 0.8951352834701538,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 96,
                      "sentence": "Spare components address the first fundamental characteristic of fault tolerance in three ways: Replication: Providing multiple identical instances of the same system or subsystem, directing tasks or requests to all of them in parallel, and choosing the correct result on the basis of a quorum; Redundancy: Providing multiple identical instances of the same system and switching to one of the remaining instances in case of a failure (failover); Diversity: Providing multiple different implementations of the same specification, and using them like replicated systems to cope with errors in a specific implementation.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 3.751453399658203,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.002626709407195449,
                        "neutral": 0.9082320332527161,
                        "support": 0.08914132416248322
                      },
                      "stance_score": 0.08651461475528777,
                      "evidence_contribution": 0.32455554564384403,
                      "combined_rank_score": 4.646588683128357
                    },
                    {
                      "id": 3738,
                      "faiss_score": 0.8935599327087402,
                      "faiss_rank": 20,
                      "doc_id": "wiki_Byzantine_fault",
                      "file_type": ".txt",
                      "position": 28,
                      "sentence": "The objective of Byzantine fault tolerance is to be able to defend against failures of system components with or without symptoms that prevent other components of the system from reaching an agreement among themselves, where such an agreement is needed for the correct operation of the system.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Byzantine_fault",
                      "primary_category": "all accuracy disputes",
                      "rerank_score": 2.5237598419189453,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.007628699764609337,
                        "neutral": 0.9567516446113586,
                        "support": 0.03561968356370926
                      },
                      "stance_score": 0.027990983799099922,
                      "evidence_contribution": 0.07064252084797218,
                      "combined_rank_score": 3.4173197746276855
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Increasing computational resources can improve the training performance of deep learning models.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Increasing computational resources can improve the training performance of deep learning models.",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 6.743168849386467,
            "contradict": 0.0,
            "total": 6.743168849386467
          },
          "evidence": {
            "supporting": [
              {
                "id": 2622,
                "faiss_score": 0.8935152292251587,
                "faiss_rank": 6,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 217,
                "sentence": "Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "rerank_score": 2.851893901824951,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0011127914767712355,
                  "neutral": 0.14476646482944489,
                  "support": 0.8541207909584045
                },
                "stance_score": 0.8530079994816333,
                "evidence_contribution": 2.4326883119295712,
                "combined_rank_score": 3.74540913105011
              },
              {
                "id": 5906,
                "faiss_score": 0.8968743085861206,
                "faiss_rank": 4,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Early successes in deep learning were often achieved by increasing model size and training data, but this approach quickly encounters practical limits.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": 4.011983871459961,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.029276547953486443,
                  "neutral": 0.37700629234313965,
                  "support": 0.5937171578407288
                },
                "stance_score": 0.5644406098872423,
                "evidence_contribution": 2.26452662326464,
                "combined_rank_score": 4.9088581800460815
              },
              {
                "id": 1901,
                "faiss_score": 0.8911174535751343,
                "faiss_rank": 9,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 169,
                "sentence": "OptiLLM demonstrates that strategic application of computational resources at inference time can substantially improve model performance across diverse tasks, achieving significant improvements on benchmarks such as the AIME 2024 mathematics competition and various coding challenges.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "rerank_score": 3.919332504272461,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.004067023750394583,
                  "neutral": 0.642042338848114,
                  "support": 0.35389062762260437
                },
                "stance_score": 0.3498236038722098,
                "evidence_contribution": 1.3710750214180853,
                "combined_rank_score": 4.810449957847595
              },
              {
                "id": 1416,
                "faiss_score": 0.8915122747421265,
                "faiss_rank": 8,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 66,
                "sentence": "Increase the amount of training data: If the model is underfitting due to a lack of data, increasing the amount of training data may help.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "rerank_score": 2.29343318939209,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.008432808332145214,
                  "neutral": 0.6888686418533325,
                  "support": 0.3026985824108124
                },
                "stance_score": 0.29426577407866716,
                "evidence_contribution": 0.6748788927741698,
                "combined_rank_score": 3.1849454641342163
              },
              {
                "id": 1785,
                "faiss_score": 0.8816750049591064,
                "faiss_rank": 17,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Cleaned datasets can increase training efficiency and lead to improved downstream performance.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "rerank_score": -0.03195880353450775,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.005137357860803604,
                  "neutral": 0.752930760383606,
                  "support": 0.24193188548088074
                },
                "stance_score": 0.23679452762007713,
                "evidence_contribution": 0.0,
                "combined_rank_score": 0.8497162014245987
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 5907,
                "faiss_score": 0.8959633708000183,
                "faiss_rank": 5,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": 2.638784170150757,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.07758736610412598,
                  "neutral": 0.8997015953063965,
                  "support": 0.022711053490638733
                },
                "stance_score": -0.054876312613487244,
                "evidence_contribution": -0.14480674504071445,
                "combined_rank_score": 3.534747540950775
              },
              {
                "id": 6044,
                "faiss_score": 0.8992515802383423,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 2.371992588043213,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.0009964535711333156,
                  "neutral": 0.9319743514060974,
                  "support": 0.06702922284603119
                },
                "stance_score": 0.06603276927489787,
                "evidence_contribution": 0.15662923928802536,
                "combined_rank_score": 3.271244168281555
              },
              {
                "id": 6092,
                "faiss_score": 0.8839632868766785,
                "faiss_rank": 12,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "The computational cost of training large language models is substantial.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 0.24331992864608765,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.10281243920326233,
                  "neutral": 0.8933481574058533,
                  "support": 0.0038394108414649963
                },
                "stance_score": -0.09897302836179733,
                "evidence_contribution": -0.024082110198879736,
                "combined_rank_score": 1.1272832155227661
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Increasing computational resources can improve the training performance of deep learning models.",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5906,
                      "faiss_score": 0.8968743085861206,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 1,
                      "sentence": "Early successes in deep learning were often achieved by increasing model size and training data, but this approach quickly encounters practical limits.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "rerank_score": 4.011983871459961,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.029276547953486443,
                        "neutral": 0.37700629234313965,
                        "support": 0.5937171578407288
                      },
                      "stance_score": 0.5644406098872423,
                      "evidence_contribution": 2.26452662326464,
                      "combined_rank_score": 4.9088581800460815
                    },
                    {
                      "id": 1901,
                      "faiss_score": 0.8911174535751343,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 169,
                      "sentence": "OptiLLM demonstrates that strategic application of computational resources at inference time can substantially improve model performance across diverse tasks, achieving significant improvements on benchmarks such as the AIME 2024 mathematics competition and various coding challenges.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "rerank_score": 3.919332504272461,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.004067023750394583,
                        "neutral": 0.642042338848114,
                        "support": 0.35389062762260437
                      },
                      "stance_score": 0.3498236038722098,
                      "evidence_contribution": 1.3710750214180853,
                      "combined_rank_score": 4.810449957847595
                    },
                    {
                      "id": 2622,
                      "faiss_score": 0.8935152292251587,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 217,
                      "sentence": "Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "rerank_score": 2.851893901824951,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0011127914767712355,
                        "neutral": 0.14476646482944489,
                        "support": 0.8541207909584045
                      },
                      "stance_score": 0.8530079994816333,
                      "evidence_contribution": 2.4326883119295712,
                      "combined_rank_score": 3.74540913105011
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 5907,
                      "faiss_score": 0.8959633708000183,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 2,
                      "sentence": "Training large models requires substantial computational resources, and deploying them in real-world systems introduces constraints related to latency, memory, and energy consumption.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "rerank_score": 2.638784170150757,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.07758736610412598,
                        "neutral": 0.8997015953063965,
                        "support": 0.022711053490638733
                      },
                      "stance_score": -0.054876312613487244,
                      "evidence_contribution": -0.14480674504071445,
                      "combined_rank_score": 3.534747540950775
                    },
                    {
                      "id": 6044,
                      "faiss_score": 0.8992515802383423,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 4,
                      "sentence": "Increasing the number of parameters, the amount of training data, and the total compute used during training has been shown to produce consistent improvements in performance across many benchmarks.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 2.371992588043213,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.0009964535711333156,
                        "neutral": 0.9319743514060974,
                        "support": 0.06702922284603119
                      },
                      "stance_score": 0.06603276927489787,
                      "evidence_contribution": 0.15662923928802536,
                      "combined_rank_score": 3.271244168281555
                    },
                    {
                      "id": 6092,
                      "faiss_score": 0.8839632868766785,
                      "faiss_rank": 12,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 52,
                      "sentence": "The computational cost of training large language models is substantial.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 0.24331992864608765,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.10281243920326233,
                        "neutral": 0.8933481574058533,
                        "support": 0.0038394108414649963
                      },
                      "stance_score": -0.09897302836179733,
                      "evidence_contribution": -0.024082110198879736,
                      "combined_rank_score": 1.1272832155227661
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Large language models can perform multiple language tasks without task-specific fine-tuning.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Large language models can perform multiple language tasks",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 12.668652140865667,
            "contradict": 0.0,
            "total": 12.668652140865667
          },
          "evidence": {
            "supporting": [
              {
                "id": 6079,
                "faiss_score": 0.9092576503753662,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Large language models are often described as general-purpose systems because they can be adapted to many tasks with minimal fine-tuning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 6.446345329284668,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.0010351998498663306,
                  "neutral": 0.16859209537506104,
                  "support": 0.8303727507591248
                },
                "stance_score": 0.8293375509092584,
                "evidence_contribution": 5.346196247704284,
                "combined_rank_score": 7.355602979660034
              },
              {
                "id": 6042,
                "faiss_score": 0.8853220343589783,
                "faiss_rank": 11,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "This simple training signal, when combined with large datasets and high model capacity, produces systems that can generate coherent text, answer questions, summarize documents, and perform a wide variety of language-related tasks without explicit task-specific programming.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 4.042299270629883,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.0015242607332766056,
                  "neutral": 0.19606323540210724,
                  "support": 0.8024125099182129
                },
                "stance_score": 0.8008882491849363,
                "evidence_contribution": 3.237429985536312,
                "combined_rank_score": 4.927621304988861
              },
              {
                "id": 6040,
                "faiss_score": 0.9093468189239502,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 5.019293785095215,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0017207523342221975,
                  "neutral": 0.6858500242233276,
                  "support": 0.312429279088974
                },
                "stance_score": 0.3107085267547518,
                "evidence_contribution": 1.559537377316216,
                "combined_rank_score": 5.928640604019165
              },
              {
                "id": 6121,
                "faiss_score": 0.9074077606201172,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 5.14181661605835,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.007413278333842754,
                  "neutral": 0.82762211561203,
                  "support": 0.16496461629867554
                },
                "stance_score": 0.15755133796483278,
                "evidence_contribution": 0.8101000874298019,
                "combined_rank_score": 6.049224376678467
              },
              {
                "id": 6043,
                "faiss_score": 0.8912434577941895,
                "faiss_rank": 6,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 3.5135903358459473,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.002225017175078392,
                  "neutral": 0.8620526790618896,
                  "support": 0.13572227954864502
                },
                "stance_score": 0.13349726237356663,
                "evidence_contribution": 0.4690546909376545,
                "combined_rank_score": 4.404833793640137
              },
              {
                "id": 2185,
                "faiss_score": 0.8812185525894165,
                "faiss_rank": 17,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 116,
                "sentence": "Many modern large language models such as ChatGPT, GPT-4, and BERT use this architecture.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "rerank_score": 3.2154648303985596,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.001421264372766018,
                  "neutral": 0.8628906011581421,
                  "support": 0.1356882005929947
                },
                "stance_score": 0.13426693622022867,
                "evidence_contribution": 0.4317306113015118,
                "combined_rank_score": 4.096683382987976
              },
              {
                "id": 6047,
                "faiss_score": 0.883418083190918,
                "faiss_rank": 14,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Despite these capabilities, the behavior of large language models remains fundamentally probabilistic.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 3.7385928630828857,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.0030133984982967377,
                  "neutral": 0.8811923265457153,
                  "support": 0.11579427868127823
                },
                "stance_score": 0.11278088018298149,
                "evidence_contribution": 0.42164179374430066,
                "combined_rank_score": 4.622010946273804
              },
              {
                "id": 6115,
                "faiss_score": 0.8896223306655884,
                "faiss_rank": 7,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Large language models also influence how users interact with technology.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 3.2091166973114014,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.0022298081312328577,
                  "neutral": 0.8730888366699219,
                  "support": 0.12468136847019196
                },
                "stance_score": 0.1224515603389591,
                "evidence_contribution": 0.3929613468955882,
                "combined_rank_score": 4.09873902797699
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 3009,
                "faiss_score": 0.8790433406829834,
                "faiss_rank": 19,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 64,
                "sentence": "In general, there are 3 classes of language modelling tasks: \"masked\", \"autoregressive\", and \"prefixLM\".",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "rerank_score": 3.828814744949341,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.005533924791961908,
                  "neutral": 0.9516805410385132,
                  "support": 0.04278552904725075
                },
                "stance_score": 0.03725160425528884,
                "evidence_contribution": 0.14262949164566752,
                "combined_rank_score": 4.707858085632324
              },
              {
                "id": 6099,
                "faiss_score": 0.8944740891456604,
                "faiss_rank": 5,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 59,
                "sentence": "Large language models are increasingly deployed as components within larger systems rather than standalone tools.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 3.510206699371338,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.0012955378042533994,
                  "neutral": 0.9265615344047546,
                  "support": 0.07214298099279404
                },
                "stance_score": 0.07084744318854064,
                "evidence_contribution": 0.2486891697137456,
                "combined_rank_score": 4.404680788516998
              }
            ]
          }
        },
        {
          "subclaim": "without task-specific fine-tuning",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 6.715901575618437,
            "contradict": 0.0,
            "total": 6.715901575618437
          },
          "evidence": {
            "supporting": [
              {
                "id": 1833,
                "faiss_score": 0.8788925409317017,
                "faiss_rank": 5,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 101,
                "sentence": "This technique, called few-shot prompting, allows LLMs to be adapted to any task without requiring fine-tuning.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "rerank_score": 5.452361583709717,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.0010085511021316051,
                  "neutral": 0.02543622814118862,
                  "support": 0.9735552668571472
                },
                "stance_score": 0.9725467157550156,
                "evidence_contribution": 5.302676351345701,
                "combined_rank_score": 6.3312541246414185
              },
              {
                "id": 6079,
                "faiss_score": 0.8675508499145508,
                "faiss_rank": 14,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Large language models are often described as general-purpose systems because they can be adapted to many tasks with minimal fine-tuning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 0.734641432762146,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.0036333799362182617,
                  "neutral": 0.07261178642511368,
                  "support": 0.9237548112869263
                },
                "stance_score": 0.920121431350708,
                "evidence_contribution": 0.6759593266426407,
                "combined_rank_score": 1.6021922826766968
              },
              {
                "id": 2566,
                "faiss_score": 0.875229001045227,
                "faiss_rank": 7,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 161,
                "sentence": "Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "rerank_score": 0.4810207486152649,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0010565657867118716,
                  "neutral": 0.06393749266862869,
                  "support": 0.9350059628486633
                },
                "stance_score": 0.9339493970619515,
                "evidence_contribution": 0.4492490381435152,
                "combined_rank_score": 1.356249749660492
              },
              {
                "id": 6432,
                "faiss_score": 0.8805605173110962,
                "faiss_rank": 4,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 171,
                "sentence": "By framing tasks as variations of a common input-output format, practitioners can leverage pretrained models without extensive task-specific training.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 0.30624258518218994,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.0018275665352120996,
                  "neutral": 0.055858906358480453,
                  "support": 0.942313551902771
                },
                "stance_score": 0.9404859853675589,
                "evidence_contribution": 0.2880168594865805,
                "combined_rank_score": 1.1868031024932861
              },
              {
                "id": 287,
                "faiss_score": 0.8709167242050171,
                "faiss_rank": 11,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 178,
                "sentence": "Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "rerank_score": -2.324951648712158,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.0012470762012526393,
                  "neutral": 0.12183920294046402,
                  "support": 0.8769136667251587
                },
                "stance_score": 0.875666590523906,
                "evidence_contribution": 0.0,
                "combined_rank_score": -1.4540349245071411
              }
            ],
            "contradicting": [
              {
                "id": 6085,
                "faiss_score": 0.8813949823379517,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 45,
                "sentence": "Fine-tuning is commonly used to adapt large language models to specific domains or behaviors.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": -0.16154561936855316,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.9929386973381042,
                  "neutral": 0.005900803487747908,
                  "support": 0.001160479267127812
                },
                "stance_score": -0.9917782180709764,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.7198493629693985
              },
              {
                "id": 1802,
                "faiss_score": 0.8630768656730652,
                "faiss_rank": 18,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 70,
                "sentence": "Instruction fine-tuning is a form of supervised learning used to teach LLMs to follow user instructions.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "rerank_score": -0.5821276307106018,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.9954550266265869,
                  "neutral": 0.0036955545656383038,
                  "support": 0.0008494564681313932
                },
                "stance_score": -0.9946055701584555,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.2809492349624634
              },
              {
                "id": 6335,
                "faiss_score": 0.8739376664161682,
                "faiss_rank": 8,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 74,
                "sentence": "These pretrained models are then adapted to downstream tasks through fine-tuning or lightweight adaptation mechanisms.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": -0.7192176580429077,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.9972085356712341,
                  "neutral": 0.002253232290968299,
                  "support": 0.0005383074167184532
                },
                "stance_score": -0.9966702282545157,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.1547200083732605
              },
              {
                "id": 6087,
                "faiss_score": 0.8714344501495361,
                "faiss_rank": 10,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "While fine-tuning can improve performance, it may also introduce overfitting or reduce generality if not carefully managed.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": -1.157218337059021,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.9041840434074402,
                  "neutral": 0.08107355237007141,
                  "support": 0.014742383733391762
                },
                "stance_score": -0.8894416596740484,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.28578388690948486
              },
              {
                "id": 6088,
                "faiss_score": 0.8841488361358643,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "Parameter-efficient fine-tuning methods aim to mitigate these risks by modifying only a subset of parameters.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": -2.0797901153564453,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.9841687083244324,
                  "neutral": 0.014658700674772263,
                  "support": 0.001172599266283214
                },
                "stance_score": -0.9829961090581492,
                "evidence_contribution": -0.0,
                "combined_rank_score": -1.195641279220581
              }
            ],
            "neutral": []
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Large language models can perform multiple language tasks",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6079,
                      "faiss_score": 0.9092576503753662,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "Large language models are often described as general-purpose systems because they can be adapted to many tasks with minimal fine-tuning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 6.446345329284668,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.0010351998498663306,
                        "neutral": 0.16859209537506104,
                        "support": 0.8303727507591248
                      },
                      "stance_score": 0.8293375509092584,
                      "evidence_contribution": 5.346196247704284,
                      "combined_rank_score": 7.355602979660034
                    },
                    {
                      "id": 6121,
                      "faiss_score": 0.9074077606201172,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 5.14181661605835,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.007413278333842754,
                        "neutral": 0.82762211561203,
                        "support": 0.16496461629867554
                      },
                      "stance_score": 0.15755133796483278,
                      "evidence_contribution": 0.8101000874298019,
                      "combined_rank_score": 6.049224376678467
                    },
                    {
                      "id": 6040,
                      "faiss_score": 0.9093468189239502,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 5.019293785095215,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0017207523342221975,
                        "neutral": 0.6858500242233276,
                        "support": 0.312429279088974
                      },
                      "stance_score": 0.3107085267547518,
                      "evidence_contribution": 1.559537377316216,
                      "combined_rank_score": 5.928640604019165
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 3009,
                      "faiss_score": 0.8790433406829834,
                      "faiss_rank": 19,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 64,
                      "sentence": "In general, there are 3 classes of language modelling tasks: \"masked\", \"autoregressive\", and \"prefixLM\".",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "rerank_score": 3.828814744949341,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.005533924791961908,
                        "neutral": 0.9516805410385132,
                        "support": 0.04278552904725075
                      },
                      "stance_score": 0.03725160425528884,
                      "evidence_contribution": 0.14262949164566752,
                      "combined_rank_score": 4.707858085632324
                    },
                    {
                      "id": 6099,
                      "faiss_score": 0.8944740891456604,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 59,
                      "sentence": "Large language models are increasingly deployed as components within larger systems rather than standalone tools.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 3.510206699371338,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.0012955378042533994,
                        "neutral": 0.9265615344047546,
                        "support": 0.07214298099279404
                      },
                      "stance_score": 0.07084744318854064,
                      "evidence_contribution": 0.2486891697137456,
                      "combined_rank_score": 4.404680788516998
                    }
                  ]
                }
              },
              {
                "subclaim": "without task-specific fine-tuning",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 1833,
                      "faiss_score": 0.8788925409317017,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 101,
                      "sentence": "This technique, called few-shot prompting, allows LLMs to be adapted to any task without requiring fine-tuning.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "rerank_score": 5.452361583709717,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.0010085511021316051,
                        "neutral": 0.02543622814118862,
                        "support": 0.9735552668571472
                      },
                      "stance_score": 0.9725467157550156,
                      "evidence_contribution": 5.302676351345701,
                      "combined_rank_score": 6.3312541246414185
                    },
                    {
                      "id": 6079,
                      "faiss_score": 0.8675508499145508,
                      "faiss_rank": 14,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "Large language models are often described as general-purpose systems because they can be adapted to many tasks with minimal fine-tuning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 0.734641432762146,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.0036333799362182617,
                        "neutral": 0.07261178642511368,
                        "support": 0.9237548112869263
                      },
                      "stance_score": 0.920121431350708,
                      "evidence_contribution": 0.6759593266426407,
                      "combined_rank_score": 1.6021922826766968
                    },
                    {
                      "id": 2566,
                      "faiss_score": 0.875229001045227,
                      "faiss_rank": 7,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 161,
                      "sentence": "Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "rerank_score": 0.4810207486152649,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0010565657867118716,
                        "neutral": 0.06393749266862869,
                        "support": 0.9350059628486633
                      },
                      "stance_score": 0.9339493970619515,
                      "evidence_contribution": 0.4492490381435152,
                      "combined_rank_score": 1.356249749660492
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6085,
                      "faiss_score": 0.8813949823379517,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 45,
                      "sentence": "Fine-tuning is commonly used to adapt large language models to specific domains or behaviors.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": -0.16154561936855316,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.9929386973381042,
                        "neutral": 0.005900803487747908,
                        "support": 0.001160479267127812
                      },
                      "stance_score": -0.9917782180709764,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.7198493629693985
                    },
                    {
                      "id": 1802,
                      "faiss_score": 0.8630768656730652,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 70,
                      "sentence": "Instruction fine-tuning is a form of supervised learning used to teach LLMs to follow user instructions.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "rerank_score": -0.5821276307106018,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.9954550266265869,
                        "neutral": 0.0036955545656383038,
                        "support": 0.0008494564681313932
                      },
                      "stance_score": -0.9946055701584555,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.2809492349624634
                    },
                    {
                      "id": 6335,
                      "faiss_score": 0.8739376664161682,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 74,
                      "sentence": "These pretrained models are then adapted to downstream tasks through fine-tuning or lightweight adaptation mechanisms.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": -0.7192176580429077,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.9972085356712341,
                        "neutral": 0.002253232290968299,
                        "support": 0.0005383074167184532
                      },
                      "stance_score": -0.9966702282545157,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.1547200083732605
                    }
                  ],
                  "neutral": []
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Distributed consensus protocols help systems remain consistent despite node failures.",
      "expected_verdict": "SUPPORT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Distributed consensus protocols help systems remain consistent",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 1.8874435073039542,
            "total": 1.8874435073039542
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 5618,
                "faiss_score": 0.9274933934211731,
                "faiss_rank": 1,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Consensus is a fundamental problem in distributed systems that captures the difficulty of agreement in the presence of failures.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": 2.1761515140533447,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.8703222274780273,
                  "neutral": 0.12668642401695251,
                  "support": 0.002991301706060767
                },
                "stance_score": -0.8673309257719666,
                "evidence_contribution": -1.8874435073039542,
                "combined_rank_score": 3.103644907474518
              },
              {
                "id": 3637,
                "faiss_score": 0.9029970765113831,
                "faiss_rank": 5,
                "doc_id": "wiki_Consensus_algorithm",
                "file_type": ".txt",
                "position": 46,
                "sentence": "The consensus problem may be considered in the case of asynchronous or synchronous systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                "primary_category": "articles with short description",
                "rerank_score": -1.7597379684448242,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.18643596768379211,
                  "neutral": 0.8109642267227173,
                  "support": 0.0025998535566031933
                },
                "stance_score": -0.18383611412718892,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.8567408919334412
              }
            ],
            "neutral": [
              {
                "id": 5612,
                "faiss_score": 0.888638973236084,
                "faiss_rank": 18,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 15,
                "sentence": "Strong consistency models aim to make distributed systems behave as if there were a single shared state, but enforcing such behavior requires coordination and synchronization, which can be expensive or impossible under certain failure conditions.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": 3.147623062133789,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.018985481932759285,
                  "neutral": 0.9624131917953491,
                  "support": 0.01860135607421398
                },
                "stance_score": -0.00038412585854530334,
                "evidence_contribution": -0.0012090834111191384,
                "combined_rank_score": 4.036262035369873
              },
              {
                "id": 5610,
                "faiss_score": 0.9084477424621582,
                "faiss_rank": 3,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Consistency is a central concept in distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": 1.8636924028396606,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.000766043784096837,
                  "neutral": 0.9977141618728638,
                  "support": 0.0015198341570794582
                },
                "stance_score": 0.0007537903729826212,
                "evidence_contribution": 0.0014048333914613853,
                "combined_rank_score": 2.772140145301819
              },
              {
                "id": 3592,
                "faiss_score": 0.9013365507125854,
                "faiss_rank": 6,
                "doc_id": "wiki_Consensus_algorithm",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Some of the processes (agents) may fail or be unreliable in other ways, so consensus protocols must be fault-tolerant or resilient.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                "primary_category": "articles with short description",
                "rerank_score": 0.459737092256546,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.0038521725218743086,
                  "neutral": 0.950269341468811,
                  "support": 0.045878443866968155
                },
                "stance_score": 0.042026271345093846,
                "evidence_contribution": 0.019321035786578046,
                "combined_rank_score": 1.3610736429691315
              }
            ]
          }
        },
        {
          "subclaim": "Systems remain consistent despite node failures",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 5.206657191986313,
            "contradict": 0.0,
            "total": 5.206657191986313
          },
          "evidence": {
            "supporting": [
              {
                "id": 3474,
                "faiss_score": 0.9279701709747314,
                "faiss_rank": 1,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 45,
                "sentence": "Resilient networks continue to transmit data despite the failure of some links or nodes.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 2.9349451065063477,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.001138089457526803,
                  "neutral": 0.016104355454444885,
                  "support": 0.9827576279640198
                },
                "stance_score": 0.981619538506493,
                "evidence_contribution": 2.880999460990651,
                "combined_rank_score": 3.862915277481079
              },
              {
                "id": 5615,
                "faiss_score": 0.9032431840896606,
                "faiss_rank": 3,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "By maintaining multiple copies of data across different nodes, a system can continue to operate even if some replicas fail.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": 2.553046703338623,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.0009699473739601672,
                  "neutral": 0.08712581545114517,
                  "support": 0.9119042158126831
                },
                "stance_score": 0.9109342684387229,
                "evidence_contribution": 2.325657730995662,
                "combined_rank_score": 3.4562898874282837
              },
              {
                "id": 3463,
                "faiss_score": 0.9054452180862427,
                "faiss_rank": 2,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 34,
                "sentence": "A highly fault-tolerant system might continue at the same level of performance even though one or more components have failed.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": -2.004009246826172,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.00400190707296133,
                  "neutral": 0.46762439608573914,
                  "support": 0.5283737182617188
                },
                "stance_score": 0.5243718111887574,
                "evidence_contribution": 0.0,
                "combined_rank_score": -1.0985640287399292
              },
              {
                "id": 430,
                "faiss_score": 0.8767738342285156,
                "faiss_rank": 17,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 6,
                "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "rerank_score": -4.0686445236206055,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.034422557801008224,
                  "neutral": 0.791019082069397,
                  "support": 0.17455832660198212
                },
                "stance_score": 0.1401357688009739,
                "evidence_contribution": 0.0,
                "combined_rank_score": -3.19187068939209
              }
            ],
            "contradicting": [
              {
                "id": 6603,
                "faiss_score": 0.8794848322868347,
                "faiss_rank": 11,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 6,
                "sentence": "A system may tolerate certain failures gracefully yet still exhibit low overall reliability if failures occur frequently.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "rerank_score": -0.1449195146560669,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.7329874634742737,
                  "neutral": 0.24647438526153564,
                  "support": 0.020538147538900375
                },
                "stance_score": -0.7124493159353733,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.7345653176307678
              },
              {
                "id": 6605,
                "faiss_score": 0.8778896331787109,
                "faiss_rank": 15,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Failures in computing systems take many forms.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "rerank_score": -2.2687134742736816,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.8227906823158264,
                  "neutral": 0.1751573234796524,
                  "support": 0.0020519725512713194
                },
                "stance_score": -0.8207387097645551,
                "evidence_contribution": -0.0,
                "combined_rank_score": -1.3908238410949707
              },
              {
                "id": 6659,
                "faiss_score": 0.878364622592926,
                "faiss_rank": 14,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 62,
                "sentence": "In large-scale systems, failures are often correlated rather than independent.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "rerank_score": -3.2208199501037598,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.4171348512172699,
                  "neutral": 0.5790106058120728,
                  "support": 0.0038546037394553423
                },
                "stance_score": -0.41328024747781456,
                "evidence_contribution": -0.0,
                "combined_rank_score": -2.3424553275108337
              },
              {
                "id": 5605,
                "faiss_score": 0.8787782192230225,
                "faiss_rank": 13,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Failures are another fundamental aspect of distributed systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": -3.792255401611328,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.11729293316602707,
                  "neutral": 0.876907467842102,
                  "support": 0.005799655802547932
                },
                "stance_score": -0.11149327736347914,
                "evidence_contribution": -0.0,
                "combined_rank_score": -2.9134771823883057
              }
            ],
            "neutral": []
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Systems remain consistent despite node failures",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 3474,
                      "faiss_score": 0.9279701709747314,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 45,
                      "sentence": "Resilient networks continue to transmit data despite the failure of some links or nodes.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 2.9349451065063477,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.001138089457526803,
                        "neutral": 0.016104355454444885,
                        "support": 0.9827576279640198
                      },
                      "stance_score": 0.981619538506493,
                      "evidence_contribution": 2.880999460990651,
                      "combined_rank_score": 3.862915277481079
                    },
                    {
                      "id": 5615,
                      "faiss_score": 0.9032431840896606,
                      "faiss_rank": 3,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "By maintaining multiple copies of data across different nodes, a system can continue to operate even if some replicas fail.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "rerank_score": 2.553046703338623,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.0009699473739601672,
                        "neutral": 0.08712581545114517,
                        "support": 0.9119042158126831
                      },
                      "stance_score": 0.9109342684387229,
                      "evidence_contribution": 2.325657730995662,
                      "combined_rank_score": 3.4562898874282837
                    },
                    {
                      "id": 3463,
                      "faiss_score": 0.9054452180862427,
                      "faiss_rank": 2,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 34,
                      "sentence": "A highly fault-tolerant system might continue at the same level of performance even though one or more components have failed.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": -2.004009246826172,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.00400190707296133,
                        "neutral": 0.46762439608573914,
                        "support": 0.5283737182617188
                      },
                      "stance_score": 0.5243718111887574,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -1.0985640287399292
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6603,
                      "faiss_score": 0.8794848322868347,
                      "faiss_rank": 11,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 6,
                      "sentence": "A system may tolerate certain failures gracefully yet still exhibit low overall reliability if failures occur frequently.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "rerank_score": -0.1449195146560669,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.7329874634742737,
                        "neutral": 0.24647438526153564,
                        "support": 0.020538147538900375
                      },
                      "stance_score": -0.7124493159353733,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.7345653176307678
                    },
                    {
                      "id": 6605,
                      "faiss_score": 0.8778896331787109,
                      "faiss_rank": 15,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Failures in computing systems take many forms.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "rerank_score": -2.2687134742736816,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.8227906823158264,
                        "neutral": 0.1751573234796524,
                        "support": 0.0020519725512713194
                      },
                      "stance_score": -0.8207387097645551,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -1.3908238410949707
                    },
                    {
                      "id": 6659,
                      "faiss_score": 0.878364622592926,
                      "faiss_rank": 14,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 62,
                      "sentence": "In large-scale systems, failures are often correlated rather than independent.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "rerank_score": -3.2208199501037598,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.4171348512172699,
                        "neutral": 0.5790106058120728,
                        "support": 0.0038546037394553423
                      },
                      "stance_score": -0.41328024747781456,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -2.3424553275108337
                    }
                  ],
                  "neutral": []
                }
              }
            ]
          },
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Distributed consensus protocols help systems remain consistent",
                "verdict": "CONTRADICT",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 5618,
                      "faiss_score": 0.9274933934211731,
                      "faiss_rank": 1,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "Consensus is a fundamental problem in distributed systems that captures the difficulty of agreement in the presence of failures.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "rerank_score": 2.1761515140533447,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.8703222274780273,
                        "neutral": 0.12668642401695251,
                        "support": 0.002991301706060767
                      },
                      "stance_score": -0.8673309257719666,
                      "evidence_contribution": -1.8874435073039542,
                      "combined_rank_score": 3.103644907474518
                    },
                    {
                      "id": 3637,
                      "faiss_score": 0.9029970765113831,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Consensus_algorithm",
                      "file_type": ".txt",
                      "position": 46,
                      "sentence": "The consensus problem may be considered in the case of asynchronous or synchronous systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                      "primary_category": "articles with short description",
                      "rerank_score": -1.7597379684448242,
                      "rerank_rank": 10,
                      "probs": {
                        "contradict": 0.18643596768379211,
                        "neutral": 0.8109642267227173,
                        "support": 0.0025998535566031933
                      },
                      "stance_score": -0.18383611412718892,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -0.8567408919334412
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5612,
                      "faiss_score": 0.888638973236084,
                      "faiss_rank": 18,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 15,
                      "sentence": "Strong consistency models aim to make distributed systems behave as if there were a single shared state, but enforcing such behavior requires coordination and synchronization, which can be expensive or impossible under certain failure conditions.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "rerank_score": 3.147623062133789,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.018985481932759285,
                        "neutral": 0.9624131917953491,
                        "support": 0.01860135607421398
                      },
                      "stance_score": -0.00038412585854530334,
                      "evidence_contribution": -0.0012090834111191384,
                      "combined_rank_score": 4.036262035369873
                    },
                    {
                      "id": 5610,
                      "faiss_score": 0.9084477424621582,
                      "faiss_rank": 3,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Consistency is a central concept in distributed systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "rerank_score": 1.8636924028396606,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.000766043784096837,
                        "neutral": 0.9977141618728638,
                        "support": 0.0015198341570794582
                      },
                      "stance_score": 0.0007537903729826212,
                      "evidence_contribution": 0.0014048333914613853,
                      "combined_rank_score": 2.772140145301819
                    },
                    {
                      "id": 3592,
                      "faiss_score": 0.9013365507125854,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Consensus_algorithm",
                      "file_type": ".txt",
                      "position": 1,
                      "sentence": "Some of the processes (agents) may fail or be unreliable in other ways, so consensus protocols must be fault-tolerant or resilient.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Consensus_(computer_science)",
                      "primary_category": "articles with short description",
                      "rerank_score": 0.459737092256546,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.0038521725218743086,
                        "neutral": 0.950269341468811,
                        "support": 0.045878443866968155
                      },
                      "stance_score": 0.042026271345093846,
                      "evidence_contribution": 0.019321035786578046,
                      "combined_rank_score": 1.3610736429691315
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Increasing model size always guarantees better generalization performance.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Increasing model size always guarantees better generalization performance.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 9.356575939596496,
            "total": 9.356575939596496
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6133,
                "faiss_score": 0.8974666595458984,
                "faiss_rank": 15,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 5.871306896209717,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.904425859451294,
                  "neutral": 0.09184230118989944,
                  "support": 0.003731856355443597
                },
                "stance_score": -0.9006940030958503,
                "evidence_contribution": -5.288250911751402,
                "combined_rank_score": 6.768773555755615
              },
              {
                "id": 5941,
                "faiss_score": 0.901360034942627,
                "faiss_rank": 9,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 36,
                "sentence": "Smaller or compressed models may generalize better due to implicit regularization, but excessive compression can harm performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": 2.947385549545288,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.9887085556983948,
                  "neutral": 0.010507587343454361,
                  "support": 0.0007837332668714225
                },
                "stance_score": -0.9879248224315234,
                "evidence_contribution": -2.9117953456717665,
                "combined_rank_score": 3.848745584487915
              },
              {
                "id": 1453,
                "faiss_score": 0.9143708348274231,
                "faiss_rank": 4,
                "doc_id": "wiki_Regularization_(mathematics)",
                "file_type": ".txt",
                "position": 25,
                "sentence": "By regularizing for time, model complexity can be controlled, improving generalization.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Regularization_(mathematics)",
                "primary_category": "articles with short description",
                "rerank_score": 1.1829490661621094,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.9792255163192749,
                  "neutral": 0.019215479493141174,
                  "support": 0.0015590087277814746
                },
                "stance_score": -0.9776665075914934,
                "evidence_contribution": -1.156529682173328,
                "combined_rank_score": 2.0973199009895325
              },
              {
                "id": 5922,
                "faiss_score": 0.8979805111885071,
                "faiss_rank": 14,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 17,
                "sentence": "Distilled models often achieve better performance than models trained directly on the same data, given similar size constraints.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": -1.044982671737671,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.7945719957351685,
                  "neutral": 0.20232698321342468,
                  "support": 0.0031010955572128296
                },
                "stance_score": -0.7914709001779556,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.14700216054916382
              },
              {
                "id": 5906,
                "faiss_score": 0.895328938961029,
                "faiss_rank": 18,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Early successes in deep learning were often achieved by increasing model size and training data, but this approach quickly encounters practical limits.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": -1.0923975706100464,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.8033847808837891,
                  "neutral": 0.19272951781749725,
                  "support": 0.0038856947794556618
                },
                "stance_score": -0.7994990861043334,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.19706863164901733
              },
              {
                "id": 6221,
                "faiss_score": 0.900503396987915,
                "faiss_rank": 10,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 29,
                "sentence": "Surprisingly, such models can still generalize well.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "rerank_score": -1.5820221900939941,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.26446568965911865,
                  "neutral": 0.7334563732147217,
                  "support": 0.002077879384160042
                },
                "stance_score": -0.2623878102749586,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.6815187931060791
              },
              {
                "id": 6211,
                "faiss_score": 0.9146316051483154,
                "faiss_rank": 3,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 19,
                "sentence": "Batch size influences both optimization efficiency and generalization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "rerank_score": -3.0013480186462402,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.12615004181861877,
                  "neutral": 0.8723376989364624,
                  "support": 0.0015121976612135768
                },
                "stance_score": -0.1246378441574052,
                "evidence_contribution": -0.0,
                "combined_rank_score": -2.086716413497925
              },
              {
                "id": 1443,
                "faiss_score": 0.8999907970428467,
                "faiss_rank": 11,
                "doc_id": "wiki_Regularization_(mathematics)",
                "file_type": ".txt",
                "position": 15,
                "sentence": "Regularization can be motivated as a technique to improve the generalizability of a learned model.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Regularization_(mathematics)",
                "primary_category": "articles with short description",
                "rerank_score": -3.3324716091156006,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.5267986059188843,
                  "neutral": 0.4700230360031128,
                  "support": 0.0031784214079380035
                },
                "stance_score": -0.5236201845109463,
                "evidence_contribution": -0.0,
                "combined_rank_score": -2.432480812072754
              }
            ],
            "neutral": [
              {
                "id": 6137,
                "faiss_score": 0.9333542585372925,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 3.651726245880127,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.08033034205436707,
                  "neutral": 0.8913941979408264,
                  "support": 0.028275374323129654
                },
                "stance_score": -0.05205496773123741,
                "evidence_contribution": -0.19009049189260274,
                "combined_rank_score": 4.585080504417419
              },
              {
                "id": 6127,
                "faiss_score": 0.9018120765686035,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 2.1988959312438965,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.02673305943608284,
                  "neutral": 0.8649839162826538,
                  "support": 0.10828303545713425
                },
                "stance_score": 0.0815499760210514,
                "evidence_contribution": 0.17931991046572726,
                "combined_rank_score": 3.1007080078125
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Increasing model size always guarantees better generalization performance.",
                "verdict": "CONTRADICT",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6133,
                      "faiss_score": 0.8974666595458984,
                      "faiss_rank": 15,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 5.871306896209717,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.904425859451294,
                        "neutral": 0.09184230118989944,
                        "support": 0.003731856355443597
                      },
                      "stance_score": -0.9006940030958503,
                      "evidence_contribution": -5.288250911751402,
                      "combined_rank_score": 6.768773555755615
                    },
                    {
                      "id": 5941,
                      "faiss_score": 0.901360034942627,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 36,
                      "sentence": "Smaller or compressed models may generalize better due to implicit regularization, but excessive compression can harm performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "rerank_score": 2.947385549545288,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.9887085556983948,
                        "neutral": 0.010507587343454361,
                        "support": 0.0007837332668714225
                      },
                      "stance_score": -0.9879248224315234,
                      "evidence_contribution": -2.9117953456717665,
                      "combined_rank_score": 3.848745584487915
                    },
                    {
                      "id": 1453,
                      "faiss_score": 0.9143708348274231,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Regularization_(mathematics)",
                      "file_type": ".txt",
                      "position": 25,
                      "sentence": "By regularizing for time, model complexity can be controlled, improving generalization.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Regularization_(mathematics)",
                      "primary_category": "articles with short description",
                      "rerank_score": 1.1829490661621094,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.9792255163192749,
                        "neutral": 0.019215479493141174,
                        "support": 0.0015590087277814746
                      },
                      "stance_score": -0.9776665075914934,
                      "evidence_contribution": -1.156529682173328,
                      "combined_rank_score": 2.0973199009895325
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6137,
                      "faiss_score": 0.9333542585372925,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 3.651726245880127,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.08033034205436707,
                        "neutral": 0.8913941979408264,
                        "support": 0.028275374323129654
                      },
                      "stance_score": -0.05205496773123741,
                      "evidence_contribution": -0.19009049189260274,
                      "combined_rank_score": 4.585080504417419
                    },
                    {
                      "id": 6127,
                      "faiss_score": 0.9018120765686035,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 2.1988959312438965,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.02673305943608284,
                        "neutral": 0.8649839162826538,
                        "support": 0.10828303545713425
                      },
                      "stance_score": 0.0815499760210514,
                      "evidence_contribution": 0.17931991046572726,
                      "combined_rank_score": 3.1007080078125
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Distributed systems do not need fault tolerance mechanisms.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Distributed systems do not need fault tolerance mechanisms.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.29039730421702314,
            "contradict": 2.4744526756058063,
            "total": 2.7648499798228294
          },
          "evidence": {
            "supporting": [
              {
                "id": 3487,
                "faiss_score": 0.8769917488098145,
                "faiss_rank": 17,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 58,
                "sentence": "Some components, like the drive shaft in a car, are not likely to fail, so no fault tolerance is needed.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 0.529964804649353,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.023633461445569992,
                  "neutral": 0.4047772288322449,
                  "support": 0.5715892910957336
                },
                "stance_score": 0.5479558296501637,
                "evidence_contribution": 0.29039730421702314,
                "combined_rank_score": 1.4069565534591675
              }
            ],
            "contradicting": [
              {
                "id": 430,
                "faiss_score": 0.8796877861022949,
                "faiss_rank": 13,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 6,
                "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "rerank_score": 1.483339786529541,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.9988288283348083,
                  "neutral": 0.0008527741301804781,
                  "support": 0.0003183769586030394
                },
                "stance_score": -0.9985104513762053,
                "evidence_contribution": -1.481130279791896,
                "combined_rank_score": 2.363027572631836
              },
              {
                "id": 3809,
                "faiss_score": 0.9038978815078735,
                "faiss_rank": 4,
                "doc_id": "wiki_CAP_theorem",
                "file_type": ".txt",
                "position": 0,
                "sentence": "No distributed system is safe from network failures, thus network partitioning generally has to be tolerated.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/CAP_theorem",
                "primary_category": "all articles with unsourced statements",
                "rerank_score": 0.8771834373474121,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.9990100860595703,
                  "neutral": 0.0007420883048325777,
                  "support": 0.0002478054666426033
                },
                "stance_score": -0.9987622805929277,
                "evidence_contribution": -0.8760977303834449,
                "combined_rank_score": 1.7810813188552856
              },
              {
                "id": 3482,
                "faiss_score": 0.9055246114730835,
                "faiss_rank": 3,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Providing fault-tolerant design for every component is normally not an option.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 0.31907758116722107,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.4294501543045044,
                  "neutral": 0.508485734462738,
                  "support": 0.06206406280398369
                },
                "stance_score": -0.3673860915005207,
                "evidence_contribution": -0.1172246654304655,
                "combined_rank_score": 1.2246021926403046
              },
              {
                "id": 3508,
                "faiss_score": 0.8738317489624023,
                "faiss_rank": 20,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 79,
                "sentence": "The basic characteristics of fault tolerance require: No single point of failure \u2013 If a system experiences a failure, it must continue to operate without interruption during the repair process.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": -0.11146597564220428,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.8368813395500183,
                  "neutral": 0.15880845487117767,
                  "support": 0.004310184624046087
                },
                "stance_score": -0.8325711549259722,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.7623657733201981
              },
              {
                "id": 3588,
                "faiss_score": 0.9097967147827148,
                "faiss_rank": 2,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 159,
                "sentence": "There is a difference between fault tolerance and systems that rarely have problems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": -0.7256827354431152,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.19584187865257263,
                  "neutral": 0.7686963081359863,
                  "support": 0.03546185418963432
                },
                "stance_score": -0.1603800244629383,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.1841139793395996
              },
              {
                "id": 6665,
                "faiss_score": 0.9101653099060059,
                "faiss_rank": 1,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 68,
                "sentence": "Ultimately, fault tolerance and reliability are not properties that can be added as afterthoughts.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "rerank_score": -1.6267772912979126,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.5150806307792664,
                  "neutral": 0.46868276596069336,
                  "support": 0.01623660698533058
                },
                "stance_score": -0.4988440237939358,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.7166119813919067
              }
            ],
            "neutral": [
              {
                "id": 3456,
                "faiss_score": 0.893700361251831,
                "faiss_rank": 9,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 27,
                "sentence": "It is helpful if the time between failures is as long as possible, but this is not specifically required in a fault-tolerant system.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 0.8421114683151245,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.051901448518037796,
                  "neutral": 0.8763694167137146,
                  "support": 0.07172917574644089
                },
                "stance_score": 0.01982772722840309,
                "evidence_contribution": 0.0166971564896623,
                "combined_rank_score": 1.7358118295669556
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Distributed systems do not need fault tolerance mechanisms.",
                "verdict": "CONTRADICT",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 3487,
                      "faiss_score": 0.8769917488098145,
                      "faiss_rank": 17,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 58,
                      "sentence": "Some components, like the drive shaft in a car, are not likely to fail, so no fault tolerance is needed.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 0.529964804649353,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.023633461445569992,
                        "neutral": 0.4047772288322449,
                        "support": 0.5715892910957336
                      },
                      "stance_score": 0.5479558296501637,
                      "evidence_contribution": 0.29039730421702314,
                      "combined_rank_score": 1.4069565534591675
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 430,
                      "faiss_score": 0.8796877861022949,
                      "faiss_rank": 13,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 6,
                      "sentence": "Other typical properties of distributed systems are: The system must tolerate failures in individual computers.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "rerank_score": 1.483339786529541,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.9988288283348083,
                        "neutral": 0.0008527741301804781,
                        "support": 0.0003183769586030394
                      },
                      "stance_score": -0.9985104513762053,
                      "evidence_contribution": -1.481130279791896,
                      "combined_rank_score": 2.363027572631836
                    },
                    {
                      "id": 3809,
                      "faiss_score": 0.9038978815078735,
                      "faiss_rank": 4,
                      "doc_id": "wiki_CAP_theorem",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "No distributed system is safe from network failures, thus network partitioning generally has to be tolerated.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/CAP_theorem",
                      "primary_category": "all articles with unsourced statements",
                      "rerank_score": 0.8771834373474121,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.9990100860595703,
                        "neutral": 0.0007420883048325777,
                        "support": 0.0002478054666426033
                      },
                      "stance_score": -0.9987622805929277,
                      "evidence_contribution": -0.8760977303834449,
                      "combined_rank_score": 1.7810813188552856
                    },
                    {
                      "id": 3482,
                      "faiss_score": 0.9055246114730835,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "Providing fault-tolerant design for every component is normally not an option.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 0.31907758116722107,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.4294501543045044,
                        "neutral": 0.508485734462738,
                        "support": 0.06206406280398369
                      },
                      "stance_score": -0.3673860915005207,
                      "evidence_contribution": -0.1172246654304655,
                      "combined_rank_score": 1.2246021926403046
                    }
                  ],
                  "neutral": [
                    {
                      "id": 3456,
                      "faiss_score": 0.893700361251831,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "It is helpful if the time between failures is as long as possible, but this is not specifically required in a fault-tolerant system.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 0.8421114683151245,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.051901448518037796,
                        "neutral": 0.8763694167137146,
                        "support": 0.07172917574644089
                      },
                      "stance_score": 0.01982772722840309,
                      "evidence_contribution": 0.0166971564896623,
                      "combined_rank_score": 1.7358118295669556
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Quantum computers can function reliably without error correction.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Quantum computers can function reliably without error correction.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 21.481415764491658,
            "total": 21.481415764491658
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6553,
                "faiss_score": 0.9091418981552124,
                "faiss_rank": 1,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "rerank_score": 4.795175075531006,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.9906208515167236,
                  "neutral": 0.008175135590136051,
                  "support": 0.001204083557240665
                },
                "stance_score": -0.989416767959483,
                "evidence_contribution": -4.744426625031758,
                "combined_rank_score": 5.704316973686218
              },
              {
                "id": 6561,
                "faiss_score": 0.8931423425674438,
                "faiss_rank": 16,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Small errors accumulate quickly in quantum circuits, limiting the depth of computations that can be performed reliably.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "rerank_score": 4.629236221313477,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.9992790818214417,
                  "neutral": 0.000551443372387439,
                  "support": 0.00016951408179011196
                },
                "stance_score": -0.9991095677396515,
                "evidence_contribution": -4.625114200041246,
                "combined_rank_score": 5.52237856388092
              },
              {
                "id": 671,
                "faiss_score": 0.9006523489952087,
                "faiss_rank": 2,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Scientists at Harvard University successfully created \"quantum circuits\" that correct errors more efficiently than alternative methods, which may potentially remove a major obstacle to practical quantum computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 3.718876361846924,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.998163640499115,
                  "neutral": 0.0014617514098063111,
                  "support": 0.00037455931305885315
                },
                "stance_score": -0.9977890811860561,
                "evidence_contribution": -3.7106542281317854,
                "combined_rank_score": 4.619528710842133
              },
              {
                "id": 793,
                "faiss_score": 0.8939269781112671,
                "faiss_rank": 13,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 4.389732837677002,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.7898147106170654,
                  "neutral": 0.20260053873062134,
                  "support": 0.007584744598716497
                },
                "stance_score": -0.7822299660183489,
                "evidence_contribution": -3.4337805684457114,
                "combined_rank_score": 5.283659815788269
              },
              {
                "id": 4824,
                "faiss_score": 0.8938266038894653,
                "faiss_rank": 15,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 71,
                "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "rerank_score": 2.4530763626098633,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.976203203201294,
                  "neutral": 0.022158455103635788,
                  "support": 0.0016382795292884111
                },
                "stance_score": -0.9745649236720055,
                "evidence_contribution": -2.3906821780884826,
                "combined_rank_score": 3.3469029664993286
              },
              {
                "id": 4862,
                "faiss_score": 0.9004368782043457,
                "faiss_rank": 4,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 109,
                "sentence": "Quantum error correction can be applied to quantum metrology.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "rerank_score": 1.515055537223816,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.9318203926086426,
                  "neutral": 0.066192626953125,
                  "support": 0.0019869431853294373
                },
                "stance_score": -0.9298334494233131,
                "evidence_contribution": -1.4087493162447116,
                "combined_rank_score": 2.4154924154281616
              },
              {
                "id": 6554,
                "faiss_score": 0.8949320316314697,
                "faiss_rank": 10,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "rerank_score": 1.2565362453460693,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.9315681457519531,
                  "neutral": 0.06641007959842682,
                  "support": 0.002021821215748787
                },
                "stance_score": -0.9295463245362043,
                "evidence_contribution": -1.168008648507961,
                "combined_rank_score": 2.151468276977539
              }
            ],
            "neutral": [
              {
                "id": 4930,
                "faiss_score": 0.8965480923652649,
                "faiss_rank": 6,
                "doc_id": "wiki_Computational_complexity",
                "file_type": ".txt",
                "position": 60,
                "sentence": "A quantum computer is a computer whose model of computation is based on quantum mechanics.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Computational_complexity",
                "primary_category": "all articles containing potentially dated statements",
                "rerank_score": -1.024182677268982,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.010156561620533466,
                  "neutral": 0.9860877394676208,
                  "support": 0.0037557336036115885
                },
                "stance_score": -0.006400828016921878,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.12763458490371704
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Quantum computers can function reliably without error correction.",
                "verdict": "CONTRADICT",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6553,
                      "faiss_score": 0.9091418981552124,
                      "faiss_rank": 1,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "rerank_score": 4.795175075531006,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.9906208515167236,
                        "neutral": 0.008175135590136051,
                        "support": 0.001204083557240665
                      },
                      "stance_score": -0.989416767959483,
                      "evidence_contribution": -4.744426625031758,
                      "combined_rank_score": 5.704316973686218
                    },
                    {
                      "id": 6561,
                      "faiss_score": 0.8931423425674438,
                      "faiss_rank": 16,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "Small errors accumulate quickly in quantum circuits, limiting the depth of computations that can be performed reliably.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "rerank_score": 4.629236221313477,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.9992790818214417,
                        "neutral": 0.000551443372387439,
                        "support": 0.00016951408179011196
                      },
                      "stance_score": -0.9991095677396515,
                      "evidence_contribution": -4.625114200041246,
                      "combined_rank_score": 5.52237856388092
                    },
                    {
                      "id": 793,
                      "faiss_score": 0.8939269781112671,
                      "faiss_rank": 13,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 4.389732837677002,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.7898147106170654,
                        "neutral": 0.20260053873062134,
                        "support": 0.007584744598716497
                      },
                      "stance_score": -0.7822299660183489,
                      "evidence_contribution": -3.4337805684457114,
                      "combined_rank_score": 5.283659815788269
                    }
                  ],
                  "neutral": [
                    {
                      "id": 4930,
                      "faiss_score": 0.8965480923652649,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Computational_complexity",
                      "file_type": ".txt",
                      "position": 60,
                      "sentence": "A quantum computer is a computer whose model of computation is based on quantum mechanics.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Computational_complexity",
                      "primary_category": "all articles containing potentially dated statements",
                      "rerank_score": -1.024182677268982,
                      "rerank_rank": 10,
                      "probs": {
                        "contradict": 0.010156561620533466,
                        "neutral": 0.9860877394676208,
                        "support": 0.0037557336036115885
                      },
                      "stance_score": -0.006400828016921878,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -0.12763458490371704
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Scaling neural networks has no impact on performance improvements.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Scaling neural networks has no impact on performance improvements.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 0.7321178700026582,
            "total": 0.7321178700026582
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6131,
                "faiss_score": 0.8818397521972656,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 0.9271154403686523,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.7417044043540955,
                  "neutral": 0.25547850131988525,
                  "support": 0.002817087108269334
                },
                "stance_score": -0.7388873172458261,
                "evidence_contribution": -0.6850338405111762,
                "combined_rank_score": 1.808955192565918
              },
              {
                "id": 6124,
                "faiss_score": 0.8662250638008118,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 0.04794492572546005,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.9827069044113159,
                  "neutral": 0.016630327329039574,
                  "support": 0.0006628449191339314
                },
                "stance_score": -0.982044059492182,
                "evidence_contribution": -0.04708402949148194,
                "combined_rank_score": 0.9141699895262718
              },
              {
                "id": 6125,
                "faiss_score": 0.8836263418197632,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Over the past decade, scaling has emerged as one of the most reliable drivers of progress in machine learning systems, particularly in deep learning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -1.5403499603271484,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.9991558790206909,
                  "neutral": 0.0007174470811150968,
                  "support": 0.0001267673069378361
                },
                "stance_score": -0.9990291117137531,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.6567236185073853
              },
              {
                "id": 6161,
                "faiss_score": 0.8589440584182739,
                "faiss_rank": 15,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "Scaling affects robustness and generalization in nontrivial ways.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -2.0357778072357178,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.8270083069801331,
                  "neutral": 0.17144151031970978,
                  "support": 0.001550139975734055
                },
                "stance_score": -0.825458167004399,
                "evidence_contribution": -0.0,
                "combined_rank_score": -1.1768337488174438
              },
              {
                "id": 2393,
                "faiss_score": 0.8614013195037842,
                "faiss_rank": 13,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 324,
                "sentence": "Large and effective neural networks require considerable computing resources.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "rerank_score": -4.691199779510498,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.9643079042434692,
                  "neutral": 0.03442241623997688,
                  "support": 0.0012696814956143498
                },
                "stance_score": -0.9630382227478549,
                "evidence_contribution": -0.0,
                "combined_rank_score": -3.829798460006714
              },
              {
                "id": 6142,
                "faiss_score": 0.8561908602714539,
                "faiss_rank": 20,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -4.71311092376709,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.8800991773605347,
                  "neutral": 0.11783106625080109,
                  "support": 0.0020697445143014193
                },
                "stance_score": -0.8780294328462332,
                "evidence_contribution": -0.0,
                "combined_rank_score": -3.856920063495636
              },
              {
                "id": 6128,
                "faiss_score": 0.8699010610580444,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 4,
                "sentence": "These trends have been observed across different domains and architectures, suggesting that scaling captures general properties of learning systems rather than task-specific quirks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -4.945844650268555,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.7391960620880127,
                  "neutral": 0.25634506344795227,
                  "support": 0.004458927549421787
                },
                "stance_score": -0.7347371345385909,
                "evidence_contribution": -0.0,
                "combined_rank_score": -4.07594358921051
              },
              {
                "id": 6137,
                "faiss_score": 0.8579269051551819,
                "faiss_rank": 17,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -5.073082447052002,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.8592372536659241,
                  "neutral": 0.1386318802833557,
                  "support": 0.0021308623254299164
                },
                "stance_score": -0.8571063913404942,
                "evidence_contribution": -0.0,
                "combined_rank_score": -4.21515554189682
              },
              {
                "id": 6135,
                "faiss_score": 0.867847204208374,
                "faiss_rank": 6,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 11,
                "sentence": "Data scaling plays an equally important role.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -5.08654260635376,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.9858559370040894,
                  "neutral": 0.013569191098213196,
                  "support": 0.0005748308030888438
                },
                "stance_score": -0.9852811062010005,
                "evidence_contribution": -0.0,
                "combined_rank_score": -4.218695402145386
              },
              {
                "id": 2985,
                "faiss_score": 0.8640903234481812,
                "faiss_rank": 11,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 40,
                "sentence": "Its parallelizability was an important factor to its widespread use in large neural networks.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "rerank_score": -5.778621673583984,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.9947782754898071,
                  "neutral": 0.0048780133947730064,
                  "support": 0.0003436481347307563
                },
                "stance_score": -0.9944346273550764,
                "evidence_contribution": -0.0,
                "combined_rank_score": -4.914531350135803
              }
            ],
            "neutral": []
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Scaling neural networks has no impact on performance improvements.",
                "verdict": "CONTRADICT",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6131,
                      "faiss_score": 0.8818397521972656,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 0.9271154403686523,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.7417044043540955,
                        "neutral": 0.25547850131988525,
                        "support": 0.002817087108269334
                      },
                      "stance_score": -0.7388873172458261,
                      "evidence_contribution": -0.6850338405111762,
                      "combined_rank_score": 1.808955192565918
                    },
                    {
                      "id": 6124,
                      "faiss_score": 0.8662250638008118,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 0.04794492572546005,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.9827069044113159,
                        "neutral": 0.016630327329039574,
                        "support": 0.0006628449191339314
                      },
                      "stance_score": -0.982044059492182,
                      "evidence_contribution": -0.04708402949148194,
                      "combined_rank_score": 0.9141699895262718
                    },
                    {
                      "id": 6125,
                      "faiss_score": 0.8836263418197632,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 1,
                      "sentence": "Over the past decade, scaling has emerged as one of the most reliable drivers of progress in machine learning systems, particularly in deep learning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -1.5403499603271484,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.9991558790206909,
                        "neutral": 0.0007174470811150968,
                        "support": 0.0001267673069378361
                      },
                      "stance_score": -0.9990291117137531,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -0.6567236185073853
                    }
                  ],
                  "neutral": []
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Larger datasets always reduce overfitting in machine learning models.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Larger datasets reduce overfitting in machine learning models.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 3.4076481726903425,
            "total": 3.4076481726903425
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6136,
                "faiss_score": 0.912011444568634,
                "faiss_rank": 5,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 3.8103489875793457,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.8988689184188843,
                  "neutral": 0.0965760350227356,
                  "support": 0.004554989747703075
                },
                "stance_score": -0.8943139286711812,
                "evidence_contribution": -3.4076481726903425,
                "combined_rank_score": 4.72236043214798
              }
            ],
            "neutral": [
              {
                "id": 2613,
                "faiss_score": 0.8993738889694214,
                "faiss_rank": 10,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 208,
                "sentence": "Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "rerank_score": 4.625890731811523,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.008702030405402184,
                  "neutral": 0.91930091381073,
                  "support": 0.0719970092177391
                },
                "stance_score": 0.06329497881233692,
                "evidence_contribution": 0.2927956558581961,
                "combined_rank_score": 5.525264620780945
              },
              {
                "id": 6309,
                "faiss_score": 0.901115894317627,
                "faiss_rank": 8,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "High-capacity models are prone to overfitting when data is scarce, and strong generalization typically requires pretraining on massive corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 1.2675398588180542,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0038825219962745905,
                  "neutral": 0.929321825504303,
                  "support": 0.06679567694664001
                },
                "stance_score": 0.06291315495036542,
                "evidence_contribution": 0.07974493154358456,
                "combined_rank_score": 2.168655753135681
              },
              {
                "id": 1341,
                "faiss_score": 0.8920928239822388,
                "faiss_rank": 18,
                "doc_id": "wiki_Bias\u2013variance_tradeoff",
                "file_type": ".txt",
                "position": 18,
                "sentence": "The limiting case where only a finite number of data points are selected over a broad sample space may result in improved precision and lower variance overall, but may also result in an overreliance on the training data (overfitting).",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff",
                "primary_category": "machine learning",
                "rerank_score": 1.2561531066894531,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.00855045486241579,
                  "neutral": 0.9845532178878784,
                  "support": 0.0068963379599153996
                },
                "stance_score": -0.001654116902500391,
                "evidence_contribution": -0.0020778240859034014,
                "combined_rank_score": 2.148245930671692
              }
            ]
          }
        },
        {
          "subclaim": "Machine learning models can suffer from overfitting.",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 18.904998382540064,
            "contradict": 0.0,
            "total": 18.904998382540064
          },
          "evidence": {
            "supporting": [
              {
                "id": 1218,
                "faiss_score": 0.9458591341972351,
                "faiss_rank": 1,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 243,
                "sentence": "Overfitting is something to watch out for when training a machine learning model.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "rerank_score": 5.892265319824219,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.0004957018536515534,
                  "neutral": 0.013847441412508488,
                  "support": 0.9856568574905396
                },
                "stance_score": 0.985161155636888,
                "evidence_contribution": 5.804830911797184,
                "combined_rank_score": 6.838124454021454
              },
              {
                "id": 1311,
                "faiss_score": 0.9410011172294617,
                "faiss_rank": 3,
                "doc_id": "wiki_Statistical_learning_theory",
                "file_type": ".txt",
                "position": 21,
                "sentence": "In machine learning problems, a major problem that arises is that of overfitting.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                "primary_category": "machine learning",
                "rerank_score": 5.9156341552734375,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.0006119771278463304,
                  "neutral": 0.030699515715241432,
                  "support": 0.9686884880065918
                },
                "stance_score": 0.9680765108787455,
                "evidence_contribution": 5.726786472672244,
                "combined_rank_score": 6.856635272502899
              },
              {
                "id": 2607,
                "faiss_score": 0.9083086252212524,
                "faiss_rank": 16,
                "doc_id": "wiki_Deep_learning",
                "file_type": ".txt",
                "position": 202,
                "sentence": "DNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                "primary_category": "deep learning",
                "rerank_score": 3.5356929302215576,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.0009529117960482836,
                  "neutral": 0.06537891179323196,
                  "support": 0.9336680769920349
                },
                "stance_score": 0.9327151651959866,
                "evidence_contribution": 3.297794415493882,
                "combined_rank_score": 4.44400155544281
              },
              {
                "id": 5988,
                "faiss_score": 0.9075533747673035,
                "faiss_rank": 18,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Overfitting occurs when a model learns patterns specific to the training data that do not generalize.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "rerank_score": 4.331396102905273,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.0010803007753565907,
                  "neutral": 0.7501620054244995,
                  "support": 0.24875766038894653
                },
                "stance_score": 0.24767735961358994,
                "evidence_contribution": 1.0727887502081714,
                "combined_rank_score": 5.238949477672577
              },
              {
                "id": 1377,
                "faiss_score": 0.9115912914276123,
                "faiss_rank": 13,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 27,
                "sentence": "Overfitting is especially likely in cases where learning was performed too long or where training examples are rare, causing the learner to adjust to very specific random features of the training data that have no causal relation to the target function.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "rerank_score": 2.787229061126709,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.0014486738946288824,
                  "neutral": 0.6907151937484741,
                  "support": 0.3078361749649048
                },
                "stance_score": 0.3063875010702759,
                "evidence_contribution": 0.8539721469490636,
                "combined_rank_score": 3.6988203525543213
              },
              {
                "id": 6136,
                "faiss_score": 0.9201747179031372,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 3.697188377380371,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.0011870772577822208,
                  "neutral": 0.7740406394004822,
                  "support": 0.22477230429649353
                },
                "stance_score": 0.2235852270387113,
                "evidence_contribution": 0.8266367027614749,
                "combined_rank_score": 4.617363095283508
              },
              {
                "id": 6309,
                "faiss_score": 0.9066196084022522,
                "faiss_rank": 19,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 48,
                "sentence": "High-capacity models are prone to overfitting when data is scarce, and strong generalization typically requires pretraining on massive corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 3.5030198097229004,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.0012985646026208997,
                  "neutral": 0.762039303779602,
                  "support": 0.2366621494293213
                },
                "stance_score": 0.2353635848267004,
                "evidence_contribution": 0.8244833001353278,
                "combined_rank_score": 4.409639418125153
              },
              {
                "id": 1359,
                "faiss_score": 0.9295470118522644,
                "faiss_rank": 4,
                "doc_id": "wiki_Overfitting",
                "file_type": ".txt",
                "position": 9,
                "sentence": "With so many candidate models, overfitting is a real danger.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Overfitting",
                "primary_category": "machine learning",
                "rerank_score": 3.042015552520752,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.0013157170033082366,
                  "neutral": 0.8337580561637878,
                  "support": 0.164926216006279
                },
                "stance_score": 0.16361049900297076,
                "evidence_contribution": 0.497705682522718,
                "combined_rank_score": 3.9715625643730164
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 5990,
                "faiss_score": 0.9263968467712402,
                "faiss_rank": 6,
                "doc_id": "local_ml_evaluation_and_generalization.txt",
                "file_type": ".txt",
                "position": 16,
                "sentence": "Overfitting can arise from excessive model capacity, insufficient data, or overly aggressive optimization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                "primary_category": null,
                "rerank_score": 3.749330997467041,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.001319977454841137,
                  "neutral": 0.9183411002159119,
                  "support": 0.08033887296915054
                },
                "stance_score": 0.0790188955143094,
                "evidence_contribution": 0.2962679943374096,
                "combined_rank_score": 4.675727844238281
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Machine learning models can suffer from overfitting.",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 1311,
                      "faiss_score": 0.9410011172294617,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Statistical_learning_theory",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "In machine learning problems, a major problem that arises is that of overfitting.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                      "primary_category": "machine learning",
                      "rerank_score": 5.9156341552734375,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.0006119771278463304,
                        "neutral": 0.030699515715241432,
                        "support": 0.9686884880065918
                      },
                      "stance_score": 0.9680765108787455,
                      "evidence_contribution": 5.726786472672244,
                      "combined_rank_score": 6.856635272502899
                    },
                    {
                      "id": 1218,
                      "faiss_score": 0.9458591341972351,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 243,
                      "sentence": "Overfitting is something to watch out for when training a machine learning model.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "rerank_score": 5.892265319824219,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.0004957018536515534,
                        "neutral": 0.013847441412508488,
                        "support": 0.9856568574905396
                      },
                      "stance_score": 0.985161155636888,
                      "evidence_contribution": 5.804830911797184,
                      "combined_rank_score": 6.838124454021454
                    },
                    {
                      "id": 5988,
                      "faiss_score": 0.9075533747673035,
                      "faiss_rank": 18,
                      "doc_id": "local_ml_evaluation_and_generalization.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Overfitting occurs when a model learns patterns specific to the training data that do not generalize.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                      "primary_category": null,
                      "rerank_score": 4.331396102905273,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.0010803007753565907,
                        "neutral": 0.7501620054244995,
                        "support": 0.24875766038894653
                      },
                      "stance_score": 0.24767735961358994,
                      "evidence_contribution": 1.0727887502081714,
                      "combined_rank_score": 5.238949477672577
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 5990,
                      "faiss_score": 0.9263968467712402,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_evaluation_and_generalization.txt",
                      "file_type": ".txt",
                      "position": 16,
                      "sentence": "Overfitting can arise from excessive model capacity, insufficient data, or overly aggressive optimization.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_evaluation_and_generalization.txt",
                      "primary_category": null,
                      "rerank_score": 3.749330997467041,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.001319977454841137,
                        "neutral": 0.9183411002159119,
                        "support": 0.08033887296915054
                      },
                      "stance_score": 0.0790188955143094,
                      "evidence_contribution": 0.2962679943374096,
                      "combined_rank_score": 4.675727844238281
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Larger datasets reduce overfitting in machine learning models.",
                "verdict": "CONTRADICT",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6136,
                      "faiss_score": 0.912011444568634,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 12,
                      "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 3.8103489875793457,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.8988689184188843,
                        "neutral": 0.0965760350227356,
                        "support": 0.004554989747703075
                      },
                      "stance_score": -0.8943139286711812,
                      "evidence_contribution": -3.4076481726903425,
                      "combined_rank_score": 4.72236043214798
                    }
                  ],
                  "neutral": [
                    {
                      "id": 2613,
                      "faiss_score": 0.8993738889694214,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Deep_learning",
                      "file_type": ".txt",
                      "position": 208,
                      "sentence": "Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Deep_learning",
                      "primary_category": "deep learning",
                      "rerank_score": 4.625890731811523,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.008702030405402184,
                        "neutral": 0.91930091381073,
                        "support": 0.0719970092177391
                      },
                      "stance_score": 0.06329497881233692,
                      "evidence_contribution": 0.2927956558581961,
                      "combined_rank_score": 5.525264620780945
                    },
                    {
                      "id": 6309,
                      "faiss_score": 0.901115894317627,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 48,
                      "sentence": "High-capacity models are prone to overfitting when data is scarce, and strong generalization typically requires pretraining on massive corpora.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": 1.2675398588180542,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0038825219962745905,
                        "neutral": 0.929321825504303,
                        "support": 0.06679567694664001
                      },
                      "stance_score": 0.06291315495036542,
                      "evidence_contribution": 0.07974493154358456,
                      "combined_rank_score": 2.168655753135681
                    },
                    {
                      "id": 1341,
                      "faiss_score": 0.8920928239822388,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Bias\u2013variance_tradeoff",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "The limiting case where only a finite number of data points are selected over a broad sample space may result in improved precision and lower variance overall, but may also result in an overreliance on the training data (overfitting).",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff",
                      "primary_category": "machine learning",
                      "rerank_score": 1.2561531066894531,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.00855045486241579,
                        "neutral": 0.9845532178878784,
                        "support": 0.0068963379599153996
                      },
                      "stance_score": -0.001654116902500391,
                      "evidence_contribution": -0.0020778240859034014,
                      "combined_rank_score": 2.148245930671692
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Transformer models eliminate the need for optimization techniques.",
      "expected_verdict": "CONTRADICT",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Transformer models exist",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 19.16384684320196,
            "contradict": 0.0,
            "total": 19.16384684320196
          },
          "evidence": {
            "supporting": [
              {
                "id": 6392,
                "faiss_score": 0.8948999643325806,
                "faiss_rank": 8,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 131,
                "sentence": "As transformer-based models become more capable, concerns about misuse and unintended consequences grow.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 4.196916580200195,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.018157165497541428,
                  "neutral": 0.15676067769527435,
                  "support": 0.8250821828842163
                },
                "stance_score": 0.8069250173866749,
                "evidence_contribution": 3.3865969844484667,
                "combined_rank_score": 5.091816544532776
              },
              {
                "id": 1759,
                "faiss_score": 0.9132465124130249,
                "faiss_rank": 1,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 27,
                "sentence": "As of 2024, the largest and most capable models are all based on the transformer architecture.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "rerank_score": 4.139178276062012,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.011396590620279312,
                  "neutral": 0.17400501668453217,
                  "support": 0.8145983815193176
                },
                "stance_score": 0.8032017908990383,
                "evidence_contribution": 3.324595404183402,
                "combined_rank_score": 5.052424788475037
              },
              {
                "id": 2987,
                "faiss_score": 0.8926093578338623,
                "faiss_rank": 12,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Transformer architecture is now used alongside many generative models that contribute to the ongoing AI boom.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "rerank_score": 4.5255537033081055,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.022291269153356552,
                  "neutral": 0.24094286561012268,
                  "support": 0.7367658615112305
                },
                "stance_score": 0.7144745923578739,
                "evidence_contribution": 3.2333931373647253,
                "combined_rank_score": 5.418163061141968
              },
              {
                "id": 6300,
                "faiss_score": 0.8872029781341553,
                "faiss_rank": 15,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 2.884159564971924,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.04400254786014557,
                  "neutral": 0.12755577266216278,
                  "support": 0.8284416794776917
                },
                "stance_score": 0.7844391316175461,
                "evidence_contribution": 2.2624476245930154,
                "combined_rank_score": 3.771362543106079
              },
              {
                "id": 6363,
                "faiss_score": 0.8928086161613464,
                "faiss_rank": 11,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 102,
                "sentence": "These hybrid models attempt to balance efficiency and flexibility, though they often sacrifice the simplicity of the original transformer design.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 3.275681972503662,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.060536615550518036,
                  "neutral": 0.2372356504201889,
                  "support": 0.7022277116775513
                },
                "stance_score": 0.6416910961270332,
                "evidence_contribution": 2.1019759554994373,
                "combined_rank_score": 4.1684905886650085
              },
              {
                "id": 6367,
                "faiss_score": 0.8867349624633789,
                "faiss_rank": 17,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 106,
                "sentence": "Interpretability remains a challenging aspect of transformer-based models.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 2.800401210784912,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.021283458918333054,
                  "neutral": 0.21903814375400543,
                  "support": 0.7596783638000488
                },
                "stance_score": 0.7383949048817158,
                "evidence_contribution": 2.067801985668167,
                "combined_rank_score": 3.687136173248291
              },
              {
                "id": 3066,
                "faiss_score": 0.8990744352340698,
                "faiss_rank": 5,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 121,
                "sentence": "These feed-forward layers contain most of the parameters in a transformer model.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "rerank_score": 2.170119285583496,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.006744684651494026,
                  "neutral": 0.3021673262119293,
                  "support": 0.6910879611968994
                },
                "stance_score": 0.6843432765454054,
                "evidence_contribution": 1.485106542390584,
                "combined_rank_score": 3.069193720817566
              },
              {
                "id": 3010,
                "faiss_score": 0.902931809425354,
                "faiss_rank": 4,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 65,
                "sentence": "These classes are independent of a specific modeling architecture such as transformer, but they are often discussed in the context of transformer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "rerank_score": 1.9379291534423828,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.031252454966306686,
                  "neutral": 0.3576362133026123,
                  "support": 0.6111113429069519
                },
                "stance_score": 0.5798588879406452,
                "evidence_contribution": 1.123725443822856,
                "combined_rank_score": 2.840860962867737
              },
              {
                "id": 6304,
                "faiss_score": 0.9101985692977905,
                "faiss_rank": 2,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 43,
                "sentence": "To address these issues, numerous variants of the transformer architecture have been proposed.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 0.21942584216594696,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.004565074574202299,
                  "neutral": 0.17873318493366241,
                  "support": 0.8167017102241516
                },
                "stance_score": 0.8121366356499493,
                "evidence_contribution": 0.17820376523130896,
                "combined_rank_score": 1.1296244114637375
              },
              {
                "id": 6298,
                "faiss_score": 0.8935939073562622,
                "faiss_rank": 9,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "Models based on transformers achieved state-of-the-art performance in translation, summarization, language modeling, and many other tasks.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": -0.21881964802742004,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.0069143869914114475,
                  "neutral": 0.1628517508506775,
                  "support": 0.8302338123321533
                },
                "stance_score": 0.8233194253407419,
                "evidence_contribution": 0.0,
                "combined_rank_score": 0.6747742593288422
              }
            ],
            "contradicting": [],
            "neutral": []
          }
        },
        {
          "subclaim": "Optimization techniques are needed",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 1.7940795439702546,
            "contradict": 1.0483818562035632,
            "total": 2.8424614001738178
          },
          "evidence": {
            "supporting": [
              {
                "id": 1636,
                "faiss_score": 0.8969464898109436,
                "faiss_rank": 4,
                "doc_id": "wiki_Optimization_(mathematics)",
                "file_type": ".txt",
                "position": 85,
                "sentence": "Many optimization algorithms need to start from a feasible point.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                "primary_category": "all articles with style issues",
                "rerank_score": 4.919436454772949,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.005357774440199137,
                  "neutral": 0.7723470330238342,
                  "support": 0.2222951352596283
                },
                "stance_score": 0.21693736081942916,
                "evidence_contribution": 1.0672095612173327,
                "combined_rank_score": 5.816382944583893
              },
              {
                "id": 5951,
                "faiss_score": 0.8863611221313477,
                "faiss_rank": 16,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 46,
                "sentence": "Effective optimization requires understanding how model behavior interacts with system architecture.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": 2.5880959033966064,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.00443139998242259,
                  "neutral": 0.7683227062225342,
                  "support": 0.22724591195583344
                },
                "stance_score": 0.22281451197341084,
                "evidence_contribution": 0.5766653256556987,
                "combined_rank_score": 3.474457025527954
              },
              {
                "id": 5899,
                "faiss_score": 0.8871976137161255,
                "faiss_rank": 14,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 68,
                "sentence": "From a systems perspective, optimization must be efficient not only in iteration count but also in wall-clock time.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "rerank_score": 1.000978708267212,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.0027748181018978357,
                  "neutral": 0.8443925976753235,
                  "support": 0.15283261239528656
                },
                "stance_score": 0.15005779429338872,
                "evidence_contribution": 0.15020465709722325,
                "combined_rank_score": 1.8881763219833374
              }
            ],
            "contradicting": [
              {
                "id": 1632,
                "faiss_score": 0.8906309604644775,
                "faiss_rank": 9,
                "doc_id": "wiki_Optimization_(mathematics)",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Classical optimization techniques due to their iterative approach do not perform satisfactorily when they are used to obtain multiple solutions, since it is not guaranteed that different solutions will be obtained even with different starting points in multiple runs of the algorithm.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                "primary_category": "all articles with style issues",
                "rerank_score": 3.218745708465576,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.2238139808177948,
                  "neutral": 0.7673050165176392,
                  "support": 0.008881048299372196
                },
                "stance_score": -0.2149329325184226,
                "evidence_contribution": -0.691814454151594,
                "combined_rank_score": 4.109376668930054
              },
              {
                "id": 6229,
                "faiss_score": 0.8993328809738159,
                "faiss_rank": 3,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 37,
                "sentence": "These techniques alter the optimization path as well as the final solution.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "rerank_score": 2.6126317977905273,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.1437188684940338,
                  "neutral": 0.8490404486656189,
                  "support": 0.007240623701363802
                },
                "stance_score": -0.13647824479267,
                "evidence_contribution": -0.35656740205196913,
                "combined_rank_score": 3.5119646787643433
              }
            ],
            "neutral": [
              {
                "id": 5957,
                "faiss_score": 0.892740786075592,
                "faiss_rank": 6,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 52,
                "sentence": "Implementing advanced compression or optimization techniques may require specialized expertise and tooling.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": 5.0751824378967285,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.006101752631366253,
                  "neutral": 0.921724796295166,
                  "support": 0.07217340916395187
                },
                "stance_score": 0.06607165653258562,
                "evidence_contribution": 0.3353257108769232,
                "combined_rank_score": 5.967923223972321
              },
              {
                "id": 1719,
                "faiss_score": 0.885511040687561,
                "faiss_rank": 18,
                "doc_id": "wiki_Optimization_(mathematics)",
                "file_type": ".txt",
                "position": 168,
                "sentence": "Another field that uses optimization techniques extensively is operations research.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                "primary_category": "all articles with style issues",
                "rerank_score": 3.6928787231445312,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0008080819970928133,
                  "neutral": 0.9960877895355225,
                  "support": 0.003104150528088212
                },
                "stance_score": 0.0022960685309953988,
                "evidence_contribution": 0.008479102624994628,
                "combined_rank_score": 4.578389763832092
              },
              {
                "id": 6174,
                "faiss_score": 0.8904021978378296,
                "faiss_rank": 10,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 50,
                "sentence": "Approaches include better architectures, improved training objectives, and more effective optimization methods.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 1.238701581954956,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.002908584661781788,
                  "neutral": 0.9507206678390503,
                  "support": 0.046370696276426315
                },
                "stance_score": 0.04346211161464453,
                "evidence_contribution": 0.053836586412163046,
                "combined_rank_score": 2.1291037797927856
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Transformer models exist",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 2987,
                      "faiss_score": 0.8926093578338623,
                      "faiss_rank": 12,
                      "doc_id": "wiki_Transformer_(machine_learning_model)",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Transformer architecture is now used alongside many generative models that contribute to the ongoing AI boom.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                      "primary_category": "artificial intelligence",
                      "rerank_score": 4.5255537033081055,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.022291269153356552,
                        "neutral": 0.24094286561012268,
                        "support": 0.7367658615112305
                      },
                      "stance_score": 0.7144745923578739,
                      "evidence_contribution": 3.2333931373647253,
                      "combined_rank_score": 5.418163061141968
                    },
                    {
                      "id": 6392,
                      "faiss_score": 0.8948999643325806,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 131,
                      "sentence": "As transformer-based models become more capable, concerns about misuse and unintended consequences grow.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": 4.196916580200195,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.018157165497541428,
                        "neutral": 0.15676067769527435,
                        "support": 0.8250821828842163
                      },
                      "stance_score": 0.8069250173866749,
                      "evidence_contribution": 3.3865969844484667,
                      "combined_rank_score": 5.091816544532776
                    },
                    {
                      "id": 1759,
                      "faiss_score": 0.9132465124130249,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 27,
                      "sentence": "As of 2024, the largest and most capable models are all based on the transformer architecture.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "rerank_score": 4.139178276062012,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.011396590620279312,
                        "neutral": 0.17400501668453217,
                        "support": 0.8145983815193176
                      },
                      "stance_score": 0.8032017908990383,
                      "evidence_contribution": 3.324595404183402,
                      "combined_rank_score": 5.052424788475037
                    }
                  ],
                  "contradicting": [],
                  "neutral": []
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Optimization techniques are needed",
                "verdict": "MIXED",
                "controversial": true,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 1636,
                      "faiss_score": 0.8969464898109436,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Optimization_(mathematics)",
                      "file_type": ".txt",
                      "position": 85,
                      "sentence": "Many optimization algorithms need to start from a feasible point.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                      "primary_category": "all articles with style issues",
                      "rerank_score": 4.919436454772949,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.005357774440199137,
                        "neutral": 0.7723470330238342,
                        "support": 0.2222951352596283
                      },
                      "stance_score": 0.21693736081942916,
                      "evidence_contribution": 1.0672095612173327,
                      "combined_rank_score": 5.816382944583893
                    },
                    {
                      "id": 5951,
                      "faiss_score": 0.8863611221313477,
                      "faiss_rank": 16,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 46,
                      "sentence": "Effective optimization requires understanding how model behavior interacts with system architecture.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "rerank_score": 2.5880959033966064,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.00443139998242259,
                        "neutral": 0.7683227062225342,
                        "support": 0.22724591195583344
                      },
                      "stance_score": 0.22281451197341084,
                      "evidence_contribution": 0.5766653256556987,
                      "combined_rank_score": 3.474457025527954
                    },
                    {
                      "id": 5899,
                      "faiss_score": 0.8871976137161255,
                      "faiss_rank": 14,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 68,
                      "sentence": "From a systems perspective, optimization must be efficient not only in iteration count but also in wall-clock time.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "rerank_score": 1.000978708267212,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.0027748181018978357,
                        "neutral": 0.8443925976753235,
                        "support": 0.15283261239528656
                      },
                      "stance_score": 0.15005779429338872,
                      "evidence_contribution": 0.15020465709722325,
                      "combined_rank_score": 1.8881763219833374
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 1632,
                      "faiss_score": 0.8906309604644775,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Optimization_(mathematics)",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Classical optimization techniques due to their iterative approach do not perform satisfactorily when they are used to obtain multiple solutions, since it is not guaranteed that different solutions will be obtained even with different starting points in multiple runs of the algorithm.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                      "primary_category": "all articles with style issues",
                      "rerank_score": 3.218745708465576,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.2238139808177948,
                        "neutral": 0.7673050165176392,
                        "support": 0.008881048299372196
                      },
                      "stance_score": -0.2149329325184226,
                      "evidence_contribution": -0.691814454151594,
                      "combined_rank_score": 4.109376668930054
                    },
                    {
                      "id": 6229,
                      "faiss_score": 0.8993328809738159,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 37,
                      "sentence": "These techniques alter the optimization path as well as the final solution.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "rerank_score": 2.6126317977905273,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.1437188684940338,
                        "neutral": 0.8490404486656189,
                        "support": 0.007240623701363802
                      },
                      "stance_score": -0.13647824479267,
                      "evidence_contribution": -0.35656740205196913,
                      "combined_rank_score": 3.5119646787643433
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5957,
                      "faiss_score": 0.892740786075592,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 52,
                      "sentence": "Implementing advanced compression or optimization techniques may require specialized expertise and tooling.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "rerank_score": 5.0751824378967285,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.006101752631366253,
                        "neutral": 0.921724796295166,
                        "support": 0.07217340916395187
                      },
                      "stance_score": 0.06607165653258562,
                      "evidence_contribution": 0.3353257108769232,
                      "combined_rank_score": 5.967923223972321
                    },
                    {
                      "id": 1719,
                      "faiss_score": 0.885511040687561,
                      "faiss_rank": 18,
                      "doc_id": "wiki_Optimization_(mathematics)",
                      "file_type": ".txt",
                      "position": 168,
                      "sentence": "Another field that uses optimization techniques extensively is operations research.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                      "primary_category": "all articles with style issues",
                      "rerank_score": 3.6928787231445312,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0008080819970928133,
                        "neutral": 0.9960877895355225,
                        "support": 0.003104150528088212
                      },
                      "stance_score": 0.0022960685309953988,
                      "evidence_contribution": 0.008479102624994628,
                      "combined_rank_score": 4.578389763832092
                    },
                    {
                      "id": 6174,
                      "faiss_score": 0.8904021978378296,
                      "faiss_rank": 10,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 50,
                      "sentence": "Approaches include better architectures, improved training objectives, and more effective optimization methods.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 1.238701581954956,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.002908584661781788,
                        "neutral": 0.9507206678390503,
                        "support": 0.046370696276426315
                      },
                      "stance_score": 0.04346211161464453,
                      "evidence_contribution": 0.053836586412163046,
                      "combined_rank_score": 2.1291037797927856
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Scaling model size improves performance but introduces efficiency and stability challenges.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Scaling model size improves performance",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 24.978872569263523,
            "contradict": 0.0,
            "total": 24.978872569263523
          },
          "evidence": {
            "supporting": [
              {
                "id": 6300,
                "faiss_score": 0.8937974572181702,
                "faiss_rank": 13,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "As transformer models grew larger, their performance continued to improve, reinforcing the idea that scaling was a key driver of success.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 6.097304344177246,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.0006018584244884551,
                  "neutral": 0.04180032014846802,
                  "support": 0.9575978517532349
                },
                "stance_score": 0.9569959933287464,
                "evidence_contribution": 5.835095827483585,
                "combined_rank_score": 6.991101801395416
              },
              {
                "id": 6127,
                "faiss_score": 0.9101240634918213,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 6.25351619720459,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.000981850316748023,
                  "neutral": 0.09745568037033081,
                  "support": 0.901562511920929
                },
                "stance_score": 0.9005806616041809,
                "evidence_contribution": 5.631795754230971,
                "combined_rank_score": 7.163640260696411
              },
              {
                "id": 6124,
                "faiss_score": 0.9064903259277344,
                "faiss_rank": 6,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 7.801340579986572,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.0015502498717978597,
                  "neutral": 0.32961592078208923,
                  "support": 0.66883385181427
                },
                "stance_score": 0.6672836019424722,
                "evidence_contribution": 5.205706642193415,
                "combined_rank_score": 8.707830905914307
              },
              {
                "id": 6137,
                "faiss_score": 0.9351097345352173,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 5.056931018829346,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.00106658018194139,
                  "neutral": 0.08652021735906601,
                  "support": 0.9124131798744202
                },
                "stance_score": 0.9113465996924788,
                "evidence_contribution": 4.6086168888895465,
                "combined_rank_score": 5.992040753364563
              },
              {
                "id": 6133,
                "faiss_score": 0.9184768795967102,
                "faiss_rank": 2,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 7.172950744628906,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.1632184386253357,
                  "neutral": 0.1580629199743271,
                  "support": 0.678718626499176
                },
                "stance_score": 0.5155001878738403,
                "evidence_contribution": 3.697657456466004,
                "combined_rank_score": 8.091427624225616
              }
            ],
            "contradicting": [
              {
                "id": 6349,
                "faiss_score": 0.8993617296218872,
                "faiss_rank": 10,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 88,
                "sentence": "As models scale, training efficiency becomes a primary concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": -1.0130536556243896,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.26972973346710205,
                  "neutral": 0.7104320526123047,
                  "support": 0.019838299602270126
                },
                "stance_score": -0.24989143386483192,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.11369192600250244
              }
            ],
            "neutral": [
              {
                "id": 6142,
                "faiss_score": 0.9155328869819641,
                "faiss_rank": 3,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 4.632805347442627,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.003673245431855321,
                  "neutral": 0.966631293296814,
                  "support": 0.029695525765419006
                },
                "stance_score": 0.026022280333563685,
                "evidence_contribution": 0.12055615948198495,
                "combined_rank_score": 5.548338234424591
              },
              {
                "id": 6131,
                "faiss_score": 0.9074476361274719,
                "faiss_rank": 5,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 2.8586673736572266,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.0011911247856914997,
                  "neutral": 0.995375394821167,
                  "support": 0.0034334997180849314
                },
                "stance_score": 0.0022423749323934317,
                "evidence_contribution": 0.006410204058739932,
                "combined_rank_score": 3.7661150097846985
              },
              {
                "id": 6045,
                "faiss_score": 0.8938406705856323,
                "faiss_rank": 12,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 5,
                "sentence": "As models scale, they appear to acquire new capabilities that were not present in smaller versions.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 0.17277783155441284,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.002974959323182702,
                  "neutral": 0.9193781018257141,
                  "support": 0.07764695584774017
                },
                "stance_score": 0.07467199652455747,
                "evidence_contribution": 0.012901665637351692,
                "combined_rank_score": 1.0666185021400452
              }
            ]
          }
        },
        {
          "subclaim": "Scaling model size introduces efficiency challenges",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 1.9101070100796687,
            "contradict": 0.0,
            "total": 1.9101070100796687
          },
          "evidence": {
            "supporting": [
              {
                "id": 6349,
                "faiss_score": 0.9152157306671143,
                "faiss_rank": 3,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 88,
                "sentence": "As models scale, training efficiency becomes a primary concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": 1.1722049713134766,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.0020032706670463085,
                  "neutral": 0.1527910679578781,
                  "support": 0.8452056646347046
                },
                "stance_score": 0.8432023939676583,
                "evidence_contribution": 0.9884060380323136,
                "combined_rank_score": 2.087420701980591
              },
              {
                "id": 6149,
                "faiss_score": 0.9049237966537476,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 25,
                "sentence": "Scaling also introduces engineering challenges.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 2.976050615310669,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.003267299383878708,
                  "neutral": 0.6837592720985413,
                  "support": 0.31297338008880615
                },
                "stance_score": 0.30970608070492744,
                "evidence_contribution": 0.921700972047355,
                "combined_rank_score": 3.8809744119644165
              },
              {
                "id": 6157,
                "faiss_score": 0.9232777953147888,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 33,
                "sentence": "Inference efficiency is another scaling concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -0.5988900661468506,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.0029566814191639423,
                  "neutral": 0.8427377939224243,
                  "support": 0.15430548787117004
                },
                "stance_score": 0.1513488064520061,
                "evidence_contribution": 0.0,
                "combined_rank_score": 0.32438772916793823
              },
              {
                "id": 6173,
                "faiss_score": 0.8956167697906494,
                "faiss_rank": 10,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 49,
                "sentence": "Efficiency-oriented research aims to counterbalance brute-force scaling by achieving comparable performance with fewer resources.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -0.9426184892654419,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.0026571243070065975,
                  "neutral": 0.8857571482658386,
                  "support": 0.11158574372529984
                },
                "stance_score": 0.10892861941829324,
                "evidence_contribution": 0.0,
                "combined_rank_score": -0.04700171947479248
              },
              {
                "id": 5905,
                "faiss_score": 0.9015026092529297,
                "faiss_rank": 5,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": -2.95443058013916,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.0009848137851804495,
                  "neutral": 0.09008853882551193,
                  "support": 0.9089266657829285
                },
                "stance_score": 0.907941851997748,
                "evidence_contribution": 0.0,
                "combined_rank_score": -2.0529279708862305
              },
              {
                "id": 6211,
                "faiss_score": 0.8909123539924622,
                "faiss_rank": 16,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 19,
                "sentence": "Batch size influences both optimization efficiency and generalization.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "rerank_score": -5.489606857299805,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.005222289822995663,
                  "neutral": 0.8444947600364685,
                  "support": 0.15028297901153564
                },
                "stance_score": 0.14506068918853998,
                "evidence_contribution": 0.0,
                "combined_rank_score": -4.5986945033073425
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 6124,
                "faiss_score": 0.8902746438980103,
                "faiss_rank": 18,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 0.3690628707408905,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0213742908090353,
                  "neutral": 0.974280059337616,
                  "support": 0.004345625638961792
                },
                "stance_score": -0.01702866517007351,
                "evidence_contribution": -0.006284648052552744,
                "combined_rank_score": 1.2593375146389008
              },
              {
                "id": 6142,
                "faiss_score": 0.8960381746292114,
                "faiss_rank": 9,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -1.240119218826294,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.013231821358203888,
                  "neutral": 0.9757226705551147,
                  "support": 0.011045468039810658
                },
                "stance_score": -0.0021863533183932304,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.3440810441970825
              },
              {
                "id": 6131,
                "faiss_score": 0.8946009874343872,
                "faiss_rank": 11,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -2.0848493576049805,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.0008040505927056074,
                  "neutral": 0.9974097609519958,
                  "support": 0.0017861495725810528
                },
                "stance_score": 0.0009820989798754454,
                "evidence_contribution": 0.0,
                "combined_rank_score": -1.1902483701705933
              }
            ]
          }
        },
        {
          "subclaim": "Scaling model size introduces stability challenges",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 0.3388324719993685,
            "contradict": 0.0,
            "total": 0.3388324719993685
          },
          "evidence": {
            "supporting": [
              {
                "id": 6149,
                "faiss_score": 0.8830956220626831,
                "faiss_rank": 8,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 25,
                "sentence": "Scaling also introduces engineering challenges.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 2.749152183532715,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.010862507857382298,
                  "neutral": 0.8550251126289368,
                  "support": 0.13411231338977814
                },
                "stance_score": 0.12324980553239584,
                "evidence_contribution": 0.3388324719993685,
                "combined_rank_score": 3.632247805595398
              },
              {
                "id": 6133,
                "faiss_score": 0.9155011177062988,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -1.6219263076782227,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.004420503508299589,
                  "neutral": 0.3866603672504425,
                  "support": 0.608919084072113
                },
                "stance_score": 0.6044985805638134,
                "evidence_contribution": 0.0,
                "combined_rank_score": -0.7064251899719238
              },
              {
                "id": 5968,
                "faiss_score": 0.8963637351989746,
                "faiss_rank": 2,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 63,
                "sentence": "As models continue to scale, new bottlenecks emerge.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": -6.650618076324463,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.0010524292010813951,
                  "neutral": 0.18886996805667877,
                  "support": 0.8100776076316833
                },
                "stance_score": 0.809025178430602,
                "evidence_contribution": 0.0,
                "combined_rank_score": -5.754254341125488
              },
              {
                "id": 6349,
                "faiss_score": 0.8802475929260254,
                "faiss_rank": 12,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 88,
                "sentence": "As models scale, training efficiency becomes a primary concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": -7.273441791534424,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.0099205132573843,
                  "neutral": 0.7918288707733154,
                  "support": 0.1982506662607193
                },
                "stance_score": 0.188330153003335,
                "evidence_contribution": 0.0,
                "combined_rank_score": -6.393194198608398
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 6131,
                "faiss_score": 0.8920418620109558,
                "faiss_rank": 3,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -2.5046567916870117,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0010439755860716105,
                  "neutral": 0.9971585273742676,
                  "support": 0.001797515549696982
                },
                "stance_score": 0.0007535399636253715,
                "evidence_contribution": 0.0,
                "combined_rank_score": -1.612614929676056
              },
              {
                "id": 6142,
                "faiss_score": 0.8803155422210693,
                "faiss_rank": 11,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 18,
                "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -2.551440715789795,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.01365591213107109,
                  "neutral": 0.980880081653595,
                  "support": 0.00546405790373683
                },
                "stance_score": -0.008191854227334261,
                "evidence_contribution": -0.0,
                "combined_rank_score": -1.6711251735687256
              },
              {
                "id": 5919,
                "faiss_score": 0.878303587436676,
                "faiss_rank": 14,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "The challenge lies in maintaining numerical stability and avoiding excessive loss of accuracy.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": -5.721813201904297,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.0014828282874077559,
                  "neutral": 0.9933990240097046,
                  "support": 0.005118160974234343
                },
                "stance_score": 0.0036353326868265867,
                "evidence_contribution": 0.0,
                "combined_rank_score": -4.843509614467621
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Scaling model size improves performance",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6124,
                      "faiss_score": 0.9064903259277344,
                      "faiss_rank": 6,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 7.801340579986572,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.0015502498717978597,
                        "neutral": 0.32961592078208923,
                        "support": 0.66883385181427
                      },
                      "stance_score": 0.6672836019424722,
                      "evidence_contribution": 5.205706642193415,
                      "combined_rank_score": 8.707830905914307
                    },
                    {
                      "id": 6133,
                      "faiss_score": 0.9184768795967102,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 7.172950744628906,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.1632184386253357,
                        "neutral": 0.1580629199743271,
                        "support": 0.678718626499176
                      },
                      "stance_score": 0.5155001878738403,
                      "evidence_contribution": 3.697657456466004,
                      "combined_rank_score": 8.091427624225616
                    },
                    {
                      "id": 6127,
                      "faiss_score": 0.9101240634918213,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "Empirical observations have shown that, under certain conditions, model performance improves predictably as scale increases.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 6.25351619720459,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.000981850316748023,
                        "neutral": 0.09745568037033081,
                        "support": 0.901562511920929
                      },
                      "stance_score": 0.9005806616041809,
                      "evidence_contribution": 5.631795754230971,
                      "combined_rank_score": 7.163640260696411
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 6349,
                      "faiss_score": 0.8993617296218872,
                      "faiss_rank": 10,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 88,
                      "sentence": "As models scale, training efficiency becomes a primary concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": -1.0130536556243896,
                      "rerank_rank": 10,
                      "probs": {
                        "contradict": 0.26972973346710205,
                        "neutral": 0.7104320526123047,
                        "support": 0.019838299602270126
                      },
                      "stance_score": -0.24989143386483192,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -0.11369192600250244
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6142,
                      "faiss_score": 0.9155328869819641,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 4.632805347442627,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.003673245431855321,
                        "neutral": 0.966631293296814,
                        "support": 0.029695525765419006
                      },
                      "stance_score": 0.026022280333563685,
                      "evidence_contribution": 0.12055615948198495,
                      "combined_rank_score": 5.548338234424591
                    },
                    {
                      "id": 6131,
                      "faiss_score": 0.9074476361274719,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 2.8586673736572266,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.0011911247856914997,
                        "neutral": 0.995375394821167,
                        "support": 0.0034334997180849314
                      },
                      "stance_score": 0.0022423749323934317,
                      "evidence_contribution": 0.006410204058739932,
                      "combined_rank_score": 3.7661150097846985
                    },
                    {
                      "id": 6045,
                      "faiss_score": 0.8938406705856323,
                      "faiss_rank": 12,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 5,
                      "sentence": "As models scale, they appear to acquire new capabilities that were not present in smaller versions.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 0.17277783155441284,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.002974959323182702,
                        "neutral": 0.9193781018257141,
                        "support": 0.07764695584774017
                      },
                      "stance_score": 0.07467199652455747,
                      "evidence_contribution": 0.012901665637351692,
                      "combined_rank_score": 1.0666185021400452
                    }
                  ]
                }
              },
              {
                "subclaim": "Scaling model size introduces efficiency challenges",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6149,
                      "faiss_score": 0.9049237966537476,
                      "faiss_rank": 4,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 25,
                      "sentence": "Scaling also introduces engineering challenges.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 2.976050615310669,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.003267299383878708,
                        "neutral": 0.6837592720985413,
                        "support": 0.31297338008880615
                      },
                      "stance_score": 0.30970608070492744,
                      "evidence_contribution": 0.921700972047355,
                      "combined_rank_score": 3.8809744119644165
                    },
                    {
                      "id": 6349,
                      "faiss_score": 0.9152157306671143,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_transformers.txt",
                      "file_type": ".txt",
                      "position": 88,
                      "sentence": "As models scale, training efficiency becomes a primary concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                      "primary_category": null,
                      "rerank_score": 1.1722049713134766,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.0020032706670463085,
                        "neutral": 0.1527910679578781,
                        "support": 0.8452056646347046
                      },
                      "stance_score": 0.8432023939676583,
                      "evidence_contribution": 0.9884060380323136,
                      "combined_rank_score": 2.087420701980591
                    },
                    {
                      "id": 6157,
                      "faiss_score": 0.9232777953147888,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 33,
                      "sentence": "Inference efficiency is another scaling concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -0.5988900661468506,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.0029566814191639423,
                        "neutral": 0.8427377939224243,
                        "support": 0.15430548787117004
                      },
                      "stance_score": 0.1513488064520061,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": 0.32438772916793823
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 6124,
                      "faiss_score": 0.8902746438980103,
                      "faiss_rank": 18,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 0.3690628707408905,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0213742908090353,
                        "neutral": 0.974280059337616,
                        "support": 0.004345625638961792
                      },
                      "stance_score": -0.01702866517007351,
                      "evidence_contribution": -0.006284648052552744,
                      "combined_rank_score": 1.2593375146389008
                    },
                    {
                      "id": 6142,
                      "faiss_score": 0.8960381746292114,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -1.240119218826294,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.013231821358203888,
                        "neutral": 0.9757226705551147,
                        "support": 0.011045468039810658
                      },
                      "stance_score": -0.0021863533183932304,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -0.3440810441970825
                    },
                    {
                      "id": 6131,
                      "faiss_score": 0.8946009874343872,
                      "faiss_rank": 11,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -2.0848493576049805,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.0008040505927056074,
                        "neutral": 0.9974097609519958,
                        "support": 0.0017861495725810528
                      },
                      "stance_score": 0.0009820989798754454,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -1.1902483701705933
                    }
                  ]
                }
              },
              {
                "subclaim": "Scaling model size introduces stability challenges",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "weak",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6149,
                      "faiss_score": 0.8830956220626831,
                      "faiss_rank": 8,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 25,
                      "sentence": "Scaling also introduces engineering challenges.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 2.749152183532715,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.010862507857382298,
                        "neutral": 0.8550251126289368,
                        "support": 0.13411231338977814
                      },
                      "stance_score": 0.12324980553239584,
                      "evidence_contribution": 0.3388324719993685,
                      "combined_rank_score": 3.632247805595398
                    },
                    {
                      "id": 6133,
                      "faiss_score": 0.9155011177062988,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "In practice, increasing model size often improves performance up to a point, after which gains diminish or become unstable if other factors are not adjusted.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -1.6219263076782227,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.004420503508299589,
                        "neutral": 0.3866603672504425,
                        "support": 0.608919084072113
                      },
                      "stance_score": 0.6044985805638134,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -0.7064251899719238
                    },
                    {
                      "id": 5968,
                      "faiss_score": 0.8963637351989746,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 63,
                      "sentence": "As models continue to scale, new bottlenecks emerge.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "rerank_score": -6.650618076324463,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.0010524292010813951,
                        "neutral": 0.18886996805667877,
                        "support": 0.8100776076316833
                      },
                      "stance_score": 0.809025178430602,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -5.754254341125488
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 6131,
                      "faiss_score": 0.8920418620109558,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Model scaling involves increasing the number of parameters in a neural network.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -2.5046567916870117,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0010439755860716105,
                        "neutral": 0.9971585273742676,
                        "support": 0.001797515549696982
                      },
                      "stance_score": 0.0007535399636253715,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -1.612614929676056
                    },
                    {
                      "id": 6142,
                      "faiss_score": 0.8803155422210693,
                      "faiss_rank": 11,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 18,
                      "sentence": "Scaling laws attempt to formalize the relationship between model size, data size, compute, and performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -2.551440715789795,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.01365591213107109,
                        "neutral": 0.980880081653595,
                        "support": 0.00546405790373683
                      },
                      "stance_score": -0.008191854227334261,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -1.6711251735687256
                    },
                    {
                      "id": 5919,
                      "faiss_score": 0.878303587436676,
                      "faiss_rank": 14,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "The challenge lies in maintaining numerical stability and avoiding excessive loss of accuracy.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "rerank_score": -5.721813201904297,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.0014828282874077559,
                        "neutral": 0.9933990240097046,
                        "support": 0.005118160974234343
                      },
                      "stance_score": 0.0036353326868265867,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -4.843509614467621
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Distributed systems improve scalability but increase system complexity.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Distributed systems improve scalability",
          "verdict": "CONTRADICT",
          "controversial": true,
          "strengths": {
            "support": 1.0321325065354696,
            "contradict": 2.1855973309983234,
            "total": 3.217729837533793
          },
          "evidence": {
            "supporting": [
              {
                "id": 499,
                "faiss_score": 0.9017831683158875,
                "faiss_rank": 10,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "rerank_score": 1.7927249670028687,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.0015425255987793207,
                  "neutral": 0.4211810231208801,
                  "support": 0.5772764086723328
                },
                "stance_score": 0.5757338830735534,
                "evidence_contribution": 1.0321325065354696,
                "combined_rank_score": 2.694508135318756
              }
            ],
            "contradicting": [
              {
                "id": 5658,
                "faiss_score": 0.9028811454772949,
                "faiss_rank": 9,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 61,
                "sentence": "Eventually consistent systems illustrate how relaxing guarantees can improve scalability.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": 2.7626805305480957,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.8435043692588806,
                  "neutral": 0.10410597920417786,
                  "support": 0.052389614284038544
                },
                "stance_score": -0.7911147549748421,
                "evidence_contribution": -2.1855973309983234,
                "combined_rank_score": 3.6655616760253906
              }
            ],
            "neutral": [
              {
                "id": 445,
                "faiss_score": 0.9056973457336426,
                "faiss_rank": 4,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Distributed systems are groups of networked computers which share a common goal for their work.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "rerank_score": 1.2563084363937378,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.000767619232647121,
                  "neutral": 0.9977124929428101,
                  "support": 0.001519894110970199
                },
                "stance_score": 0.0007522748783230782,
                "evidence_contribution": 0.0009450892761243557,
                "combined_rank_score": 2.1620057821273804
              },
              {
                "id": 5597,
                "faiss_score": 0.9030466675758362,
                "faiss_rank": 8,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Distributed systems are collections of independent computing components that coordinate their actions through communication in order to achieve a common goal.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": 1.2206794023513794,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.0007695626700296998,
                  "neutral": 0.9976724982261658,
                  "support": 0.0015579789178445935
                },
                "stance_score": 0.0007884162478148937,
                "evidence_contribution": 0.0009624034741868015,
                "combined_rank_score": 2.1237260699272156
              },
              {
                "id": 5646,
                "faiss_score": 0.9050657749176025,
                "faiss_rank": 7,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 49,
                "sentence": "The evolution of distributed systems has been driven by practical needs.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": -0.1592615842819214,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.0006361278356052935,
                  "neutral": 0.9965994954109192,
                  "support": 0.002764445496723056
                },
                "stance_score": 0.0021283176611177623,
                "evidence_contribution": 0.0,
                "combined_rank_score": 0.7458041906356812
              }
            ]
          }
        },
        {
          "subclaim": "Distributed systems increase system complexity",
          "verdict": "MIXED",
          "controversial": true,
          "strengths": {
            "support": 1.6687459316599744,
            "contradict": 1.3767160541470862,
            "total": 3.0454619858070604
          },
          "evidence": {
            "supporting": [
              {
                "id": 6234,
                "faiss_score": 0.8951437473297119,
                "faiss_rank": 15,
                "doc_id": "local_ml_training_dynamics.txt",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Distributed training introduces additional complexity into training dynamics.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                "primary_category": null,
                "rerank_score": 0.9794656038284302,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.0011164408642798662,
                  "neutral": 0.06910634785890579,
                  "support": 0.929777204990387
                },
                "stance_score": 0.9286607641261071,
                "evidence_contribution": 0.9095912760865489,
                "combined_rank_score": 1.874609351158142
              },
              {
                "id": 5674,
                "faiss_score": 0.9308851957321167,
                "faiss_rank": 1,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 77,
                "sentence": "Distributed systems exemplify the broader theme that complexity emerges from interaction.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": 6.873047828674316,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.13098503649234772,
                  "neutral": 0.6275760531425476,
                  "support": 0.24143889546394348
                },
                "stance_score": 0.11045385897159576,
                "evidence_contribution": 0.7591546555734254,
                "combined_rank_score": 7.803933024406433
              }
            ],
            "contradicting": [
              {
                "id": 499,
                "faiss_score": 0.9024401903152466,
                "faiss_rank": 8,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 75,
                "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "rerank_score": 1.669622778892517,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.8282386660575867,
                  "neutral": 0.16808989644050598,
                  "support": 0.0036715413443744183
                },
                "stance_score": -0.8245671247132123,
                "evidence_contribution": -1.3767160541470862,
                "combined_rank_score": 2.5720629692077637
              }
            ],
            "neutral": [
              {
                "id": 5597,
                "faiss_score": 0.9027834534645081,
                "faiss_rank": 7,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Distributed systems are collections of independent computing components that coordinate their actions through communication in order to achieve a common goal.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": 1.5515655279159546,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.04560400918126106,
                  "neutral": 0.9508848190307617,
                  "support": 0.0035111713223159313
                },
                "stance_score": -0.04209283785894513,
                "evidence_contribution": -0.06530979619409488,
                "combined_rank_score": 2.4543489813804626
              },
              {
                "id": 445,
                "faiss_score": 0.9034885168075562,
                "faiss_rank": 3,
                "doc_id": "wiki_Distributed_computing",
                "file_type": ".txt",
                "position": 21,
                "sentence": "Distributed systems are groups of networked computers which share a common goal for their work.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                "primary_category": "all articles with unsourced statements",
                "rerank_score": 1.5492687225341797,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.03827379271388054,
                  "neutral": 0.9580088257789612,
                  "support": 0.003717323299497366
                },
                "stance_score": -0.03455646941438317,
                "evidence_contribution": -0.05353725722491287,
                "combined_rank_score": 2.452757239341736
              },
              {
                "id": 5650,
                "faiss_score": 0.9090577363967896,
                "faiss_rank": 2,
                "doc_id": "local_distributed_systems_fundamentals.txt",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Distributed systems also intersect with security concerns.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                "primary_category": null,
                "rerank_score": 0.526348888874054,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.0072384984232485294,
                  "neutral": 0.9825186729431152,
                  "support": 0.010242801159620285
                },
                "stance_score": 0.0030043027363717556,
                "evidence_contribution": 0.0015813114071305534,
                "combined_rank_score": 1.4354066252708435
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Distributed systems improve scalability",
                "verdict": "CONTRADICT",
                "controversial": true,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 499,
                      "faiss_score": 0.9017831683158875,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "rerank_score": 1.7927249670028687,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.0015425255987793207,
                        "neutral": 0.4211810231208801,
                        "support": 0.5772764086723328
                      },
                      "stance_score": 0.5757338830735534,
                      "evidence_contribution": 1.0321325065354696,
                      "combined_rank_score": 2.694508135318756
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 5658,
                      "faiss_score": 0.9028811454772949,
                      "faiss_rank": 9,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 61,
                      "sentence": "Eventually consistent systems illustrate how relaxing guarantees can improve scalability.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "rerank_score": 2.7626805305480957,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.8435043692588806,
                        "neutral": 0.10410597920417786,
                        "support": 0.052389614284038544
                      },
                      "stance_score": -0.7911147549748421,
                      "evidence_contribution": -2.1855973309983234,
                      "combined_rank_score": 3.6655616760253906
                    }
                  ],
                  "neutral": [
                    {
                      "id": 445,
                      "faiss_score": 0.9056973457336426,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "Distributed systems are groups of networked computers which share a common goal for their work.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "rerank_score": 1.2563084363937378,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.000767619232647121,
                        "neutral": 0.9977124929428101,
                        "support": 0.001519894110970199
                      },
                      "stance_score": 0.0007522748783230782,
                      "evidence_contribution": 0.0009450892761243557,
                      "combined_rank_score": 2.1620057821273804
                    },
                    {
                      "id": 5597,
                      "faiss_score": 0.9030466675758362,
                      "faiss_rank": 8,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Distributed systems are collections of independent computing components that coordinate their actions through communication in order to achieve a common goal.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "rerank_score": 1.2206794023513794,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.0007695626700296998,
                        "neutral": 0.9976724982261658,
                        "support": 0.0015579789178445935
                      },
                      "stance_score": 0.0007884162478148937,
                      "evidence_contribution": 0.0009624034741868015,
                      "combined_rank_score": 2.1237260699272156
                    },
                    {
                      "id": 5646,
                      "faiss_score": 0.9050657749176025,
                      "faiss_rank": 7,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 49,
                      "sentence": "The evolution of distributed systems has been driven by practical needs.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "rerank_score": -0.1592615842819214,
                      "rerank_rank": 9,
                      "probs": {
                        "contradict": 0.0006361278356052935,
                        "neutral": 0.9965994954109192,
                        "support": 0.002764445496723056
                      },
                      "stance_score": 0.0021283176611177623,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": 0.7458041906356812
                    }
                  ]
                }
              }
            ]
          },
          {
            "type": "CONTROVERSIAL_ASPECTS",
            "items": [
              {
                "subclaim": "Distributed systems increase system complexity",
                "verdict": "MIXED",
                "controversial": true,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 5674,
                      "faiss_score": 0.9308851957321167,
                      "faiss_rank": 1,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 77,
                      "sentence": "Distributed systems exemplify the broader theme that complexity emerges from interaction.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "rerank_score": 6.873047828674316,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.13098503649234772,
                        "neutral": 0.6275760531425476,
                        "support": 0.24143889546394348
                      },
                      "stance_score": 0.11045385897159576,
                      "evidence_contribution": 0.7591546555734254,
                      "combined_rank_score": 7.803933024406433
                    },
                    {
                      "id": 6234,
                      "faiss_score": 0.8951437473297119,
                      "faiss_rank": 15,
                      "doc_id": "local_ml_training_dynamics.txt",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Distributed training introduces additional complexity into training dynamics.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_training_dynamics.txt",
                      "primary_category": null,
                      "rerank_score": 0.9794656038284302,
                      "rerank_rank": 9,
                      "probs": {
                        "contradict": 0.0011164408642798662,
                        "neutral": 0.06910634785890579,
                        "support": 0.929777204990387
                      },
                      "stance_score": 0.9286607641261071,
                      "evidence_contribution": 0.9095912760865489,
                      "combined_rank_score": 1.874609351158142
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 499,
                      "faiss_score": 0.9024401903152466,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 75,
                      "sentence": "Moreover, a distributed system may be easier to expand and manage than a monolithic uniprocessor system.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "rerank_score": 1.669622778892517,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.8282386660575867,
                        "neutral": 0.16808989644050598,
                        "support": 0.0036715413443744183
                      },
                      "stance_score": -0.8245671247132123,
                      "evidence_contribution": -1.3767160541470862,
                      "combined_rank_score": 2.5720629692077637
                    }
                  ],
                  "neutral": [
                    {
                      "id": 5597,
                      "faiss_score": 0.9027834534645081,
                      "faiss_rank": 7,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Distributed systems are collections of independent computing components that coordinate their actions through communication in order to achieve a common goal.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "rerank_score": 1.5515655279159546,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.04560400918126106,
                        "neutral": 0.9508848190307617,
                        "support": 0.0035111713223159313
                      },
                      "stance_score": -0.04209283785894513,
                      "evidence_contribution": -0.06530979619409488,
                      "combined_rank_score": 2.4543489813804626
                    },
                    {
                      "id": 445,
                      "faiss_score": 0.9034885168075562,
                      "faiss_rank": 3,
                      "doc_id": "wiki_Distributed_computing",
                      "file_type": ".txt",
                      "position": 21,
                      "sentence": "Distributed systems are groups of networked computers which share a common goal for their work.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Distributed_computing",
                      "primary_category": "all articles with unsourced statements",
                      "rerank_score": 1.5492687225341797,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.03827379271388054,
                        "neutral": 0.9580088257789612,
                        "support": 0.003717323299497366
                      },
                      "stance_score": -0.03455646941438317,
                      "evidence_contribution": -0.05353725722491287,
                      "combined_rank_score": 2.452757239341736
                    },
                    {
                      "id": 5650,
                      "faiss_score": 0.9090577363967896,
                      "faiss_rank": 2,
                      "doc_id": "local_distributed_systems_fundamentals.txt",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "Distributed systems also intersect with security concerns.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\distributed_systems_fundamentals.txt",
                      "primary_category": null,
                      "rerank_score": 0.526348888874054,
                      "rerank_rank": 10,
                      "probs": {
                        "contradict": 0.0072384984232485294,
                        "neutral": 0.9825186729431152,
                        "support": 0.010242801159620285
                      },
                      "stance_score": 0.0030043027363717556,
                      "evidence_contribution": 0.0015813114071305534,
                      "combined_rank_score": 1.4354066252708435
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Large language models are powerful but can produce incorrect or misleading outputs.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Large language models are powerful",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 7.616252655345128,
            "contradict": 0.9706514910640749,
            "total": 8.586904146409204
          },
          "evidence": {
            "supporting": [
              {
                "id": 6121,
                "faiss_score": 0.9278501868247986,
                "faiss_rank": 1,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 81,
                "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 9.14767837524414,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.007072408217936754,
                  "neutral": 0.2285161018371582,
                  "support": 0.764411449432373
                },
                "stance_score": 0.7573390412144363,
                "evidence_contribution": 6.92789397004543,
                "combined_rank_score": 10.07552856206894
              },
              {
                "id": 6043,
                "faiss_score": 0.9241077899932861,
                "faiss_rank": 3,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 3,
                "sentence": "The defining feature of large language models is scale.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 5.496891975402832,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.005367050878703594,
                  "neutral": 0.8640390634536743,
                  "support": 0.130593940615654
                },
                "stance_score": 0.1252268897369504,
                "evidence_contribution": 0.6883586852996979,
                "combined_rank_score": 6.420999765396118
              }
            ],
            "contradicting": [
              {
                "id": 2020,
                "faiss_score": 0.9012563228607178,
                "faiss_rank": 10,
                "doc_id": "wiki_Large_language_model",
                "file_type": ".txt",
                "position": 288,
                "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                "primary_category": "natural language processing",
                "rerank_score": 6.476112365722656,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.2466990351676941,
                  "neutral": 0.6564837694168091,
                  "support": 0.09681721776723862
                },
                "stance_score": -0.14988181740045547,
                "evidence_contribution": -0.9706514910640749,
                "combined_rank_score": 7.377368688583374
              }
            ],
            "neutral": [
              {
                "id": 6040,
                "faiss_score": 0.925839900970459,
                "faiss_rank": 2,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 6.383889675140381,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0008157117408700287,
                  "neutral": 0.9963352680206299,
                  "support": 0.002849036827683449
                },
                "stance_score": 0.00203332508681342,
                "evidence_contribution": 0.012980523027912111,
                "combined_rank_score": 7.30972957611084
              },
              {
                "id": 6079,
                "faiss_score": 0.8906152248382568,
                "faiss_rank": 14,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 39,
                "sentence": "Large language models are often described as general-purpose systems because they can be adapted to many tasks with minimal fine-tuning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 6.289165019989014,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.0016379584558308125,
                  "neutral": 0.9570803046226501,
                  "support": 0.04128176346421242
                },
                "stance_score": 0.039643805008381605,
                "evidence_contribution": 0.24932643171797886,
                "combined_rank_score": 7.1797802448272705
              },
              {
                "id": 6047,
                "faiss_score": 0.9033905267715454,
                "faiss_rank": 9,
                "doc_id": "local_ml_llms.txt",
                "file_type": ".txt",
                "position": 7,
                "sentence": "Despite these capabilities, the behavior of large language models remains fundamentally probabilistic.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                "primary_category": null,
                "rerank_score": 5.861764430999756,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.013952930457890034,
                  "neutral": 0.9331933259963989,
                  "support": 0.052853744477033615
                },
                "stance_score": 0.03890081401914358,
                "evidence_contribution": 0.2280274079543525,
                "combined_rank_score": 6.765154957771301
              }
            ]
          }
        },
        {
          "subclaim": "can produce incorrect or misleading outputs",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 3.027372747354259,
            "contradict": 0.0,
            "total": 3.027372747354259
          },
          "evidence": {
            "supporting": [
              {
                "id": 6606,
                "faiss_score": 0.863052248954773,
                "faiss_rank": 1,
                "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "Components may crash completely, producing no output, or they may continue running while producing incorrect results.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                "primary_category": null,
                "rerank_score": 3.4065425395965576,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.0009414730593562126,
                  "neutral": 0.20099835097789764,
                  "support": 0.7980602383613586
                },
                "stance_score": 0.7971187653020024,
                "evidence_contribution": 2.715418983111956,
                "combined_rank_score": 4.269594788551331
              },
              {
                "id": 3535,
                "faiss_score": 0.8539549112319946,
                "faiss_rank": 4,
                "doc_id": "wiki_Fault_tolerance",
                "file_type": ".txt",
                "position": 106,
                "sentence": "In this case, the voting circuit can output the correct result, and discard the erroneous version.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 1.0036264657974243,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.11982972174882889,
                  "neutral": 0.4495139420032501,
                  "support": 0.4306562840938568
                },
                "stance_score": 0.3108265623450279,
                "evidence_contribution": 0.31195376424230314,
                "combined_rank_score": 1.857581377029419
              },
              {
                "id": 892,
                "faiss_score": 0.8531967401504517,
                "faiss_rank": 5,
                "doc_id": "wiki_Error_correction",
                "file_type": ".txt",
                "position": 65,
                "sentence": "of errors in the output.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Error_detection_and_correction",
                "primary_category": "all articles needing additional references",
                "rerank_score": -0.670259952545166,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0012530958047136664,
                  "neutral": 0.3292033076286316,
                  "support": 0.6695435643196106
                },
                "stance_score": 0.6682904685148969,
                "evidence_contribution": 0.0,
                "combined_rank_score": 0.18293678760528564
              },
              {
                "id": 2227,
                "faiss_score": 0.8592409491539001,
                "faiss_rank": 2,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 158,
                "sentence": "The outputs are actually numbers, so when the error is low, the difference between the output (almost certainly a cat) and the correct answer (cat) is small.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "rerank_score": -0.9176287651062012,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.007495637983083725,
                  "neutral": 0.5303006172180176,
                  "support": 0.4622037410736084
                },
                "stance_score": 0.4547081030905247,
                "evidence_contribution": 0.0,
                "combined_rank_score": -0.058387815952301025
              },
              {
                "id": 2969,
                "faiss_score": 0.8526178598403931,
                "faiss_rank": 6,
                "doc_id": "wiki_Transformer_(machine_learning_model)",
                "file_type": ".txt",
                "position": 24,
                "sentence": "If the input is long, then the output vector would not be able to contain all relevant information, degrading the output.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning)",
                "primary_category": "artificial intelligence",
                "rerank_score": -6.412653923034668,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.002237267093732953,
                  "neutral": 0.8547115921974182,
                  "support": 0.1430511325597763
                },
                "stance_score": 0.14081386546604335,
                "evidence_contribution": 0.0,
                "combined_rank_score": -5.560036063194275
              },
              {
                "id": 6428,
                "faiss_score": 0.843582034111023,
                "faiss_rank": 13,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 167,
                "sentence": "Small changes in phrasing, ordering, or context can lead to significant differences in output.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": -6.489630699157715,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.0022780755534768105,
                  "neutral": 0.7048073410987854,
                  "support": 0.29291456937789917
                },
                "stance_score": 0.29063649382442236,
                "evidence_contribution": 0.0,
                "combined_rank_score": -5.646048665046692
              },
              {
                "id": 6360,
                "faiss_score": 0.8480008840560913,
                "faiss_rank": 9,
                "doc_id": "local_ml_transformers.txt",
                "file_type": ".txt",
                "position": 99,
                "sentence": "However, approximations can introduce errors or biases that affect model behavior in subtle ways.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_transformers.txt",
                "primary_category": null,
                "rerank_score": -7.292495250701904,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.0016916384920477867,
                  "neutral": 0.5194053053855896,
                  "support": 0.4789030849933624
                },
                "stance_score": 0.47721144650131464,
                "evidence_contribution": 0.0,
                "combined_rank_score": -6.444494366645813
              },
              {
                "id": 1219,
                "faiss_score": 0.8399705290794373,
                "faiss_rank": 16,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 244,
                "sentence": "Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "rerank_score": -7.369985580444336,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.0005253414856269956,
                  "neutral": 0.025972124189138412,
                  "support": 0.973502516746521
                },
                "stance_score": 0.972977175260894,
                "evidence_contribution": 0.0,
                "combined_rank_score": -6.530015051364899
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 1310,
                "faiss_score": 0.8482428789138794,
                "faiss_rank": 8,
                "doc_id": "wiki_Statistical_learning_theory",
                "file_type": ".txt",
                "position": 20,
                "sentence": "It takes the value 0 if the predicted output is the same as the actual output, and it takes the value 1 if the predicted output is different from the actual output.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                "primary_category": "machine learning",
                "rerank_score": -6.68577766418457,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.004643861670047045,
                  "neutral": 0.9214097261428833,
                  "support": 0.07394646108150482
                },
                "stance_score": 0.06930259941145778,
                "evidence_contribution": 0.0,
                "combined_rank_score": -5.837534785270691
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Large language models are powerful",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6121,
                      "faiss_score": 0.9278501868247986,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 81,
                      "sentence": "Ultimately, large language models represent a powerful but imperfect approach to language processing.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 9.14767837524414,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.007072408217936754,
                        "neutral": 0.2285161018371582,
                        "support": 0.764411449432373
                      },
                      "stance_score": 0.7573390412144363,
                      "evidence_contribution": 6.92789397004543,
                      "combined_rank_score": 10.07552856206894
                    },
                    {
                      "id": 6043,
                      "faiss_score": 0.9241077899932861,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 3,
                      "sentence": "The defining feature of large language models is scale.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 5.496891975402832,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.005367050878703594,
                        "neutral": 0.8640390634536743,
                        "support": 0.130593940615654
                      },
                      "stance_score": 0.1252268897369504,
                      "evidence_contribution": 0.6883586852996979,
                      "combined_rank_score": 6.420999765396118
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 2020,
                      "faiss_score": 0.9012563228607178,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Large_language_model",
                      "file_type": ".txt",
                      "position": 288,
                      "sentence": "Despite sophisticated architectures and massive scale, large language models exhibit persistent and well-documented limitations that constrain their deployment in high-stakes applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Large_language_model",
                      "primary_category": "natural language processing",
                      "rerank_score": 6.476112365722656,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.2466990351676941,
                        "neutral": 0.6564837694168091,
                        "support": 0.09681721776723862
                      },
                      "stance_score": -0.14988181740045547,
                      "evidence_contribution": -0.9706514910640749,
                      "combined_rank_score": 7.377368688583374
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6040,
                      "faiss_score": 0.925839900970459,
                      "faiss_rank": 2,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Large language models are neural systems designed to process and generate human language by learning statistical patterns from large text corpora.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 6.383889675140381,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0008157117408700287,
                        "neutral": 0.9963352680206299,
                        "support": 0.002849036827683449
                      },
                      "stance_score": 0.00203332508681342,
                      "evidence_contribution": 0.012980523027912111,
                      "combined_rank_score": 7.30972957611084
                    },
                    {
                      "id": 6079,
                      "faiss_score": 0.8906152248382568,
                      "faiss_rank": 14,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 39,
                      "sentence": "Large language models are often described as general-purpose systems because they can be adapted to many tasks with minimal fine-tuning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 6.289165019989014,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.0016379584558308125,
                        "neutral": 0.9570803046226501,
                        "support": 0.04128176346421242
                      },
                      "stance_score": 0.039643805008381605,
                      "evidence_contribution": 0.24932643171797886,
                      "combined_rank_score": 7.1797802448272705
                    },
                    {
                      "id": 6047,
                      "faiss_score": 0.9033905267715454,
                      "faiss_rank": 9,
                      "doc_id": "local_ml_llms.txt",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "Despite these capabilities, the behavior of large language models remains fundamentally probabilistic.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_llms.txt",
                      "primary_category": null,
                      "rerank_score": 5.861764430999756,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.013952930457890034,
                        "neutral": 0.9331933259963989,
                        "support": 0.052853744477033615
                      },
                      "stance_score": 0.03890081401914358,
                      "evidence_contribution": 0.2280274079543525,
                      "combined_rank_score": 6.765154957771301
                    }
                  ]
                }
              },
              {
                "subclaim": "can produce incorrect or misleading outputs",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6606,
                      "faiss_score": 0.863052248954773,
                      "faiss_rank": 1,
                      "doc_id": "local_systems_fault_tolerance_and_reliability.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "Components may crash completely, producing no output, or they may continue running while producing incorrect results.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\systems_fault_tolerance_and_reliability.txt",
                      "primary_category": null,
                      "rerank_score": 3.4065425395965576,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.0009414730593562126,
                        "neutral": 0.20099835097789764,
                        "support": 0.7980602383613586
                      },
                      "stance_score": 0.7971187653020024,
                      "evidence_contribution": 2.715418983111956,
                      "combined_rank_score": 4.269594788551331
                    },
                    {
                      "id": 3535,
                      "faiss_score": 0.8539549112319946,
                      "faiss_rank": 4,
                      "doc_id": "wiki_Fault_tolerance",
                      "file_type": ".txt",
                      "position": 106,
                      "sentence": "In this case, the voting circuit can output the correct result, and discard the erroneous version.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Fault_tolerance",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 1.0036264657974243,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.11982972174882889,
                        "neutral": 0.4495139420032501,
                        "support": 0.4306562840938568
                      },
                      "stance_score": 0.3108265623450279,
                      "evidence_contribution": 0.31195376424230314,
                      "combined_rank_score": 1.857581377029419
                    },
                    {
                      "id": 892,
                      "faiss_score": 0.8531967401504517,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Error_correction",
                      "file_type": ".txt",
                      "position": 65,
                      "sentence": "of errors in the output.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Error_detection_and_correction",
                      "primary_category": "all articles needing additional references",
                      "rerank_score": -0.670259952545166,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0012530958047136664,
                        "neutral": 0.3292033076286316,
                        "support": 0.6695435643196106
                      },
                      "stance_score": 0.6682904685148969,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": 0.18293678760528564
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 1310,
                      "faiss_score": 0.8482428789138794,
                      "faiss_rank": 8,
                      "doc_id": "wiki_Statistical_learning_theory",
                      "file_type": ".txt",
                      "position": 20,
                      "sentence": "It takes the value 0 if the predicted output is the same as the actual output, and it takes the value 1 if the predicted output is different from the actual output.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Statistical_learning_theory",
                      "primary_category": "machine learning",
                      "rerank_score": -6.68577766418457,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.004643861670047045,
                        "neutral": 0.9214097261428833,
                        "support": 0.07394646108150482
                      },
                      "stance_score": 0.06930259941145778,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -5.837534785270691
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Quantum error correction enables scaling but adds significant overhead.",
      "expected_verdict": "MIXED",
      "predicted_verdict": "SUPPORT",
      "subclaims": [
        {
          "subclaim": "Quantum error correction enables scaling",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 10.564751768059006,
            "contradict": 0.0,
            "total": 10.564751768059006
          },
          "evidence": {
            "supporting": [
              {
                "id": 6553,
                "faiss_score": 0.9426121711730957,
                "faiss_rank": 3,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "rerank_score": 6.97873592376709,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.009470941498875618,
                  "neutral": 0.13609865307807922,
                  "support": 0.8544303774833679
                },
                "stance_score": 0.8449594359844923,
                "evidence_contribution": 5.896748770030955,
                "combined_rank_score": 7.9213480949401855
              },
              {
                "id": 4795,
                "faiss_score": 0.9083656072616577,
                "faiss_rank": 9,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "rerank_score": 4.952396392822266,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.020467771217226982,
                  "neutral": 0.22572223842144012,
                  "support": 0.7538099884986877
                },
                "stance_score": 0.7333422172814608,
                "evidence_contribution": 3.6318013515689884,
                "combined_rank_score": 5.860762000083923
              },
              {
                "id": 4719,
                "faiss_score": 0.9455520510673523,
                "faiss_rank": 1,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 6.933759689331055,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.1649482250213623,
                  "neutral": 0.5206605792045593,
                  "support": 0.31439119577407837
                },
                "stance_score": 0.14944297075271606,
                "evidence_contribution": 1.0362016464590624,
                "combined_rank_score": 7.879311740398407
              }
            ],
            "contradicting": [],
            "neutral": [
              {
                "id": 4862,
                "faiss_score": 0.9224804043769836,
                "faiss_rank": 6,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 109,
                "sentence": "Quantum error correction can be applied to quantum metrology.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "rerank_score": 1.7925801277160645,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.0023149496410042048,
                  "neutral": 0.9899492263793945,
                  "support": 0.007735862862318754
                },
                "stance_score": 0.0054209132213145494,
                "evidence_contribution": 0.009717421314601737,
                "combined_rank_score": 2.715060532093048
              },
              {
                "id": 756,
                "faiss_score": 0.9023146629333496,
                "faiss_rank": 11,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 160,
                "sentence": "As described by the threshold theorem, if the error rate is small enough, it is thought to be possible to use quantum error correction to suppress errors and decoherence.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 1.5890746116638184,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.002483957214280963,
                  "neutral": 0.988044798374176,
                  "support": 0.009471235796809196
                },
                "stance_score": 0.0069872785825282335,
                "evidence_contribution": 0.011103307000117968,
                "combined_rank_score": 2.491389274597168
              },
              {
                "id": 4824,
                "faiss_score": 0.9028662443161011,
                "faiss_rank": 10,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 71,
                "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "rerank_score": 1.4517815113067627,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.001554966322146356,
                  "neutral": 0.9931433200836182,
                  "support": 0.0053017293103039265
                },
                "stance_score": 0.0037467629881575704,
                "evidence_contribution": 0.00543948123345564,
                "combined_rank_score": 2.3546477556228638
              }
            ]
          }
        },
        {
          "subclaim": "Quantum error correction adds significant overhead",
          "verdict": "SUPPORT",
          "controversial": false,
          "strengths": {
            "support": 8.773727150002745,
            "contradict": 0.0,
            "total": 8.773727150002745
          },
          "evidence": {
            "supporting": [
              {
                "id": 764,
                "faiss_score": 0.9263245463371277,
                "faiss_rank": 6,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 168,
                "sentence": "However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 5.299180507659912,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.001764934859238565,
                  "neutral": 0.11494402587413788,
                  "support": 0.8832909464836121
                },
                "stance_score": 0.8815260116243735,
                "evidence_contribution": 4.671365457795065,
                "combined_rank_score": 6.22550505399704
              },
              {
                "id": 4719,
                "faiss_score": 0.9596387147903442,
                "faiss_rank": 1,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 197,
                "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 4.731478214263916,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.001737573416903615,
                  "neutral": 0.12948888540267944,
                  "support": 0.8687735199928284
                },
                "stance_score": 0.8670359465759248,
                "evidence_contribution": 4.102361692207681,
                "combined_rank_score": 5.69111692905426
              },
              {
                "id": 6553,
                "faiss_score": 0.9569774270057678,
                "faiss_rank": 3,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "rerank_score": -0.2708771228790283,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.0009398495312780142,
                  "neutral": 0.05072243511676788,
                  "support": 0.9483376741409302
                },
                "stance_score": 0.9473978246096522,
                "evidence_contribution": 0.0,
                "combined_rank_score": 0.6861003041267395
              }
            ],
            "contradicting": [
              {
                "id": 4795,
                "faiss_score": 0.89435875415802,
                "faiss_rank": 11,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 42,
                "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "rerank_score": -0.4065723419189453,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.14968205988407135,
                  "neutral": 0.841672420501709,
                  "support": 0.008645503781735897
                },
                "stance_score": -0.14103655610233545,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.4877864122390747
              },
              {
                "id": 4824,
                "faiss_score": 0.8923410177230835,
                "faiss_rank": 14,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 71,
                "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "rerank_score": -0.7281641960144043,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.20826101303100586,
                  "neutral": 0.7879799008369446,
                  "support": 0.003759042825549841
                },
                "stance_score": -0.20450197020545602,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.1641768217086792
              }
            ],
            "neutral": [
              {
                "id": 4862,
                "faiss_score": 0.894229531288147,
                "faiss_rank": 12,
                "doc_id": "wiki_Quantum_error_correction",
                "file_type": ".txt",
                "position": 109,
                "sentence": "Quantum error correction can be applied to quantum metrology.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                "primary_category": "articles with short description",
                "rerank_score": -0.7784135341644287,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.00450995983555913,
                  "neutral": 0.9947214126586914,
                  "support": 0.0007686226163059473
                },
                "stance_score": -0.0037413372192531824,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.11581599712371826
              },
              {
                "id": 6555,
                "faiss_score": 0.9089707136154175,
                "faiss_rank": 9,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 15,
                "sentence": "This overhead means that a useful, fault-tolerant quantum computer would need orders of magnitude more qubits than are currently available.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "rerank_score": -0.9043731689453125,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.008294355124235153,
                  "neutral": 0.9852702617645264,
                  "support": 0.006435340270400047
                },
                "stance_score": -0.001859014853835106,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.0045975446701049805
              },
              {
                "id": 6554,
                "faiss_score": 0.915757417678833,
                "faiss_rank": 8,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 14,
                "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "rerank_score": -0.9889041781425476,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.0015190973645076156,
                  "neutral": 0.9730349183082581,
                  "support": 0.025445954874157906
                },
                "stance_score": 0.02392685750965029,
                "evidence_contribution": 0.0,
                "combined_rank_score": -0.0731467604637146
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is generally supported by the available evidence, with some limitations.",
        "sections": [
          {
            "type": "SUPPORTED_ASPECTS",
            "items": [
              {
                "subclaim": "Quantum error correction enables scaling",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 6553,
                      "faiss_score": 0.9426121711730957,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "rerank_score": 6.97873592376709,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.009470941498875618,
                        "neutral": 0.13609865307807922,
                        "support": 0.8544303774833679
                      },
                      "stance_score": 0.8449594359844923,
                      "evidence_contribution": 5.896748770030955,
                      "combined_rank_score": 7.9213480949401855
                    },
                    {
                      "id": 4719,
                      "faiss_score": 0.9455520510673523,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 6.933759689331055,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.1649482250213623,
                        "neutral": 0.5206605792045593,
                        "support": 0.31439119577407837
                      },
                      "stance_score": 0.14944297075271606,
                      "evidence_contribution": 1.0362016464590624,
                      "combined_rank_score": 7.879311740398407
                    },
                    {
                      "id": 4795,
                      "faiss_score": 0.9083656072616577,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "rerank_score": 4.952396392822266,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.020467771217226982,
                        "neutral": 0.22572223842144012,
                        "support": 0.7538099884986877
                      },
                      "stance_score": 0.7333422172814608,
                      "evidence_contribution": 3.6318013515689884,
                      "combined_rank_score": 5.860762000083923
                    }
                  ],
                  "contradicting": [],
                  "neutral": [
                    {
                      "id": 4862,
                      "faiss_score": 0.9224804043769836,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 109,
                      "sentence": "Quantum error correction can be applied to quantum metrology.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "rerank_score": 1.7925801277160645,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.0023149496410042048,
                        "neutral": 0.9899492263793945,
                        "support": 0.007735862862318754
                      },
                      "stance_score": 0.0054209132213145494,
                      "evidence_contribution": 0.009717421314601737,
                      "combined_rank_score": 2.715060532093048
                    },
                    {
                      "id": 756,
                      "faiss_score": 0.9023146629333496,
                      "faiss_rank": 11,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 160,
                      "sentence": "As described by the threshold theorem, if the error rate is small enough, it is thought to be possible to use quantum error correction to suppress errors and decoherence.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 1.5890746116638184,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.002483957214280963,
                        "neutral": 0.988044798374176,
                        "support": 0.009471235796809196
                      },
                      "stance_score": 0.0069872785825282335,
                      "evidence_contribution": 0.011103307000117968,
                      "combined_rank_score": 2.491389274597168
                    },
                    {
                      "id": 4824,
                      "faiss_score": 0.9028662443161011,
                      "faiss_rank": 10,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 71,
                      "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "rerank_score": 1.4517815113067627,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.001554966322146356,
                        "neutral": 0.9931433200836182,
                        "support": 0.0053017293103039265
                      },
                      "stance_score": 0.0037467629881575704,
                      "evidence_contribution": 0.00543948123345564,
                      "combined_rank_score": 2.3546477556228638
                    }
                  ]
                }
              },
              {
                "subclaim": "Quantum error correction adds significant overhead",
                "verdict": "SUPPORT",
                "controversial": false,
                "strength_summary": {
                  "support": "strong",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 764,
                      "faiss_score": 0.9263245463371277,
                      "faiss_rank": 6,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 168,
                      "sentence": "However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 5.299180507659912,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.001764934859238565,
                        "neutral": 0.11494402587413788,
                        "support": 0.8832909464836121
                      },
                      "stance_score": 0.8815260116243735,
                      "evidence_contribution": 4.671365457795065,
                      "combined_rank_score": 6.22550505399704
                    },
                    {
                      "id": 4719,
                      "faiss_score": 0.9596387147903442,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 197,
                      "sentence": "If quantum error correction is used to scale quantum computers to practical applications, its overhead may undermine the speedup offered by many quantum algorithms.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 4.731478214263916,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.001737573416903615,
                        "neutral": 0.12948888540267944,
                        "support": 0.8687735199928284
                      },
                      "stance_score": 0.8670359465759248,
                      "evidence_contribution": 4.102361692207681,
                      "combined_rank_score": 5.69111692905426
                    },
                    {
                      "id": 6553,
                      "faiss_score": 0.9569774270057678,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Error correction is essential for scaling quantum computers, but it comes at a substantial cost.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "rerank_score": -0.2708771228790283,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.0009398495312780142,
                        "neutral": 0.05072243511676788,
                        "support": 0.9483376741409302
                      },
                      "stance_score": 0.9473978246096522,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": 0.6861003041267395
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 4795,
                      "faiss_score": 0.89435875415802,
                      "faiss_rank": 11,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 42,
                      "sentence": "Surface codes are pivotal for scalable quantum error correction in 2025, enabling below-threshold logical qubits with improved fidelity in superconducting systems.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "rerank_score": -0.4065723419189453,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.14968205988407135,
                        "neutral": 0.841672420501709,
                        "support": 0.008645503781735897
                      },
                      "stance_score": -0.14103655610233545,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.4877864122390747
                    },
                    {
                      "id": 4824,
                      "faiss_score": 0.8923410177230835,
                      "faiss_rank": 14,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 71,
                      "sentence": "In April 2024, researchers at Microsoft claimed to have successfully tested a quantum error correction code that allowed them to achieve an error rate with logical qubits that is 800 times better than the underlying physical error rate.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "rerank_score": -0.7281641960144043,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.20826101303100586,
                        "neutral": 0.7879799008369446,
                        "support": 0.003759042825549841
                      },
                      "stance_score": -0.20450197020545602,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.1641768217086792
                    }
                  ],
                  "neutral": [
                    {
                      "id": 4862,
                      "faiss_score": 0.894229531288147,
                      "faiss_rank": 12,
                      "doc_id": "wiki_Quantum_error_correction",
                      "file_type": ".txt",
                      "position": 109,
                      "sentence": "Quantum error correction can be applied to quantum metrology.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_error_correction",
                      "primary_category": "articles with short description",
                      "rerank_score": -0.7784135341644287,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.00450995983555913,
                        "neutral": 0.9947214126586914,
                        "support": 0.0007686226163059473
                      },
                      "stance_score": -0.0037413372192531824,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.11581599712371826
                    },
                    {
                      "id": 6555,
                      "faiss_score": 0.9089707136154175,
                      "faiss_rank": 9,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 15,
                      "sentence": "This overhead means that a useful, fault-tolerant quantum computer would need orders of magnitude more qubits than are currently available.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "rerank_score": -0.9043731689453125,
                      "rerank_rank": 9,
                      "probs": {
                        "contradict": 0.008294355124235153,
                        "neutral": 0.9852702617645264,
                        "support": 0.006435340270400047
                      },
                      "stance_score": -0.001859014853835106,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.0045975446701049805
                    },
                    {
                      "id": 6554,
                      "faiss_score": 0.915757417678833,
                      "faiss_rank": 8,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 14,
                      "sentence": "Quantum error correction schemes require many physical qubits to represent a single logical qubit.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "rerank_score": -0.9889041781425476,
                      "rerank_rank": 10,
                      "probs": {
                        "contradict": 0.0015190973645076156,
                        "neutral": 0.9730349183082581,
                        "support": 0.025445954874157906
                      },
                      "stance_score": 0.02392685750965029,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": -0.0731467604637146
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Future architectures will eliminate the need for large datasets in machine learning.",
      "expected_verdict": "INCONCLUSIVE",
      "predicted_verdict": "INCONCLUSIVE",
      "subclaims": [
        {
          "subclaim": "Future architectures will eliminate the need for large datasets in machine learning.",
          "verdict": "INCONCLUSIVE",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 0.0,
            "total": 0.0
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6124,
                "faiss_score": 0.8617883920669556,
                "faiss_rank": 16,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -1.6935912370681763,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.10562246292829514,
                  "neutral": 0.893295168876648,
                  "support": 0.0010824142955243587
                },
                "stance_score": -0.10454004863277078,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.8318028450012207
              },
              {
                "id": 5905,
                "faiss_score": 0.9030225276947021,
                "faiss_rank": 1,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": -2.905686140060425,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.11705312877893448,
                  "neutral": 0.8816056251525879,
                  "support": 0.0013412677217274904
                },
                "stance_score": -0.11571186105720699,
                "evidence_contribution": -0.0,
                "combined_rank_score": -2.0026636123657227
              },
              {
                "id": 6125,
                "faiss_score": 0.8606041669845581,
                "faiss_rank": 18,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 1,
                "sentence": "Over the past decade, scaling has emerged as one of the most reliable drivers of progress in machine learning systems, particularly in deep learning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -4.260554313659668,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.22337916493415833,
                  "neutral": 0.7750259637832642,
                  "support": 0.0015949285589158535
                },
                "stance_score": -0.22178423637524247,
                "evidence_contribution": -0.0,
                "combined_rank_score": -3.39995014667511
              },
              {
                "id": 6165,
                "faiss_score": 0.8752605319023132,
                "faiss_rank": 4,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 41,
                "sentence": "From a systems perspective, scaling reshapes the entire machine learning pipeline.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -5.4250335693359375,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.1764662116765976,
                  "neutral": 0.8213576674461365,
                  "support": 0.002176115522161126
                },
                "stance_score": -0.17429009615443647,
                "evidence_contribution": -0.0,
                "combined_rank_score": -4.549773037433624
              }
            ],
            "neutral": [
              {
                "id": 2944,
                "faiss_score": 0.8668415546417236,
                "faiss_rank": 9,
                "doc_id": "wiki_Self-supervised_learning",
                "file_type": ".txt",
                "position": 53,
                "sentence": "Its ability to leverage unlabeled data effectively opens new possibilities for advancement in machine learning, especially in data-driven application domains.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Self-supervised_learning",
                "primary_category": "machine learning",
                "rerank_score": -2.1371984481811523,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.02333276905119419,
                  "neutral": 0.9753410816192627,
                  "support": 0.0013262011343613267
                },
                "stance_score": -0.022006567916832864,
                "evidence_contribution": -0.0,
                "combined_rank_score": -1.2703568935394287
              },
              {
                "id": 349,
                "faiss_score": 0.8643662333488464,
                "faiss_rank": 13,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 240,
                "sentence": "Typically, machine learning models require a high quantity of reliable data to perform accurate predictions.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "rerank_score": -2.83878231048584,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.01353005226701498,
                  "neutral": 0.9858565330505371,
                  "support": 0.0006134053110145032
                },
                "stance_score": -0.012916646956000477,
                "evidence_contribution": -0.0,
                "combined_rank_score": -1.9744160771369934
              },
              {
                "id": 6126,
                "faiss_score": 0.872998833656311,
                "faiss_rank": 5,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 2,
                "sentence": "Rather than relying on narrowly optimized architectures or handcrafted features, many modern systems achieve strong performance by training large models on vast amounts of data using substantial compute.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -3.1559386253356934,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.0634174570441246,
                  "neutral": 0.935447633266449,
                  "support": 0.0011348612606525421
                },
                "stance_score": -0.06228259578347206,
                "evidence_contribution": -0.0,
                "combined_rank_score": -2.2829397916793823
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "There is not enough strong evidence to reach a clear conclusion.",
        "sections": [
          {
            "type": "EVIDENCE_LIMITATIONS",
            "items": [
              {
                "subclaim": "Future architectures will eliminate the need for large datasets in machine learning.",
                "verdict": "INCONCLUSIVE",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6124,
                      "faiss_score": 0.8617883920669556,
                      "faiss_rank": 16,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Scaling in machine learning refers to the practice of increasing model size, dataset size, or computational resources in order to improve performance.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -1.6935912370681763,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.10562246292829514,
                        "neutral": 0.893295168876648,
                        "support": 0.0010824142955243587
                      },
                      "stance_score": -0.10454004863277078,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -0.8318028450012207
                    },
                    {
                      "id": 5905,
                      "faiss_score": 0.9030225276947021,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_efficiency_and_compression.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "As machine learning models have grown larger and more capable, efficiency has become a central concern.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                      "primary_category": null,
                      "rerank_score": -2.905686140060425,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.11705312877893448,
                        "neutral": 0.8816056251525879,
                        "support": 0.0013412677217274904
                      },
                      "stance_score": -0.11571186105720699,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -2.0026636123657227
                    },
                    {
                      "id": 6125,
                      "faiss_score": 0.8606041669845581,
                      "faiss_rank": 18,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 1,
                      "sentence": "Over the past decade, scaling has emerged as one of the most reliable drivers of progress in machine learning systems, particularly in deep learning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -4.260554313659668,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.22337916493415833,
                        "neutral": 0.7750259637832642,
                        "support": 0.0015949285589158535
                      },
                      "stance_score": -0.22178423637524247,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -3.39995014667511
                    }
                  ],
                  "neutral": [
                    {
                      "id": 2944,
                      "faiss_score": 0.8668415546417236,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Self-supervised_learning",
                      "file_type": ".txt",
                      "position": 53,
                      "sentence": "Its ability to leverage unlabeled data effectively opens new possibilities for advancement in machine learning, especially in data-driven application domains.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Self-supervised_learning",
                      "primary_category": "machine learning",
                      "rerank_score": -2.1371984481811523,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.02333276905119419,
                        "neutral": 0.9753410816192627,
                        "support": 0.0013262011343613267
                      },
                      "stance_score": -0.022006567916832864,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -1.2703568935394287
                    },
                    {
                      "id": 349,
                      "faiss_score": 0.8643662333488464,
                      "faiss_rank": 13,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 240,
                      "sentence": "Typically, machine learning models require a high quantity of reliable data to perform accurate predictions.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "rerank_score": -2.83878231048584,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.01353005226701498,
                        "neutral": 0.9858565330505371,
                        "support": 0.0006134053110145032
                      },
                      "stance_score": -0.012916646956000477,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -1.9744160771369934
                    },
                    {
                      "id": 6126,
                      "faiss_score": 0.872998833656311,
                      "faiss_rank": 5,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 2,
                      "sentence": "Rather than relying on narrowly optimized architectures or handcrafted features, many modern systems achieve strong performance by training large models on vast amounts of data using substantial compute.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -3.1559386253356934,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.0634174570441246,
                        "neutral": 0.935447633266449,
                        "support": 0.0011348612606525421
                      },
                      "stance_score": -0.06228259578347206,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -2.2829397916793823
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "A single algorithm can optimally solve all machine learning problems.",
      "expected_verdict": "INCONCLUSIVE",
      "predicted_verdict": "INCONCLUSIVE",
      "subclaims": [
        {
          "subclaim": "A single algorithm can optimally solve all machine learning problems.",
          "verdict": "INCONCLUSIVE",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 0.0,
            "total": 0.0
          },
          "evidence": {
            "supporting": [
              {
                "id": 267,
                "faiss_score": 0.8847181797027588,
                "faiss_rank": 9,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 158,
                "sentence": "This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "rerank_score": -0.3544308841228485,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.04583118110895157,
                  "neutral": 0.5406124591827393,
                  "support": 0.41355639696121216
                },
                "stance_score": 0.3677252158522606,
                "evidence_contribution": 0.0,
                "combined_rank_score": 0.5302872955799103
              }
            ],
            "contradicting": [
              {
                "id": 1558,
                "faiss_score": 0.8794730305671692,
                "faiss_rank": 14,
                "doc_id": "wiki_Optimization_(mathematics)",
                "file_type": ".txt",
                "position": 7,
                "sentence": "In machine learning, it is always necessary to continuously evaluate the quality of a data model by using a cost function where a minimum implies a set of possibly optimal parameters with an optimal (lowest) error.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                "primary_category": "all articles with style issues",
                "rerank_score": -0.5462067127227783,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.8922678232192993,
                  "neutral": 0.10589844733476639,
                  "support": 0.0018336758948862553
                },
                "stance_score": -0.8904341473244131,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.33326631784439087
              },
              {
                "id": 5840,
                "faiss_score": 0.8876022100448608,
                "faiss_rank": 4,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "Gradient-based methods are the most widely used optimization techniques in machine learning.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "rerank_score": -0.7626746296882629,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.8216201663017273,
                  "neutral": 0.17583926022052765,
                  "support": 0.0025405713822692633
                },
                "stance_score": -0.819079594919458,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.1249275803565979
              },
              {
                "id": 338,
                "faiss_score": 0.8796346187591553,
                "faiss_rank": 12,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 229,
                "sentence": "In machine learning, genetic algorithms were used in the 1980s and 1990s.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "rerank_score": -1.477332592010498,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.12754929065704346,
                  "neutral": 0.8693177700042725,
                  "support": 0.0031329584307968616
                },
                "stance_score": -0.1244163322262466,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.5976979732513428
              },
              {
                "id": 2303,
                "faiss_score": 0.8766059875488281,
                "faiss_rank": 17,
                "doc_id": "wiki_Artificial_neural_network",
                "file_type": ".txt",
                "position": 234,
                "sentence": "Learning algorithm: Numerous trade-offs exist between learning algorithms.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Neural_network_(machine_learning)",
                "primary_category": "neural networks",
                "rerank_score": -2.7333645820617676,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.9910756349563599,
                  "neutral": 0.008461421355605125,
                  "support": 0.00046292017214000225
                },
                "stance_score": -0.9906127147842199,
                "evidence_contribution": -0.0,
                "combined_rank_score": -1.8567585945129395
              }
            ],
            "neutral": [
              {
                "id": 331,
                "faiss_score": 0.8863186836242676,
                "faiss_rank": 5,
                "doc_id": "wiki_Machine_learning",
                "file_type": ".txt",
                "position": 222,
                "sentence": "Efficient algorithms exist that perform inference and learning.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                "primary_category": "machine learning",
                "rerank_score": -0.2585304081439972,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.029771577566862106,
                  "neutral": 0.967642605304718,
                  "support": 0.0025857884902507067
                },
                "stance_score": -0.0271857890766114,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.6277882754802704
              },
              {
                "id": 5831,
                "faiss_score": 0.8993061780929565,
                "faiss_rank": 1,
                "doc_id": "local_math_optimization_and_convergence.txt",
                "file_type": ".txt",
                "position": 0,
                "sentence": "Optimization lies at the core of modern machine learning and computational systems.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                "primary_category": null,
                "rerank_score": -1.4539523124694824,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.07188953459262848,
                  "neutral": 0.9265451431274414,
                  "support": 0.001565277692861855
                },
                "stance_score": -0.07032425689976662,
                "evidence_contribution": -0.0,
                "combined_rank_score": -0.5546461343765259
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "There is not enough strong evidence to reach a clear conclusion.",
        "sections": [
          {
            "type": "EVIDENCE_LIMITATIONS",
            "items": [
              {
                "subclaim": "A single algorithm can optimally solve all machine learning problems.",
                "verdict": "INCONCLUSIVE",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "none"
                },
                "evidence": {
                  "supporting": [
                    {
                      "id": 267,
                      "faiss_score": 0.8847181797027588,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 158,
                      "sentence": "This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "rerank_score": -0.3544308841228485,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.04583118110895157,
                        "neutral": 0.5406124591827393,
                        "support": 0.41355639696121216
                      },
                      "stance_score": 0.3677252158522606,
                      "evidence_contribution": 0.0,
                      "combined_rank_score": 0.5302872955799103
                    }
                  ],
                  "contradicting": [
                    {
                      "id": 1558,
                      "faiss_score": 0.8794730305671692,
                      "faiss_rank": 14,
                      "doc_id": "wiki_Optimization_(mathematics)",
                      "file_type": ".txt",
                      "position": 7,
                      "sentence": "In machine learning, it is always necessary to continuously evaluate the quality of a data model by using a cost function where a minimum implies a set of possibly optimal parameters with an optimal (lowest) error.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
                      "primary_category": "all articles with style issues",
                      "rerank_score": -0.5462067127227783,
                      "rerank_rank": 5,
                      "probs": {
                        "contradict": 0.8922678232192993,
                        "neutral": 0.10589844733476639,
                        "support": 0.0018336758948862553
                      },
                      "stance_score": -0.8904341473244131,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.33326631784439087
                    },
                    {
                      "id": 5840,
                      "faiss_score": 0.8876022100448608,
                      "faiss_rank": 4,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 9,
                      "sentence": "Gradient-based methods are the most widely used optimization techniques in machine learning.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "rerank_score": -0.7626746296882629,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.8216201663017273,
                        "neutral": 0.17583926022052765,
                        "support": 0.0025405713822692633
                      },
                      "stance_score": -0.819079594919458,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.1249275803565979
                    },
                    {
                      "id": 338,
                      "faiss_score": 0.8796346187591553,
                      "faiss_rank": 12,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 229,
                      "sentence": "In machine learning, genetic algorithms were used in the 1980s and 1990s.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "rerank_score": -1.477332592010498,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.12754929065704346,
                        "neutral": 0.8693177700042725,
                        "support": 0.0031329584307968616
                      },
                      "stance_score": -0.1244163322262466,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -0.5976979732513428
                    }
                  ],
                  "neutral": [
                    {
                      "id": 331,
                      "faiss_score": 0.8863186836242676,
                      "faiss_rank": 5,
                      "doc_id": "wiki_Machine_learning",
                      "file_type": ".txt",
                      "position": 222,
                      "sentence": "Efficient algorithms exist that perform inference and learning.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Machine_learning",
                      "primary_category": "machine learning",
                      "rerank_score": -0.2585304081439972,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.029771577566862106,
                        "neutral": 0.967642605304718,
                        "support": 0.0025857884902507067
                      },
                      "stance_score": -0.0271857890766114,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.6277882754802704
                    },
                    {
                      "id": 5831,
                      "faiss_score": 0.8993061780929565,
                      "faiss_rank": 1,
                      "doc_id": "local_math_optimization_and_convergence.txt",
                      "file_type": ".txt",
                      "position": 0,
                      "sentence": "Optimization lies at the core of modern machine learning and computational systems.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_optimization_and_convergence.txt",
                      "primary_category": null,
                      "rerank_score": -1.4539523124694824,
                      "rerank_rank": 7,
                      "probs": {
                        "contradict": 0.07188953459262848,
                        "neutral": 0.9265451431274414,
                        "support": 0.001565277692861855
                      },
                      "stance_score": -0.07032425689976662,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -0.5546461343765259
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Quantum computers will replace classical computers for most workloads.",
      "expected_verdict": "INCONCLUSIVE",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Quantum computers will replace classical computers for most workloads.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 16.151414573391225,
            "total": 16.151414573391225
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6574,
                "faiss_score": 0.9328113794326782,
                "faiss_rank": 3,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 34,
                "sentence": "Rather than replacing classical systems, quantum computers are expected to act as accelerators for specific subroutines.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "rerank_score": 5.315627098083496,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.9586077928543091,
                  "neutral": 0.03871520608663559,
                  "support": 0.002676980337128043
                },
                "stance_score": -0.955930812517181,
                "evidence_contribution": -5.081371730909302,
                "combined_rank_score": 6.248438477516174
              },
              {
                "id": 736,
                "faiss_score": 0.9381494522094727,
                "faiss_rank": 1,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 140,
                "sentence": "As of 2023, classical computers outperform quantum computers for all real-world applications.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 4.903462886810303,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.9913483262062073,
                  "neutral": 0.006687983404844999,
                  "support": 0.0019637111108750105
                },
                "stance_score": -0.9893846150953323,
                "evidence_contribution": -4.851410740901058,
                "combined_rank_score": 5.841612339019775
              },
              {
                "id": 6594,
                "faiss_score": 0.9081912636756897,
                "faiss_rank": 11,
                "doc_id": "local_physics_quantum_overview.txt",
                "file_type": ".txt",
                "position": 54,
                "sentence": "Ultimately, quantum computing represents a long-term research effort rather than a near-term replacement for classical computation.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                "primary_category": null,
                "rerank_score": 3.555327892303467,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.990568220615387,
                  "neutral": 0.007592997048050165,
                  "support": 0.001838862313888967
                },
                "stance_score": -0.988729358301498,
                "evidence_contribution": -3.515257065508624,
                "combined_rank_score": 4.4635191559791565
              },
              {
                "id": 820,
                "faiss_score": 0.9049538373947144,
                "faiss_rank": 15,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 224,
                "sentence": "In other words, quantum computers provide no additional power over classical computers in terms of computability.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 3.0737595558166504,
                "rerank_rank": 5,
                "probs": {
                  "contradict": 0.5743324160575867,
                  "neutral": 0.4228309094905853,
                  "support": 0.002836654195562005
                },
                "stance_score": -0.5714957618620247,
                "evidence_contribution": -1.7566405591321153,
                "combined_rank_score": 3.9787133932113647
              },
              {
                "id": 822,
                "faiss_score": 0.902823269367218,
                "faiss_rank": 19,
                "doc_id": "wiki_Quantum_computing",
                "file_type": ".txt",
                "position": 226,
                "sentence": "While quantum computers cannot solve any problems that classical computers cannot already solve, it is suspected that they can solve certain problems faster than classical computers.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                "primary_category": "all wikipedia articles written in american english",
                "rerank_score": 2.7105321884155273,
                "rerank_rank": 7,
                "probs": {
                  "contradict": 0.35174041986465454,
                  "neutral": 0.6457991003990173,
                  "support": 0.002460495801642537
                },
                "stance_score": -0.349279924063012,
                "evidence_contribution": -0.9467344769401251,
                "combined_rank_score": 3.6133554577827454
              }
            ],
            "neutral": [
              {
                "id": 4932,
                "faiss_score": 0.9101486206054688,
                "faiss_rank": 9,
                "doc_id": "wiki_Computational_complexity",
                "file_type": ".txt",
                "position": 62,
                "sentence": "However, some problems may theoretically be solved with a much lower time complexity using a quantum computer rather than a classical computer.",
                "source_type": "wikipedia",
                "credibility": 0.6,
                "source_url": "https://en.wikipedia.org/wiki/Computational_complexity",
                "primary_category": "all articles containing potentially dated statements",
                "rerank_score": 2.1743216514587402,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.09721063077449799,
                  "neutral": 0.9004706144332886,
                  "support": 0.0023187061306089163
                },
                "stance_score": -0.09489192464388907,
                "evidence_contribution": -0.2063255663017992,
                "combined_rank_score": 3.084470272064209
              },
              {
                "id": 6518,
                "faiss_score": 0.9088791608810425,
                "faiss_rank": 10,
                "doc_id": "local_physics_computation.txt",
                "file_type": ".txt",
                "position": 47,
                "sentence": "Quantum computing represents a fundamentally different approach, exploiting quantum mechanical phenomena to perform certain computations more efficiently than classical machines.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                "primary_category": null,
                "rerank_score": 1.8257582187652588,
                "rerank_rank": 10,
                "probs": {
                  "contradict": 0.002322460524737835,
                  "neutral": 0.9969102740287781,
                  "support": 0.0007673114887438715
                },
                "stance_score": -0.0015551490359939635,
                "evidence_contribution": -0.002839326133870848,
                "combined_rank_score": 2.7346373796463013
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Quantum computers will replace classical computers for most workloads.",
                "verdict": "CONTRADICT",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6574,
                      "faiss_score": 0.9328113794326782,
                      "faiss_rank": 3,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 34,
                      "sentence": "Rather than replacing classical systems, quantum computers are expected to act as accelerators for specific subroutines.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "rerank_score": 5.315627098083496,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.9586077928543091,
                        "neutral": 0.03871520608663559,
                        "support": 0.002676980337128043
                      },
                      "stance_score": -0.955930812517181,
                      "evidence_contribution": -5.081371730909302,
                      "combined_rank_score": 6.248438477516174
                    },
                    {
                      "id": 736,
                      "faiss_score": 0.9381494522094727,
                      "faiss_rank": 1,
                      "doc_id": "wiki_Quantum_computing",
                      "file_type": ".txt",
                      "position": 140,
                      "sentence": "As of 2023, classical computers outperform quantum computers for all real-world applications.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Quantum_computing",
                      "primary_category": "all wikipedia articles written in american english",
                      "rerank_score": 4.903462886810303,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.9913483262062073,
                        "neutral": 0.006687983404844999,
                        "support": 0.0019637111108750105
                      },
                      "stance_score": -0.9893846150953323,
                      "evidence_contribution": -4.851410740901058,
                      "combined_rank_score": 5.841612339019775
                    },
                    {
                      "id": 6594,
                      "faiss_score": 0.9081912636756897,
                      "faiss_rank": 11,
                      "doc_id": "local_physics_quantum_overview.txt",
                      "file_type": ".txt",
                      "position": 54,
                      "sentence": "Ultimately, quantum computing represents a long-term research effort rather than a near-term replacement for classical computation.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_quantum_overview.txt",
                      "primary_category": null,
                      "rerank_score": 3.555327892303467,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.990568220615387,
                        "neutral": 0.007592997048050165,
                        "support": 0.001838862313888967
                      },
                      "stance_score": -0.988729358301498,
                      "evidence_contribution": -3.515257065508624,
                      "combined_rank_score": 4.4635191559791565
                    }
                  ],
                  "neutral": [
                    {
                      "id": 4932,
                      "faiss_score": 0.9101486206054688,
                      "faiss_rank": 9,
                      "doc_id": "wiki_Computational_complexity",
                      "file_type": ".txt",
                      "position": 62,
                      "sentence": "However, some problems may theoretically be solved with a much lower time complexity using a quantum computer rather than a classical computer.",
                      "source_type": "wikipedia",
                      "credibility": 0.6,
                      "source_url": "https://en.wikipedia.org/wiki/Computational_complexity",
                      "primary_category": "all articles containing potentially dated statements",
                      "rerank_score": 2.1743216514587402,
                      "rerank_rank": 9,
                      "probs": {
                        "contradict": 0.09721063077449799,
                        "neutral": 0.9004706144332886,
                        "support": 0.0023187061306089163
                      },
                      "stance_score": -0.09489192464388907,
                      "evidence_contribution": -0.2063255663017992,
                      "combined_rank_score": 3.084470272064209
                    },
                    {
                      "id": 6518,
                      "faiss_score": 0.9088791608810425,
                      "faiss_rank": 10,
                      "doc_id": "local_physics_computation.txt",
                      "file_type": ".txt",
                      "position": 47,
                      "sentence": "Quantum computing represents a fundamentally different approach, exploiting quantum mechanical phenomena to perform certain computations more efficiently than classical machines.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\physics_computation.txt",
                      "primary_category": null,
                      "rerank_score": 1.8257582187652588,
                      "rerank_rank": 10,
                      "probs": {
                        "contradict": 0.002322460524737835,
                        "neutral": 0.9969102740287781,
                        "support": 0.0007673114887438715
                      },
                      "stance_score": -0.0015551490359939635,
                      "evidence_contribution": -0.002839326133870848,
                      "combined_rank_score": 2.7346373796463013
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    },
    {
      "claim": "Increasing data quality is more important than model size for all tasks.",
      "expected_verdict": "INCONCLUSIVE",
      "predicted_verdict": "CONTRADICT",
      "subclaims": [
        {
          "subclaim": "Increasing data quality is more important than model size for all tasks.",
          "verdict": "CONTRADICT",
          "controversial": false,
          "strengths": {
            "support": 0.0,
            "contradict": 4.907310577250371,
            "total": 4.907310577250371
          },
          "evidence": {
            "supporting": [],
            "contradicting": [
              {
                "id": 6137,
                "faiss_score": 0.9282467365264893,
                "faiss_rank": 1,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 13,
                "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 6.42487907409668,
                "rerank_rank": 1,
                "probs": {
                  "contradict": 0.7659299969673157,
                  "neutral": 0.23193812370300293,
                  "support": 0.0021318739745765924
                },
                "stance_score": -0.7637981229927391,
                "evidence_contribution": -4.907310577250371,
                "combined_rank_score": 7.353125810623169
              },
              {
                "id": 6132,
                "faiss_score": 0.8877804279327393,
                "faiss_rank": 14,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 8,
                "sentence": "Larger models have greater representational capacity, allowing them to fit more complex functions.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -3.486907720565796,
                "rerank_rank": 6,
                "probs": {
                  "contradict": 0.31466788053512573,
                  "neutral": 0.6821066737174988,
                  "support": 0.0032254562247544527
                },
                "stance_score": -0.3114424243103713,
                "evidence_contribution": -0.0,
                "combined_rank_score": -2.5991272926330566
              },
              {
                "id": 6135,
                "faiss_score": 0.912760317325592,
                "faiss_rank": 3,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 11,
                "sentence": "Data scaling plays an equally important role.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -4.107235908508301,
                "rerank_rank": 8,
                "probs": {
                  "contradict": 0.5072497725486755,
                  "neutral": 0.4902275800704956,
                  "support": 0.0025226445868611336
                },
                "stance_score": -0.5047271279618144,
                "evidence_contribution": -0.0,
                "combined_rank_score": -3.1944755911827087
              },
              {
                "id": 5914,
                "faiss_score": 0.8886445760726929,
                "faiss_rank": 11,
                "doc_id": "local_ml_efficiency_and_compression.txt",
                "file_type": ".txt",
                "position": 9,
                "sentence": "By identifying and removing such parameters, models can be made smaller and faster.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_efficiency_and_compression.txt",
                "primary_category": null,
                "rerank_score": -4.602010726928711,
                "rerank_rank": 9,
                "probs": {
                  "contradict": 0.10239699482917786,
                  "neutral": 0.8955297470092773,
                  "support": 0.002073230454698205
                },
                "stance_score": -0.10032376437447965,
                "evidence_contribution": -0.0,
                "combined_rank_score": -3.713366150856018
              }
            ],
            "neutral": [
              {
                "id": 6147,
                "faiss_score": 0.8930780291557312,
                "faiss_rank": 7,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 23,
                "sentence": "For example, increasing model size without increasing data may yield limited benefits, while increasing data without sufficient model capacity may fail to exploit the additional information.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": 4.379410743713379,
                "rerank_rank": 2,
                "probs": {
                  "contradict": 0.028468823060393333,
                  "neutral": 0.9641625881195068,
                  "support": 0.007368524093180895
                },
                "stance_score": -0.02110029896721244,
                "evidence_contribution": -0.09240687599257447,
                "combined_rank_score": 5.27248877286911
              },
              {
                "id": 5767,
                "faiss_score": 0.9157058596611023,
                "faiss_rank": 2,
                "doc_id": "local_math_information_theory_and_learning.txt",
                "file_type": ".txt",
                "position": 15,
                "sentence": "This observation emphasizes the importance of data quality and task definition.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                "primary_category": null,
                "rerank_score": -0.11810709536075592,
                "rerank_rank": 3,
                "probs": {
                  "contradict": 0.0025519374758005142,
                  "neutral": 0.9963298439979553,
                  "support": 0.00111820874735713
                },
                "stance_score": -0.0014337287284433842,
                "evidence_contribution": -0.0,
                "combined_rank_score": 0.7975987643003464
              },
              {
                "id": 6136,
                "faiss_score": 0.8884807825088501,
                "faiss_rank": 13,
                "doc_id": "local_ml_scaling_and_efficiency.txt",
                "file_type": ".txt",
                "position": 12,
                "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                "source_type": "local",
                "credibility": 0.9,
                "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                "primary_category": null,
                "rerank_score": -3.0387094020843506,
                "rerank_rank": 4,
                "probs": {
                  "contradict": 0.012909447774291039,
                  "neutral": 0.9826837182044983,
                  "support": 0.004406800959259272
                },
                "stance_score": -0.008502646815031767,
                "evidence_contribution": -0.0,
                "combined_rank_score": -2.1502286195755005
              }
            ]
          }
        }
      ],
      "explanation": {
        "summary": "The claim is contradicted by strong evidence.",
        "sections": [
          {
            "type": "CONTRADICTED_ASPECTS",
            "items": [
              {
                "subclaim": "Increasing data quality is more important than model size for all tasks.",
                "verdict": "CONTRADICT",
                "controversial": false,
                "strength_summary": {
                  "support": "none",
                  "contradict": "strong"
                },
                "evidence": {
                  "supporting": [],
                  "contradicting": [
                    {
                      "id": 6137,
                      "faiss_score": 0.9282467365264893,
                      "faiss_rank": 1,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 13,
                      "sentence": "Empirical evidence suggests that for many tasks, performance improves more reliably when both model size and dataset size are increased together.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 6.42487907409668,
                      "rerank_rank": 1,
                      "probs": {
                        "contradict": 0.7659299969673157,
                        "neutral": 0.23193812370300293,
                        "support": 0.0021318739745765924
                      },
                      "stance_score": -0.7637981229927391,
                      "evidence_contribution": -4.907310577250371,
                      "combined_rank_score": 7.353125810623169
                    },
                    {
                      "id": 6132,
                      "faiss_score": 0.8877804279327393,
                      "faiss_rank": 14,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 8,
                      "sentence": "Larger models have greater representational capacity, allowing them to fit more complex functions.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -3.486907720565796,
                      "rerank_rank": 6,
                      "probs": {
                        "contradict": 0.31466788053512573,
                        "neutral": 0.6821066737174988,
                        "support": 0.0032254562247544527
                      },
                      "stance_score": -0.3114424243103713,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -2.5991272926330566
                    },
                    {
                      "id": 6135,
                      "faiss_score": 0.912760317325592,
                      "faiss_rank": 3,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 11,
                      "sentence": "Data scaling plays an equally important role.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -4.107235908508301,
                      "rerank_rank": 8,
                      "probs": {
                        "contradict": 0.5072497725486755,
                        "neutral": 0.4902275800704956,
                        "support": 0.0025226445868611336
                      },
                      "stance_score": -0.5047271279618144,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -3.1944755911827087
                    }
                  ],
                  "neutral": [
                    {
                      "id": 6147,
                      "faiss_score": 0.8930780291557312,
                      "faiss_rank": 7,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 23,
                      "sentence": "For example, increasing model size without increasing data may yield limited benefits, while increasing data without sufficient model capacity may fail to exploit the additional information.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": 4.379410743713379,
                      "rerank_rank": 2,
                      "probs": {
                        "contradict": 0.028468823060393333,
                        "neutral": 0.9641625881195068,
                        "support": 0.007368524093180895
                      },
                      "stance_score": -0.02110029896721244,
                      "evidence_contribution": -0.09240687599257447,
                      "combined_rank_score": 5.27248877286911
                    },
                    {
                      "id": 5767,
                      "faiss_score": 0.9157058596611023,
                      "faiss_rank": 2,
                      "doc_id": "local_math_information_theory_and_learning.txt",
                      "file_type": ".txt",
                      "position": 15,
                      "sentence": "This observation emphasizes the importance of data quality and task definition.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\math_information_theory_and_learning.txt",
                      "primary_category": null,
                      "rerank_score": -0.11810709536075592,
                      "rerank_rank": 3,
                      "probs": {
                        "contradict": 0.0025519374758005142,
                        "neutral": 0.9963298439979553,
                        "support": 0.00111820874735713
                      },
                      "stance_score": -0.0014337287284433842,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": 0.7975987643003464
                    },
                    {
                      "id": 6136,
                      "faiss_score": 0.8884807825088501,
                      "faiss_rank": 13,
                      "doc_id": "local_ml_scaling_and_efficiency.txt",
                      "file_type": ".txt",
                      "position": 12,
                      "sentence": "Training large models on insufficient or low-quality data can lead to overfitting or wasted capacity.",
                      "source_type": "local",
                      "credibility": 0.9,
                      "source_url": "C:\\Users\\Harshal Raj\\Fact-Anchor\\ml-service\\data\\local_curated\\ml_scaling_and_efficiency.txt",
                      "primary_category": null,
                      "rerank_score": -3.0387094020843506,
                      "rerank_rank": 4,
                      "probs": {
                        "contradict": 0.012909447774291039,
                        "neutral": 0.9826837182044983,
                        "support": 0.004406800959259272
                      },
                      "stance_score": -0.008502646815031767,
                      "evidence_contribution": -0.0,
                      "combined_rank_score": -2.1502286195755005
                    }
                  ]
                }
              }
            ]
          }
        ]
      }
    }
  ],
  "metrics": {
    "final_accuracy": 0.6,
    "confusion_matrix": {
      "SUPPORT": {
        "SUPPORT": 5,
        "CONTRADICT": 1,
        "MIXED": 0,
        "INCONCLUSIVE": 0
      },
      "CONTRADICT": {
        "SUPPORT": 1,
        "CONTRADICT": 5,
        "MIXED": 0,
        "INCONCLUSIVE": 0
      },
      "MIXED": {
        "SUPPORT": 3,
        "CONTRADICT": 1,
        "MIXED": 0,
        "INCONCLUSIVE": 0
      },
      "INCONCLUSIVE": {
        "SUPPORT": 0,
        "CONTRADICT": 2,
        "MIXED": 0,
        "INCONCLUSIVE": 2
      }
    },
    "precision_recall_f1": {
      "per_class": {
        "SUPPORT": {
          "precision": 0.5555555555555556,
          "recall": 0.8333333333333334,
          "f1": 0.6666666666666667
        },
        "CONTRADICT": {
          "precision": 0.5555555555555556,
          "recall": 0.8333333333333334,
          "f1": 0.6666666666666667
        },
        "MIXED": {
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0.0
        },
        "INCONCLUSIVE": {
          "precision": 1.0,
          "recall": 0.5,
          "f1": 0.6666666666666666
        }
      },
      "macro_f1": 0.5
    },
    "subclaim_accuracy": null,
    "decomposition_stats": {
      "avg_subclaims_per_claim": 1.55,
      "min_subclaims": 1,
      "max_subclaims": 3
    }
  }
}